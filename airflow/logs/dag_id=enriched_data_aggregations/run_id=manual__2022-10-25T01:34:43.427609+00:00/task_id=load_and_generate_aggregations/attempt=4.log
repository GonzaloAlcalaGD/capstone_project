[2022-10-25T01:56:45.300+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: enriched_data_aggregations.load_and_generate_aggregations manual__2022-10-25T01:34:43.427609+00:00 [success]>
[2022-10-25T01:56:45.355+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: enriched_data_aggregations.load_and_generate_aggregations manual__2022-10-25T01:34:43.427609+00:00 [success]>
[2022-10-25T01:56:45.359+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-10-25T01:56:45.364+0000] {taskinstance.py:1363} INFO - Starting attempt 4 of 2
[2022-10-25T01:56:45.368+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-10-25T01:56:45.415+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): load_and_generate_aggregations> on 2022-10-25 01:34:43.427609+00:00
[2022-10-25T01:56:45.440+0000] {standard_task_runner.py:54} INFO - Started process 13332 to run task
[2022-10-25T01:56:45.468+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'enriched_data_aggregations', 'load_and_generate_aggregations', 'manual__2022-10-25T01:34:43.427609+00:00', '--job-id', '590', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/data_agg.py', '--cfg-path', '/tmp/tmp9hyzp5xk']
[2022-10-25T01:56:45.472+0000] {standard_task_runner.py:83} INFO - Job 590: Subtask load_and_generate_aggregations
[2022-10-25T01:56:45.480+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/data_agg.py
[2022-10-25T01:56:45.904+0000] {task_command.py:384} INFO - Running <TaskInstance: enriched_data_aggregations.load_and_generate_aggregations manual__2022-10-25T01:34:43.427609+00:00 [running]> on host 0c46e38e1c8e
[2022-10-25T01:56:46.312+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=enriched_data_aggregations
AIRFLOW_CTX_TASK_ID=load_and_generate_aggregations
AIRFLOW_CTX_EXECUTION_DATE=2022-10-25T01:34:43.427609+00:00
AIRFLOW_CTX_TRY_NUMBER=4
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-10-25T01:34:43.427609+00:00
[2022-10-25T01:57:28.443+0000] {pyspark_scripts.py:280} INFO - Working in  - Count and sum amount transactions for each type for day, online & offline - 
[2022-10-25T01:57:40.142+0000] {logging_mixin.py:117} INFO - +----+----------+------------------+------------------+
|type| timestamp|total_transactions|             total|
+----+----------+------------------+------------------+
|   1|2022-10-18|                72| 550923.8766937256|
|   1|2022-10-16|                52| 770093.0860799551|
|   1|2022-10-17|                86| 1133092.203715682|
|   1|2022-10-14|                 7| 11244.01019513607|
|   1|2022-10-19|                36|266427.68115758896|
|   1|2022-10-15|                43|396290.55984020233|
|   0|2022-10-15|                27|200340.61073350906|
|   0|2022-10-19|                38| 514774.3481952846|
|   0|2022-10-14|                 2|43246.169843673706|
|   0|2022-10-18|                62| 669039.1448940039|
|   0|2022-10-17|                64|  577018.139827162|
|   0|2022-10-16|                45|371993.34034085274|
+----+----------+------------------+------------------+
[2022-10-25T01:57:40.145+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/pyspark_scripts.py", line 283, in load_and_aggregate
    store_metrics = temporal_df.groupBy(temporal_df.store_id, temporal_df.timestamp).agg(f.count(temporal_df.timestamp).alias('count'), f.sum(temporal_df.amount).alias('total'))
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/dataframe.py", line 1989, in __getattr__
    "'%s' object has no attribute '%s'" % (self.__class__.__name__, name)
AttributeError: 'DataFrame' object has no attribute 'store_id'
[2022-10-25T01:57:40.229+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=enriched_data_aggregations, task_id=load_and_generate_aggregations, execution_date=20221025T013443, start_date=20221025T015645, end_date=20221025T015740
[2022-10-25T01:57:40.304+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 590 for task load_and_generate_aggregations ('DataFrame' object has no attribute 'store_id'; 13332)
[2022-10-25T01:57:40.439+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-10-25T01:57:40.594+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
