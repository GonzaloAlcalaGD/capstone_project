[2022-10-25T15:54:05.480+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: load_and_normalize_data_headers.load_and_normalize_rdbms_data manual__2022-10-25T15:49:29.430645+00:00 [queued]>
[2022-10-25T15:54:05.511+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: load_and_normalize_data_headers.load_and_normalize_rdbms_data manual__2022-10-25T15:49:29.430645+00:00 [queued]>
[2022-10-25T15:54:05.513+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-10-25T15:54:05.514+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 2
[2022-10-25T15:54:05.515+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-10-25T15:54:05.545+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): load_and_normalize_rdbms_data> on 2022-10-25 15:49:29.430645+00:00
[2022-10-25T15:54:05.562+0000] {standard_task_runner.py:54} INFO - Started process 4835 to run task
[2022-10-25T15:54:05.575+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'load_and_normalize_data_headers', 'load_and_normalize_rdbms_data', 'manual__2022-10-25T15:49:29.430645+00:00', '--job-id', '600', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_jobs.py', '--cfg-path', '/tmp/tmpd6jj1zel']
[2022-10-25T15:54:05.580+0000] {standard_task_runner.py:83} INFO - Job 600: Subtask load_and_normalize_rdbms_data
[2022-10-25T15:54:05.595+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/pyspark_jobs.py
[2022-10-25T15:54:05.771+0000] {task_command.py:384} INFO - Running <TaskInstance: load_and_normalize_data_headers.load_and_normalize_rdbms_data manual__2022-10-25T15:49:29.430645+00:00 [running]> on host faf467258cbc
[2022-10-25T15:54:05.981+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=load_and_normalize_data_headers
AIRFLOW_CTX_TASK_ID=load_and_normalize_rdbms_data
AIRFLOW_CTX_EXECUTION_DATE=2022-10-25T15:49:29.430645+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-10-25T15:49:29.430645+00:00
[2022-10-25T15:54:31.035+0000] {logging_mixin.py:117} INFO - +---+-----------+----------+-------------------+------------------+------------+-----------------+-------------------+
| id|customer_id|    amount|customer_first_name|customer_last_name|phone_number|          address|          timestamp|
+---+-----------+----------+-------------------+------------------+------------+-----------------+-------------------+
|463|        301|    $42.59|               Alan|          Cummings|  8639812356|    Michelleburgh|2022-10-17T04:09:06|
|148|         26|$54,978.36|            Matthew|          Harrison|  2708524121|       Averymouth|2022-10-17T01:13:51|
|580|        545| $5,695.84|               Erin|          Phillips|  7107276687|         Lanefurt|2022-10-16T20:33:10|
|808|        620|   $723.26|              Becky|            Turner|  3969111249|  Lake Jamesville|2022-10-15T18:51:54|
|451|        511|    $71.86|             Amanda|            Hansen|  7365048669|       Averymouth|2022-10-16T03:25:50|
|137|         25| $1,536.82|            William|          Phillips|  6479849693|     Brownchester|2022-10-15T09:45:38|
|458|         42|   $383.01|              Alexa|          Matthews|  7385827905|    Michelleburgh|2022-10-16T10:45:33|
| 65|        437|     $5.59|              Kelly|           Jimenez|  9367664281|      Melissafurt|2022-10-16T09:40:20|
|804|        877| $1,532.64|              Kevin|            Horton|  0311159100|       Robertland|2022-10-15T23:51:13|
|481|        693|   $780.31|            Richard|            Walker|  0842580280|Port Benjaminfurt|2022-10-18T21:56:44|
+---+-----------+----------+-------------------+------------------+------------+-----------------+-------------------+
only showing top 10 rows
[2022-10-25T15:54:32.217+0000] {pyspark_scripts.py:121} INFO - Working with 2 partitions
[2022-10-25T15:54:36.291+0000] {pyspark_scripts.py:10} INFO - Closing spark session...
[2022-10-25T15:54:36.868+0000] {pyspark_scripts.py:13} INFO - Spark session succesfully closed
[2022-10-25T15:54:36.870+0000] {pyspark_scripts.py:125} INFO - Spark session and context status: Closed
[2022-10-25T15:54:36.872+0000] {python.py:177} INFO - Done. Returned value was: None
[2022-10-25T15:54:36.904+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=load_and_normalize_data_headers, task_id=load_and_normalize_rdbms_data, execution_date=20221025T154929, start_date=20221025T155405, end_date=20221025T155436
[2022-10-25T15:54:37.006+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2022-10-25T15:54:37.130+0000] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
