[2022-10-25T17:30:00.000+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: load_and_normalize_data_headers.load_and_normalize_jsonlines manual__2022-10-25T17:29:53.291929+00:00 [queued]>
[2022-10-25T17:30:00.037+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: load_and_normalize_data_headers.load_and_normalize_jsonlines manual__2022-10-25T17:29:53.291929+00:00 [queued]>
[2022-10-25T17:30:00.044+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-10-25T17:30:00.053+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 2
[2022-10-25T17:30:00.058+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-10-25T17:30:00.184+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): load_and_normalize_jsonlines> on 2022-10-25 17:29:53.291929+00:00
[2022-10-25T17:30:00.243+0000] {standard_task_runner.py:54} INFO - Started process 1815 to run task
[2022-10-25T17:30:00.346+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'load_and_normalize_data_headers', 'load_and_normalize_jsonlines', 'manual__2022-10-25T17:29:53.291929+00:00', '--job-id', '616', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_jobs.py', '--cfg-path', '/tmp/tmps5xrblxq']
[2022-10-25T17:30:00.366+0000] {standard_task_runner.py:83} INFO - Job 616: Subtask load_and_normalize_jsonlines
[2022-10-25T17:30:00.374+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/pyspark_jobs.py
[2022-10-25T17:30:02.285+0000] {task_command.py:384} INFO - Running <TaskInstance: load_and_normalize_data_headers.load_and_normalize_jsonlines manual__2022-10-25T17:29:53.291929+00:00 [running]> on host caeffc6e0742
[2022-10-25T17:30:03.342+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=load_and_normalize_data_headers
AIRFLOW_CTX_TASK_ID=load_and_normalize_jsonlines
AIRFLOW_CTX_EXECUTION_DATE=2022-10-25T17:29:53.291929+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-10-25T17:29:53.291929+00:00
[2022-10-25T17:30:22.100+0000] {directories.py:15} INFO - Found the following subdirectories ['2022-10-25']
[2022-10-25T17:30:22.124+0000] {directories.py:24} INFO - Latest folder: 2022-10-25
[2022-10-25T17:31:00.288+0000] {pyspark_scripts.py:40} INFO - Working with 2 partitions
[2022-10-25T17:31:01.715+0000] {logging_mixin.py:117} INFO - +----+-------------------+-------------------+------------------+----------+----+
|  id|          timestamp|customer_first_name|customer_last_name|    amount|type|
+----+-------------------+-------------------+------------------+----------+----+
|4783|2022-10-24T11:57:31|            Jeffrey|           Flowers|   $662.19|   0|
|7077|2022-10-23T02:10:44|             Brandy|           Perkins|$98,169.07|   0|
|9279|2022-10-22T19:47:43|              David|          Franklin|    $62.53|   1|
|6161|2022-10-23T10:24:57|             Steven|          Morrison| $4,237.17|   0|
|6883|2022-10-22T19:30:23|             Steven|             Brown|     $8.56|   0|
|9393|2022-10-24T22:44:19|              David|             Smith|$99,250.50|   0|
|1576|2022-10-25T04:27:41|            Natasha|            Wilson|     $2.20|   0|
|7174|2022-10-24T19:58:44|          Elizabeth|             Brown|$21,985.06|   0|
|3353|2022-10-25T14:27:12|             Morgan|           Sanchez|     $6.90|   1|
|7602|2022-10-25T05:55:55|            William|            Phelps|     $2.06|   0|
+----+-------------------+-------------------+------------------+----------+----+
only showing top 10 rows
[2022-10-25T17:31:06.868+0000] {pyspark_scripts.py:44} INFO - Normalized dataframe saved into .parquet format into /opt/***/dags/storage/jsonlines_temp
[2022-10-25T17:31:06.870+0000] {pyspark_scripts.py:10} INFO - Closing spark session...
[2022-10-25T17:31:07.920+0000] {pyspark_scripts.py:13} INFO - Spark session succesfully closed
[2022-10-25T17:31:07.923+0000] {pyspark_scripts.py:47} INFO - Spark session and context status: Closed
[2022-10-25T17:31:07.932+0000] {pyspark_scripts.py:48} INFO - JSONLines Dataframe succesfully loaded and normalized headers.
[2022-10-25T17:31:07.934+0000] {python.py:177} INFO - Done. Returned value was: None
[2022-10-25T17:31:08.109+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=load_and_normalize_data_headers, task_id=load_and_normalize_jsonlines, execution_date=20221025T172953, start_date=20221025T173000, end_date=20221025T173108
[2022-10-25T17:31:08.698+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2022-10-25T17:31:09.220+0000] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
