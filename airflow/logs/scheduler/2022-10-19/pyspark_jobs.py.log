[2022-10-19 16:52:28,945] {processor.py:153} INFO - Started process (PID=23474) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:28,946] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:52:28,947] {logging_mixin.py:115} INFO - [2022-10-19 16:52:28,947] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:28,970] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:29,104] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,104] {manager.py:508} INFO - Created Permission View: can edit on DAG:pyspark_jobs
[2022-10-19 16:52:29,123] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,123] {manager.py:508} INFO - Created Permission View: can delete on DAG:pyspark_jobs
[2022-10-19 16:52:29,131] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,131] {manager.py:508} INFO - Created Permission View: can read on DAG:pyspark_jobs
[2022-10-19 16:52:29,132] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,132] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:52:29,145] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,145] {dag.py:2439} INFO - Creating ORM DAG for pyspark_jobs
[2022-10-19 16:52:29,160] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,160] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:52:28.968879+00:00, run_after=2022-10-20T16:52:28.968879+00:00
[2022-10-19 16:52:29,177] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.238 seconds
[2022-10-19 16:52:29,557] {processor.py:153} INFO - Started process (PID=33099) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:29,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:52:29,560] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,560] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:29,571] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:29,592] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,592] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:52:29,624] {logging_mixin.py:115} INFO - [2022-10-19 16:52:29,624] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:52:29.570797+00:00, run_after=2022-10-20T16:52:29.570797+00:00
[2022-10-19 16:52:29,640] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 16:52:59,573] {processor.py:153} INFO - Started process (PID=23512) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:59,576] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:52:59,577] {logging_mixin.py:115} INFO - [2022-10-19 16:52:59,577] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:59,588] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:59,673] {logging_mixin.py:115} INFO - [2022-10-19 16:52:59,672] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:52:59,707] {logging_mixin.py:115} INFO - [2022-10-19 16:52:59,707] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:52:59.587352+00:00, run_after=2022-10-20T16:52:59.587352+00:00
[2022-10-19 16:52:59,724] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 16:52:59,776] {processor.py:153} INFO - Started process (PID=33131) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:59,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:52:59,779] {logging_mixin.py:115} INFO - [2022-10-19 16:52:59,779] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:59,790] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:52:59,811] {logging_mixin.py:115} INFO - [2022-10-19 16:52:59,811] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:52:59,842] {logging_mixin.py:115} INFO - [2022-10-19 16:52:59,842] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:52:59.788929+00:00, run_after=2022-10-20T16:52:59.788929+00:00
[2022-10-19 16:52:59,858] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 16:53:30,457] {processor.py:153} INFO - Started process (PID=23549) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:53:30,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:53:30,461] {logging_mixin.py:115} INFO - [2022-10-19 16:53:30,461] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:53:30,472] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:53:30,512] {processor.py:153} INFO - Started process (PID=33161) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:53:30,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:53:30,516] {logging_mixin.py:115} INFO - [2022-10-19 16:53:30,516] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:53:30,537] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:53:30,593] {logging_mixin.py:115} INFO - [2022-10-19 16:53:30,593] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:53:30,638] {logging_mixin.py:115} INFO - [2022-10-19 16:53:30,638] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:53:30.471390+00:00, run_after=2022-10-20T16:53:30.471390+00:00
[2022-10-19 16:53:30,655] {logging_mixin.py:115} INFO - [2022-10-19 16:53:30,655] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:53:30,677] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.225 seconds
[2022-10-19 16:53:30,691] {logging_mixin.py:115} INFO - [2022-10-19 16:53:30,691] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:53:30.536700+00:00, run_after=2022-10-20T16:53:30.536700+00:00
[2022-10-19 16:53:30,715] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.215 seconds
[2022-10-19 16:54:00,953] {processor.py:153} INFO - Started process (PID=33192) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:00,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:54:00,955] {logging_mixin.py:115} INFO - [2022-10-19 16:54:00,955] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:00,969] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:01,061] {logging_mixin.py:115} INFO - [2022-10-19 16:54:01,061] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:54:01,088] {logging_mixin.py:115} INFO - [2022-10-19 16:54:01,088] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:54:00.966379+00:00, run_after=2022-10-20T16:54:00.966379+00:00
[2022-10-19 16:54:01,109] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.162 seconds
[2022-10-19 16:54:01,330] {processor.py:153} INFO - Started process (PID=23580) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:01,331] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:54:01,333] {logging_mixin.py:115} INFO - [2022-10-19 16:54:01,332] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:01,344] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:01,366] {logging_mixin.py:115} INFO - [2022-10-19 16:54:01,366] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:54:01,403] {logging_mixin.py:115} INFO - [2022-10-19 16:54:01,402] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:54:01.343665+00:00, run_after=2022-10-20T16:54:01.343665+00:00
[2022-10-19 16:54:01,423] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.097 seconds
[2022-10-19 16:54:31,353] {processor.py:153} INFO - Started process (PID=33224) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:31,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:54:31,357] {logging_mixin.py:115} INFO - [2022-10-19 16:54:31,356] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:31,367] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:31,450] {logging_mixin.py:115} INFO - [2022-10-19 16:54:31,449] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:54:31,475] {logging_mixin.py:115} INFO - [2022-10-19 16:54:31,475] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:54:31.366335+00:00, run_after=2022-10-20T16:54:31.366335+00:00
[2022-10-19 16:54:31,495] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.146 seconds
[2022-10-19 16:54:32,113] {processor.py:153} INFO - Started process (PID=23617) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:32,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:54:32,116] {logging_mixin.py:115} INFO - [2022-10-19 16:54:32,115] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:32,126] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:54:32,147] {logging_mixin.py:115} INFO - [2022-10-19 16:54:32,147] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:54:32,176] {logging_mixin.py:115} INFO - [2022-10-19 16:54:32,176] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:54:32.125472+00:00, run_after=2022-10-20T16:54:32.125472+00:00
[2022-10-19 16:54:32,194] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 16:55:02,197] {processor.py:153} INFO - Started process (PID=33257) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:02,199] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:55:02,200] {logging_mixin.py:115} INFO - [2022-10-19 16:55:02,200] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:02,211] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:02,291] {logging_mixin.py:115} INFO - [2022-10-19 16:55:02,290] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:55:02,316] {logging_mixin.py:115} INFO - [2022-10-19 16:55:02,316] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:55:02.210031+00:00, run_after=2022-10-20T16:55:02.210031+00:00
[2022-10-19 16:55:02,336] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.144 seconds
[2022-10-19 16:55:02,864] {processor.py:153} INFO - Started process (PID=23646) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:02,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:55:02,866] {logging_mixin.py:115} INFO - [2022-10-19 16:55:02,866] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:02,877] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:02,896] {logging_mixin.py:115} INFO - [2022-10-19 16:55:02,896] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:55:02,925] {logging_mixin.py:115} INFO - [2022-10-19 16:55:02,925] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:55:02.876009+00:00, run_after=2022-10-20T16:55:02.876009+00:00
[2022-10-19 16:55:02,942] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 16:55:33,039] {processor.py:153} INFO - Started process (PID=33289) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:33,041] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:55:33,042] {logging_mixin.py:115} INFO - [2022-10-19 16:55:33,042] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:33,054] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:33,142] {logging_mixin.py:115} INFO - [2022-10-19 16:55:33,142] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:55:33,168] {logging_mixin.py:115} INFO - [2022-10-19 16:55:33,168] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:55:33.053528+00:00, run_after=2022-10-20T16:55:33.053528+00:00
[2022-10-19 16:55:33,188] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.153 seconds
[2022-10-19 16:55:33,497] {processor.py:153} INFO - Started process (PID=23685) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:33,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:55:33,500] {logging_mixin.py:115} INFO - [2022-10-19 16:55:33,500] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:33,511] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:55:33,532] {logging_mixin.py:115} INFO - [2022-10-19 16:55:33,532] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:55:33,564] {logging_mixin.py:115} INFO - [2022-10-19 16:55:33,564] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:55:33.510404+00:00, run_after=2022-10-20T16:55:33.510404+00:00
[2022-10-19 16:55:33,580] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.088 seconds
[2022-10-19 16:56:03,881] {processor.py:153} INFO - Started process (PID=33320) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:03,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:56:03,885] {logging_mixin.py:115} INFO - [2022-10-19 16:56:03,885] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:03,899] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:03,983] {logging_mixin.py:115} INFO - [2022-10-19 16:56:03,983] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:56:04,011] {logging_mixin.py:115} INFO - [2022-10-19 16:56:04,010] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:56:03.898837+00:00, run_after=2022-10-20T16:56:03.898837+00:00
[2022-10-19 16:56:04,030] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.154 seconds
[2022-10-19 16:56:04,148] {processor.py:153} INFO - Started process (PID=23725) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:04,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:56:04,151] {logging_mixin.py:115} INFO - [2022-10-19 16:56:04,151] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:04,162] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:04,184] {logging_mixin.py:115} INFO - [2022-10-19 16:56:04,184] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:56:04,214] {logging_mixin.py:115} INFO - [2022-10-19 16:56:04,214] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:56:04.161781+00:00, run_after=2022-10-20T16:56:04.161781+00:00
[2022-10-19 16:56:04,232] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.088 seconds
[2022-10-19 16:56:34,741] {processor.py:153} INFO - Started process (PID=33353) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:34,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:56:34,745] {logging_mixin.py:115} INFO - [2022-10-19 16:56:34,745] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:34,756] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:34,829] {processor.py:153} INFO - Started process (PID=23756) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:34,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:56:34,831] {logging_mixin.py:115} INFO - [2022-10-19 16:56:34,831] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:34,842] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:56:34,847] {logging_mixin.py:115} INFO - [2022-10-19 16:56:34,847] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:56:34,873] {logging_mixin.py:115} INFO - [2022-10-19 16:56:34,873] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:56:34.755872+00:00, run_after=2022-10-20T16:56:34.755872+00:00
[2022-10-19 16:56:34,890] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.154 seconds
[2022-10-19 16:56:34,930] {logging_mixin.py:115} INFO - [2022-10-19 16:56:34,930] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:56:34,956] {logging_mixin.py:115} INFO - [2022-10-19 16:56:34,956] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:56:34.841426+00:00, run_after=2022-10-20T16:56:34.841426+00:00
[2022-10-19 16:56:34,977] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.153 seconds
[2022-10-19 16:57:05,552] {processor.py:153} INFO - Started process (PID=23794) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:05,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:57:05,555] {logging_mixin.py:115} INFO - [2022-10-19 16:57:05,555] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:05,565] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:05,603] {processor.py:153} INFO - Started process (PID=33392) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:05,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:57:05,605] {logging_mixin.py:115} INFO - [2022-10-19 16:57:05,605] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:05,616] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:05,654] {logging_mixin.py:115} INFO - [2022-10-19 16:57:05,654] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:57:05,681] {logging_mixin.py:115} INFO - [2022-10-19 16:57:05,680] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:57:05.564355+00:00, run_after=2022-10-20T16:57:05.564355+00:00
[2022-10-19 16:57:05,699] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.152 seconds
[2022-10-19 16:57:05,706] {logging_mixin.py:115} INFO - [2022-10-19 16:57:05,706] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:57:05,732] {logging_mixin.py:115} INFO - [2022-10-19 16:57:05,732] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:57:05.615199+00:00, run_after=2022-10-20T16:57:05.615199+00:00
[2022-10-19 16:57:05,751] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.153 seconds
[2022-10-19 16:57:35,911] {processor.py:153} INFO - Started process (PID=33425) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:35,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:57:35,915] {logging_mixin.py:115} INFO - [2022-10-19 16:57:35,915] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:35,942] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:36,056] {logging_mixin.py:115} INFO - [2022-10-19 16:57:36,056] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:57:36,094] {logging_mixin.py:115} INFO - [2022-10-19 16:57:36,094] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:57:35.941262+00:00, run_after=2022-10-20T16:57:35.941262+00:00
[2022-10-19 16:57:36,119] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.216 seconds
[2022-10-19 16:57:36,352] {processor.py:153} INFO - Started process (PID=23834) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:36,353] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:57:36,356] {logging_mixin.py:115} INFO - [2022-10-19 16:57:36,355] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:36,371] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:57:36,402] {logging_mixin.py:115} INFO - [2022-10-19 16:57:36,402] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:57:36,442] {logging_mixin.py:115} INFO - [2022-10-19 16:57:36,441] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:57:36.370408+00:00, run_after=2022-10-20T16:57:36.370408+00:00
[2022-10-19 16:57:36,490] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.144 seconds
[2022-10-19 16:58:06,277] {processor.py:153} INFO - Started process (PID=33458) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:06,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:58:06,281] {logging_mixin.py:115} INFO - [2022-10-19 16:58:06,281] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:06,292] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:06,385] {logging_mixin.py:115} INFO - [2022-10-19 16:58:06,385] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:58:06,414] {logging_mixin.py:115} INFO - [2022-10-19 16:58:06,414] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:58:06.291454+00:00, run_after=2022-10-20T16:58:06.291454+00:00
[2022-10-19 16:58:06,432] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.160 seconds
[2022-10-19 16:58:07,177] {processor.py:153} INFO - Started process (PID=23863) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:07,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:58:07,180] {logging_mixin.py:115} INFO - [2022-10-19 16:58:07,179] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:07,190] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:07,210] {logging_mixin.py:115} INFO - [2022-10-19 16:58:07,210] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:58:07,241] {logging_mixin.py:115} INFO - [2022-10-19 16:58:07,241] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:58:07.189562+00:00, run_after=2022-10-20T16:58:07.189562+00:00
[2022-10-19 16:58:07,259] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 16:58:37,171] {processor.py:153} INFO - Started process (PID=33491) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:37,173] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:58:37,175] {logging_mixin.py:115} INFO - [2022-10-19 16:58:37,175] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:37,189] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:37,289] {logging_mixin.py:115} INFO - [2022-10-19 16:58:37,288] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:58:37,327] {logging_mixin.py:115} INFO - [2022-10-19 16:58:37,327] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:58:37.188562+00:00, run_after=2022-10-20T16:58:37.188562+00:00
[2022-10-19 16:58:37,348] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.184 seconds
[2022-10-19 16:58:37,394] {processor.py:153} INFO - Started process (PID=23901) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:37,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:58:37,397] {logging_mixin.py:115} INFO - [2022-10-19 16:58:37,397] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:37,407] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:58:37,426] {logging_mixin.py:115} INFO - [2022-10-19 16:58:37,426] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:58:37,457] {logging_mixin.py:115} INFO - [2022-10-19 16:58:37,457] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:58:37.406467+00:00, run_after=2022-10-20T16:58:37.406467+00:00
[2022-10-19 16:58:37,473] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 16:59:07,883] {processor.py:153} INFO - Started process (PID=23931) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:07,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:59:07,885] {logging_mixin.py:115} INFO - [2022-10-19 16:59:07,885] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:07,897] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:07,984] {logging_mixin.py:115} INFO - [2022-10-19 16:59:07,983] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:59:08,011] {logging_mixin.py:115} INFO - [2022-10-19 16:59:08,011] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:59:07.896528+00:00, run_after=2022-10-20T16:59:07.896528+00:00
[2022-10-19 16:59:08,034] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 16:59:08,098] {processor.py:153} INFO - Started process (PID=33523) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:08,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:59:08,100] {logging_mixin.py:115} INFO - [2022-10-19 16:59:08,100] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:08,112] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:08,133] {logging_mixin.py:115} INFO - [2022-10-19 16:59:08,133] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:59:08,163] {logging_mixin.py:115} INFO - [2022-10-19 16:59:08,163] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:59:08.110741+00:00, run_after=2022-10-20T16:59:08.110741+00:00
[2022-10-19 16:59:08,181] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.088 seconds
[2022-10-19 16:59:38,305] {processor.py:153} INFO - Started process (PID=33557) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:38,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:59:38,313] {logging_mixin.py:115} INFO - [2022-10-19 16:59:38,312] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:38,329] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:38,432] {logging_mixin.py:115} INFO - [2022-10-19 16:59:38,432] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:59:38,465] {logging_mixin.py:115} INFO - [2022-10-19 16:59:38,465] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:59:38.327447+00:00, run_after=2022-10-20T16:59:38.327447+00:00
[2022-10-19 16:59:38,486] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.190 seconds
[2022-10-19 16:59:38,560] {processor.py:153} INFO - Started process (PID=23969) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:38,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 16:59:38,562] {logging_mixin.py:115} INFO - [2022-10-19 16:59:38,562] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:38,581] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 16:59:38,603] {logging_mixin.py:115} INFO - [2022-10-19 16:59:38,602] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 16:59:38,636] {logging_mixin.py:115} INFO - [2022-10-19 16:59:38,636] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T16:59:38.579918+00:00, run_after=2022-10-20T16:59:38.579918+00:00
[2022-10-19 16:59:38,657] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.102 seconds
[2022-10-19 17:00:08,658] {processor.py:153} INFO - Started process (PID=33589) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:08,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:00:08,663] {logging_mixin.py:115} INFO - [2022-10-19 17:00:08,663] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:08,676] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:08,782] {logging_mixin.py:115} INFO - [2022-10-19 17:00:08,782] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:00:08,813] {logging_mixin.py:115} INFO - [2022-10-19 17:00:08,812] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:00:08.675177+00:00, run_after=2022-10-20T17:00:08.675177+00:00
[2022-10-19 17:00:08,831] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.179 seconds
[2022-10-19 17:00:09,341] {processor.py:153} INFO - Started process (PID=24008) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:09,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:00:09,344] {logging_mixin.py:115} INFO - [2022-10-19 17:00:09,344] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:09,359] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:09,399] {logging_mixin.py:115} INFO - [2022-10-19 17:00:09,398] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:00:09,449] {logging_mixin.py:115} INFO - [2022-10-19 17:00:09,449] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:00:09.357934+00:00, run_after=2022-10-20T17:00:09.357934+00:00
[2022-10-19 17:00:09,493] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.157 seconds
[2022-10-19 17:00:39,411] {processor.py:153} INFO - Started process (PID=33624) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:39,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:00:39,414] {logging_mixin.py:115} INFO - [2022-10-19 17:00:39,414] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:39,426] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:39,511] {logging_mixin.py:115} INFO - [2022-10-19 17:00:39,511] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:00:39,542] {logging_mixin.py:115} INFO - [2022-10-19 17:00:39,542] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:00:39.425278+00:00, run_after=2022-10-20T17:00:39.425278+00:00
[2022-10-19 17:00:39,563] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 17:00:39,759] {processor.py:153} INFO - Started process (PID=24036) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:39,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:00:39,762] {logging_mixin.py:115} INFO - [2022-10-19 17:00:39,761] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:39,773] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:00:39,792] {logging_mixin.py:115} INFO - [2022-10-19 17:00:39,792] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:00:39,823] {logging_mixin.py:115} INFO - [2022-10-19 17:00:39,823] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:00:39.772537+00:00, run_after=2022-10-20T17:00:39.772537+00:00
[2022-10-19 17:00:39,838] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 17:01:10,456] {processor.py:153} INFO - Started process (PID=33656) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:10,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:01:10,459] {logging_mixin.py:115} INFO - [2022-10-19 17:01:10,459] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:10,470] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:10,515] {processor.py:153} INFO - Started process (PID=24074) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:10,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:01:10,518] {logging_mixin.py:115} INFO - [2022-10-19 17:01:10,518] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:10,530] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:10,564] {logging_mixin.py:115} INFO - [2022-10-19 17:01:10,563] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:01:10,593] {logging_mixin.py:115} INFO - [2022-10-19 17:01:10,593] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:01:10.469526+00:00, run_after=2022-10-20T17:01:10.469526+00:00
[2022-10-19 17:01:10,612] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.163 seconds
[2022-10-19 17:01:10,629] {logging_mixin.py:115} INFO - [2022-10-19 17:01:10,629] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:01:10,656] {logging_mixin.py:115} INFO - [2022-10-19 17:01:10,656] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:01:10.529495+00:00, run_after=2022-10-20T17:01:10.529495+00:00
[2022-10-19 17:01:10,675] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.165 seconds
[2022-10-19 17:01:41,349] {processor.py:153} INFO - Started process (PID=33688) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:41,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:01:41,354] {logging_mixin.py:115} INFO - [2022-10-19 17:01:41,353] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:41,367] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:41,391] {processor.py:153} INFO - Started process (PID=24105) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:41,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:01:41,393] {logging_mixin.py:115} INFO - [2022-10-19 17:01:41,393] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:41,405] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:01:41,484] {logging_mixin.py:115} INFO - [2022-10-19 17:01:41,484] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:01:41,528] {logging_mixin.py:115} INFO - [2022-10-19 17:01:41,528] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:01:41.365905+00:00, run_after=2022-10-20T17:01:41.365905+00:00
[2022-10-19 17:01:41,543] {logging_mixin.py:115} INFO - [2022-10-19 17:01:41,543] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:01:41,547] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.203 seconds
[2022-10-19 17:01:41,578] {logging_mixin.py:115} INFO - [2022-10-19 17:01:41,578] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:01:41.404481+00:00, run_after=2022-10-20T17:01:41.404481+00:00
[2022-10-19 17:01:41,595] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.210 seconds
[2022-10-19 17:02:12,279] {processor.py:153} INFO - Started process (PID=24142) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:12,279] {processor.py:153} INFO - Started process (PID=33722) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:12,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:02:12,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:02:12,284] {logging_mixin.py:115} INFO - [2022-10-19 17:02:12,284] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:12,284] {logging_mixin.py:115} INFO - [2022-10-19 17:02:12,284] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:12,295] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:12,297] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:12,381] {logging_mixin.py:115} INFO - [2022-10-19 17:02:12,381] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:02:12,392] {logging_mixin.py:115} INFO - [2022-10-19 17:02:12,392] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:02:12,407] {logging_mixin.py:115} INFO - [2022-10-19 17:02:12,407] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:02:12.295598+00:00, run_after=2022-10-20T17:02:12.295598+00:00
[2022-10-19 17:02:12,426] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.152 seconds
[2022-10-19 17:02:12,444] {logging_mixin.py:115} INFO - [2022-10-19 17:02:12,444] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:02:12.294727+00:00, run_after=2022-10-20T17:02:12.294727+00:00
[2022-10-19 17:02:12,460] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.185 seconds
[2022-10-19 17:02:42,501] {processor.py:153} INFO - Started process (PID=33755) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:42,504] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:02:42,506] {logging_mixin.py:115} INFO - [2022-10-19 17:02:42,506] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:42,589] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:42,681] {logging_mixin.py:115} INFO - [2022-10-19 17:02:42,681] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:02:42,709] {logging_mixin.py:115} INFO - [2022-10-19 17:02:42,709] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:02:42.588491+00:00, run_after=2022-10-20T17:02:42.588491+00:00
[2022-10-19 17:02:42,727] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.230 seconds
[2022-10-19 17:02:42,772] {processor.py:153} INFO - Started process (PID=24181) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:42,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:02:42,774] {logging_mixin.py:115} INFO - [2022-10-19 17:02:42,774] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:42,785] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:02:42,806] {logging_mixin.py:115} INFO - [2022-10-19 17:02:42,806] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:02:42,835] {logging_mixin.py:115} INFO - [2022-10-19 17:02:42,835] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:02:42.784145+00:00, run_after=2022-10-20T17:02:42.784145+00:00
[2022-10-19 17:02:42,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:03:12,940] {processor.py:153} INFO - Started process (PID=33787) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:12,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:03:12,944] {logging_mixin.py:115} INFO - [2022-10-19 17:03:12,944] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:12,957] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:13,043] {logging_mixin.py:115} INFO - [2022-10-19 17:03:13,043] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:03:13,075] {logging_mixin.py:115} INFO - [2022-10-19 17:03:13,075] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:03:12.955967+00:00, run_after=2022-10-20T17:03:12.955967+00:00
[2022-10-19 17:03:13,091] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.155 seconds
[2022-10-19 17:03:13,110] {processor.py:153} INFO - Started process (PID=24210) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:13,111] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:03:13,112] {logging_mixin.py:115} INFO - [2022-10-19 17:03:13,112] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:13,123] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:13,144] {logging_mixin.py:115} INFO - [2022-10-19 17:03:13,144] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:03:13,174] {logging_mixin.py:115} INFO - [2022-10-19 17:03:13,174] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:03:13.122576+00:00, run_after=2022-10-20T17:03:13.122576+00:00
[2022-10-19 17:03:13,190] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:03:43,402] {processor.py:153} INFO - Started process (PID=33820) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:43,404] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:03:43,405] {logging_mixin.py:115} INFO - [2022-10-19 17:03:43,405] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:43,416] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:43,496] {processor.py:153} INFO - Started process (PID=24247) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:43,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:03:43,505] {logging_mixin.py:115} INFO - [2022-10-19 17:03:43,505] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:43,527] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:03:43,553] {logging_mixin.py:115} INFO - [2022-10-19 17:03:43,553] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:03:43,596] {logging_mixin.py:115} INFO - [2022-10-19 17:03:43,596] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:03:43.415619+00:00, run_after=2022-10-20T17:03:43.415619+00:00
[2022-10-19 17:03:43,626] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.227 seconds
[2022-10-19 17:03:43,644] {logging_mixin.py:115} INFO - [2022-10-19 17:03:43,644] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:03:43,672] {logging_mixin.py:115} INFO - [2022-10-19 17:03:43,671] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:03:43.525956+00:00, run_after=2022-10-20T17:03:43.525956+00:00
[2022-10-19 17:03:43,690] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.199 seconds
[2022-10-19 17:04:14,326] {processor.py:153} INFO - Started process (PID=33853) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:14,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:04:14,328] {logging_mixin.py:115} INFO - [2022-10-19 17:04:14,328] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:14,340] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:14,368] {processor.py:153} INFO - Started process (PID=24285) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:14,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:04:14,371] {logging_mixin.py:115} INFO - [2022-10-19 17:04:14,371] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:14,384] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:14,452] {logging_mixin.py:115} INFO - [2022-10-19 17:04:14,452] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:04:14,476] {logging_mixin.py:115} INFO - [2022-10-19 17:04:14,476] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:04:14,482] {logging_mixin.py:115} INFO - [2022-10-19 17:04:14,482] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:04:14.339099+00:00, run_after=2022-10-20T17:04:14.339099+00:00
[2022-10-19 17:04:14,500] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.179 seconds
[2022-10-19 17:04:14,512] {logging_mixin.py:115} INFO - [2022-10-19 17:04:14,512] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:04:14.382896+00:00, run_after=2022-10-20T17:04:14.382896+00:00
[2022-10-19 17:04:14,530] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.167 seconds
[2022-10-19 17:04:44,608] {processor.py:153} INFO - Started process (PID=24314) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:44,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:04:44,611] {logging_mixin.py:115} INFO - [2022-10-19 17:04:44,611] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:44,623] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:44,706] {logging_mixin.py:115} INFO - [2022-10-19 17:04:44,706] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:04:44,734] {logging_mixin.py:115} INFO - [2022-10-19 17:04:44,734] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:04:44.622204+00:00, run_after=2022-10-20T17:04:44.622204+00:00
[2022-10-19 17:04:44,753] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:04:45,211] {processor.py:153} INFO - Started process (PID=33885) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:45,212] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:04:45,214] {logging_mixin.py:115} INFO - [2022-10-19 17:04:45,213] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:45,224] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:04:45,244] {logging_mixin.py:115} INFO - [2022-10-19 17:04:45,244] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:04:45,275] {logging_mixin.py:115} INFO - [2022-10-19 17:04:45,275] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:04:45.223840+00:00, run_after=2022-10-20T17:04:45.223840+00:00
[2022-10-19 17:04:45,291] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:05:14,916] {processor.py:153} INFO - Started process (PID=24352) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:14,918] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:05:14,919] {logging_mixin.py:115} INFO - [2022-10-19 17:05:14,919] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:14,929] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:15,012] {logging_mixin.py:115} INFO - [2022-10-19 17:05:15,012] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:05:15,037] {logging_mixin.py:115} INFO - [2022-10-19 17:05:15,037] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:05:14.928203+00:00, run_after=2022-10-20T17:05:14.928203+00:00
[2022-10-19 17:05:15,056] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:05:16,008] {processor.py:153} INFO - Started process (PID=33918) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:16,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:05:16,011] {logging_mixin.py:115} INFO - [2022-10-19 17:05:16,011] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:16,022] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:16,043] {logging_mixin.py:115} INFO - [2022-10-19 17:05:16,043] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:05:16,074] {logging_mixin.py:115} INFO - [2022-10-19 17:05:16,074] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:05:16.021049+00:00, run_after=2022-10-20T17:05:16.021049+00:00
[2022-10-19 17:05:16,090] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.089 seconds
[2022-10-19 17:05:45,228] {processor.py:153} INFO - Started process (PID=24381) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:45,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:05:45,233] {logging_mixin.py:115} INFO - [2022-10-19 17:05:45,233] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:45,244] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:45,327] {logging_mixin.py:115} INFO - [2022-10-19 17:05:45,327] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:05:45,355] {logging_mixin.py:115} INFO - [2022-10-19 17:05:45,355] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:05:45.243648+00:00, run_after=2022-10-20T17:05:45.243648+00:00
[2022-10-19 17:05:45,374] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:05:46,870] {processor.py:153} INFO - Started process (PID=33950) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:46,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:05:46,872] {logging_mixin.py:115} INFO - [2022-10-19 17:05:46,872] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:46,883] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:05:46,905] {logging_mixin.py:115} INFO - [2022-10-19 17:05:46,905] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:05:46,936] {logging_mixin.py:115} INFO - [2022-10-19 17:05:46,936] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:05:46.882330+00:00, run_after=2022-10-20T17:05:46.882330+00:00
[2022-10-19 17:05:46,951] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:06:15,496] {processor.py:153} INFO - Started process (PID=24419) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:15,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:06:15,502] {logging_mixin.py:115} INFO - [2022-10-19 17:06:15,502] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:15,518] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:15,608] {logging_mixin.py:115} INFO - [2022-10-19 17:06:15,608] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:06:15,637] {logging_mixin.py:115} INFO - [2022-10-19 17:06:15,637] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:06:15.516878+00:00, run_after=2022-10-20T17:06:15.516878+00:00
[2022-10-19 17:06:15,660] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.171 seconds
[2022-10-19 17:06:17,638] {processor.py:153} INFO - Started process (PID=33982) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:17,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:06:17,641] {logging_mixin.py:115} INFO - [2022-10-19 17:06:17,640] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:17,670] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:17,694] {logging_mixin.py:115} INFO - [2022-10-19 17:06:17,694] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:06:17,723] {logging_mixin.py:115} INFO - [2022-10-19 17:06:17,723] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:06:17.667320+00:00, run_after=2022-10-20T17:06:17.667320+00:00
[2022-10-19 17:06:17,738] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.105 seconds
[2022-10-19 17:06:45,783] {processor.py:153} INFO - Started process (PID=24456) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:45,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:06:45,786] {logging_mixin.py:115} INFO - [2022-10-19 17:06:45,786] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:45,798] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:45,883] {logging_mixin.py:115} INFO - [2022-10-19 17:06:45,883] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:06:45,911] {logging_mixin.py:115} INFO - [2022-10-19 17:06:45,911] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:06:45.797393+00:00, run_after=2022-10-20T17:06:45.797393+00:00
[2022-10-19 17:06:45,936] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.161 seconds
[2022-10-19 17:06:48,446] {processor.py:153} INFO - Started process (PID=34015) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:48,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:06:48,448] {logging_mixin.py:115} INFO - [2022-10-19 17:06:48,448] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:48,461] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:06:48,483] {logging_mixin.py:115} INFO - [2022-10-19 17:06:48,483] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:06:48,514] {logging_mixin.py:115} INFO - [2022-10-19 17:06:48,513] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:06:48.459760+00:00, run_after=2022-10-20T17:06:48.459760+00:00
[2022-10-19 17:06:48,530] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.089 seconds
[2022-10-19 17:07:16,087] {processor.py:153} INFO - Started process (PID=24486) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:16,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:07:16,090] {logging_mixin.py:115} INFO - [2022-10-19 17:07:16,090] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:16,104] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:16,197] {logging_mixin.py:115} INFO - [2022-10-19 17:07:16,197] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:07:16,228] {logging_mixin.py:115} INFO - [2022-10-19 17:07:16,228] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:07:16.103773+00:00, run_after=2022-10-20T17:07:16.103773+00:00
[2022-10-19 17:07:16,249] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.168 seconds
[2022-10-19 17:07:19,226] {processor.py:153} INFO - Started process (PID=34046) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:19,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:07:19,228] {logging_mixin.py:115} INFO - [2022-10-19 17:07:19,228] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:19,239] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:19,260] {logging_mixin.py:115} INFO - [2022-10-19 17:07:19,260] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:07:19,292] {logging_mixin.py:115} INFO - [2022-10-19 17:07:19,292] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:07:19.238332+00:00, run_after=2022-10-20T17:07:19.238332+00:00
[2022-10-19 17:07:19,307] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 17:07:46,464] {processor.py:153} INFO - Started process (PID=24524) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:46,468] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:07:46,469] {logging_mixin.py:115} INFO - [2022-10-19 17:07:46,469] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:46,485] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:46,589] {logging_mixin.py:115} INFO - [2022-10-19 17:07:46,588] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:07:46,619] {logging_mixin.py:115} INFO - [2022-10-19 17:07:46,619] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:07:46.484185+00:00, run_after=2022-10-20T17:07:46.484185+00:00
[2022-10-19 17:07:46,637] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.179 seconds
[2022-10-19 17:07:49,375] {processor.py:153} INFO - Started process (PID=34078) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:49,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:07:49,380] {logging_mixin.py:115} INFO - [2022-10-19 17:07:49,380] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:49,396] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:07:49,419] {logging_mixin.py:115} INFO - [2022-10-19 17:07:49,418] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:07:49,452] {logging_mixin.py:115} INFO - [2022-10-19 17:07:49,452] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:07:49.394459+00:00, run_after=2022-10-20T17:07:49.394459+00:00
[2022-10-19 17:07:49,467] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.107 seconds
[2022-10-19 17:08:17,194] {processor.py:153} INFO - Started process (PID=24554) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:17,197] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:08:17,199] {logging_mixin.py:115} INFO - [2022-10-19 17:08:17,199] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:17,209] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:17,290] {logging_mixin.py:115} INFO - [2022-10-19 17:08:17,290] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:08:17,316] {logging_mixin.py:115} INFO - [2022-10-19 17:08:17,316] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:08:17.208397+00:00, run_after=2022-10-20T17:08:17.208397+00:00
[2022-10-19 17:08:17,334] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:08:19,707] {processor.py:153} INFO - Started process (PID=34110) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:19,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:08:19,710] {logging_mixin.py:115} INFO - [2022-10-19 17:08:19,710] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:19,725] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:19,751] {logging_mixin.py:115} INFO - [2022-10-19 17:08:19,751] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:08:19,786] {logging_mixin.py:115} INFO - [2022-10-19 17:08:19,786] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:08:19.723896+00:00, run_after=2022-10-20T17:08:19.723896+00:00
[2022-10-19 17:08:19,802] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.101 seconds
[2022-10-19 17:08:47,613] {processor.py:153} INFO - Started process (PID=24593) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:47,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:08:47,622] {logging_mixin.py:115} INFO - [2022-10-19 17:08:47,622] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:47,639] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:47,728] {logging_mixin.py:115} INFO - [2022-10-19 17:08:47,728] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:08:47,759] {logging_mixin.py:115} INFO - [2022-10-19 17:08:47,759] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:08:47.637994+00:00, run_after=2022-10-20T17:08:47.637994+00:00
[2022-10-19 17:08:47,775] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.167 seconds
[2022-10-19 17:08:50,599] {processor.py:153} INFO - Started process (PID=34143) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:50,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:08:50,602] {logging_mixin.py:115} INFO - [2022-10-19 17:08:50,602] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:50,614] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:08:50,639] {logging_mixin.py:115} INFO - [2022-10-19 17:08:50,639] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:08:50,668] {logging_mixin.py:115} INFO - [2022-10-19 17:08:50,668] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:08:50.612935+00:00, run_after=2022-10-20T17:08:50.612935+00:00
[2022-10-19 17:08:50,684] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.090 seconds
[2022-10-19 17:09:18,076] {processor.py:153} INFO - Started process (PID=24632) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:18,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:09:18,081] {logging_mixin.py:115} INFO - [2022-10-19 17:09:18,081] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:18,097] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:18,180] {logging_mixin.py:115} INFO - [2022-10-19 17:09:18,180] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:09:18,207] {logging_mixin.py:115} INFO - [2022-10-19 17:09:18,207] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:09:18.096867+00:00, run_after=2022-10-20T17:09:18.096867+00:00
[2022-10-19 17:09:18,226] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.155 seconds
[2022-10-19 17:09:21,424] {processor.py:153} INFO - Started process (PID=34175) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:21,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:09:21,426] {logging_mixin.py:115} INFO - [2022-10-19 17:09:21,426] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:21,438] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:21,458] {logging_mixin.py:115} INFO - [2022-10-19 17:09:21,458] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:09:21,489] {logging_mixin.py:115} INFO - [2022-10-19 17:09:21,488] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:09:21.436781+00:00, run_after=2022-10-20T17:09:21.436781+00:00
[2022-10-19 17:09:21,505] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 17:09:48,722] {processor.py:153} INFO - Started process (PID=24661) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:48,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:09:48,724] {logging_mixin.py:115} INFO - [2022-10-19 17:09:48,724] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:48,735] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:48,818] {logging_mixin.py:115} INFO - [2022-10-19 17:09:48,818] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:09:48,846] {logging_mixin.py:115} INFO - [2022-10-19 17:09:48,846] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:09:48.734170+00:00, run_after=2022-10-20T17:09:48.734170+00:00
[2022-10-19 17:09:48,865] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.147 seconds
[2022-10-19 17:09:52,244] {processor.py:153} INFO - Started process (PID=34207) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:52,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:09:52,247] {logging_mixin.py:115} INFO - [2022-10-19 17:09:52,247] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:52,257] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:09:52,278] {logging_mixin.py:115} INFO - [2022-10-19 17:09:52,278] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:09:52,309] {logging_mixin.py:115} INFO - [2022-10-19 17:09:52,309] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:09:52.256264+00:00, run_after=2022-10-20T17:09:52.256264+00:00
[2022-10-19 17:09:52,325] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:10:19,399] {processor.py:153} INFO - Started process (PID=24699) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:19,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:10:19,402] {logging_mixin.py:115} INFO - [2022-10-19 17:10:19,402] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:19,413] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:19,494] {logging_mixin.py:115} INFO - [2022-10-19 17:10:19,494] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:10:19,521] {logging_mixin.py:115} INFO - [2022-10-19 17:10:19,521] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:10:19.412686+00:00, run_after=2022-10-20T17:10:19.412686+00:00
[2022-10-19 17:10:19,538] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 17:10:22,967] {processor.py:153} INFO - Started process (PID=34239) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:22,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:10:22,970] {logging_mixin.py:115} INFO - [2022-10-19 17:10:22,970] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:22,981] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:23,026] {logging_mixin.py:115} INFO - [2022-10-19 17:10:23,026] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:10:23,070] {logging_mixin.py:115} INFO - [2022-10-19 17:10:23,070] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:10:22.980266+00:00, run_after=2022-10-20T17:10:22.980266+00:00
[2022-10-19 17:10:23,090] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.128 seconds
[2022-10-19 17:10:50,096] {processor.py:153} INFO - Started process (PID=24738) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:50,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:10:50,099] {logging_mixin.py:115} INFO - [2022-10-19 17:10:50,099] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:50,110] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:50,201] {logging_mixin.py:115} INFO - [2022-10-19 17:10:50,201] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:10:50,227] {logging_mixin.py:115} INFO - [2022-10-19 17:10:50,227] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:10:50.109277+00:00, run_after=2022-10-20T17:10:50.109277+00:00
[2022-10-19 17:10:50,247] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.155 seconds
[2022-10-19 17:10:53,818] {processor.py:153} INFO - Started process (PID=34279) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:53,819] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:10:53,821] {logging_mixin.py:115} INFO - [2022-10-19 17:10:53,821] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:53,833] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:10:53,855] {logging_mixin.py:115} INFO - [2022-10-19 17:10:53,855] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:10:53,892] {logging_mixin.py:115} INFO - [2022-10-19 17:10:53,891] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:10:53.831840+00:00, run_after=2022-10-20T17:10:53.831840+00:00
[2022-10-19 17:10:53,910] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.098 seconds
[2022-10-19 17:11:20,809] {processor.py:153} INFO - Started process (PID=24767) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:20,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:11:20,813] {logging_mixin.py:115} INFO - [2022-10-19 17:11:20,813] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:20,836] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:20,940] {logging_mixin.py:115} INFO - [2022-10-19 17:11:20,940] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:11:20,968] {logging_mixin.py:115} INFO - [2022-10-19 17:11:20,968] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:11:20.833495+00:00, run_after=2022-10-20T17:11:20.833495+00:00
[2022-10-19 17:11:20,986] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.192 seconds
[2022-10-19 17:11:24,572] {processor.py:153} INFO - Started process (PID=34311) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:24,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:11:24,577] {logging_mixin.py:115} INFO - [2022-10-19 17:11:24,576] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:24,592] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:24,614] {logging_mixin.py:115} INFO - [2022-10-19 17:11:24,614] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:11:24,649] {logging_mixin.py:115} INFO - [2022-10-19 17:11:24,649] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:11:24.591656+00:00, run_after=2022-10-20T17:11:24.591656+00:00
[2022-10-19 17:11:24,663] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.098 seconds
[2022-10-19 17:11:51,483] {processor.py:153} INFO - Started process (PID=24804) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:51,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:11:51,489] {logging_mixin.py:115} INFO - [2022-10-19 17:11:51,489] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:51,505] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:51,589] {logging_mixin.py:115} INFO - [2022-10-19 17:11:51,589] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:11:51,616] {logging_mixin.py:115} INFO - [2022-10-19 17:11:51,616] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:11:51.504054+00:00, run_after=2022-10-20T17:11:51.504054+00:00
[2022-10-19 17:11:51,636] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.157 seconds
[2022-10-19 17:11:55,359] {processor.py:153} INFO - Started process (PID=34342) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:55,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:11:55,362] {logging_mixin.py:115} INFO - [2022-10-19 17:11:55,362] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:55,377] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:11:55,400] {logging_mixin.py:115} INFO - [2022-10-19 17:11:55,400] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:11:55,429] {logging_mixin.py:115} INFO - [2022-10-19 17:11:55,429] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:11:55.376754+00:00, run_after=2022-10-20T17:11:55.376754+00:00
[2022-10-19 17:11:55,443] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.092 seconds
[2022-10-19 17:12:21,745] {processor.py:153} INFO - Started process (PID=24833) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:21,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:12:21,748] {logging_mixin.py:115} INFO - [2022-10-19 17:12:21,748] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:21,759] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:21,860] {logging_mixin.py:115} INFO - [2022-10-19 17:12:21,860] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:12:21,889] {logging_mixin.py:115} INFO - [2022-10-19 17:12:21,888] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:12:21.758398+00:00, run_after=2022-10-20T17:12:21.758398+00:00
[2022-10-19 17:12:21,906] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.166 seconds
[2022-10-19 17:12:26,180] {processor.py:153} INFO - Started process (PID=34373) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:26,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:12:26,183] {logging_mixin.py:115} INFO - [2022-10-19 17:12:26,182] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:26,195] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:26,215] {logging_mixin.py:115} INFO - [2022-10-19 17:12:26,215] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:12:26,249] {logging_mixin.py:115} INFO - [2022-10-19 17:12:26,249] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:12:26.194020+00:00, run_after=2022-10-20T17:12:26.194020+00:00
[2022-10-19 17:12:26,265] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.089 seconds
[2022-10-19 17:12:52,425] {processor.py:153} INFO - Started process (PID=24870) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:52,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:12:52,432] {logging_mixin.py:115} INFO - [2022-10-19 17:12:52,432] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:52,454] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:52,602] {logging_mixin.py:115} INFO - [2022-10-19 17:12:52,602] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:12:52,639] {logging_mixin.py:115} INFO - [2022-10-19 17:12:52,639] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:12:52.453404+00:00, run_after=2022-10-20T17:12:52.453404+00:00
[2022-10-19 17:12:52,660] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.242 seconds
[2022-10-19 17:12:57,030] {processor.py:153} INFO - Started process (PID=34407) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:57,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:12:57,033] {logging_mixin.py:115} INFO - [2022-10-19 17:12:57,032] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:57,052] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:12:57,073] {logging_mixin.py:115} INFO - [2022-10-19 17:12:57,073] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:12:57,105] {logging_mixin.py:115} INFO - [2022-10-19 17:12:57,105] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:12:57.050788+00:00, run_after=2022-10-20T17:12:57.050788+00:00
[2022-10-19 17:12:57,120] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.095 seconds
[2022-10-19 17:13:22,827] {processor.py:153} INFO - Started process (PID=24908) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:22,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:13:22,830] {logging_mixin.py:115} INFO - [2022-10-19 17:13:22,830] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:22,843] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:22,946] {logging_mixin.py:115} INFO - [2022-10-19 17:13:22,946] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:13:22,970] {logging_mixin.py:115} INFO - [2022-10-19 17:13:22,970] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:13:22.842185+00:00, run_after=2022-10-20T17:13:22.842185+00:00
[2022-10-19 17:13:22,995] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.175 seconds
[2022-10-19 17:13:27,828] {processor.py:153} INFO - Started process (PID=34438) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:27,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:13:27,833] {logging_mixin.py:115} INFO - [2022-10-19 17:13:27,832] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:27,852] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:27,879] {logging_mixin.py:115} INFO - [2022-10-19 17:13:27,879] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:13:27,912] {logging_mixin.py:115} INFO - [2022-10-19 17:13:27,912] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:13:27.851303+00:00, run_after=2022-10-20T17:13:27.851303+00:00
[2022-10-19 17:13:27,940] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.123 seconds
[2022-10-19 17:13:53,538] {processor.py:153} INFO - Started process (PID=24937) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:53,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:13:53,543] {logging_mixin.py:115} INFO - [2022-10-19 17:13:53,543] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:53,556] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:53,670] {logging_mixin.py:115} INFO - [2022-10-19 17:13:53,669] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:13:53,696] {logging_mixin.py:115} INFO - [2022-10-19 17:13:53,696] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:13:53.554922+00:00, run_after=2022-10-20T17:13:53.554922+00:00
[2022-10-19 17:13:53,717] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.185 seconds
[2022-10-19 17:13:58,669] {processor.py:153} INFO - Started process (PID=34469) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:58,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:13:58,672] {logging_mixin.py:115} INFO - [2022-10-19 17:13:58,672] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:58,686] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:13:58,707] {logging_mixin.py:115} INFO - [2022-10-19 17:13:58,707] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:13:58,743] {logging_mixin.py:115} INFO - [2022-10-19 17:13:58,743] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:13:58.685676+00:00, run_after=2022-10-20T17:13:58.685676+00:00
[2022-10-19 17:13:58,759] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.098 seconds
[2022-10-19 17:14:24,179] {processor.py:153} INFO - Started process (PID=24975) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:24,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:14:24,184] {logging_mixin.py:115} INFO - [2022-10-19 17:14:24,184] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:24,198] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:24,291] {logging_mixin.py:115} INFO - [2022-10-19 17:14:24,291] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:14:24,329] {logging_mixin.py:115} INFO - [2022-10-19 17:14:24,329] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:14:24.197373+00:00, run_after=2022-10-20T17:14:24.197373+00:00
[2022-10-19 17:14:24,348] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.175 seconds
[2022-10-19 17:14:29,441] {processor.py:153} INFO - Started process (PID=34500) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:29,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:14:29,443] {logging_mixin.py:115} INFO - [2022-10-19 17:14:29,443] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:29,454] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:29,474] {logging_mixin.py:115} INFO - [2022-10-19 17:14:29,474] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:14:29,504] {logging_mixin.py:115} INFO - [2022-10-19 17:14:29,503] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:14:29.453185+00:00, run_after=2022-10-20T17:14:29.453185+00:00
[2022-10-19 17:14:29,520] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.084 seconds
[2022-10-19 17:14:54,828] {processor.py:153} INFO - Started process (PID=25013) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:54,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:14:54,832] {logging_mixin.py:115} INFO - [2022-10-19 17:14:54,832] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:54,852] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:14:54,965] {logging_mixin.py:115} INFO - [2022-10-19 17:14:54,965] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:14:55,002] {logging_mixin.py:115} INFO - [2022-10-19 17:14:55,002] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:14:54.850376+00:00, run_after=2022-10-20T17:14:54.850376+00:00
[2022-10-19 17:14:55,019] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.198 seconds
[2022-10-19 17:15:00,206] {processor.py:153} INFO - Started process (PID=34532) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:00,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:15:00,208] {logging_mixin.py:115} INFO - [2022-10-19 17:15:00,208] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:00,220] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:00,248] {logging_mixin.py:115} INFO - [2022-10-19 17:15:00,248] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:15:00,279] {logging_mixin.py:115} INFO - [2022-10-19 17:15:00,279] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:15:00.219463+00:00, run_after=2022-10-20T17:15:00.219463+00:00
[2022-10-19 17:15:00,294] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.093 seconds
[2022-10-19 17:15:25,054] {processor.py:153} INFO - Started process (PID=25041) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:25,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:15:25,057] {logging_mixin.py:115} INFO - [2022-10-19 17:15:25,057] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:25,069] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:25,153] {logging_mixin.py:115} INFO - [2022-10-19 17:15:25,152] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:15:25,188] {logging_mixin.py:115} INFO - [2022-10-19 17:15:25,188] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:15:25.068014+00:00, run_after=2022-10-20T17:15:25.068014+00:00
[2022-10-19 17:15:25,206] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 17:15:30,957] {processor.py:153} INFO - Started process (PID=34564) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:30,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:15:30,959] {logging_mixin.py:115} INFO - [2022-10-19 17:15:30,959] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:30,968] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:30,988] {logging_mixin.py:115} INFO - [2022-10-19 17:15:30,988] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:15:31,018] {logging_mixin.py:115} INFO - [2022-10-19 17:15:31,018] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:15:30.967889+00:00, run_after=2022-10-20T17:15:30.967889+00:00
[2022-10-19 17:15:31,033] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.081 seconds
[2022-10-19 17:15:55,771] {processor.py:153} INFO - Started process (PID=25078) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:55,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:15:55,776] {logging_mixin.py:115} INFO - [2022-10-19 17:15:55,776] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:55,788] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:15:55,876] {logging_mixin.py:115} INFO - [2022-10-19 17:15:55,875] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:15:55,913] {logging_mixin.py:115} INFO - [2022-10-19 17:15:55,913] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:15:55.787160+00:00, run_after=2022-10-20T17:15:55.787160+00:00
[2022-10-19 17:15:55,933] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.167 seconds
[2022-10-19 17:16:01,735] {processor.py:153} INFO - Started process (PID=34597) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:01,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:16:01,738] {logging_mixin.py:115} INFO - [2022-10-19 17:16:01,738] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:01,749] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:01,770] {logging_mixin.py:115} INFO - [2022-10-19 17:16:01,770] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:16:01,801] {logging_mixin.py:115} INFO - [2022-10-19 17:16:01,801] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:16:01.748702+00:00, run_after=2022-10-20T17:16:01.748702+00:00
[2022-10-19 17:16:01,817] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:16:26,001] {processor.py:153} INFO - Started process (PID=25108) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:26,003] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:16:26,004] {logging_mixin.py:115} INFO - [2022-10-19 17:16:26,004] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:26,015] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:26,094] {logging_mixin.py:115} INFO - [2022-10-19 17:16:26,094] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:16:26,123] {logging_mixin.py:115} INFO - [2022-10-19 17:16:26,123] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:16:26.014290+00:00, run_after=2022-10-20T17:16:26.014290+00:00
[2022-10-19 17:16:26,140] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 17:16:32,488] {processor.py:153} INFO - Started process (PID=34631) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:32,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:16:32,490] {logging_mixin.py:115} INFO - [2022-10-19 17:16:32,490] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:32,501] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:32,520] {logging_mixin.py:115} INFO - [2022-10-19 17:16:32,520] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:16:32,551] {logging_mixin.py:115} INFO - [2022-10-19 17:16:32,550] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:16:32.499949+00:00, run_after=2022-10-20T17:16:32.499949+00:00
[2022-10-19 17:16:32,568] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:16:56,742] {processor.py:153} INFO - Started process (PID=25148) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:56,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:16:56,746] {logging_mixin.py:115} INFO - [2022-10-19 17:16:56,746] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:56,756] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:16:56,849] {logging_mixin.py:115} INFO - [2022-10-19 17:16:56,849] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:16:56,875] {logging_mixin.py:115} INFO - [2022-10-19 17:16:56,874] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:16:56.755770+00:00, run_after=2022-10-20T17:16:56.755770+00:00
[2022-10-19 17:16:56,893] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 17:17:03,253] {processor.py:153} INFO - Started process (PID=34663) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:03,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:17:03,255] {logging_mixin.py:115} INFO - [2022-10-19 17:17:03,255] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:03,266] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:03,285] {logging_mixin.py:115} INFO - [2022-10-19 17:17:03,285] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:17:03,315] {logging_mixin.py:115} INFO - [2022-10-19 17:17:03,315] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:17:03.264998+00:00, run_after=2022-10-20T17:17:03.264998+00:00
[2022-10-19 17:17:03,332] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:17:27,480] {processor.py:153} INFO - Started process (PID=25185) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:27,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:17:27,482] {logging_mixin.py:115} INFO - [2022-10-19 17:17:27,482] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:27,493] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:27,574] {logging_mixin.py:115} INFO - [2022-10-19 17:17:27,574] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:17:27,601] {logging_mixin.py:115} INFO - [2022-10-19 17:17:27,600] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:17:27.492267+00:00, run_after=2022-10-20T17:17:27.492267+00:00
[2022-10-19 17:17:27,621] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.146 seconds
[2022-10-19 17:17:34,089] {processor.py:153} INFO - Started process (PID=34695) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:34,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:17:34,091] {logging_mixin.py:115} INFO - [2022-10-19 17:17:34,091] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:34,102] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:34,123] {logging_mixin.py:115} INFO - [2022-10-19 17:17:34,123] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:17:34,154] {logging_mixin.py:115} INFO - [2022-10-19 17:17:34,154] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:17:34.101111+00:00, run_after=2022-10-20T17:17:34.101111+00:00
[2022-10-19 17:17:34,170] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:17:58,601] {processor.py:153} INFO - Started process (PID=25214) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:58,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:17:58,603] {logging_mixin.py:115} INFO - [2022-10-19 17:17:58,603] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:58,613] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:17:58,696] {logging_mixin.py:115} INFO - [2022-10-19 17:17:58,696] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:17:58,723] {logging_mixin.py:115} INFO - [2022-10-19 17:17:58,723] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:17:58.612866+00:00, run_after=2022-10-20T17:17:58.612866+00:00
[2022-10-19 17:17:58,741] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:18:04,852] {processor.py:153} INFO - Started process (PID=34727) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:04,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:18:04,854] {logging_mixin.py:115} INFO - [2022-10-19 17:18:04,854] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:04,865] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:04,885] {logging_mixin.py:115} INFO - [2022-10-19 17:18:04,884] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:18:04,915] {logging_mixin.py:115} INFO - [2022-10-19 17:18:04,914] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:18:04.864680+00:00, run_after=2022-10-20T17:18:04.864680+00:00
[2022-10-19 17:18:04,932] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:18:29,040] {processor.py:153} INFO - Started process (PID=25253) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:29,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:18:29,043] {logging_mixin.py:115} INFO - [2022-10-19 17:18:29,043] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:29,057] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:29,143] {logging_mixin.py:115} INFO - [2022-10-19 17:18:29,143] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:18:29,175] {logging_mixin.py:115} INFO - [2022-10-19 17:18:29,175] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:18:29.056200+00:00, run_after=2022-10-20T17:18:29.056200+00:00
[2022-10-19 17:18:29,200] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.166 seconds
[2022-10-19 17:18:35,687] {processor.py:153} INFO - Started process (PID=34759) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:35,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:18:35,692] {logging_mixin.py:115} INFO - [2022-10-19 17:18:35,692] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:35,707] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:35,740] {logging_mixin.py:115} INFO - [2022-10-19 17:18:35,740] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:18:35,803] {logging_mixin.py:115} INFO - [2022-10-19 17:18:35,803] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:18:35.706590+00:00, run_after=2022-10-20T17:18:35.706590+00:00
[2022-10-19 17:18:35,819] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.136 seconds
[2022-10-19 17:18:59,908] {processor.py:153} INFO - Started process (PID=25291) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:59,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:18:59,910] {logging_mixin.py:115} INFO - [2022-10-19 17:18:59,910] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:18:59,921] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:00,003] {logging_mixin.py:115} INFO - [2022-10-19 17:19:00,003] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:19:00,031] {logging_mixin.py:115} INFO - [2022-10-19 17:19:00,031] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:18:59.920662+00:00, run_after=2022-10-20T17:18:59.920662+00:00
[2022-10-19 17:19:00,051] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.148 seconds
[2022-10-19 17:19:06,531] {processor.py:153} INFO - Started process (PID=34791) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:06,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:19:06,533] {logging_mixin.py:115} INFO - [2022-10-19 17:19:06,533] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:06,544] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:06,565] {logging_mixin.py:115} INFO - [2022-10-19 17:19:06,565] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:19:06,597] {logging_mixin.py:115} INFO - [2022-10-19 17:19:06,597] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:19:06.543827+00:00, run_after=2022-10-20T17:19:06.543827+00:00
[2022-10-19 17:19:06,611] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:19:30,746] {processor.py:153} INFO - Started process (PID=25321) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:30,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:19:30,751] {logging_mixin.py:115} INFO - [2022-10-19 17:19:30,751] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:30,762] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:30,843] {logging_mixin.py:115} INFO - [2022-10-19 17:19:30,843] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:19:30,871] {logging_mixin.py:115} INFO - [2022-10-19 17:19:30,871] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:19:30.761830+00:00, run_after=2022-10-20T17:19:30.761830+00:00
[2022-10-19 17:19:30,889] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.150 seconds
[2022-10-19 17:19:37,325] {processor.py:153} INFO - Started process (PID=34822) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:37,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:19:37,328] {logging_mixin.py:115} INFO - [2022-10-19 17:19:37,327] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:37,339] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:19:37,358] {logging_mixin.py:115} INFO - [2022-10-19 17:19:37,358] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:19:37,390] {logging_mixin.py:115} INFO - [2022-10-19 17:19:37,390] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:19:37.338138+00:00, run_after=2022-10-20T17:19:37.338138+00:00
[2022-10-19 17:19:37,407] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:20:01,593] {processor.py:153} INFO - Started process (PID=25360) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:01,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:20:01,595] {logging_mixin.py:115} INFO - [2022-10-19 17:20:01,595] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:01,606] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:01,685] {logging_mixin.py:115} INFO - [2022-10-19 17:20:01,685] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:20:01,724] {logging_mixin.py:115} INFO - [2022-10-19 17:20:01,724] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:20:01.605093+00:00, run_after=2022-10-20T17:20:01.605093+00:00
[2022-10-19 17:20:01,741] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.153 seconds
[2022-10-19 17:20:08,132] {processor.py:153} INFO - Started process (PID=34855) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:08,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:20:08,136] {logging_mixin.py:115} INFO - [2022-10-19 17:20:08,136] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:08,148] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:08,200] {logging_mixin.py:115} INFO - [2022-10-19 17:20:08,200] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:20:08,236] {logging_mixin.py:115} INFO - [2022-10-19 17:20:08,236] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:20:08.147394+00:00, run_after=2022-10-20T17:20:08.147394+00:00
[2022-10-19 17:20:08,251] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.125 seconds
[2022-10-19 17:20:32,460] {processor.py:153} INFO - Started process (PID=25398) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:32,462] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:20:32,464] {logging_mixin.py:115} INFO - [2022-10-19 17:20:32,464] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:32,476] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:32,571] {logging_mixin.py:115} INFO - [2022-10-19 17:20:32,570] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:20:32,608] {logging_mixin.py:115} INFO - [2022-10-19 17:20:32,608] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:20:32.475033+00:00, run_after=2022-10-20T17:20:32.475033+00:00
[2022-10-19 17:20:32,626] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.172 seconds
[2022-10-19 17:20:38,848] {processor.py:153} INFO - Started process (PID=34891) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:38,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:20:38,850] {logging_mixin.py:115} INFO - [2022-10-19 17:20:38,850] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:38,861] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:20:38,881] {logging_mixin.py:115} INFO - [2022-10-19 17:20:38,881] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:20:38,911] {logging_mixin.py:115} INFO - [2022-10-19 17:20:38,911] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:20:38.860645+00:00, run_after=2022-10-20T17:20:38.860645+00:00
[2022-10-19 17:20:38,927] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.084 seconds
[2022-10-19 17:21:03,309] {processor.py:153} INFO - Started process (PID=25427) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:03,311] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:21:03,312] {logging_mixin.py:115} INFO - [2022-10-19 17:21:03,312] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:03,322] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:03,403] {logging_mixin.py:115} INFO - [2022-10-19 17:21:03,403] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:21:03,433] {logging_mixin.py:115} INFO - [2022-10-19 17:21:03,433] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:21:03.321619+00:00, run_after=2022-10-20T17:21:03.321619+00:00
[2022-10-19 17:21:03,450] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:21:09,674] {processor.py:153} INFO - Started process (PID=34924) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:09,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:21:09,678] {logging_mixin.py:115} INFO - [2022-10-19 17:21:09,678] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:09,690] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:09,711] {logging_mixin.py:115} INFO - [2022-10-19 17:21:09,711] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:21:09,741] {logging_mixin.py:115} INFO - [2022-10-19 17:21:09,741] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:21:09.689850+00:00, run_after=2022-10-20T17:21:09.689850+00:00
[2022-10-19 17:21:09,756] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.088 seconds
[2022-10-19 17:21:34,165] {processor.py:153} INFO - Started process (PID=25466) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:34,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:21:34,168] {logging_mixin.py:115} INFO - [2022-10-19 17:21:34,168] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:34,180] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:34,263] {logging_mixin.py:115} INFO - [2022-10-19 17:21:34,263] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:21:34,291] {logging_mixin.py:115} INFO - [2022-10-19 17:21:34,291] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:21:34.179027+00:00, run_after=2022-10-20T17:21:34.179027+00:00
[2022-10-19 17:21:34,311] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:21:40,486] {processor.py:153} INFO - Started process (PID=34956) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:40,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:21:40,490] {logging_mixin.py:115} INFO - [2022-10-19 17:21:40,490] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:40,501] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:21:40,524] {logging_mixin.py:115} INFO - [2022-10-19 17:21:40,524] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:21:40,554] {logging_mixin.py:115} INFO - [2022-10-19 17:21:40,554] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:21:40.500892+00:00, run_after=2022-10-20T17:21:40.500892+00:00
[2022-10-19 17:21:40,568] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:22:04,564] {processor.py:153} INFO - Started process (PID=25504) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:04,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:22:04,569] {logging_mixin.py:115} INFO - [2022-10-19 17:22:04,569] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:04,580] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:04,677] {logging_mixin.py:115} INFO - [2022-10-19 17:22:04,677] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:22:04,705] {logging_mixin.py:115} INFO - [2022-10-19 17:22:04,705] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:22:04.579711+00:00, run_after=2022-10-20T17:22:04.579711+00:00
[2022-10-19 17:22:04,724] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.164 seconds
[2022-10-19 17:22:10,737] {processor.py:153} INFO - Started process (PID=34988) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:10,739] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:22:10,740] {logging_mixin.py:115} INFO - [2022-10-19 17:22:10,740] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:10,755] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:10,779] {logging_mixin.py:115} INFO - [2022-10-19 17:22:10,779] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:22:10,813] {logging_mixin.py:115} INFO - [2022-10-19 17:22:10,813] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:22:10.753948+00:00, run_after=2022-10-20T17:22:10.753948+00:00
[2022-10-19 17:22:10,830] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.100 seconds
[2022-10-19 17:22:35,161] {processor.py:153} INFO - Started process (PID=25533) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:35,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:22:35,164] {logging_mixin.py:115} INFO - [2022-10-19 17:22:35,164] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:35,176] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:35,269] {logging_mixin.py:115} INFO - [2022-10-19 17:22:35,269] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:22:35,298] {logging_mixin.py:115} INFO - [2022-10-19 17:22:35,298] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:22:35.174950+00:00, run_after=2022-10-20T17:22:35.174950+00:00
[2022-10-19 17:22:35,324] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.168 seconds
[2022-10-19 17:22:41,683] {processor.py:153} INFO - Started process (PID=35022) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:41,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:22:41,686] {logging_mixin.py:115} INFO - [2022-10-19 17:22:41,686] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:41,697] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:22:41,715] {logging_mixin.py:115} INFO - [2022-10-19 17:22:41,715] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:22:41,746] {logging_mixin.py:115} INFO - [2022-10-19 17:22:41,746] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:22:41.696078+00:00, run_after=2022-10-20T17:22:41.696078+00:00
[2022-10-19 17:22:41,764] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 17:23:05,626] {processor.py:153} INFO - Started process (PID=25572) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:05,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:23:05,628] {logging_mixin.py:115} INFO - [2022-10-19 17:23:05,628] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:05,640] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:05,721] {logging_mixin.py:115} INFO - [2022-10-19 17:23:05,721] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:23:05,749] {logging_mixin.py:115} INFO - [2022-10-19 17:23:05,749] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:23:05.638962+00:00, run_after=2022-10-20T17:23:05.638962+00:00
[2022-10-19 17:23:05,765] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.144 seconds
[2022-10-19 17:23:12,494] {processor.py:153} INFO - Started process (PID=35054) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:12,495] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:23:12,496] {logging_mixin.py:115} INFO - [2022-10-19 17:23:12,496] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:12,506] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:12,526] {logging_mixin.py:115} INFO - [2022-10-19 17:23:12,526] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:23:12,556] {logging_mixin.py:115} INFO - [2022-10-19 17:23:12,556] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:23:12.505845+00:00, run_after=2022-10-20T17:23:12.505845+00:00
[2022-10-19 17:23:12,571] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.082 seconds
[2022-10-19 17:23:36,492] {processor.py:153} INFO - Started process (PID=25610) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:36,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:23:36,495] {logging_mixin.py:115} INFO - [2022-10-19 17:23:36,495] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:36,510] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:36,607] {logging_mixin.py:115} INFO - [2022-10-19 17:23:36,606] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:23:36,646] {logging_mixin.py:115} INFO - [2022-10-19 17:23:36,646] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:23:36.509622+00:00, run_after=2022-10-20T17:23:36.509622+00:00
[2022-10-19 17:23:36,666] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.181 seconds
[2022-10-19 17:23:43,281] {processor.py:153} INFO - Started process (PID=35087) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:43,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:23:43,283] {logging_mixin.py:115} INFO - [2022-10-19 17:23:43,283] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:43,295] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:23:43,315] {logging_mixin.py:115} INFO - [2022-10-19 17:23:43,315] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:23:43,345] {logging_mixin.py:115} INFO - [2022-10-19 17:23:43,345] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:23:43.293970+00:00, run_after=2022-10-20T17:23:43.293970+00:00
[2022-10-19 17:23:43,362] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:24:07,375] {processor.py:153} INFO - Started process (PID=25640) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:07,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:24:07,377] {logging_mixin.py:115} INFO - [2022-10-19 17:24:07,377] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:07,389] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:07,480] {logging_mixin.py:115} INFO - [2022-10-19 17:24:07,480] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:24:07,511] {logging_mixin.py:115} INFO - [2022-10-19 17:24:07,510] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:24:07.387318+00:00, run_after=2022-10-20T17:24:07.387318+00:00
[2022-10-19 17:24:07,534] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.164 seconds
[2022-10-19 17:24:14,039] {processor.py:153} INFO - Started process (PID=35119) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:14,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:24:14,042] {logging_mixin.py:115} INFO - [2022-10-19 17:24:14,041] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:14,052] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:14,072] {logging_mixin.py:115} INFO - [2022-10-19 17:24:14,072] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:24:14,102] {logging_mixin.py:115} INFO - [2022-10-19 17:24:14,102] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:24:14.051769+00:00, run_after=2022-10-20T17:24:14.051769+00:00
[2022-10-19 17:24:14,116] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.082 seconds
[2022-10-19 17:24:38,208] {processor.py:153} INFO - Started process (PID=25678) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:38,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:24:38,212] {logging_mixin.py:115} INFO - [2022-10-19 17:24:38,212] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:38,223] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:38,302] {logging_mixin.py:115} INFO - [2022-10-19 17:24:38,301] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:24:38,329] {logging_mixin.py:115} INFO - [2022-10-19 17:24:38,328] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:24:38.222344+00:00, run_after=2022-10-20T17:24:38.222344+00:00
[2022-10-19 17:24:38,346] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 17:24:44,858] {processor.py:153} INFO - Started process (PID=35151) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:44,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:24:44,861] {logging_mixin.py:115} INFO - [2022-10-19 17:24:44,861] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:44,875] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:24:44,899] {logging_mixin.py:115} INFO - [2022-10-19 17:24:44,899] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:24:44,933] {logging_mixin.py:115} INFO - [2022-10-19 17:24:44,932] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:24:44.874717+00:00, run_after=2022-10-20T17:24:44.874717+00:00
[2022-10-19 17:24:44,953] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.101 seconds
[2022-10-19 17:25:08,417] {processor.py:153} INFO - Started process (PID=25707) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:25:08,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:25:08,420] {logging_mixin.py:115} INFO - [2022-10-19 17:25:08,420] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:25:08,433] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:25:08,523] {logging_mixin.py:115} INFO - [2022-10-19 17:25:08,523] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:25:08,552] {logging_mixin.py:115} INFO - [2022-10-19 17:25:08,552] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:25:08.432255+00:00, run_after=2022-10-20T17:25:08.432255+00:00
[2022-10-19 17:25:08,572] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.160 seconds
[2022-10-19 17:25:15,527] {processor.py:153} INFO - Started process (PID=35183) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:25:15,531] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:25:15,533] {logging_mixin.py:115} INFO - [2022-10-19 17:25:15,533] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:25:15,550] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:25:15,575] {logging_mixin.py:115} INFO - [2022-10-19 17:25:15,574] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:25:15,618] {logging_mixin.py:115} INFO - [2022-10-19 17:25:15,618] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:25:15.549223+00:00, run_after=2022-10-20T17:25:15.549223+00:00
[2022-10-19 17:25:15,634] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.114 seconds
[2022-10-19 17:27:15,544] {processor.py:153} INFO - Started process (PID=25720) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:15,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:27:15,547] {logging_mixin.py:115} INFO - [2022-10-19 17:27:15,547] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:15,569] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:15,689] {logging_mixin.py:115} INFO - [2022-10-19 17:27:15,689] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:27:15,724] {logging_mixin.py:115} INFO - [2022-10-19 17:27:15,724] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:27:15.567222+00:00, run_after=2022-10-20T17:27:15.567222+00:00
[2022-10-19 17:27:15,771] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.232 seconds
[2022-10-19 17:27:16,234] {processor.py:153} INFO - Started process (PID=35186) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:16,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:27:16,246] {logging_mixin.py:115} INFO - [2022-10-19 17:27:16,246] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:16,281] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:16,359] {logging_mixin.py:115} INFO - [2022-10-19 17:27:16,358] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:27:16,472] {logging_mixin.py:115} INFO - [2022-10-19 17:27:16,472] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:27:16.279497+00:00, run_after=2022-10-20T17:27:16.279497+00:00
[2022-10-19 17:27:16,552] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.328 seconds
[2022-10-19 17:27:46,284] {processor.py:153} INFO - Started process (PID=25757) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:46,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:27:46,286] {logging_mixin.py:115} INFO - [2022-10-19 17:27:46,286] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:46,298] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:46,384] {logging_mixin.py:115} INFO - [2022-10-19 17:27:46,383] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:27:46,411] {logging_mixin.py:115} INFO - [2022-10-19 17:27:46,411] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:27:46.297193+00:00, run_after=2022-10-20T17:27:46.297193+00:00
[2022-10-19 17:27:46,428] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.149 seconds
[2022-10-19 17:27:47,249] {processor.py:153} INFO - Started process (PID=35223) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:47,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:27:47,251] {logging_mixin.py:115} INFO - [2022-10-19 17:27:47,251] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:47,265] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:27:47,290] {logging_mixin.py:115} INFO - [2022-10-19 17:27:47,290] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:27:47,339] {logging_mixin.py:115} INFO - [2022-10-19 17:27:47,339] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:27:47.264333+00:00, run_after=2022-10-20T17:27:47.264333+00:00
[2022-10-19 17:27:47,354] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.110 seconds
[2022-10-19 17:28:16,556] {processor.py:153} INFO - Started process (PID=25786) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:16,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:28:16,558] {logging_mixin.py:115} INFO - [2022-10-19 17:28:16,558] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:16,572] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:16,660] {logging_mixin.py:115} INFO - [2022-10-19 17:28:16,660] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:28:16,696] {logging_mixin.py:115} INFO - [2022-10-19 17:28:16,696] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:28:16.571038+00:00, run_after=2022-10-20T17:28:16.571038+00:00
[2022-10-19 17:28:16,722] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.171 seconds
[2022-10-19 17:28:17,554] {processor.py:153} INFO - Started process (PID=35256) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:17,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:28:17,557] {logging_mixin.py:115} INFO - [2022-10-19 17:28:17,557] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:17,568] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:17,594] {logging_mixin.py:115} INFO - [2022-10-19 17:28:17,594] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:28:17,625] {logging_mixin.py:115} INFO - [2022-10-19 17:28:17,625] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:28:17.567313+00:00, run_after=2022-10-20T17:28:17.567313+00:00
[2022-10-19 17:28:17,639] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.090 seconds
[2022-10-19 17:28:46,897] {processor.py:153} INFO - Started process (PID=25824) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:46,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:28:46,899] {logging_mixin.py:115} INFO - [2022-10-19 17:28:46,899] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:46,911] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:46,994] {logging_mixin.py:115} INFO - [2022-10-19 17:28:46,994] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:28:47,021] {logging_mixin.py:115} INFO - [2022-10-19 17:28:47,021] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:28:46.910808+00:00, run_after=2022-10-20T17:28:46.910808+00:00
[2022-10-19 17:28:47,041] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.148 seconds
[2022-10-19 17:28:47,925] {processor.py:153} INFO - Started process (PID=35287) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:47,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:28:47,933] {logging_mixin.py:115} INFO - [2022-10-19 17:28:47,933] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:47,944] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:28:47,966] {logging_mixin.py:115} INFO - [2022-10-19 17:28:47,965] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:28:47,995] {logging_mixin.py:115} INFO - [2022-10-19 17:28:47,994] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:28:47.943636+00:00, run_after=2022-10-20T17:28:47.943636+00:00
[2022-10-19 17:28:48,012] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.091 seconds
[2022-10-19 17:29:17,820] {processor.py:153} INFO - Started process (PID=25853) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:17,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:29:17,822] {logging_mixin.py:115} INFO - [2022-10-19 17:29:17,822] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:17,833] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:17,916] {logging_mixin.py:115} INFO - [2022-10-19 17:29:17,916] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:29:17,942] {logging_mixin.py:115} INFO - [2022-10-19 17:29:17,942] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:29:17.832088+00:00, run_after=2022-10-20T17:29:17.832088+00:00
[2022-10-19 17:29:17,961] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:29:18,212] {processor.py:153} INFO - Started process (PID=35321) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:18,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:29:18,217] {logging_mixin.py:115} INFO - [2022-10-19 17:29:18,217] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:18,229] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:18,259] {logging_mixin.py:115} INFO - [2022-10-19 17:29:18,259] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:29:18,292] {logging_mixin.py:115} INFO - [2022-10-19 17:29:18,292] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:29:18.227679+00:00, run_after=2022-10-20T17:29:18.227679+00:00
[2022-10-19 17:29:18,308] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.105 seconds
[2022-10-19 17:29:48,075] {processor.py:153} INFO - Started process (PID=25891) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:48,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:29:48,077] {logging_mixin.py:115} INFO - [2022-10-19 17:29:48,077] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:48,088] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:48,168] {logging_mixin.py:115} INFO - [2022-10-19 17:29:48,167] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:29:48,196] {logging_mixin.py:115} INFO - [2022-10-19 17:29:48,196] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:29:48.087499+00:00, run_after=2022-10-20T17:29:48.087499+00:00
[2022-10-19 17:29:48,221] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:29:48,395] {processor.py:153} INFO - Started process (PID=35353) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:48,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:29:48,398] {logging_mixin.py:115} INFO - [2022-10-19 17:29:48,398] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:48,408] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:29:48,428] {logging_mixin.py:115} INFO - [2022-10-19 17:29:48,428] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:29:48,462] {logging_mixin.py:115} INFO - [2022-10-19 17:29:48,462] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:29:48.407688+00:00, run_after=2022-10-20T17:29:48.407688+00:00
[2022-10-19 17:29:48,479] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.088 seconds
[2022-10-19 17:30:18,300] {processor.py:153} INFO - Started process (PID=25929) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:18,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:30:18,304] {logging_mixin.py:115} INFO - [2022-10-19 17:30:18,304] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:18,317] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:18,426] {logging_mixin.py:115} INFO - [2022-10-19 17:30:18,426] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:30:18,455] {logging_mixin.py:115} INFO - [2022-10-19 17:30:18,455] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:30:18.316178+00:00, run_after=2022-10-20T17:30:18.316178+00:00
[2022-10-19 17:30:18,473] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.179 seconds
[2022-10-19 17:30:18,522] {processor.py:153} INFO - Started process (PID=35384) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:18,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:30:18,525] {logging_mixin.py:115} INFO - [2022-10-19 17:30:18,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:18,536] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:18,560] {logging_mixin.py:115} INFO - [2022-10-19 17:30:18,560] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:30:18,596] {logging_mixin.py:115} INFO - [2022-10-19 17:30:18,596] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:30:18.535780+00:00, run_after=2022-10-20T17:30:18.535780+00:00
[2022-10-19 17:30:18,612] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.095 seconds
[2022-10-19 17:30:48,543] {processor.py:153} INFO - Started process (PID=25958) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:48,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:30:48,548] {logging_mixin.py:115} INFO - [2022-10-19 17:30:48,547] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:48,566] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:48,681] {logging_mixin.py:115} INFO - [2022-10-19 17:30:48,681] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:30:48,709] {logging_mixin.py:115} INFO - [2022-10-19 17:30:48,709] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:30:48.564877+00:00, run_after=2022-10-20T17:30:48.564877+00:00
[2022-10-19 17:30:48,711] {processor.py:153} INFO - Started process (PID=35417) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:48,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:30:48,715] {logging_mixin.py:115} INFO - [2022-10-19 17:30:48,714] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:48,729] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:30:48,729] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.190 seconds
[2022-10-19 17:30:48,756] {logging_mixin.py:115} INFO - [2022-10-19 17:30:48,755] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:30:48,790] {logging_mixin.py:115} INFO - [2022-10-19 17:30:48,789] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:30:48.727799+00:00, run_after=2022-10-20T17:30:48.727799+00:00
[2022-10-19 17:30:48,809] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.107 seconds
[2022-10-19 17:31:19,107] {processor.py:153} INFO - Started process (PID=35448) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:19,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:31:19,109] {logging_mixin.py:115} INFO - [2022-10-19 17:31:19,109] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:19,119] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:19,201] {logging_mixin.py:115} INFO - [2022-10-19 17:31:19,201] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:31:19,226] {logging_mixin.py:115} INFO - [2022-10-19 17:31:19,226] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:31:19.118547+00:00, run_after=2022-10-20T17:31:19.118547+00:00
[2022-10-19 17:31:19,244] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 17:31:19,439] {processor.py:153} INFO - Started process (PID=25996) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:19,440] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:31:19,441] {logging_mixin.py:115} INFO - [2022-10-19 17:31:19,441] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:19,451] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:19,471] {logging_mixin.py:115} INFO - [2022-10-19 17:31:19,471] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:31:19,503] {logging_mixin.py:115} INFO - [2022-10-19 17:31:19,503] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:31:19.450517+00:00, run_after=2022-10-20T17:31:19.450517+00:00
[2022-10-19 17:31:19,519] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:31:49,472] {processor.py:153} INFO - Started process (PID=35480) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:49,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:31:49,476] {logging_mixin.py:115} INFO - [2022-10-19 17:31:49,476] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:49,487] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:49,577] {logging_mixin.py:115} INFO - [2022-10-19 17:31:49,577] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:31:49,605] {logging_mixin.py:115} INFO - [2022-10-19 17:31:49,605] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:31:49.486489+00:00, run_after=2022-10-20T17:31:49.486489+00:00
[2022-10-19 17:31:49,622] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.155 seconds
[2022-10-19 17:31:49,739] {processor.py:153} INFO - Started process (PID=26025) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:49,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:31:49,741] {logging_mixin.py:115} INFO - [2022-10-19 17:31:49,741] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:49,752] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:31:49,772] {logging_mixin.py:115} INFO - [2022-10-19 17:31:49,772] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:31:49,800] {logging_mixin.py:115} INFO - [2022-10-19 17:31:49,800] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:31:49.751668+00:00, run_after=2022-10-20T17:31:49.751668+00:00
[2022-10-19 17:31:49,816] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 17:32:19,668] {processor.py:153} INFO - Started process (PID=35511) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:19,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:32:19,673] {logging_mixin.py:115} INFO - [2022-10-19 17:32:19,673] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:19,684] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:19,767] {logging_mixin.py:115} INFO - [2022-10-19 17:32:19,766] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:32:19,793] {logging_mixin.py:115} INFO - [2022-10-19 17:32:19,793] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:32:19.683235+00:00, run_after=2022-10-20T17:32:19.683235+00:00
[2022-10-19 17:32:19,811] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.147 seconds
[2022-10-19 17:32:19,948] {processor.py:153} INFO - Started process (PID=26064) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:19,952] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:32:19,955] {logging_mixin.py:115} INFO - [2022-10-19 17:32:19,955] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:19,978] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:19,997] {logging_mixin.py:115} INFO - [2022-10-19 17:32:19,997] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:32:20,028] {logging_mixin.py:115} INFO - [2022-10-19 17:32:20,027] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:32:19.976457+00:00, run_after=2022-10-20T17:32:19.976457+00:00
[2022-10-19 17:32:20,044] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.101 seconds
[2022-10-19 17:32:49,859] {processor.py:153} INFO - Started process (PID=35543) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:49,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:32:49,864] {logging_mixin.py:115} INFO - [2022-10-19 17:32:49,864] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:49,874] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:49,953] {logging_mixin.py:115} INFO - [2022-10-19 17:32:49,953] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:32:49,978] {logging_mixin.py:115} INFO - [2022-10-19 17:32:49,978] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:32:49.873265+00:00, run_after=2022-10-20T17:32:49.873265+00:00
[2022-10-19 17:32:49,996] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 17:32:50,342] {processor.py:153} INFO - Started process (PID=26102) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:50,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:32:50,347] {logging_mixin.py:115} INFO - [2022-10-19 17:32:50,347] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:50,362] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:32:50,385] {logging_mixin.py:115} INFO - [2022-10-19 17:32:50,385] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:32:50,420] {logging_mixin.py:115} INFO - [2022-10-19 17:32:50,419] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:32:50.361586+00:00, run_after=2022-10-20T17:32:50.361586+00:00
[2022-10-19 17:32:50,440] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.104 seconds
[2022-10-19 17:33:20,081] {processor.py:153} INFO - Started process (PID=35575) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:20,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:33:20,084] {logging_mixin.py:115} INFO - [2022-10-19 17:33:20,084] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:20,094] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:20,181] {logging_mixin.py:115} INFO - [2022-10-19 17:33:20,181] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:33:20,210] {logging_mixin.py:115} INFO - [2022-10-19 17:33:20,210] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:33:20.093330+00:00, run_after=2022-10-20T17:33:20.093330+00:00
[2022-10-19 17:33:20,231] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 17:33:20,639] {processor.py:153} INFO - Started process (PID=26131) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:20,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:33:20,642] {logging_mixin.py:115} INFO - [2022-10-19 17:33:20,642] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:20,652] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:20,672] {logging_mixin.py:115} INFO - [2022-10-19 17:33:20,672] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:33:20,703] {logging_mixin.py:115} INFO - [2022-10-19 17:33:20,702] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:33:20.651835+00:00, run_after=2022-10-20T17:33:20.651835+00:00
[2022-10-19 17:33:20,721] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 17:33:50,611] {processor.py:153} INFO - Started process (PID=35609) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:50,613] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:33:50,614] {logging_mixin.py:115} INFO - [2022-10-19 17:33:50,614] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:50,625] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:50,704] {logging_mixin.py:115} INFO - [2022-10-19 17:33:50,704] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:33:50,732] {logging_mixin.py:115} INFO - [2022-10-19 17:33:50,732] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:33:50.624241+00:00, run_after=2022-10-20T17:33:50.624241+00:00
[2022-10-19 17:33:50,748] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.142 seconds
[2022-10-19 17:33:50,907] {processor.py:153} INFO - Started process (PID=26169) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:50,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:33:50,910] {logging_mixin.py:115} INFO - [2022-10-19 17:33:50,910] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:50,920] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:33:50,940] {logging_mixin.py:115} INFO - [2022-10-19 17:33:50,940] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:33:50,969] {logging_mixin.py:115} INFO - [2022-10-19 17:33:50,969] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:33:50.919236+00:00, run_after=2022-10-20T17:33:50.919236+00:00
[2022-10-19 17:33:50,986] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 17:34:21,108] {processor.py:153} INFO - Started process (PID=26209) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:21,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:34:21,111] {logging_mixin.py:115} INFO - [2022-10-19 17:34:21,111] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:21,118] {processor.py:153} INFO - Started process (PID=35641) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:21,120] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:34:21,121] {logging_mixin.py:115} INFO - [2022-10-19 17:34:21,121] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:21,129] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:21,142] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:21,227] {logging_mixin.py:115} INFO - [2022-10-19 17:34:21,227] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:34:21,232] {logging_mixin.py:115} INFO - [2022-10-19 17:34:21,232] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:34:21,258] {logging_mixin.py:115} INFO - [2022-10-19 17:34:21,258] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:34:21.127751+00:00, run_after=2022-10-20T17:34:21.127751+00:00
[2022-10-19 17:34:21,275] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.172 seconds
[2022-10-19 17:34:21,285] {logging_mixin.py:115} INFO - [2022-10-19 17:34:21,285] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:34:21.140101+00:00, run_after=2022-10-20T17:34:21.140101+00:00
[2022-10-19 17:34:21,299] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.192 seconds
[2022-10-19 17:34:51,401] {processor.py:153} INFO - Started process (PID=26238) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:51,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:34:51,404] {logging_mixin.py:115} INFO - [2022-10-19 17:34:51,404] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:51,415] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:51,497] {logging_mixin.py:115} INFO - [2022-10-19 17:34:51,497] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:34:51,524] {logging_mixin.py:115} INFO - [2022-10-19 17:34:51,524] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:34:51.414585+00:00, run_after=2022-10-20T17:34:51.414585+00:00
[2022-10-19 17:34:51,542] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.147 seconds
[2022-10-19 17:34:51,665] {processor.py:153} INFO - Started process (PID=35674) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:51,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:34:51,667] {logging_mixin.py:115} INFO - [2022-10-19 17:34:51,667] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:51,679] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:34:51,701] {logging_mixin.py:115} INFO - [2022-10-19 17:34:51,701] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:34:51,736] {logging_mixin.py:115} INFO - [2022-10-19 17:34:51,736] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:34:51.678059+00:00, run_after=2022-10-20T17:34:51.678059+00:00
[2022-10-19 17:34:51,751] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.090 seconds
[2022-10-19 17:35:21,688] {processor.py:153} INFO - Started process (PID=26276) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:21,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:35:21,691] {logging_mixin.py:115} INFO - [2022-10-19 17:35:21,690] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:21,704] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:21,784] {logging_mixin.py:115} INFO - [2022-10-19 17:35:21,784] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:35:21,809] {logging_mixin.py:115} INFO - [2022-10-19 17:35:21,809] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:35:21.703024+00:00, run_after=2022-10-20T17:35:21.703024+00:00
[2022-10-19 17:35:21,828] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:35:21,897] {processor.py:153} INFO - Started process (PID=35706) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:21,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:35:21,899] {logging_mixin.py:115} INFO - [2022-10-19 17:35:21,899] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:21,910] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:21,930] {logging_mixin.py:115} INFO - [2022-10-19 17:35:21,930] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:35:21,960] {logging_mixin.py:115} INFO - [2022-10-19 17:35:21,960] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:35:21.909313+00:00, run_after=2022-10-20T17:35:21.909313+00:00
[2022-10-19 17:35:21,977] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:35:51,880] {processor.py:153} INFO - Started process (PID=26305) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:51,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:35:51,883] {logging_mixin.py:115} INFO - [2022-10-19 17:35:51,883] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:51,893] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:51,973] {logging_mixin.py:115} INFO - [2022-10-19 17:35:51,972] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:35:52,001] {logging_mixin.py:115} INFO - [2022-10-19 17:35:52,001] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:35:51.892394+00:00, run_after=2022-10-20T17:35:51.892394+00:00
[2022-10-19 17:35:52,005] {processor.py:153} INFO - Started process (PID=35738) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:52,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:35:52,008] {logging_mixin.py:115} INFO - [2022-10-19 17:35:52,008] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:52,019] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:35:52,021] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.146 seconds
[2022-10-19 17:35:52,043] {logging_mixin.py:115} INFO - [2022-10-19 17:35:52,043] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:35:52,077] {logging_mixin.py:115} INFO - [2022-10-19 17:35:52,077] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:35:52.018071+00:00, run_after=2022-10-20T17:35:52.018071+00:00
[2022-10-19 17:35:52,097] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.096 seconds
[2022-10-19 17:36:22,078] {processor.py:153} INFO - Started process (PID=26343) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:22,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:36:22,081] {logging_mixin.py:115} INFO - [2022-10-19 17:36:22,081] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:22,093] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:22,175] {logging_mixin.py:115} INFO - [2022-10-19 17:36:22,174] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:36:22,200] {logging_mixin.py:115} INFO - [2022-10-19 17:36:22,200] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:36:22.091862+00:00, run_after=2022-10-20T17:36:22.091862+00:00
[2022-10-19 17:36:22,220] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.147 seconds
[2022-10-19 17:36:22,223] {processor.py:153} INFO - Started process (PID=35770) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:22,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:36:22,226] {logging_mixin.py:115} INFO - [2022-10-19 17:36:22,226] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:22,237] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:22,257] {logging_mixin.py:115} INFO - [2022-10-19 17:36:22,257] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:36:22,288] {logging_mixin.py:115} INFO - [2022-10-19 17:36:22,287] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:36:22.236591+00:00, run_after=2022-10-20T17:36:22.236591+00:00
[2022-10-19 17:36:22,304] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:36:52,264] {processor.py:153} INFO - Started process (PID=26382) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:52,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:36:52,267] {logging_mixin.py:115} INFO - [2022-10-19 17:36:52,267] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:52,279] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:52,357] {processor.py:153} INFO - Started process (PID=35801) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:52,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:36:52,360] {logging_mixin.py:115} INFO - [2022-10-19 17:36:52,360] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:52,371] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:36:52,380] {logging_mixin.py:115} INFO - [2022-10-19 17:36:52,380] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:36:52,409] {logging_mixin.py:115} INFO - [2022-10-19 17:36:52,409] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:36:52.278637+00:00, run_after=2022-10-20T17:36:52.278637+00:00
[2022-10-19 17:36:52,431] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.171 seconds
[2022-10-19 17:36:52,484] {logging_mixin.py:115} INFO - [2022-10-19 17:36:52,483] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:36:52,516] {logging_mixin.py:115} INFO - [2022-10-19 17:36:52,516] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:36:52.370665+00:00, run_after=2022-10-20T17:36:52.370665+00:00
[2022-10-19 17:36:52,533] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.182 seconds
[2022-10-19 17:37:22,554] {processor.py:153} INFO - Started process (PID=26412) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:22,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:37:22,557] {logging_mixin.py:115} INFO - [2022-10-19 17:37:22,557] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:22,567] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:22,649] {logging_mixin.py:115} INFO - [2022-10-19 17:37:22,649] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:37:22,674] {logging_mixin.py:115} INFO - [2022-10-19 17:37:22,674] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:37:22.566224+00:00, run_after=2022-10-20T17:37:22.566224+00:00
[2022-10-19 17:37:22,693] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 17:37:23,174] {processor.py:153} INFO - Started process (PID=35833) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:23,175] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:37:23,176] {logging_mixin.py:115} INFO - [2022-10-19 17:37:23,176] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:23,186] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:23,207] {logging_mixin.py:115} INFO - [2022-10-19 17:37:23,206] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:37:23,237] {logging_mixin.py:115} INFO - [2022-10-19 17:37:23,237] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:37:23.185891+00:00, run_after=2022-10-20T17:37:23.185891+00:00
[2022-10-19 17:37:23,253] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 17:37:52,745] {processor.py:153} INFO - Started process (PID=26450) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:52,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:37:52,747] {logging_mixin.py:115} INFO - [2022-10-19 17:37:52,747] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:52,758] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:52,840] {logging_mixin.py:115} INFO - [2022-10-19 17:37:52,840] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:37:52,865] {logging_mixin.py:115} INFO - [2022-10-19 17:37:52,865] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:37:52.757605+00:00, run_after=2022-10-20T17:37:52.757605+00:00
[2022-10-19 17:37:52,885] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:37:53,284] {processor.py:153} INFO - Started process (PID=35867) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:53,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:37:53,286] {logging_mixin.py:115} INFO - [2022-10-19 17:37:53,286] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:53,296] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:37:53,316] {logging_mixin.py:115} INFO - [2022-10-19 17:37:53,316] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:37:53,348] {logging_mixin.py:115} INFO - [2022-10-19 17:37:53,348] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:37:53.295951+00:00, run_after=2022-10-20T17:37:53.295951+00:00
[2022-10-19 17:37:53,363] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.084 seconds
[2022-10-19 17:38:23,106] {processor.py:153} INFO - Started process (PID=26479) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:23,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:38:23,109] {logging_mixin.py:115} INFO - [2022-10-19 17:38:23,109] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:23,120] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:23,206] {logging_mixin.py:115} INFO - [2022-10-19 17:38:23,206] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:38:23,235] {logging_mixin.py:115} INFO - [2022-10-19 17:38:23,235] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:38:23.119382+00:00, run_after=2022-10-20T17:38:23.119382+00:00
[2022-10-19 17:38:23,258] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 17:38:23,583] {processor.py:153} INFO - Started process (PID=35900) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:23,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:38:23,585] {logging_mixin.py:115} INFO - [2022-10-19 17:38:23,585] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:23,596] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:23,616] {logging_mixin.py:115} INFO - [2022-10-19 17:38:23,616] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:38:23,647] {logging_mixin.py:115} INFO - [2022-10-19 17:38:23,647] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:38:23.594720+00:00, run_after=2022-10-20T17:38:23.594720+00:00
[2022-10-19 17:38:23,665] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:38:53,421] {processor.py:153} INFO - Started process (PID=26518) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:53,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:38:53,423] {logging_mixin.py:115} INFO - [2022-10-19 17:38:53,423] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:53,435] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:53,523] {logging_mixin.py:115} INFO - [2022-10-19 17:38:53,523] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:38:53,549] {logging_mixin.py:115} INFO - [2022-10-19 17:38:53,549] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:38:53.434595+00:00, run_after=2022-10-20T17:38:53.434595+00:00
[2022-10-19 17:38:53,568] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.152 seconds
[2022-10-19 17:38:53,867] {processor.py:153} INFO - Started process (PID=35932) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:53,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:38:53,870] {logging_mixin.py:115} INFO - [2022-10-19 17:38:53,869] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:53,880] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:38:53,900] {logging_mixin.py:115} INFO - [2022-10-19 17:38:53,900] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:38:53,931] {logging_mixin.py:115} INFO - [2022-10-19 17:38:53,931] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:38:53.879472+00:00, run_after=2022-10-20T17:38:53.879472+00:00
[2022-10-19 17:38:53,948] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:39:23,730] {processor.py:153} INFO - Started process (PID=26557) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:23,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:39:23,732] {logging_mixin.py:115} INFO - [2022-10-19 17:39:23,732] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:23,743] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:23,825] {logging_mixin.py:115} INFO - [2022-10-19 17:39:23,825] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:39:23,856] {logging_mixin.py:115} INFO - [2022-10-19 17:39:23,856] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:39:23.742699+00:00, run_after=2022-10-20T17:39:23.742699+00:00
[2022-10-19 17:39:23,876] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:39:24,245] {processor.py:153} INFO - Started process (PID=35964) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:24,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:39:24,248] {logging_mixin.py:115} INFO - [2022-10-19 17:39:24,248] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:24,259] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:24,279] {logging_mixin.py:115} INFO - [2022-10-19 17:39:24,279] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:39:24,309] {logging_mixin.py:115} INFO - [2022-10-19 17:39:24,309] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:39:24.258143+00:00, run_after=2022-10-20T17:39:24.258143+00:00
[2022-10-19 17:39:24,325] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.084 seconds
[2022-10-19 17:39:53,955] {processor.py:153} INFO - Started process (PID=26586) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:53,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:39:53,957] {logging_mixin.py:115} INFO - [2022-10-19 17:39:53,957] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:53,968] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:54,053] {logging_mixin.py:115} INFO - [2022-10-19 17:39:54,053] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:39:54,080] {logging_mixin.py:115} INFO - [2022-10-19 17:39:54,079] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:39:53.967857+00:00, run_after=2022-10-20T17:39:53.967857+00:00
[2022-10-19 17:39:54,098] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.148 seconds
[2022-10-19 17:39:54,519] {processor.py:153} INFO - Started process (PID=35996) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:54,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:39:54,521] {logging_mixin.py:115} INFO - [2022-10-19 17:39:54,521] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:54,533] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:39:54,553] {logging_mixin.py:115} INFO - [2022-10-19 17:39:54,553] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:39:54,584] {logging_mixin.py:115} INFO - [2022-10-19 17:39:54,584] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:39:54.532252+00:00, run_after=2022-10-20T17:39:54.532252+00:00
[2022-10-19 17:39:54,601] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 17:40:24,164] {processor.py:153} INFO - Started process (PID=26624) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:24,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:40:24,168] {logging_mixin.py:115} INFO - [2022-10-19 17:40:24,168] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:24,183] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:24,270] {logging_mixin.py:115} INFO - [2022-10-19 17:40:24,270] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:40:24,296] {logging_mixin.py:115} INFO - [2022-10-19 17:40:24,296] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:40:24.182460+00:00, run_after=2022-10-20T17:40:24.182460+00:00
[2022-10-19 17:40:24,315] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.158 seconds
[2022-10-19 17:40:24,812] {processor.py:153} INFO - Started process (PID=36029) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:24,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:40:24,814] {logging_mixin.py:115} INFO - [2022-10-19 17:40:24,814] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:24,825] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:24,846] {logging_mixin.py:115} INFO - [2022-10-19 17:40:24,845] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:40:24,875] {logging_mixin.py:115} INFO - [2022-10-19 17:40:24,875] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:40:24.823971+00:00, run_after=2022-10-20T17:40:24.823971+00:00
[2022-10-19 17:40:24,892] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:40:54,407] {processor.py:153} INFO - Started process (PID=26653) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:54,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:40:54,409] {logging_mixin.py:115} INFO - [2022-10-19 17:40:54,409] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:54,424] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:54,511] {logging_mixin.py:115} INFO - [2022-10-19 17:40:54,511] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:40:54,537] {logging_mixin.py:115} INFO - [2022-10-19 17:40:54,537] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:40:54.423140+00:00, run_after=2022-10-20T17:40:54.423140+00:00
[2022-10-19 17:40:54,556] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.157 seconds
[2022-10-19 17:40:54,969] {processor.py:153} INFO - Started process (PID=36061) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:54,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:40:54,972] {logging_mixin.py:115} INFO - [2022-10-19 17:40:54,972] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:54,986] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:40:55,007] {logging_mixin.py:115} INFO - [2022-10-19 17:40:55,007] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:40:55,043] {logging_mixin.py:115} INFO - [2022-10-19 17:40:55,043] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:40:54.985692+00:00, run_after=2022-10-20T17:40:54.985692+00:00
[2022-10-19 17:40:55,062] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.101 seconds
[2022-10-19 17:41:25,043] {processor.py:153} INFO - Started process (PID=26691) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:25,045] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:41:25,046] {logging_mixin.py:115} INFO - [2022-10-19 17:41:25,046] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:25,059] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:25,155] {logging_mixin.py:115} INFO - [2022-10-19 17:41:25,155] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:41:25,185] {logging_mixin.py:115} INFO - [2022-10-19 17:41:25,185] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:41:25.058010+00:00, run_after=2022-10-20T17:41:25.058010+00:00
[2022-10-19 17:41:25,203] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.167 seconds
[2022-10-19 17:41:25,252] {processor.py:153} INFO - Started process (PID=36094) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:25,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:41:25,255] {logging_mixin.py:115} INFO - [2022-10-19 17:41:25,255] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:25,268] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:25,289] {logging_mixin.py:115} INFO - [2022-10-19 17:41:25,289] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:41:25,321] {logging_mixin.py:115} INFO - [2022-10-19 17:41:25,321] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:41:25.267383+00:00, run_after=2022-10-20T17:41:25.267383+00:00
[2022-10-19 17:41:25,337] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.090 seconds
[2022-10-19 17:41:55,633] {processor.py:153} INFO - Started process (PID=26729) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:55,636] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:41:55,638] {logging_mixin.py:115} INFO - [2022-10-19 17:41:55,638] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:55,640] {processor.py:153} INFO - Started process (PID=36127) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:55,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:41:55,643] {logging_mixin.py:115} INFO - [2022-10-19 17:41:55,642] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:55,651] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:55,654] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:41:55,736] {logging_mixin.py:115} INFO - [2022-10-19 17:41:55,736] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:41:55,740] {logging_mixin.py:115} INFO - [2022-10-19 17:41:55,740] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:41:55,762] {logging_mixin.py:115} INFO - [2022-10-19 17:41:55,762] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:41:55.650311+00:00, run_after=2022-10-20T17:41:55.650311+00:00
[2022-10-19 17:41:55,781] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.154 seconds
[2022-10-19 17:41:55,796] {logging_mixin.py:115} INFO - [2022-10-19 17:41:55,796] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:41:55.653242+00:00, run_after=2022-10-20T17:41:55.653242+00:00
[2022-10-19 17:41:55,811] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.177 seconds
[2022-10-19 17:42:25,927] {processor.py:153} INFO - Started process (PID=36159) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:25,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:42:25,932] {logging_mixin.py:115} INFO - [2022-10-19 17:42:25,932] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:25,955] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:26,054] {logging_mixin.py:115} INFO - [2022-10-19 17:42:26,054] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:42:26,081] {logging_mixin.py:115} INFO - [2022-10-19 17:42:26,081] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:42:25.953991+00:00, run_after=2022-10-20T17:42:25.953991+00:00
[2022-10-19 17:42:26,099] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.179 seconds
[2022-10-19 17:42:26,286] {processor.py:153} INFO - Started process (PID=26758) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:26,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:42:26,290] {logging_mixin.py:115} INFO - [2022-10-19 17:42:26,289] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:26,300] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:26,322] {logging_mixin.py:115} INFO - [2022-10-19 17:42:26,322] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:42:26,352] {logging_mixin.py:115} INFO - [2022-10-19 17:42:26,352] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:42:26.299851+00:00, run_after=2022-10-20T17:42:26.299851+00:00
[2022-10-19 17:42:26,371] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.089 seconds
[2022-10-19 17:42:56,282] {processor.py:153} INFO - Started process (PID=36192) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:56,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:42:56,286] {logging_mixin.py:115} INFO - [2022-10-19 17:42:56,286] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:56,297] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:56,382] {logging_mixin.py:115} INFO - [2022-10-19 17:42:56,382] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:42:56,408] {logging_mixin.py:115} INFO - [2022-10-19 17:42:56,408] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:42:56.296226+00:00, run_after=2022-10-20T17:42:56.296226+00:00
[2022-10-19 17:42:56,427] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.150 seconds
[2022-10-19 17:42:57,036] {processor.py:153} INFO - Started process (PID=26797) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:57,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:42:57,039] {logging_mixin.py:115} INFO - [2022-10-19 17:42:57,038] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:57,051] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:42:57,072] {logging_mixin.py:115} INFO - [2022-10-19 17:42:57,072] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:42:57,103] {logging_mixin.py:115} INFO - [2022-10-19 17:42:57,103] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:42:57.050749+00:00, run_after=2022-10-20T17:42:57.050749+00:00
[2022-10-19 17:42:57,122] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.091 seconds
[2022-10-19 17:43:26,693] {processor.py:153} INFO - Started process (PID=36225) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:26,696] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:43:26,698] {logging_mixin.py:115} INFO - [2022-10-19 17:43:26,698] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:26,713] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:26,800] {logging_mixin.py:115} INFO - [2022-10-19 17:43:26,800] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:43:26,830] {logging_mixin.py:115} INFO - [2022-10-19 17:43:26,830] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:43:26.711834+00:00, run_after=2022-10-20T17:43:26.711834+00:00
[2022-10-19 17:43:26,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.167 seconds
[2022-10-19 17:43:27,641] {processor.py:153} INFO - Started process (PID=26835) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:27,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:43:27,643] {logging_mixin.py:115} INFO - [2022-10-19 17:43:27,643] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:27,654] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:28,358] {logging_mixin.py:115} INFO - [2022-10-19 17:43:28,358] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:43:28,399] {logging_mixin.py:115} INFO - [2022-10-19 17:43:28,399] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:43:27.653603+00:00, run_after=2022-10-20T17:43:27.653603+00:00
[2022-10-19 17:43:28,414] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.778 seconds
[2022-10-19 17:43:57,210] {processor.py:153} INFO - Started process (PID=36258) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:57,213] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:43:57,215] {logging_mixin.py:115} INFO - [2022-10-19 17:43:57,215] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:57,227] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:57,318] {logging_mixin.py:115} INFO - [2022-10-19 17:43:57,317] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:43:57,353] {logging_mixin.py:115} INFO - [2022-10-19 17:43:57,353] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:43:57.226308+00:00, run_after=2022-10-20T17:43:57.226308+00:00
[2022-10-19 17:43:57,369] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.164 seconds
[2022-10-19 17:43:58,637] {processor.py:153} INFO - Started process (PID=26864) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:58,638] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:43:58,639] {logging_mixin.py:115} INFO - [2022-10-19 17:43:58,639] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:58,650] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:43:58,674] {logging_mixin.py:115} INFO - [2022-10-19 17:43:58,674] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:43:58,704] {logging_mixin.py:115} INFO - [2022-10-19 17:43:58,704] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:43:58.649278+00:00, run_after=2022-10-20T17:43:58.649278+00:00
[2022-10-19 17:43:58,722] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.091 seconds
[2022-10-19 17:44:27,571] {processor.py:153} INFO - Started process (PID=36290) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:27,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:44:27,575] {logging_mixin.py:115} INFO - [2022-10-19 17:44:27,575] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:27,586] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:27,668] {logging_mixin.py:115} INFO - [2022-10-19 17:44:27,668] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:44:27,695] {logging_mixin.py:115} INFO - [2022-10-19 17:44:27,695] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:44:27.585071+00:00, run_after=2022-10-20T17:44:27.585071+00:00
[2022-10-19 17:44:27,710] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.144 seconds
[2022-10-19 17:44:28,835] {processor.py:153} INFO - Started process (PID=26902) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:28,836] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:44:28,838] {logging_mixin.py:115} INFO - [2022-10-19 17:44:28,837] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:28,849] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:28,869] {logging_mixin.py:115} INFO - [2022-10-19 17:44:28,868] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:44:28,899] {logging_mixin.py:115} INFO - [2022-10-19 17:44:28,899] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:44:28.847924+00:00, run_after=2022-10-20T17:44:28.847924+00:00
[2022-10-19 17:44:28,917] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 17:44:58,554] {processor.py:153} INFO - Started process (PID=36323) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:58,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:44:58,557] {logging_mixin.py:115} INFO - [2022-10-19 17:44:58,556] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:58,567] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:58,650] {logging_mixin.py:115} INFO - [2022-10-19 17:44:58,650] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:44:58,676] {logging_mixin.py:115} INFO - [2022-10-19 17:44:58,676] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:44:58.566749+00:00, run_after=2022-10-20T17:44:58.566749+00:00
[2022-10-19 17:44:58,694] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.144 seconds
[2022-10-19 17:44:59,303] {processor.py:153} INFO - Started process (PID=26931) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:59,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:44:59,307] {logging_mixin.py:115} INFO - [2022-10-19 17:44:59,307] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:59,319] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:44:59,340] {logging_mixin.py:115} INFO - [2022-10-19 17:44:59,339] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:44:59,377] {logging_mixin.py:115} INFO - [2022-10-19 17:44:59,377] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:44:59.318871+00:00, run_after=2022-10-20T17:44:59.318871+00:00
[2022-10-19 17:44:59,394] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.098 seconds
[2022-10-19 17:45:28,845] {processor.py:153} INFO - Started process (PID=36338) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:28,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:45:28,850] {logging_mixin.py:115} INFO - [2022-10-19 17:45:28,850] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:28,865] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:29,005] {logging_mixin.py:115} INFO - [2022-10-19 17:45:29,005] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:45:29,047] {logging_mixin.py:115} INFO - [2022-10-19 17:45:29,047] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:45:28.864653+00:00, run_after=2022-10-20T17:45:28.864653+00:00
[2022-10-19 17:45:29,115] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.276 seconds
[2022-10-19 17:45:29,452] {processor.py:153} INFO - Started process (PID=26971) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:29,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:45:29,456] {logging_mixin.py:115} INFO - [2022-10-19 17:45:29,456] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:29,469] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:29,492] {logging_mixin.py:115} INFO - [2022-10-19 17:45:29,491] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:45:29,523] {logging_mixin.py:115} INFO - [2022-10-19 17:45:29,523] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:45:29.468127+00:00, run_after=2022-10-20T17:45:29.468127+00:00
[2022-10-19 17:45:29,541] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.095 seconds
[2022-10-19 17:45:59,440] {processor.py:153} INFO - Started process (PID=36356) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:59,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:45:59,444] {logging_mixin.py:115} INFO - [2022-10-19 17:45:59,444] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:59,463] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:59,552] {logging_mixin.py:115} INFO - [2022-10-19 17:45:59,551] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:45:59,579] {logging_mixin.py:115} INFO - [2022-10-19 17:45:59,579] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:45:59.462151+00:00, run_after=2022-10-20T17:45:59.462151+00:00
[2022-10-19 17:45:59,597] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.165 seconds
[2022-10-19 17:45:59,660] {processor.py:153} INFO - Started process (PID=27009) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:59,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:45:59,663] {logging_mixin.py:115} INFO - [2022-10-19 17:45:59,663] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:59,676] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:45:59,701] {logging_mixin.py:115} INFO - [2022-10-19 17:45:59,700] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:45:59,749] {logging_mixin.py:115} INFO - [2022-10-19 17:45:59,749] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:45:59.675504+00:00, run_after=2022-10-20T17:45:59.675504+00:00
[2022-10-19 17:45:59,764] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.108 seconds
[2022-10-19 17:46:29,820] {processor.py:153} INFO - Started process (PID=36388) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:46:29,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:46:29,822] {logging_mixin.py:115} INFO - [2022-10-19 17:46:29,822] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:46:29,832] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:46:29,917] {logging_mixin.py:115} INFO - [2022-10-19 17:46:29,917] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:46:29,943] {logging_mixin.py:115} INFO - [2022-10-19 17:46:29,943] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:46:29.831530+00:00, run_after=2022-10-20T17:46:29.831530+00:00
[2022-10-19 17:46:29,961] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.146 seconds
[2022-10-19 17:46:30,141] {processor.py:153} INFO - Started process (PID=27038) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:46:30,142] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:46:30,144] {logging_mixin.py:115} INFO - [2022-10-19 17:46:30,144] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:46:30,160] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:46:30,184] {logging_mixin.py:115} INFO - [2022-10-19 17:46:30,184] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:46:30,220] {logging_mixin.py:115} INFO - [2022-10-19 17:46:30,219] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:46:30.158584+00:00, run_after=2022-10-20T17:46:30.158584+00:00
[2022-10-19 17:46:30,239] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.105 seconds
[2022-10-19 17:47:00,031] {processor.py:153} INFO - Started process (PID=36419) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:00,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:47:00,034] {logging_mixin.py:115} INFO - [2022-10-19 17:47:00,034] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:00,045] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:00,152] {logging_mixin.py:115} INFO - [2022-10-19 17:47:00,152] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:47:00,181] {logging_mixin.py:115} INFO - [2022-10-19 17:47:00,181] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:47:00.044146+00:00, run_after=2022-10-20T17:47:00.044146+00:00
[2022-10-19 17:47:00,201] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.175 seconds
[2022-10-19 17:47:00,552] {processor.py:153} INFO - Started process (PID=27076) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:00,553] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:47:00,555] {logging_mixin.py:115} INFO - [2022-10-19 17:47:00,555] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:00,567] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:00,589] {logging_mixin.py:115} INFO - [2022-10-19 17:47:00,589] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:47:00,618] {logging_mixin.py:115} INFO - [2022-10-19 17:47:00,618] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:47:00.566247+00:00, run_after=2022-10-20T17:47:00.566247+00:00
[2022-10-19 17:47:00,637] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.091 seconds
[2022-10-19 17:47:30,399] {processor.py:153} INFO - Started process (PID=36452) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:30,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:47:30,401] {logging_mixin.py:115} INFO - [2022-10-19 17:47:30,401] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:30,413] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:30,499] {logging_mixin.py:115} INFO - [2022-10-19 17:47:30,499] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:47:30,528] {logging_mixin.py:115} INFO - [2022-10-19 17:47:30,527] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:47:30.412394+00:00, run_after=2022-10-20T17:47:30.412394+00:00
[2022-10-19 17:47:30,548] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.154 seconds
[2022-10-19 17:47:31,054] {processor.py:153} INFO - Started process (PID=27106) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:31,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:47:31,059] {logging_mixin.py:115} INFO - [2022-10-19 17:47:31,058] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:31,075] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:47:31,098] {logging_mixin.py:115} INFO - [2022-10-19 17:47:31,098] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:47:31,131] {logging_mixin.py:115} INFO - [2022-10-19 17:47:31,131] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:47:31.074525+00:00, run_after=2022-10-20T17:47:31.074525+00:00
[2022-10-19 17:47:31,153] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.107 seconds
[2022-10-19 17:48:00,659] {processor.py:153} INFO - Started process (PID=36484) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:00,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:48:00,664] {logging_mixin.py:115} INFO - [2022-10-19 17:48:00,664] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:00,677] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:00,786] {logging_mixin.py:115} INFO - [2022-10-19 17:48:00,786] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:48:00,817] {logging_mixin.py:115} INFO - [2022-10-19 17:48:00,817] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:48:00.676080+00:00, run_after=2022-10-20T17:48:00.676080+00:00
[2022-10-19 17:48:00,833] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.179 seconds
[2022-10-19 17:48:01,746] {processor.py:153} INFO - Started process (PID=27146) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:01,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:48:01,749] {logging_mixin.py:115} INFO - [2022-10-19 17:48:01,749] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:01,761] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:01,781] {logging_mixin.py:115} INFO - [2022-10-19 17:48:01,781] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:48:01,816] {logging_mixin.py:115} INFO - [2022-10-19 17:48:01,815] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:48:01.759927+00:00, run_after=2022-10-20T17:48:01.759927+00:00
[2022-10-19 17:48:01,835] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.095 seconds
[2022-10-19 17:48:31,122] {processor.py:153} INFO - Started process (PID=36517) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:31,124] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:48:31,125] {logging_mixin.py:115} INFO - [2022-10-19 17:48:31,125] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:31,139] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:31,226] {logging_mixin.py:115} INFO - [2022-10-19 17:48:31,226] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:48:31,263] {logging_mixin.py:115} INFO - [2022-10-19 17:48:31,263] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:48:31.138580+00:00, run_after=2022-10-20T17:48:31.138580+00:00
[2022-10-19 17:48:31,283] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.166 seconds
[2022-10-19 17:48:31,961] {processor.py:153} INFO - Started process (PID=27175) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:31,963] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:48:31,964] {logging_mixin.py:115} INFO - [2022-10-19 17:48:31,964] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:31,979] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:48:32,004] {logging_mixin.py:115} INFO - [2022-10-19 17:48:32,004] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:48:32,037] {logging_mixin.py:115} INFO - [2022-10-19 17:48:32,037] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:48:31.978313+00:00, run_after=2022-10-20T17:48:31.978313+00:00
[2022-10-19 17:48:32,056] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.104 seconds
[2022-10-19 17:49:01,372] {processor.py:153} INFO - Started process (PID=36549) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:01,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:49:01,375] {logging_mixin.py:115} INFO - [2022-10-19 17:49:01,375] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:01,395] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:01,493] {logging_mixin.py:115} INFO - [2022-10-19 17:49:01,493] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:49:01,526] {logging_mixin.py:115} INFO - [2022-10-19 17:49:01,526] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:49:01.394490+00:00, run_after=2022-10-20T17:49:01.394490+00:00
[2022-10-19 17:49:01,555] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.191 seconds
[2022-10-19 17:49:02,849] {processor.py:153} INFO - Started process (PID=27211) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:02,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:49:02,853] {logging_mixin.py:115} INFO - [2022-10-19 17:49:02,853] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:02,864] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:02,883] {logging_mixin.py:115} INFO - [2022-10-19 17:49:02,883] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:49:02,930] {logging_mixin.py:115} INFO - [2022-10-19 17:49:02,929] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:49:02.862747+00:00, run_after=2022-10-20T17:49:02.862747+00:00
[2022-10-19 17:49:02,945] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.102 seconds
[2022-10-19 17:49:32,303] {processor.py:153} INFO - Started process (PID=36580) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:32,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:49:32,308] {logging_mixin.py:115} INFO - [2022-10-19 17:49:32,308] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:32,318] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:32,403] {logging_mixin.py:115} INFO - [2022-10-19 17:49:32,403] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:49:32,431] {logging_mixin.py:115} INFO - [2022-10-19 17:49:32,430] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:49:32.317504+00:00, run_after=2022-10-20T17:49:32.317504+00:00
[2022-10-19 17:49:32,450] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:49:33,048] {processor.py:153} INFO - Started process (PID=27249) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:33,050] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:49:33,051] {logging_mixin.py:115} INFO - [2022-10-19 17:49:33,051] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:33,062] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:49:33,083] {logging_mixin.py:115} INFO - [2022-10-19 17:49:33,083] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:49:33,115] {logging_mixin.py:115} INFO - [2022-10-19 17:49:33,115] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:49:33.061519+00:00, run_after=2022-10-20T17:49:33.061519+00:00
[2022-10-19 17:49:33,130] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 17:50:02,498] {processor.py:153} INFO - Started process (PID=36612) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:02,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:50:02,500] {logging_mixin.py:115} INFO - [2022-10-19 17:50:02,500] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:02,512] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:02,599] {logging_mixin.py:115} INFO - [2022-10-19 17:50:02,599] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:50:02,625] {logging_mixin.py:115} INFO - [2022-10-19 17:50:02,624] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:50:02.510730+00:00, run_after=2022-10-20T17:50:02.510730+00:00
[2022-10-19 17:50:02,642] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.149 seconds
[2022-10-19 17:50:03,823] {processor.py:153} INFO - Started process (PID=27274) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:03,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:50:03,825] {logging_mixin.py:115} INFO - [2022-10-19 17:50:03,825] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:03,837] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:03,859] {logging_mixin.py:115} INFO - [2022-10-19 17:50:03,859] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:50:03,893] {logging_mixin.py:115} INFO - [2022-10-19 17:50:03,893] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:50:03.836757+00:00, run_after=2022-10-20T17:50:03.836757+00:00
[2022-10-19 17:50:03,910] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.092 seconds
[2022-10-19 17:50:33,357] {processor.py:153} INFO - Started process (PID=36645) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:33,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:50:33,359] {logging_mixin.py:115} INFO - [2022-10-19 17:50:33,359] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:33,372] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:33,462] {logging_mixin.py:115} INFO - [2022-10-19 17:50:33,462] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:50:33,491] {logging_mixin.py:115} INFO - [2022-10-19 17:50:33,491] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:50:33.370957+00:00, run_after=2022-10-20T17:50:33.370957+00:00
[2022-10-19 17:50:33,510] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.159 seconds
[2022-10-19 17:50:34,193] {processor.py:153} INFO - Started process (PID=27312) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:34,195] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:50:34,196] {logging_mixin.py:115} INFO - [2022-10-19 17:50:34,196] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:34,207] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:50:34,227] {logging_mixin.py:115} INFO - [2022-10-19 17:50:34,226] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:50:34,257] {logging_mixin.py:115} INFO - [2022-10-19 17:50:34,256] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:50:34.206353+00:00, run_after=2022-10-20T17:50:34.206353+00:00
[2022-10-19 17:50:34,271] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.082 seconds
[2022-10-19 17:51:03,824] {processor.py:153} INFO - Started process (PID=36677) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:03,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:51:03,828] {logging_mixin.py:115} INFO - [2022-10-19 17:51:03,828] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:03,840] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:03,925] {logging_mixin.py:115} INFO - [2022-10-19 17:51:03,924] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:51:03,952] {logging_mixin.py:115} INFO - [2022-10-19 17:51:03,951] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:51:03.839116+00:00, run_after=2022-10-20T17:51:03.839116+00:00
[2022-10-19 17:51:03,970] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:51:04,423] {processor.py:153} INFO - Started process (PID=27350) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:04,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:51:04,427] {logging_mixin.py:115} INFO - [2022-10-19 17:51:04,426] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:04,439] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:04,465] {logging_mixin.py:115} INFO - [2022-10-19 17:51:04,465] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:51:04,496] {logging_mixin.py:115} INFO - [2022-10-19 17:51:04,496] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:51:04.438554+00:00, run_after=2022-10-20T17:51:04.438554+00:00
[2022-10-19 17:51:04,513] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.095 seconds
[2022-10-19 17:51:34,419] {processor.py:153} INFO - Started process (PID=36710) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:34,420] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:51:34,421] {logging_mixin.py:115} INFO - [2022-10-19 17:51:34,421] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:34,438] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:34,527] {logging_mixin.py:115} INFO - [2022-10-19 17:51:34,527] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:51:34,556] {logging_mixin.py:115} INFO - [2022-10-19 17:51:34,555] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:51:34.436817+00:00, run_after=2022-10-20T17:51:34.436817+00:00
[2022-10-19 17:51:34,581] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.169 seconds
[2022-10-19 17:51:34,671] {processor.py:153} INFO - Started process (PID=27380) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:34,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:51:34,674] {logging_mixin.py:115} INFO - [2022-10-19 17:51:34,673] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:34,687] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:51:34,708] {logging_mixin.py:115} INFO - [2022-10-19 17:51:34,708] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:51:34,740] {logging_mixin.py:115} INFO - [2022-10-19 17:51:34,740] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:51:34.685796+00:00, run_after=2022-10-20T17:51:34.685796+00:00
[2022-10-19 17:51:34,755] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.089 seconds
[2022-10-19 17:52:04,844] {processor.py:153} INFO - Started process (PID=27418) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:04,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:52:04,846] {logging_mixin.py:115} INFO - [2022-10-19 17:52:04,846] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:04,857] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:04,941] {logging_mixin.py:115} INFO - [2022-10-19 17:52:04,941] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:52:04,967] {logging_mixin.py:115} INFO - [2022-10-19 17:52:04,967] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:52:04.856479+00:00, run_after=2022-10-20T17:52:04.856479+00:00
[2022-10-19 17:52:04,985] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:52:05,015] {processor.py:153} INFO - Started process (PID=36742) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:05,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:52:05,017] {logging_mixin.py:115} INFO - [2022-10-19 17:52:05,017] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:05,028] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:05,049] {logging_mixin.py:115} INFO - [2022-10-19 17:52:05,049] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:52:05,080] {logging_mixin.py:115} INFO - [2022-10-19 17:52:05,080] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:52:05.027803+00:00, run_after=2022-10-20T17:52:05.027803+00:00
[2022-10-19 17:52:05,094] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.084 seconds
[2022-10-19 17:52:35,340] {processor.py:153} INFO - Started process (PID=27447) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:35,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:52:35,345] {logging_mixin.py:115} INFO - [2022-10-19 17:52:35,345] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:35,367] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:35,369] {processor.py:153} INFO - Started process (PID=36775) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:35,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:52:35,373] {logging_mixin.py:115} INFO - [2022-10-19 17:52:35,373] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:35,389] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:52:35,474] {logging_mixin.py:115} INFO - [2022-10-19 17:52:35,474] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:52:35,490] {logging_mixin.py:115} INFO - [2022-10-19 17:52:35,490] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:52:35,506] {logging_mixin.py:115} INFO - [2022-10-19 17:52:35,506] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:52:35.364837+00:00, run_after=2022-10-20T17:52:35.364837+00:00
[2022-10-19 17:52:35,522] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.188 seconds
[2022-10-19 17:52:35,536] {logging_mixin.py:115} INFO - [2022-10-19 17:52:35,536] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:52:35.387622+00:00, run_after=2022-10-20T17:52:35.387622+00:00
[2022-10-19 17:52:35,552] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.192 seconds
[2022-10-19 17:53:05,660] {processor.py:153} INFO - Started process (PID=36808) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:05,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:53:05,663] {logging_mixin.py:115} INFO - [2022-10-19 17:53:05,663] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:05,675] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:05,759] {logging_mixin.py:115} INFO - [2022-10-19 17:53:05,759] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:53:05,786] {logging_mixin.py:115} INFO - [2022-10-19 17:53:05,786] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:53:05.674300+00:00, run_after=2022-10-20T17:53:05.674300+00:00
[2022-10-19 17:53:05,808] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.154 seconds
[2022-10-19 17:53:06,343] {processor.py:153} INFO - Started process (PID=27485) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:06,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:53:06,349] {logging_mixin.py:115} INFO - [2022-10-19 17:53:06,349] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:06,362] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:06,386] {logging_mixin.py:115} INFO - [2022-10-19 17:53:06,386] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:53:06,418] {logging_mixin.py:115} INFO - [2022-10-19 17:53:06,418] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:53:06.360368+00:00, run_after=2022-10-20T17:53:06.360368+00:00
[2022-10-19 17:53:06,435] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.097 seconds
[2022-10-19 17:53:36,527] {processor.py:153} INFO - Started process (PID=36841) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:36,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:53:36,530] {logging_mixin.py:115} INFO - [2022-10-19 17:53:36,530] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:36,543] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:36,562] {processor.py:153} INFO - Started process (PID=27523) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:36,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:53:36,565] {logging_mixin.py:115} INFO - [2022-10-19 17:53:36,565] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:36,588] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:53:36,640] {logging_mixin.py:115} INFO - [2022-10-19 17:53:36,640] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:53:36,667] {logging_mixin.py:115} INFO - [2022-10-19 17:53:36,667] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:53:36.541241+00:00, run_after=2022-10-20T17:53:36.541241+00:00
[2022-10-19 17:53:36,681] {logging_mixin.py:115} INFO - [2022-10-19 17:53:36,681] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:53:36,685] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.164 seconds
[2022-10-19 17:53:36,707] {logging_mixin.py:115} INFO - [2022-10-19 17:53:36,707] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:53:36.587448+00:00, run_after=2022-10-20T17:53:36.587448+00:00
[2022-10-19 17:53:36,731] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.177 seconds
[2022-10-19 17:54:07,036] {processor.py:153} INFO - Started process (PID=27553) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:07,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:54:07,039] {logging_mixin.py:115} INFO - [2022-10-19 17:54:07,039] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:07,050] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:07,133] {logging_mixin.py:115} INFO - [2022-10-19 17:54:07,132] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:54:07,159] {logging_mixin.py:115} INFO - [2022-10-19 17:54:07,159] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:54:07.049097+00:00, run_after=2022-10-20T17:54:07.049097+00:00
[2022-10-19 17:54:07,177] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.146 seconds
[2022-10-19 17:54:07,411] {processor.py:153} INFO - Started process (PID=36873) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:07,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:54:07,415] {logging_mixin.py:115} INFO - [2022-10-19 17:54:07,414] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:07,434] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:07,456] {logging_mixin.py:115} INFO - [2022-10-19 17:54:07,456] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:54:07,504] {logging_mixin.py:115} INFO - [2022-10-19 17:54:07,503] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:54:07.432793+00:00, run_after=2022-10-20T17:54:07.432793+00:00
[2022-10-19 17:54:07,518] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.111 seconds
[2022-10-19 17:54:37,449] {processor.py:153} INFO - Started process (PID=27591) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:37,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:54:37,452] {logging_mixin.py:115} INFO - [2022-10-19 17:54:37,452] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:37,464] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:37,545] {logging_mixin.py:115} INFO - [2022-10-19 17:54:37,545] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:54:37,571] {logging_mixin.py:115} INFO - [2022-10-19 17:54:37,571] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:54:37.463197+00:00, run_after=2022-10-20T17:54:37.463197+00:00
[2022-10-19 17:54:37,588] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 17:54:37,623] {processor.py:153} INFO - Started process (PID=36905) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:37,624] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:54:37,625] {logging_mixin.py:115} INFO - [2022-10-19 17:54:37,625] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:37,636] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:54:37,657] {logging_mixin.py:115} INFO - [2022-10-19 17:54:37,657] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:54:37,691] {logging_mixin.py:115} INFO - [2022-10-19 17:54:37,691] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:54:37.635157+00:00, run_after=2022-10-20T17:54:37.635157+00:00
[2022-10-19 17:54:37,708] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.090 seconds
[2022-10-19 17:55:07,677] {processor.py:153} INFO - Started process (PID=27620) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:07,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:55:07,680] {logging_mixin.py:115} INFO - [2022-10-19 17:55:07,680] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:07,691] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:07,784] {logging_mixin.py:115} INFO - [2022-10-19 17:55:07,782] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:55:07,811] {logging_mixin.py:115} INFO - [2022-10-19 17:55:07,811] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:55:07.689915+00:00, run_after=2022-10-20T17:55:07.689915+00:00
[2022-10-19 17:55:07,830] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.158 seconds
[2022-10-19 17:55:07,952] {processor.py:153} INFO - Started process (PID=36938) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:07,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:55:07,954] {logging_mixin.py:115} INFO - [2022-10-19 17:55:07,954] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:07,966] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:07,985] {logging_mixin.py:115} INFO - [2022-10-19 17:55:07,985] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:55:08,015] {logging_mixin.py:115} INFO - [2022-10-19 17:55:08,015] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:55:07.964910+00:00, run_after=2022-10-20T17:55:07.964910+00:00
[2022-10-19 17:55:08,033] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 17:55:37,902] {processor.py:153} INFO - Started process (PID=27658) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:37,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:55:37,905] {logging_mixin.py:115} INFO - [2022-10-19 17:55:37,905] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:37,922] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:38,013] {logging_mixin.py:115} INFO - [2022-10-19 17:55:38,012] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:55:38,040] {logging_mixin.py:115} INFO - [2022-10-19 17:55:38,039] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:55:37.921098+00:00, run_after=2022-10-20T17:55:37.921098+00:00
[2022-10-19 17:55:38,063] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.168 seconds
[2022-10-19 17:55:38,157] {processor.py:153} INFO - Started process (PID=36971) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:38,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:55:38,160] {logging_mixin.py:115} INFO - [2022-10-19 17:55:38,160] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:38,173] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:55:38,197] {logging_mixin.py:115} INFO - [2022-10-19 17:55:38,197] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:55:38,229] {logging_mixin.py:115} INFO - [2022-10-19 17:55:38,229] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:55:38.172848+00:00, run_after=2022-10-20T17:55:38.172848+00:00
[2022-10-19 17:55:38,246] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.094 seconds
[2022-10-19 17:56:08,243] {processor.py:153} INFO - Started process (PID=27697) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:08,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:56:08,245] {logging_mixin.py:115} INFO - [2022-10-19 17:56:08,245] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:08,256] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:08,338] {logging_mixin.py:115} INFO - [2022-10-19 17:56:08,338] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:56:08,367] {logging_mixin.py:115} INFO - [2022-10-19 17:56:08,367] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:56:08.255051+00:00, run_after=2022-10-20T17:56:08.255051+00:00
[2022-10-19 17:56:08,383] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.145 seconds
[2022-10-19 17:56:08,434] {processor.py:153} INFO - Started process (PID=37003) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:08,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:56:08,437] {logging_mixin.py:115} INFO - [2022-10-19 17:56:08,437] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:08,448] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:08,468] {logging_mixin.py:115} INFO - [2022-10-19 17:56:08,467] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:56:08,497] {logging_mixin.py:115} INFO - [2022-10-19 17:56:08,497] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:56:08.447055+00:00, run_after=2022-10-20T17:56:08.447055+00:00
[2022-10-19 17:56:08,513] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.084 seconds
[2022-10-19 17:56:38,590] {processor.py:153} INFO - Started process (PID=37035) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:38,591] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:56:38,593] {logging_mixin.py:115} INFO - [2022-10-19 17:56:38,592] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:38,603] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:38,663] {processor.py:153} INFO - Started process (PID=27727) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:38,664] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:56:38,666] {logging_mixin.py:115} INFO - [2022-10-19 17:56:38,666] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:38,680] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:56:38,692] {logging_mixin.py:115} INFO - [2022-10-19 17:56:38,692] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:56:38,717] {logging_mixin.py:115} INFO - [2022-10-19 17:56:38,717] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:56:38.602665+00:00, run_after=2022-10-20T17:56:38.602665+00:00
[2022-10-19 17:56:38,737] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:56:38,778] {logging_mixin.py:115} INFO - [2022-10-19 17:56:38,778] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:56:38,807] {logging_mixin.py:115} INFO - [2022-10-19 17:56:38,807] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:56:38.679562+00:00, run_after=2022-10-20T17:56:38.679562+00:00
[2022-10-19 17:56:38,829] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.173 seconds
[2022-10-19 17:57:08,779] {processor.py:153} INFO - Started process (PID=37067) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:08,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:57:08,781] {logging_mixin.py:115} INFO - [2022-10-19 17:57:08,781] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:08,797] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:08,883] {logging_mixin.py:115} INFO - [2022-10-19 17:57:08,883] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:57:08,910] {logging_mixin.py:115} INFO - [2022-10-19 17:57:08,910] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:57:08.795600+00:00, run_after=2022-10-20T17:57:08.795600+00:00
[2022-10-19 17:57:08,923] {processor.py:153} INFO - Started process (PID=27765) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:08,924] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:57:08,926] {logging_mixin.py:115} INFO - [2022-10-19 17:57:08,926] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:08,933] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.161 seconds
[2022-10-19 17:57:08,936] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:08,958] {logging_mixin.py:115} INFO - [2022-10-19 17:57:08,958] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:57:08,987] {logging_mixin.py:115} INFO - [2022-10-19 17:57:08,987] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:57:08.935497+00:00, run_after=2022-10-20T17:57:08.935497+00:00
[2022-10-19 17:57:09,005] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.086 seconds
[2022-10-19 17:57:39,121] {processor.py:153} INFO - Started process (PID=27803) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:39,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:57:39,124] {logging_mixin.py:115} INFO - [2022-10-19 17:57:39,123] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:39,135] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:39,222] {logging_mixin.py:115} INFO - [2022-10-19 17:57:39,221] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:57:39,248] {logging_mixin.py:115} INFO - [2022-10-19 17:57:39,248] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:57:39.134481+00:00, run_after=2022-10-20T17:57:39.134481+00:00
[2022-10-19 17:57:39,266] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.152 seconds
[2022-10-19 17:57:39,823] {processor.py:153} INFO - Started process (PID=37107) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:39,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:57:39,825] {logging_mixin.py:115} INFO - [2022-10-19 17:57:39,825] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:39,836] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:57:39,856] {logging_mixin.py:115} INFO - [2022-10-19 17:57:39,855] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:57:39,886] {logging_mixin.py:115} INFO - [2022-10-19 17:57:39,885] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:57:39.835562+00:00, run_after=2022-10-20T17:57:39.835562+00:00
[2022-10-19 17:57:39,903] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 17:58:09,331] {processor.py:153} INFO - Started process (PID=27832) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:09,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:58:09,334] {logging_mixin.py:115} INFO - [2022-10-19 17:58:09,334] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:09,344] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:09,426] {logging_mixin.py:115} INFO - [2022-10-19 17:58:09,426] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:58:09,464] {logging_mixin.py:115} INFO - [2022-10-19 17:58:09,464] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:58:09.343550+00:00, run_after=2022-10-20T17:58:09.343550+00:00
[2022-10-19 17:58:09,487] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.159 seconds
[2022-10-19 17:58:10,019] {processor.py:153} INFO - Started process (PID=37139) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:10,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:58:10,022] {logging_mixin.py:115} INFO - [2022-10-19 17:58:10,022] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:10,037] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:10,061] {logging_mixin.py:115} INFO - [2022-10-19 17:58:10,060] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:58:10,095] {logging_mixin.py:115} INFO - [2022-10-19 17:58:10,095] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:58:10.036255+00:00, run_after=2022-10-20T17:58:10.036255+00:00
[2022-10-19 17:58:10,114] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.103 seconds
[2022-10-19 17:58:39,683] {processor.py:153} INFO - Started process (PID=27870) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:39,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:58:39,685] {logging_mixin.py:115} INFO - [2022-10-19 17:58:39,685] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:39,696] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:39,778] {logging_mixin.py:115} INFO - [2022-10-19 17:58:39,778] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:58:39,803] {logging_mixin.py:115} INFO - [2022-10-19 17:58:39,803] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:58:39.695005+00:00, run_after=2022-10-20T17:58:39.695005+00:00
[2022-10-19 17:58:39,820] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.142 seconds
[2022-10-19 17:58:40,192] {processor.py:153} INFO - Started process (PID=37171) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:40,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:58:40,195] {logging_mixin.py:115} INFO - [2022-10-19 17:58:40,194] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:40,205] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:58:40,223] {logging_mixin.py:115} INFO - [2022-10-19 17:58:40,223] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:58:40,252] {logging_mixin.py:115} INFO - [2022-10-19 17:58:40,252] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:58:40.203923+00:00, run_after=2022-10-20T17:58:40.203923+00:00
[2022-10-19 17:58:40,269] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.081 seconds
[2022-10-19 17:59:09,973] {processor.py:153} INFO - Started process (PID=27899) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:09,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:59:09,976] {logging_mixin.py:115} INFO - [2022-10-19 17:59:09,976] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:09,988] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:10,075] {logging_mixin.py:115} INFO - [2022-10-19 17:59:10,075] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:59:10,102] {logging_mixin.py:115} INFO - [2022-10-19 17:59:10,102] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:59:09.987733+00:00, run_after=2022-10-20T17:59:09.987733+00:00
[2022-10-19 17:59:10,120] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 17:59:10,615] {processor.py:153} INFO - Started process (PID=37203) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:10,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:59:10,617] {logging_mixin.py:115} INFO - [2022-10-19 17:59:10,617] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:10,632] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:10,663] {logging_mixin.py:115} INFO - [2022-10-19 17:59:10,663] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:59:10,691] {logging_mixin.py:115} INFO - [2022-10-19 17:59:10,691] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:59:10.631472+00:00, run_after=2022-10-20T17:59:10.631472+00:00
[2022-10-19 17:59:10,711] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.103 seconds
[2022-10-19 17:59:40,241] {processor.py:153} INFO - Started process (PID=27937) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:40,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:59:40,243] {logging_mixin.py:115} INFO - [2022-10-19 17:59:40,243] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:40,254] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:40,334] {logging_mixin.py:115} INFO - [2022-10-19 17:59:40,334] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:59:40,359] {logging_mixin.py:115} INFO - [2022-10-19 17:59:40,359] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:59:40.253219+00:00, run_after=2022-10-20T17:59:40.253219+00:00
[2022-10-19 17:59:40,378] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.142 seconds
[2022-10-19 17:59:40,820] {processor.py:153} INFO - Started process (PID=37235) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:40,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 17:59:40,822] {logging_mixin.py:115} INFO - [2022-10-19 17:59:40,822] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:40,833] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 17:59:40,856] {logging_mixin.py:115} INFO - [2022-10-19 17:59:40,856] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 17:59:40,891] {logging_mixin.py:115} INFO - [2022-10-19 17:59:40,890] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T17:59:40.832542+00:00, run_after=2022-10-20T17:59:40.832542+00:00
[2022-10-19 17:59:40,909] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.094 seconds
[2022-10-19 18:00:10,603] {processor.py:153} INFO - Started process (PID=27975) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:10,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:00:10,605] {logging_mixin.py:115} INFO - [2022-10-19 18:00:10,605] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:10,615] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:10,705] {logging_mixin.py:115} INFO - [2022-10-19 18:00:10,704] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:00:10,731] {logging_mixin.py:115} INFO - [2022-10-19 18:00:10,731] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:00:10.614650+00:00, run_after=2022-10-20T18:00:10.614650+00:00
[2022-10-19 18:00:10,748] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.150 seconds
[2022-10-19 18:00:11,014] {processor.py:153} INFO - Started process (PID=37267) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:11,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:00:11,017] {logging_mixin.py:115} INFO - [2022-10-19 18:00:11,017] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:11,027] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:11,046] {logging_mixin.py:115} INFO - [2022-10-19 18:00:11,046] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:00:11,076] {logging_mixin.py:115} INFO - [2022-10-19 18:00:11,075] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:00:11.026480+00:00, run_after=2022-10-20T18:00:11.026480+00:00
[2022-10-19 18:00:11,093] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 18:00:40,959] {processor.py:153} INFO - Started process (PID=28004) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:40,961] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:00:40,962] {logging_mixin.py:115} INFO - [2022-10-19 18:00:40,962] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:40,973] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:41,054] {logging_mixin.py:115} INFO - [2022-10-19 18:00:41,054] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:00:41,084] {logging_mixin.py:115} INFO - [2022-10-19 18:00:41,084] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:00:40.972330+00:00, run_after=2022-10-20T18:00:40.972330+00:00
[2022-10-19 18:00:41,112] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.157 seconds
[2022-10-19 18:00:41,350] {processor.py:153} INFO - Started process (PID=37299) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:41,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:00:41,353] {logging_mixin.py:115} INFO - [2022-10-19 18:00:41,353] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:41,363] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:00:41,385] {logging_mixin.py:115} INFO - [2022-10-19 18:00:41,385] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:00:41,416] {logging_mixin.py:115} INFO - [2022-10-19 18:00:41,416] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:00:41.362744+00:00, run_after=2022-10-20T18:00:41.362744+00:00
[2022-10-19 18:00:41,432] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 18:01:11,190] {processor.py:153} INFO - Started process (PID=28043) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:11,191] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:01:11,192] {logging_mixin.py:115} INFO - [2022-10-19 18:01:11,192] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:11,202] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:11,281] {logging_mixin.py:115} INFO - [2022-10-19 18:01:11,281] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:01:11,307] {logging_mixin.py:115} INFO - [2022-10-19 18:01:11,307] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:01:11.201792+00:00, run_after=2022-10-20T18:01:11.201792+00:00
[2022-10-19 18:01:11,327] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 18:01:11,551] {processor.py:153} INFO - Started process (PID=37330) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:11,552] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:01:11,553] {logging_mixin.py:115} INFO - [2022-10-19 18:01:11,553] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:11,564] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:11,585] {logging_mixin.py:115} INFO - [2022-10-19 18:01:11,585] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:01:11,614] {logging_mixin.py:115} INFO - [2022-10-19 18:01:11,614] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:01:11.563611+00:00, run_after=2022-10-20T18:01:11.563611+00:00
[2022-10-19 18:01:11,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 18:01:41,699] {processor.py:153} INFO - Started process (PID=28072) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:41,701] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:01:41,703] {logging_mixin.py:115} INFO - [2022-10-19 18:01:41,703] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:41,721] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:41,758] {processor.py:153} INFO - Started process (PID=37362) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:41,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:01:41,762] {logging_mixin.py:115} INFO - [2022-10-19 18:01:41,762] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:41,778] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:01:41,842] {logging_mixin.py:115} INFO - [2022-10-19 18:01:41,842] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:01:41,868] {logging_mixin.py:115} INFO - [2022-10-19 18:01:41,868] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:01:41.719646+00:00, run_after=2022-10-20T18:01:41.719646+00:00
[2022-10-19 18:01:41,873] {logging_mixin.py:115} INFO - [2022-10-19 18:01:41,873] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:01:41,888] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.203 seconds
[2022-10-19 18:01:41,902] {logging_mixin.py:115} INFO - [2022-10-19 18:01:41,902] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:01:41.777080+00:00, run_after=2022-10-20T18:01:41.777080+00:00
[2022-10-19 18:01:41,918] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.166 seconds
[2022-10-19 18:02:11,947] {processor.py:153} INFO - Started process (PID=37388) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:11,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:02:11,952] {logging_mixin.py:115} INFO - [2022-10-19 18:02:11,952] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:11,963] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:12,076] {processor.py:153} INFO - Started process (PID=28111) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:12,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:02:12,079] {logging_mixin.py:115} INFO - [2022-10-19 18:02:12,079] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:12,090] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:12,093] {logging_mixin.py:115} INFO - [2022-10-19 18:02:12,093] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:02:12,121] {logging_mixin.py:115} INFO - [2022-10-19 18:02:12,121] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:02:11.962789+00:00, run_after=2022-10-20T18:02:11.962789+00:00
[2022-10-19 18:02:12,138] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.196 seconds
[2022-10-19 18:02:12,187] {logging_mixin.py:115} INFO - [2022-10-19 18:02:12,187] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:02:12,214] {logging_mixin.py:115} INFO - [2022-10-19 18:02:12,213] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:02:12.089097+00:00, run_after=2022-10-20T18:02:12.089097+00:00
[2022-10-19 18:02:12,230] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.171 seconds
[2022-10-19 18:02:42,294] {processor.py:153} INFO - Started process (PID=28151) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:42,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:02:42,298] {logging_mixin.py:115} INFO - [2022-10-19 18:02:42,298] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:42,313] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:42,413] {logging_mixin.py:115} INFO - [2022-10-19 18:02:42,413] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:02:42,441] {logging_mixin.py:115} INFO - [2022-10-19 18:02:42,441] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:02:42.312045+00:00, run_after=2022-10-20T18:02:42.312045+00:00
[2022-10-19 18:02:42,459] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.169 seconds
[2022-10-19 18:02:42,517] {processor.py:153} INFO - Started process (PID=37428) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:42,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:02:42,519] {logging_mixin.py:115} INFO - [2022-10-19 18:02:42,519] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:42,531] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:02:42,552] {logging_mixin.py:115} INFO - [2022-10-19 18:02:42,552] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:02:42,583] {logging_mixin.py:115} INFO - [2022-10-19 18:02:42,583] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:02:42.529829+00:00, run_after=2022-10-20T18:02:42.529829+00:00
[2022-10-19 18:02:42,599] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 18:03:12,765] {processor.py:153} INFO - Started process (PID=28180) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:12,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:03:12,768] {logging_mixin.py:115} INFO - [2022-10-19 18:03:12,768] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:12,778] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:12,797] {processor.py:153} INFO - Started process (PID=37461) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:12,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:03:12,799] {logging_mixin.py:115} INFO - [2022-10-19 18:03:12,799] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:12,810] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:12,866] {logging_mixin.py:115} INFO - [2022-10-19 18:03:12,866] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:03:12,893] {logging_mixin.py:115} INFO - [2022-10-19 18:03:12,893] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:03:12.777580+00:00, run_after=2022-10-20T18:03:12.777580+00:00
[2022-10-19 18:03:12,897] {logging_mixin.py:115} INFO - [2022-10-19 18:03:12,897] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:03:12,911] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 18:03:12,929] {logging_mixin.py:115} INFO - [2022-10-19 18:03:12,929] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:03:12.809611+00:00, run_after=2022-10-20T18:03:12.809611+00:00
[2022-10-19 18:03:12,944] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 18:03:43,021] {processor.py:153} INFO - Started process (PID=37495) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:43,025] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:03:43,027] {logging_mixin.py:115} INFO - [2022-10-19 18:03:43,027] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:43,042] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:43,123] {logging_mixin.py:115} INFO - [2022-10-19 18:03:43,123] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:03:43,149] {logging_mixin.py:115} INFO - [2022-10-19 18:03:43,149] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:03:43.041225+00:00, run_after=2022-10-20T18:03:43.041225+00:00
[2022-10-19 18:03:43,167] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.161 seconds
[2022-10-19 18:03:43,470] {processor.py:153} INFO - Started process (PID=28218) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:43,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:03:43,473] {logging_mixin.py:115} INFO - [2022-10-19 18:03:43,472] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:43,484] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:03:43,503] {logging_mixin.py:115} INFO - [2022-10-19 18:03:43,503] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:03:43,535] {logging_mixin.py:115} INFO - [2022-10-19 18:03:43,535] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:03:43.483086+00:00, run_after=2022-10-20T18:03:43.483086+00:00
[2022-10-19 18:03:43,555] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.089 seconds
[2022-10-19 18:04:13,235] {processor.py:153} INFO - Started process (PID=37522) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:13,238] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:04:13,240] {logging_mixin.py:115} INFO - [2022-10-19 18:04:13,240] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:13,256] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:13,357] {logging_mixin.py:115} INFO - [2022-10-19 18:04:13,356] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:04:13,384] {logging_mixin.py:115} INFO - [2022-10-19 18:04:13,383] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:04:13.254769+00:00, run_after=2022-10-20T18:04:13.254769+00:00
[2022-10-19 18:04:13,401] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.171 seconds
[2022-10-19 18:04:14,112] {processor.py:153} INFO - Started process (PID=28257) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:14,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:04:14,114] {logging_mixin.py:115} INFO - [2022-10-19 18:04:14,114] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:14,125] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:14,144] {logging_mixin.py:115} INFO - [2022-10-19 18:04:14,144] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:04:14,173] {logging_mixin.py:115} INFO - [2022-10-19 18:04:14,173] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:04:14.124196+00:00, run_after=2022-10-20T18:04:14.124196+00:00
[2022-10-19 18:04:14,188] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.081 seconds
[2022-10-19 18:04:44,042] {processor.py:153} INFO - Started process (PID=37561) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:44,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:04:44,044] {logging_mixin.py:115} INFO - [2022-10-19 18:04:44,044] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:44,055] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:44,136] {logging_mixin.py:115} INFO - [2022-10-19 18:04:44,135] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:04:44,162] {logging_mixin.py:115} INFO - [2022-10-19 18:04:44,162] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:04:44.053944+00:00, run_after=2022-10-20T18:04:44.053944+00:00
[2022-10-19 18:04:44,180] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.143 seconds
[2022-10-19 18:04:44,759] {processor.py:153} INFO - Started process (PID=28286) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:44,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:04:44,762] {logging_mixin.py:115} INFO - [2022-10-19 18:04:44,762] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:44,774] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:04:44,794] {logging_mixin.py:115} INFO - [2022-10-19 18:04:44,794] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:04:44,824] {logging_mixin.py:115} INFO - [2022-10-19 18:04:44,824] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:04:44.773162+00:00, run_after=2022-10-20T18:04:44.773162+00:00
[2022-10-19 18:04:44,841] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.087 seconds
[2022-10-19 18:05:14,933] {processor.py:153} INFO - Started process (PID=37593) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:14,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:05:14,936] {logging_mixin.py:115} INFO - [2022-10-19 18:05:14,935] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:14,974] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:15,056] {logging_mixin.py:115} INFO - [2022-10-19 18:05:15,055] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:05:15,084] {logging_mixin.py:115} INFO - [2022-10-19 18:05:15,084] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:05:14.973060+00:00, run_after=2022-10-20T18:05:14.973060+00:00
[2022-10-19 18:05:15,103] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.175 seconds
[2022-10-19 18:05:15,535] {processor.py:153} INFO - Started process (PID=28325) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:15,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:05:15,538] {logging_mixin.py:115} INFO - [2022-10-19 18:05:15,538] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:15,550] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:15,570] {logging_mixin.py:115} INFO - [2022-10-19 18:05:15,570] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:05:15,599] {logging_mixin.py:115} INFO - [2022-10-19 18:05:15,599] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:05:15.548885+00:00, run_after=2022-10-20T18:05:15.548885+00:00
[2022-10-19 18:05:15,612] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 18:05:45,159] {processor.py:153} INFO - Started process (PID=37626) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:45,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:05:45,163] {logging_mixin.py:115} INFO - [2022-10-19 18:05:45,163] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:45,175] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:45,259] {logging_mixin.py:115} INFO - [2022-10-19 18:05:45,259] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:05:45,287] {logging_mixin.py:115} INFO - [2022-10-19 18:05:45,287] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:05:45.174368+00:00, run_after=2022-10-20T18:05:45.174368+00:00
[2022-10-19 18:05:45,306] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 18:05:46,174] {processor.py:153} INFO - Started process (PID=28363) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:46,175] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:05:46,177] {logging_mixin.py:115} INFO - [2022-10-19 18:05:46,176] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:46,187] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:05:46,206] {logging_mixin.py:115} INFO - [2022-10-19 18:05:46,206] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:05:46,237] {logging_mixin.py:115} INFO - [2022-10-19 18:05:46,237] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:05:46.186254+00:00, run_after=2022-10-20T18:05:46.186254+00:00
[2022-10-19 18:05:46,252] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.083 seconds
[2022-10-19 18:06:15,340] {processor.py:153} INFO - Started process (PID=37658) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:15,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:06:15,344] {logging_mixin.py:115} INFO - [2022-10-19 18:06:15,344] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:15,356] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:15,436] {logging_mixin.py:115} INFO - [2022-10-19 18:06:15,436] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:06:15,463] {logging_mixin.py:115} INFO - [2022-10-19 18:06:15,463] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:06:15.355145+00:00, run_after=2022-10-20T18:06:15.355145+00:00
[2022-10-19 18:06:15,481] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.146 seconds
[2022-10-19 18:06:16,807] {processor.py:153} INFO - Started process (PID=28392) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:16,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:06:16,810] {logging_mixin.py:115} INFO - [2022-10-19 18:06:16,810] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:16,820] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:16,844] {logging_mixin.py:115} INFO - [2022-10-19 18:06:16,844] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:06:16,878] {logging_mixin.py:115} INFO - [2022-10-19 18:06:16,878] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:06:16.819163+00:00, run_after=2022-10-20T18:06:16.819163+00:00
[2022-10-19 18:06:16,897] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.096 seconds
[2022-10-19 18:06:45,509] {processor.py:153} INFO - Started process (PID=37690) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:45,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:06:45,512] {logging_mixin.py:115} INFO - [2022-10-19 18:06:45,512] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:45,523] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:45,608] {logging_mixin.py:115} INFO - [2022-10-19 18:06:45,608] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:06:45,637] {logging_mixin.py:115} INFO - [2022-10-19 18:06:45,637] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:06:45.522536+00:00, run_after=2022-10-20T18:06:45.522536+00:00
[2022-10-19 18:06:45,656] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.151 seconds
[2022-10-19 18:06:47,538] {processor.py:153} INFO - Started process (PID=28430) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:47,539] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:06:47,540] {logging_mixin.py:115} INFO - [2022-10-19 18:06:47,540] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:47,550] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:06:47,571] {logging_mixin.py:115} INFO - [2022-10-19 18:06:47,571] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:06:47,602] {logging_mixin.py:115} INFO - [2022-10-19 18:06:47,602] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:06:47.549780+00:00, run_after=2022-10-20T18:06:47.549780+00:00
[2022-10-19 18:06:47,619] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.085 seconds
[2022-10-19 18:11:49,628] {processor.py:153} INFO - Started process (PID=28457) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:11:49,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:11:49,644] {logging_mixin.py:115} INFO - [2022-10-19 18:11:49,644] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:11:49,689] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:11:49,966] {processor.py:153} INFO - Started process (PID=37718) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:11:49,988] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:11:49,996] {logging_mixin.py:115} INFO - [2022-10-19 18:11:49,996] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:11:50,033] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:11:50,091] {logging_mixin.py:115} INFO - [2022-10-19 18:11:50,090] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:11:50,161] {logging_mixin.py:115} INFO - [2022-10-19 18:11:50,161] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:11:49.687528+00:00, run_after=2022-10-20T18:11:49.687528+00:00
[2022-10-19 18:11:50,206] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.590 seconds
[2022-10-19 18:11:50,677] {logging_mixin.py:115} INFO - [2022-10-19 18:11:50,676] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:11:50,827] {logging_mixin.py:115} INFO - [2022-10-19 18:11:50,827] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:11:50.032756+00:00, run_after=2022-10-20T18:11:50.032756+00:00
[2022-10-19 18:11:50,925] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.972 seconds
[2022-10-19 18:12:21,003] {processor.py:153} INFO - Started process (PID=28492) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:21,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:12:21,005] {logging_mixin.py:115} INFO - [2022-10-19 18:12:21,005] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:21,016] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:21,119] {logging_mixin.py:115} INFO - [2022-10-19 18:12:21,118] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:12:21,144] {logging_mixin.py:115} INFO - [2022-10-19 18:12:21,144] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:12:21.015089+00:00, run_after=2022-10-20T18:12:21.015089+00:00
[2022-10-19 18:12:21,175] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.176 seconds
[2022-10-19 18:12:21,544] {processor.py:153} INFO - Started process (PID=37744) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:21,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:12:21,547] {logging_mixin.py:115} INFO - [2022-10-19 18:12:21,547] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:21,561] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:21,585] {logging_mixin.py:115} INFO - [2022-10-19 18:12:21,585] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:12:21,614] {logging_mixin.py:115} INFO - [2022-10-19 18:12:21,614] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:12:21.560150+00:00, run_after=2022-10-20T18:12:21.560150+00:00
[2022-10-19 18:12:21,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.091 seconds
[2022-10-19 18:12:51,859] {processor.py:153} INFO - Started process (PID=28523) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:51,860] {processor.py:153} INFO - Started process (PID=37776) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:51,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:12:51,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:12:51,865] {logging_mixin.py:115} INFO - [2022-10-19 18:12:51,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:51,865] {logging_mixin.py:115} INFO - [2022-10-19 18:12:51,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:51,880] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:51,887] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:12:52,005] {logging_mixin.py:115} INFO - [2022-10-19 18:12:52,005] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:12:52,006] {logging_mixin.py:115} INFO - [2022-10-19 18:12:52,005] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:12:52,035] {logging_mixin.py:115} INFO - [2022-10-19 18:12:52,035] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:12:51.885597+00:00, run_after=2022-10-20T18:12:51.885597+00:00
[2022-10-19 18:12:52,997] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.158 seconds
[2022-10-19 18:12:53,028] {logging_mixin.py:115} INFO - [2022-10-19 18:12:53,026] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:12:51.878491+00:00, run_after=2022-10-20T18:12:51.878491+00:00
[2022-10-19 18:12:53,063] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.213 seconds
[2022-10-19 18:17:17,520] {processor.py:153} INFO - Started process (PID=28552) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:17,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:17:17,525] {logging_mixin.py:115} INFO - [2022-10-19 18:17:17,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:17,545] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:17,642] {logging_mixin.py:115} INFO - [2022-10-19 18:17:17,642] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:17:17,701] {logging_mixin.py:115} INFO - [2022-10-19 18:17:17,700] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:17:17.544165+00:00, run_after=2022-10-20T18:17:17.544165+00:00
[2022-10-19 18:17:17,765] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.253 seconds
[2022-10-19 18:17:17,921] {processor.py:153} INFO - Started process (PID=37801) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:17,925] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:17:17,927] {logging_mixin.py:115} INFO - [2022-10-19 18:17:17,927] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:17,955] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:17,987] {logging_mixin.py:115} INFO - [2022-10-19 18:17:17,987] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:17:18,147] {logging_mixin.py:115} INFO - [2022-10-19 18:17:18,146] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:17:17.948805+00:00, run_after=2022-10-20T18:17:17.948805+00:00
[2022-10-19 18:17:18,267] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.355 seconds
[2022-10-19 18:17:47,973] {processor.py:153} INFO - Started process (PID=28592) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:47,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:17:47,976] {logging_mixin.py:115} INFO - [2022-10-19 18:17:47,976] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:47,989] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:48,103] {logging_mixin.py:115} INFO - [2022-10-19 18:17:48,103] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:17:48,132] {logging_mixin.py:115} INFO - [2022-10-19 18:17:48,131] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:17:47.988104+00:00, run_after=2022-10-20T18:17:47.988104+00:00
[2022-10-19 18:17:48,149] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.181 seconds
[2022-10-19 18:17:48,584] {processor.py:153} INFO - Started process (PID=37839) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:48,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:17:48,587] {logging_mixin.py:115} INFO - [2022-10-19 18:17:48,587] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:48,599] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:17:48,621] {logging_mixin.py:115} INFO - [2022-10-19 18:17:48,620] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:17:48,653] {logging_mixin.py:115} INFO - [2022-10-19 18:17:48,652] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:17:48.598603+00:00, run_after=2022-10-20T18:17:48.598603+00:00
[2022-10-19 18:17:48,668] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.088 seconds
[2022-10-19 18:18:18,473] {processor.py:153} INFO - Started process (PID=28622) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:18,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:18:18,477] {logging_mixin.py:115} INFO - [2022-10-19 18:18:18,477] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:18,492] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:18,590] {logging_mixin.py:115} INFO - [2022-10-19 18:18:18,590] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:18:18,616] {logging_mixin.py:115} INFO - [2022-10-19 18:18:18,616] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:18:18.491069+00:00, run_after=2022-10-20T18:18:18.491069+00:00
[2022-10-19 18:18:18,636] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.169 seconds
[2022-10-19 18:18:18,838] {processor.py:153} INFO - Started process (PID=37872) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:18,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:18:18,841] {logging_mixin.py:115} INFO - [2022-10-19 18:18:18,841] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:18,857] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:18,881] {logging_mixin.py:115} INFO - [2022-10-19 18:18:18,881] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:18:18,912] {logging_mixin.py:115} INFO - [2022-10-19 18:18:18,912] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:18:18.856174+00:00, run_after=2022-10-20T18:18:18.856174+00:00
[2022-10-19 18:18:18,936] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.102 seconds
[2022-10-19 18:18:48,989] {processor.py:153} INFO - Started process (PID=37904) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:48,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:18:48,992] {logging_mixin.py:115} INFO - [2022-10-19 18:18:48,992] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:49,002] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:49,079] {processor.py:153} INFO - Started process (PID=28660) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:49,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:18:49,082] {logging_mixin.py:115} INFO - [2022-10-19 18:18:49,082] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:49,106] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:18:49,112] {logging_mixin.py:115} INFO - [2022-10-19 18:18:49,111] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:18:49,138] {logging_mixin.py:115} INFO - [2022-10-19 18:18:49,138] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:18:49.001459+00:00, run_after=2022-10-20T18:18:49.001459+00:00
[2022-10-19 18:18:49,152] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.168 seconds
[2022-10-19 18:18:49,189] {logging_mixin.py:115} INFO - [2022-10-19 18:18:49,189] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:18:49,214] {logging_mixin.py:115} INFO - [2022-10-19 18:18:49,214] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:18:49.105217+00:00, run_after=2022-10-20T18:18:49.105217+00:00
[2022-10-19 18:18:49,235] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.161 seconds
[2022-10-19 18:19:19,296] {processor.py:153} INFO - Started process (PID=37937) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:19,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:19:19,301] {logging_mixin.py:115} INFO - [2022-10-19 18:19:19,301] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:19,314] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:19,405] {logging_mixin.py:115} INFO - [2022-10-19 18:19:19,405] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:19:19,431] {logging_mixin.py:115} INFO - [2022-10-19 18:19:19,431] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:19:19.313101+00:00, run_after=2022-10-20T18:19:19.313101+00:00
[2022-10-19 18:19:19,454] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.163 seconds
[2022-10-19 18:19:19,678] {processor.py:153} INFO - Started process (PID=28689) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:19,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:19:19,681] {logging_mixin.py:115} INFO - [2022-10-19 18:19:19,681] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:19,696] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:19,719] {logging_mixin.py:115} INFO - [2022-10-19 18:19:19,719] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:19:19,753] {logging_mixin.py:115} INFO - [2022-10-19 18:19:19,753] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:19:19.694481+00:00, run_after=2022-10-20T18:19:19.694481+00:00
[2022-10-19 18:19:19,772] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.101 seconds
[2022-10-19 18:19:49,852] {processor.py:153} INFO - Started process (PID=28726) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:49,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:19:49,854] {logging_mixin.py:115} INFO - [2022-10-19 18:19:49,854] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:49,865] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:49,955] {logging_mixin.py:115} INFO - [2022-10-19 18:19:49,955] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:19:49,991] {logging_mixin.py:115} INFO - [2022-10-19 18:19:49,990] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:19:49.864728+00:00, run_after=2022-10-20T18:19:49.864728+00:00
[2022-10-19 18:19:50,008] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.161 seconds
[2022-10-19 18:19:50,155] {processor.py:153} INFO - Started process (PID=37969) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:50,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:19:50,158] {logging_mixin.py:115} INFO - [2022-10-19 18:19:50,158] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:50,169] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:19:50,189] {logging_mixin.py:115} INFO - [2022-10-19 18:19:50,189] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:19:50,218] {logging_mixin.py:115} INFO - [2022-10-19 18:19:50,218] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:19:50.168279+00:00, run_after=2022-10-20T18:19:50.168279+00:00
[2022-10-19 18:19:50,235] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.084 seconds
[2022-10-19 18:20:20,067] {processor.py:153} INFO - Started process (PID=28766) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:20,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:20:20,069] {logging_mixin.py:115} INFO - [2022-10-19 18:20:20,069] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:20,080] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:20,161] {logging_mixin.py:115} INFO - [2022-10-19 18:20:20,161] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:20:20,186] {logging_mixin.py:115} INFO - [2022-10-19 18:20:20,186] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:20:20.079555+00:00, run_after=2022-10-20T18:20:20.079555+00:00
[2022-10-19 18:20:20,206] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.144 seconds
[2022-10-19 18:20:20,457] {processor.py:153} INFO - Started process (PID=38001) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:20,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:20:20,459] {logging_mixin.py:115} INFO - [2022-10-19 18:20:20,459] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:20,469] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:20,495] {logging_mixin.py:115} INFO - [2022-10-19 18:20:20,494] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:20:20,525] {logging_mixin.py:115} INFO - [2022-10-19 18:20:20,525] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:20:20.468574+00:00, run_after=2022-10-20T18:20:20.468574+00:00
[2022-10-19 18:20:20,542] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.090 seconds
[2022-10-19 18:20:50,242] {processor.py:153} INFO - Started process (PID=28795) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:50,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:20:50,247] {logging_mixin.py:115} INFO - [2022-10-19 18:20:50,247] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:50,260] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:50,341] {logging_mixin.py:115} INFO - [2022-10-19 18:20:50,341] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:20:50,366] {logging_mixin.py:115} INFO - [2022-10-19 18:20:50,366] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:20:50.259578+00:00, run_after=2022-10-20T18:20:50.259578+00:00
[2022-10-19 18:20:50,386] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.150 seconds
[2022-10-19 18:20:50,690] {processor.py:153} INFO - Started process (PID=38034) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:50,691] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:20:50,693] {logging_mixin.py:115} INFO - [2022-10-19 18:20:50,693] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:50,705] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:20:50,725] {logging_mixin.py:115} INFO - [2022-10-19 18:20:50,725] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:20:50,753] {logging_mixin.py:115} INFO - [2022-10-19 18:20:50,753] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:20:50.704223+00:00, run_after=2022-10-20T18:20:50.704223+00:00
[2022-10-19 18:20:50,776] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.091 seconds
[2022-10-19 18:21:20,667] {processor.py:153} INFO - Started process (PID=28834) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:20,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:21:20,671] {logging_mixin.py:115} INFO - [2022-10-19 18:21:20,671] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:20,684] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:20,775] {logging_mixin.py:115} INFO - [2022-10-19 18:21:20,775] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:21:20,808] {logging_mixin.py:115} INFO - [2022-10-19 18:21:20,808] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:21:20.683328+00:00, run_after=2022-10-20T18:21:20.683328+00:00
[2022-10-19 18:21:20,835] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.174 seconds
[2022-10-19 18:21:21,073] {processor.py:153} INFO - Started process (PID=38066) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:21,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:21:21,076] {logging_mixin.py:115} INFO - [2022-10-19 18:21:21,075] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:21,088] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:21,111] {logging_mixin.py:115} INFO - [2022-10-19 18:21:21,111] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:21:21,143] {logging_mixin.py:115} INFO - [2022-10-19 18:21:21,143] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:21:21.087173+00:00, run_after=2022-10-20T18:21:21.087173+00:00
[2022-10-19 18:21:21,162] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.094 seconds
[2022-10-19 18:21:51,112] {processor.py:153} INFO - Started process (PID=28863) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:51,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:21:51,117] {logging_mixin.py:115} INFO - [2022-10-19 18:21:51,117] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:51,130] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:51,211] {logging_mixin.py:115} INFO - [2022-10-19 18:21:51,211] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:21:51,240] {logging_mixin.py:115} INFO - [2022-10-19 18:21:51,240] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:21:51.129047+00:00, run_after=2022-10-20T18:21:51.129047+00:00
[2022-10-19 18:21:51,257] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.150 seconds
[2022-10-19 18:21:51,329] {processor.py:153} INFO - Started process (PID=38098) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:51,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:21:51,331] {logging_mixin.py:115} INFO - [2022-10-19 18:21:51,331] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:51,344] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:21:51,368] {logging_mixin.py:115} INFO - [2022-10-19 18:21:51,368] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:21:51,408] {logging_mixin.py:115} INFO - [2022-10-19 18:21:51,408] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:21:51.343397+00:00, run_after=2022-10-20T18:21:51.343397+00:00
[2022-10-19 18:21:51,424] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.100 seconds
[2022-10-19 18:22:21,658] {processor.py:153} INFO - Started process (PID=28901) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:21,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:22:21,663] {logging_mixin.py:115} INFO - [2022-10-19 18:22:21,662] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:21,673] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:21,754] {logging_mixin.py:115} INFO - [2022-10-19 18:22:21,754] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:22:21,784] {logging_mixin.py:115} INFO - [2022-10-19 18:22:21,784] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:22:21.672450+00:00, run_after=2022-10-20T18:22:21.672450+00:00
[2022-10-19 18:22:21,804] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.150 seconds
[2022-10-19 18:22:22,041] {processor.py:153} INFO - Started process (PID=38133) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:22,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:22:22,045] {logging_mixin.py:115} INFO - [2022-10-19 18:22:22,045] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:22,061] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:22,084] {logging_mixin.py:115} INFO - [2022-10-19 18:22:22,084] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:22:22,115] {logging_mixin.py:115} INFO - [2022-10-19 18:22:22,115] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:22:22.059409+00:00, run_after=2022-10-20T18:22:22.059409+00:00
[2022-10-19 18:22:22,133] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.097 seconds
[2022-10-19 18:22:52,300] {processor.py:153} INFO - Started process (PID=28939) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:52,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:22:52,304] {logging_mixin.py:115} INFO - [2022-10-19 18:22:52,304] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:52,317] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:52,410] {logging_mixin.py:115} INFO - [2022-10-19 18:22:52,410] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:22:52,439] {logging_mixin.py:115} INFO - [2022-10-19 18:22:52,439] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:22:52.316509+00:00, run_after=2022-10-20T18:22:52.316509+00:00
[2022-10-19 18:22:52,458] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.163 seconds
[2022-10-19 18:22:52,493] {processor.py:153} INFO - Started process (PID=38165) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:52,494] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:22:52,495] {logging_mixin.py:115} INFO - [2022-10-19 18:22:52,495] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:52,506] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:22:52,530] {logging_mixin.py:115} INFO - [2022-10-19 18:22:52,530] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:22:52,562] {logging_mixin.py:115} INFO - [2022-10-19 18:22:52,562] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:22:52.505083+00:00, run_after=2022-10-20T18:22:52.505083+00:00
[2022-10-19 18:22:52,579] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.092 seconds
[2022-10-19 18:23:22,593] {processor.py:153} INFO - Started process (PID=28968) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:22,597] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:23:22,599] {logging_mixin.py:115} INFO - [2022-10-19 18:23:22,598] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:22,615] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:22,670] {processor.py:153} INFO - Started process (PID=38196) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:22,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:23:22,673] {logging_mixin.py:115} INFO - [2022-10-19 18:23:22,673] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:22,685] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:22,706] {logging_mixin.py:115} INFO - [2022-10-19 18:23:22,706] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:23:22,735] {logging_mixin.py:115} INFO - [2022-10-19 18:23:22,734] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:23:22.613768+00:00, run_after=2022-10-20T18:23:22.613768+00:00
[2022-10-19 18:23:22,751] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.164 seconds
[2022-10-19 18:23:22,772] {logging_mixin.py:115} INFO - [2022-10-19 18:23:22,772] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:23:22,797] {logging_mixin.py:115} INFO - [2022-10-19 18:23:22,797] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:23:22.684190+00:00, run_after=2022-10-20T18:23:22.684190+00:00
[2022-10-19 18:23:22,822] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 18:23:52,797] {processor.py:153} INFO - Started process (PID=29006) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:52,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:23:52,802] {logging_mixin.py:115} INFO - [2022-10-19 18:23:52,802] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:52,816] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:52,912] {logging_mixin.py:115} INFO - [2022-10-19 18:23:52,912] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:23:52,941] {logging_mixin.py:115} INFO - [2022-10-19 18:23:52,941] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:23:52.815371+00:00, run_after=2022-10-20T18:23:52.815371+00:00
[2022-10-19 18:23:52,961] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.168 seconds
[2022-10-19 18:23:53,047] {processor.py:153} INFO - Started process (PID=38228) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:53,049] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:23:53,051] {logging_mixin.py:115} INFO - [2022-10-19 18:23:53,051] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:53,064] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:23:53,103] {logging_mixin.py:115} INFO - [2022-10-19 18:23:53,102] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:23:53,137] {logging_mixin.py:115} INFO - [2022-10-19 18:23:53,137] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:23:53.062833+00:00, run_after=2022-10-20T18:23:53.062833+00:00
[2022-10-19 18:23:53,157] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.115 seconds
[2022-10-19 18:24:23,254] {processor.py:153} INFO - Started process (PID=38261) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:23,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:24:23,261] {logging_mixin.py:115} INFO - [2022-10-19 18:24:23,260] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:23,272] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:23,308] {processor.py:153} INFO - Started process (PID=29036) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:23,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:24:23,312] {logging_mixin.py:115} INFO - [2022-10-19 18:24:23,312] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:23,328] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:23,364] {logging_mixin.py:115} INFO - [2022-10-19 18:24:23,364] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:24:23,388] {logging_mixin.py:115} INFO - [2022-10-19 18:24:23,388] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:24:23.271296+00:00, run_after=2022-10-20T18:24:23.271296+00:00
[2022-10-19 18:24:23,407] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.160 seconds
[2022-10-19 18:24:23,424] {logging_mixin.py:115} INFO - [2022-10-19 18:24:23,424] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:24:23,454] {logging_mixin.py:115} INFO - [2022-10-19 18:24:23,454] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:24:23.326794+00:00, run_after=2022-10-20T18:24:23.326794+00:00
[2022-10-19 18:24:23,476] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.175 seconds
[2022-10-19 18:24:53,648] {processor.py:153} INFO - Started process (PID=38293) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:53,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:24:53,653] {logging_mixin.py:115} INFO - [2022-10-19 18:24:53,653] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:53,666] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:53,670] {processor.py:153} INFO - Started process (PID=29074) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:53,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:24:53,673] {logging_mixin.py:115} INFO - [2022-10-19 18:24:53,673] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:53,685] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:24:53,762] {logging_mixin.py:115} INFO - [2022-10-19 18:24:53,762] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:24:53,781] {logging_mixin.py:115} INFO - [2022-10-19 18:24:53,781] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:24:53,793] {logging_mixin.py:115} INFO - [2022-10-19 18:24:53,793] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:24:53.665047+00:00, run_after=2022-10-20T18:24:53.665047+00:00
[2022-10-19 18:24:53,811] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.168 seconds
[2022-10-19 18:24:53,827] {logging_mixin.py:115} INFO - [2022-10-19 18:24:53,827] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:24:53.684661+00:00, run_after=2022-10-20T18:24:53.684661+00:00
[2022-10-19 18:24:53,843] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.178 seconds
[2022-10-19 18:25:24,051] {processor.py:153} INFO - Started process (PID=29113) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:24,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:25:24,056] {logging_mixin.py:115} INFO - [2022-10-19 18:25:24,056] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:24,071] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:24,114] {processor.py:153} INFO - Started process (PID=38325) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:24,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:25:24,119] {logging_mixin.py:115} INFO - [2022-10-19 18:25:24,119] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:24,142] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:24,203] {logging_mixin.py:115} INFO - [2022-10-19 18:25:24,202] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:25:24,239] {logging_mixin.py:115} INFO - [2022-10-19 18:25:24,239] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:25:24.070639+00:00, run_after=2022-10-20T18:25:24.070639+00:00
[2022-10-19 18:25:24,265] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.220 seconds
[2022-10-19 18:25:24,287] {logging_mixin.py:115} INFO - [2022-10-19 18:25:24,286] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:25:24,319] {logging_mixin.py:115} INFO - [2022-10-19 18:25:24,319] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:25:24.140854+00:00, run_after=2022-10-20T18:25:24.140854+00:00
[2022-10-19 18:25:24,340] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.234 seconds
[2022-10-19 18:25:54,382] {processor.py:153} INFO - Started process (PID=29142) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:54,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:25:54,386] {logging_mixin.py:115} INFO - [2022-10-19 18:25:54,386] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:54,399] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:54,522] {logging_mixin.py:115} INFO - [2022-10-19 18:25:54,521] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:25:54,563] {logging_mixin.py:115} INFO - [2022-10-19 18:25:54,563] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:25:54.398180+00:00, run_after=2022-10-20T18:25:54.398180+00:00
[2022-10-19 18:25:54,587] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.210 seconds
[2022-10-19 18:25:54,623] {processor.py:153} INFO - Started process (PID=38357) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:54,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:25:54,626] {logging_mixin.py:115} INFO - [2022-10-19 18:25:54,626] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:54,637] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:25:54,660] {logging_mixin.py:115} INFO - [2022-10-19 18:25:54,660] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:25:54,698] {logging_mixin.py:115} INFO - [2022-10-19 18:25:54,698] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:25:54.636800+00:00, run_after=2022-10-20T18:25:54.636800+00:00
[2022-10-19 18:25:54,716] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.098 seconds
[2022-10-19 18:26:24,879] {processor.py:153} INFO - Started process (PID=38389) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:24,880] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:26:24,882] {logging_mixin.py:115} INFO - [2022-10-19 18:26:24,882] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:24,893] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:24,982] {logging_mixin.py:115} INFO - [2022-10-19 18:26:24,982] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:26:25,009] {logging_mixin.py:115} INFO - [2022-10-19 18:26:25,009] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:26:24.891942+00:00, run_after=2022-10-20T18:26:24.891942+00:00
[2022-10-19 18:26:25,026] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.156 seconds
[2022-10-19 18:26:25,099] {processor.py:153} INFO - Started process (PID=29180) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:25,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:26:25,101] {logging_mixin.py:115} INFO - [2022-10-19 18:26:25,101] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:25,113] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:25,138] {logging_mixin.py:115} INFO - [2022-10-19 18:26:25,138] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:26:25,172] {logging_mixin.py:115} INFO - [2022-10-19 18:26:25,172] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:26:25.112231+00:00, run_after=2022-10-20T18:26:25.112231+00:00
[2022-10-19 18:26:25,191] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.097 seconds
[2022-10-19 18:26:55,257] {processor.py:153} INFO - Started process (PID=38421) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:55,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:26:55,260] {logging_mixin.py:115} INFO - [2022-10-19 18:26:55,260] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:55,272] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:55,361] {logging_mixin.py:115} INFO - [2022-10-19 18:26:55,360] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:26:55,391] {logging_mixin.py:115} INFO - [2022-10-19 18:26:55,390] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:26:55.271533+00:00, run_after=2022-10-20T18:26:55.271533+00:00
[2022-10-19 18:26:55,415] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.162 seconds
[2022-10-19 18:26:55,658] {processor.py:153} INFO - Started process (PID=29209) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:55,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:26:55,661] {logging_mixin.py:115} INFO - [2022-10-19 18:26:55,661] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:55,673] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:26:55,695] {logging_mixin.py:115} INFO - [2022-10-19 18:26:55,695] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:26:55,728] {logging_mixin.py:115} INFO - [2022-10-19 18:26:55,728] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:26:55.672114+00:00, run_after=2022-10-20T18:26:55.672114+00:00
[2022-10-19 18:26:55,746] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.092 seconds
[2022-10-19 18:27:25,568] {processor.py:153} INFO - Started process (PID=38453) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:25,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:27:25,571] {logging_mixin.py:115} INFO - [2022-10-19 18:27:25,570] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:25,581] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:25,664] {logging_mixin.py:115} INFO - [2022-10-19 18:27:25,664] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:27:25,692] {logging_mixin.py:115} INFO - [2022-10-19 18:27:25,692] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:27:25.580886+00:00, run_after=2022-10-20T18:27:25.580886+00:00
[2022-10-19 18:27:25,710] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.147 seconds
[2022-10-19 18:27:26,296] {processor.py:153} INFO - Started process (PID=29247) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:26,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:27:26,298] {logging_mixin.py:115} INFO - [2022-10-19 18:27:26,298] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:26,309] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:26,328] {logging_mixin.py:115} INFO - [2022-10-19 18:27:26,328] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:27:26,384] {logging_mixin.py:115} INFO - [2022-10-19 18:27:26,384] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:27:26.307882+00:00, run_after=2022-10-20T18:27:26.307882+00:00
[2022-10-19 18:27:26,400] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.109 seconds
[2022-10-19 18:27:55,882] {processor.py:153} INFO - Started process (PID=38485) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:55,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:27:55,885] {logging_mixin.py:115} INFO - [2022-10-19 18:27:55,885] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:55,896] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:55,987] {logging_mixin.py:115} INFO - [2022-10-19 18:27:55,987] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:27:56,016] {logging_mixin.py:115} INFO - [2022-10-19 18:27:56,016] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:27:55.895633+00:00, run_after=2022-10-20T18:27:55.895633+00:00
[2022-10-19 18:27:56,042] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.164 seconds
[2022-10-19 18:27:56,850] {processor.py:153} INFO - Started process (PID=29276) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:56,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:27:56,857] {logging_mixin.py:115} INFO - [2022-10-19 18:27:56,857] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:56,872] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:27:56,912] {logging_mixin.py:115} INFO - [2022-10-19 18:27:56,911] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:27:56,949] {logging_mixin.py:115} INFO - [2022-10-19 18:27:56,948] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:27:56.871229+00:00, run_after=2022-10-20T18:27:56.871229+00:00
[2022-10-19 18:27:56,967] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.128 seconds
[2022-10-19 18:28:26,079] {processor.py:153} INFO - Started process (PID=38519) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:26,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:28:26,081] {logging_mixin.py:115} INFO - [2022-10-19 18:28:26,081] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:26,092] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:26,175] {logging_mixin.py:115} INFO - [2022-10-19 18:28:26,175] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:28:26,205] {logging_mixin.py:115} INFO - [2022-10-19 18:28:26,205] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:28:26.091270+00:00, run_after=2022-10-20T18:28:26.091270+00:00
[2022-10-19 18:28:26,225] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.150 seconds
[2022-10-19 18:28:27,458] {processor.py:153} INFO - Started process (PID=29316) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:27,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:28:27,461] {logging_mixin.py:115} INFO - [2022-10-19 18:28:27,461] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:27,472] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:27,492] {logging_mixin.py:115} INFO - [2022-10-19 18:28:27,492] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:28:27,523] {logging_mixin.py:115} INFO - [2022-10-19 18:28:27,523] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:28:27.471741+00:00, run_after=2022-10-20T18:28:27.471741+00:00
[2022-10-19 18:28:27,543] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.089 seconds
[2022-10-19 18:28:56,450] {processor.py:153} INFO - Started process (PID=38552) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:56,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:28:56,453] {logging_mixin.py:115} INFO - [2022-10-19 18:28:56,453] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:56,465] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:56,563] {logging_mixin.py:115} INFO - [2022-10-19 18:28:56,563] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:28:56,593] {logging_mixin.py:115} INFO - [2022-10-19 18:28:56,593] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:28:56.464180+00:00, run_after=2022-10-20T18:28:56.464180+00:00
[2022-10-19 18:28:56,613] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.167 seconds
[2022-10-19 18:28:58,083] {processor.py:153} INFO - Started process (PID=29354) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:58,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:28:58,087] {logging_mixin.py:115} INFO - [2022-10-19 18:28:58,087] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:58,112] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:28:58,138] {logging_mixin.py:115} INFO - [2022-10-19 18:28:58,138] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:28:58,173] {logging_mixin.py:115} INFO - [2022-10-19 18:28:58,173] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:28:58.111178+00:00, run_after=2022-10-20T18:28:58.111178+00:00
[2022-10-19 18:28:58,198] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.127 seconds
[2022-10-19 18:29:26,802] {processor.py:153} INFO - Started process (PID=38584) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:26,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:29:26,807] {logging_mixin.py:115} INFO - [2022-10-19 18:29:26,807] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:26,819] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:26,902] {logging_mixin.py:115} INFO - [2022-10-19 18:29:26,902] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:29:26,930] {logging_mixin.py:115} INFO - [2022-10-19 18:29:26,930] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:29:26.818386+00:00, run_after=2022-10-20T18:29:26.818386+00:00
[2022-10-19 18:29:26,951] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.157 seconds
[2022-10-19 18:29:28,396] {processor.py:153} INFO - Started process (PID=29383) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:28,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:29:28,399] {logging_mixin.py:115} INFO - [2022-10-19 18:29:28,399] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:28,411] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:28,436] {logging_mixin.py:115} INFO - [2022-10-19 18:29:28,436] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:29:28,475] {logging_mixin.py:115} INFO - [2022-10-19 18:29:28,474] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:29:28.410616+00:00, run_after=2022-10-20T18:29:28.410616+00:00
[2022-10-19 18:29:28,501] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.111 seconds
[2022-10-19 18:29:57,122] {processor.py:153} INFO - Started process (PID=38616) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:57,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:29:57,129] {logging_mixin.py:115} INFO - [2022-10-19 18:29:57,129] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:57,151] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:57,347] {logging_mixin.py:115} INFO - [2022-10-19 18:29:57,347] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:29:57,405] {logging_mixin.py:115} INFO - [2022-10-19 18:29:57,405] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:29:57.150018+00:00, run_after=2022-10-20T18:29:57.150018+00:00
[2022-10-19 18:29:57,431] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.315 seconds
[2022-10-19 18:29:59,100] {processor.py:153} INFO - Started process (PID=29422) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:59,101] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:29:59,102] {logging_mixin.py:115} INFO - [2022-10-19 18:29:59,102] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:59,115] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:29:59,140] {logging_mixin.py:115} INFO - [2022-10-19 18:29:59,140] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:29:59,189] {logging_mixin.py:115} INFO - [2022-10-19 18:29:59,189] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:29:59.114607+00:00, run_after=2022-10-20T18:29:59.114607+00:00
[2022-10-19 18:29:59,209] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.115 seconds
[2022-10-19 18:30:27,808] {processor.py:153} INFO - Started process (PID=38649) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:27,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:30:27,811] {logging_mixin.py:115} INFO - [2022-10-19 18:30:27,811] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:27,821] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:27,901] {logging_mixin.py:115} INFO - [2022-10-19 18:30:27,901] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:30:27,928] {logging_mixin.py:115} INFO - [2022-10-19 18:30:27,928] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:30:27.820619+00:00, run_after=2022-10-20T18:30:27.820619+00:00
[2022-10-19 18:30:27,945] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.142 seconds
[2022-10-19 18:30:29,744] {processor.py:153} INFO - Started process (PID=29452) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:29,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:30:29,747] {logging_mixin.py:115} INFO - [2022-10-19 18:30:29,746] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:29,757] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:29,782] {logging_mixin.py:115} INFO - [2022-10-19 18:30:29,782] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:30:29,822] {logging_mixin.py:115} INFO - [2022-10-19 18:30:29,821] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:30:29.756711+00:00, run_after=2022-10-20T18:30:29.756711+00:00
[2022-10-19 18:30:29,838] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.099 seconds
[2022-10-19 18:30:43,834] {processor.py:153} INFO - Started process (PID=29479) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:43,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:30:43,837] {logging_mixin.py:115} INFO - [2022-10-19 18:30:43,836] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:43,880] {processor.py:153} INFO - Started process (PID=38665) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:43,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:30:43,884] {logging_mixin.py:115} INFO - [2022-10-19 18:30:43,883] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:44,391] {logging_mixin.py:115} INFO - [2022-10-19 18:30:44,388] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:30:44,393] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:44,446] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.621 seconds
[2022-10-19 18:30:48,955] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:30:48,968] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:30:48,988] {logging_mixin.py:115} INFO - [2022-10-19 18:30:48,987] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:30:49,018] {logging_mixin.py:115} INFO - [2022-10-19 18:30:49,017] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:30:48.966443+00:00, run_after=2022-10-20T18:30:48.966443+00:00
[2022-10-19 18:30:49,039] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.190 seconds
[2022-10-19 18:31:14,648] {processor.py:153} INFO - Started process (PID=29512) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:14,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:31:14,654] {logging_mixin.py:115} INFO - [2022-10-19 18:31:14,653] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:15,177] {logging_mixin.py:115} INFO - [2022-10-19 18:31:15,174] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:31:15,181] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:15,222] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.580 seconds
[2022-10-19 18:31:19,245] {processor.py:153} INFO - Started process (PID=38817) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:19,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:31:19,247] {logging_mixin.py:115} INFO - [2022-10-19 18:31:19,247] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:24,857] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:31:24,875] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:24,960] {logging_mixin.py:115} INFO - [2022-10-19 18:31:24,959] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:31:24,987] {logging_mixin.py:115} INFO - [2022-10-19 18:31:24,987] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:31:24.873772+00:00, run_after=2022-10-20T18:31:24.873772+00:00
[2022-10-19 18:31:25,006] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.768 seconds
[2022-10-19 18:31:45,859] {processor.py:153} INFO - Started process (PID=29559) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:45,860] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:31:45,861] {logging_mixin.py:115} INFO - [2022-10-19 18:31:45,861] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:46,363] {logging_mixin.py:115} INFO - [2022-10-19 18:31:46,361] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:31:46,366] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:46,419] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.565 seconds
[2022-10-19 18:31:55,460] {processor.py:153} INFO - Started process (PID=38982) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:31:55,461] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:31:55,463] {logging_mixin.py:115} INFO - [2022-10-19 18:31:55,463] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:00,470] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:32:00,514] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:00,617] {logging_mixin.py:115} INFO - [2022-10-19 18:32:00,616] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:32:00,652] {logging_mixin.py:115} INFO - [2022-10-19 18:32:00,652] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:32:00.512237+00:00, run_after=2022-10-20T18:32:00.512237+00:00
[2022-10-19 18:32:00,668] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.215 seconds
[2022-10-19 18:32:16,991] {processor.py:153} INFO - Started process (PID=29604) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:16,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:32:16,995] {logging_mixin.py:115} INFO - [2022-10-19 18:32:16,995] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:17,514] {logging_mixin.py:115} INFO - [2022-10-19 18:32:17,511] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:32:17,517] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:17,548] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.569 seconds
[2022-10-19 18:32:30,989] {processor.py:153} INFO - Started process (PID=39134) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:30,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:32:30,992] {logging_mixin.py:115} INFO - [2022-10-19 18:32:30,992] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:35,248] {processor.py:153} INFO - Started process (PID=29633) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:35,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:32:35,251] {logging_mixin.py:115} INFO - [2022-10-19 18:32:35,251] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:36,002] {logging_mixin.py:115} INFO - [2022-10-19 18:32:35,999] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:32:36,003] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:36,033] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.790 seconds
[2022-10-19 18:32:36,268] {processor.py:153} INFO - Started process (PID=29642) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:36,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:32:36,271] {logging_mixin.py:115} INFO - [2022-10-19 18:32:36,270] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:36,992] {logging_mixin.py:115} INFO - [2022-10-19 18:32:36,989] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:32:36,995] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:37,012] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:32:37,026] {logging_mixin.py:115} INFO - [2022-10-19 18:32:37,022] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
ImportError: cannot import name 'loadJsonData' from 'data_extraction_pyspark' (/opt/airflow/dags/data_extraction_pyspark.py)
[2022-10-19 18:32:37,027] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:32:37,031] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.768 seconds
[2022-10-19 18:32:37,060] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.075 seconds
[2022-10-19 18:33:07,420] {processor.py:153} INFO - Started process (PID=39294) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:07,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:33:07,423] {logging_mixin.py:115} INFO - [2022-10-19 18:33:07,423] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:07,735] {processor.py:153} INFO - Started process (PID=29688) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:07,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:33:07,738] {logging_mixin.py:115} INFO - [2022-10-19 18:33:07,738] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:08,251] {logging_mixin.py:115} INFO - [2022-10-19 18:33:08,249] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:33:08,254] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:08,285] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.554 seconds
[2022-10-19 18:33:12,169] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:33:12,183] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:12,273] {logging_mixin.py:115} INFO - [2022-10-19 18:33:12,271] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:33:12,303] {logging_mixin.py:115} INFO - [2022-10-19 18:33:12,303] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:33:12.180862+00:00, run_after=2022-10-20T18:33:12.180862+00:00
[2022-10-19 18:33:12,336] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.922 seconds
[2022-10-19 18:33:38,372] {processor.py:153} INFO - Started process (PID=29725) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:38,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:33:38,374] {logging_mixin.py:115} INFO - [2022-10-19 18:33:38,374] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:38,906] {logging_mixin.py:115} INFO - [2022-10-19 18:33:38,902] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:33:38,908] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:38,940] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.573 seconds
[2022-10-19 18:33:42,820] {processor.py:153} INFO - Started process (PID=39447) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:42,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:33:42,823] {logging_mixin.py:115} INFO - [2022-10-19 18:33:42,823] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:48,257] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:33:48,286] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:48,373] {logging_mixin.py:115} INFO - [2022-10-19 18:33:48,372] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:33:48,400] {logging_mixin.py:115} INFO - [2022-10-19 18:33:48,400] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:33:48.284890+00:00, run_after=2022-10-20T18:33:48.284890+00:00
[2022-10-19 18:33:48,423] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.631 seconds
[2022-10-19 18:33:52,302] {processor.py:153} INFO - Started process (PID=39575) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:52,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:33:52,305] {logging_mixin.py:115} INFO - [2022-10-19 18:33:52,305] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:52,596] {processor.py:153} INFO - Started process (PID=29757) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:52,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:33:52,602] {logging_mixin.py:115} INFO - [2022-10-19 18:33:52,602] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:53,323] {logging_mixin.py:115} INFO - [2022-10-19 18:33:53,320] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:33:53,326] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:53,376] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.804 seconds
[2022-10-19 18:33:57,889] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:33:57,910] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:33:57,950] {logging_mixin.py:115} INFO - [2022-10-19 18:33:57,948] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:33:58,006] {logging_mixin.py:115} INFO - [2022-10-19 18:33:58,005] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:33:57.907312+00:00, run_after=2022-10-20T18:33:57.907312+00:00
[2022-10-19 18:33:58,046] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.748 seconds
[2022-10-19 18:34:24,257] {processor.py:153} INFO - Started process (PID=29794) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:24,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:34:24,259] {logging_mixin.py:115} INFO - [2022-10-19 18:34:24,259] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:24,727] {logging_mixin.py:115} INFO - [2022-10-19 18:34:24,725] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:34:24,729] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:24,761] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.509 seconds
[2022-10-19 18:34:28,143] {processor.py:153} INFO - Started process (PID=39863) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:28,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:34:28,148] {logging_mixin.py:115} INFO - [2022-10-19 18:34:28,148] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:33,540] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:34:33,556] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:33,643] {logging_mixin.py:115} INFO - [2022-10-19 18:34:33,642] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:34:33,676] {logging_mixin.py:115} INFO - [2022-10-19 18:34:33,676] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:34:33.554726+00:00, run_after=2022-10-20T18:34:33.554726+00:00
[2022-10-19 18:34:33,721] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.582 seconds
[2022-10-19 18:34:55,529] {processor.py:153} INFO - Started process (PID=29841) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:55,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:34:55,533] {logging_mixin.py:115} INFO - [2022-10-19 18:34:55,533] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:56,033] {logging_mixin.py:115} INFO - [2022-10-19 18:34:56,025] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:34:56,037] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:34:56,085] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.562 seconds
[2022-10-19 18:35:04,406] {processor.py:153} INFO - Started process (PID=40143) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:04,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:35:04,409] {logging_mixin.py:115} INFO - [2022-10-19 18:35:04,409] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:09,294] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:35:09,311] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:09,420] {logging_mixin.py:115} INFO - [2022-10-19 18:35:09,419] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:35:09,496] {logging_mixin.py:115} INFO - [2022-10-19 18:35:09,495] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:35:09.309289+00:00, run_after=2022-10-20T18:35:09.309289+00:00
[2022-10-19 18:35:09,538] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.137 seconds
[2022-10-19 18:35:13,430] {processor.py:153} INFO - Started process (PID=40272) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:13,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:35:13,432] {logging_mixin.py:115} INFO - [2022-10-19 18:35:13,432] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:13,796] {processor.py:153} INFO - Started process (PID=29873) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:13,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:35:13,801] {logging_mixin.py:115} INFO - [2022-10-19 18:35:13,801] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:14,478] {logging_mixin.py:115} INFO - [2022-10-19 18:35:14,472] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:35:14,481] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:14,527] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.751 seconds
[2022-10-19 18:35:19,187] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:35:19,203] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:19,227] {logging_mixin.py:115} INFO - [2022-10-19 18:35:19,225] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:35:19,257] {logging_mixin.py:115} INFO - [2022-10-19 18:35:19,257] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:35:19.201166+00:00, run_after=2022-10-20T18:35:19.201166+00:00
[2022-10-19 18:35:19,277] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.875 seconds
[2022-10-19 18:35:45,216] {processor.py:153} INFO - Started process (PID=29912) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:45,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:35:45,221] {logging_mixin.py:115} INFO - [2022-10-19 18:35:45,221] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:45,938] {logging_mixin.py:115} INFO - [2022-10-19 18:35:45,934] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:35:45,940] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:45,990] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.780 seconds
[2022-10-19 18:35:49,725] {processor.py:153} INFO - Started process (PID=40679) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:49,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:35:49,728] {logging_mixin.py:115} INFO - [2022-10-19 18:35:49,728] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:54,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:35:54,843] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:35:54,930] {logging_mixin.py:115} INFO - [2022-10-19 18:35:54,929] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:35:54,956] {logging_mixin.py:115} INFO - [2022-10-19 18:35:54,955] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:35:54.841937+00:00, run_after=2022-10-20T18:35:54.841937+00:00
[2022-10-19 18:35:54,975] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.254 seconds
[2022-10-19 18:36:16,208] {processor.py:153} INFO - Started process (PID=29959) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:16,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:36:16,211] {logging_mixin.py:115} INFO - [2022-10-19 18:36:16,211] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:16,659] {logging_mixin.py:115} INFO - [2022-10-19 18:36:16,657] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:36:16,662] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:16,696] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.515 seconds
[2022-10-19 18:36:25,092] {processor.py:153} INFO - Started process (PID=40834) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:25,093] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:36:25,096] {logging_mixin.py:115} INFO - [2022-10-19 18:36:25,096] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:30,039] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:36:30,055] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:30,153] {logging_mixin.py:115} INFO - [2022-10-19 18:36:30,152] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:36:30,182] {logging_mixin.py:115} INFO - [2022-10-19 18:36:30,182] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:36:30.053315+00:00, run_after=2022-10-20T18:36:30.053315+00:00
[2022-10-19 18:36:30,203] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.119 seconds
[2022-10-19 18:36:47,126] {processor.py:153} INFO - Started process (PID=29994) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:47,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:36:47,130] {logging_mixin.py:115} INFO - [2022-10-19 18:36:47,130] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:47,633] {logging_mixin.py:115} INFO - [2022-10-19 18:36:47,630] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:36:47,635] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:36:47,667] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.546 seconds
[2022-10-19 18:37:00,253] {processor.py:153} INFO - Started process (PID=40992) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:00,255] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:37:00,256] {logging_mixin.py:115} INFO - [2022-10-19 18:37:00,256] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:05,255] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:37:05,270] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:05,354] {logging_mixin.py:115} INFO - [2022-10-19 18:37:05,353] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:37:05,380] {logging_mixin.py:115} INFO - [2022-10-19 18:37:05,380] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:37:05.268376+00:00, run_after=2022-10-20T18:37:05.268376+00:00
[2022-10-19 18:37:05,398] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.152 seconds
[2022-10-19 18:37:18,183] {processor.py:153} INFO - Started process (PID=30042) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:18,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:37:18,187] {logging_mixin.py:115} INFO - [2022-10-19 18:37:18,187] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:18,666] {logging_mixin.py:115} INFO - [2022-10-19 18:37:18,663] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:37:18,669] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:18,700] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.521 seconds
[2022-10-19 18:37:36,392] {processor.py:153} INFO - Started process (PID=41269) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:36,394] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:37:36,399] {logging_mixin.py:115} INFO - [2022-10-19 18:37:36,396] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:43,039] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:37:43,063] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:43,148] {logging_mixin.py:115} INFO - [2022-10-19 18:37:43,147] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:37:43,177] {logging_mixin.py:115} INFO - [2022-10-19 18:37:43,177] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:37:43.060653+00:00, run_after=2022-10-20T18:37:43.060653+00:00
[2022-10-19 18:37:43,199] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.819 seconds
[2022-10-19 18:37:48,896] {processor.py:153} INFO - Started process (PID=30088) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:48,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:37:48,904] {logging_mixin.py:115} INFO - [2022-10-19 18:37:48,903] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:49,588] {logging_mixin.py:115} INFO - [2022-10-19 18:37:49,586] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:37:49,590] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:37:49,622] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.742 seconds
[2022-10-19 18:38:13,820] {processor.py:153} INFO - Started process (PID=41437) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:13,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:38:13,825] {logging_mixin.py:115} INFO - [2022-10-19 18:38:13,825] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:19,729] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:38:19,742] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:19,849] {logging_mixin.py:115} INFO - [2022-10-19 18:38:19,847] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:38:19,892] {processor.py:153} INFO - Started process (PID=30126) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:19,894] {logging_mixin.py:115} INFO - [2022-10-19 18:38:19,894] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:38:19.740407+00:00, run_after=2022-10-20T18:38:19.740407+00:00
[2022-10-19 18:38:19,894] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:38:19,896] {logging_mixin.py:115} INFO - [2022-10-19 18:38:19,896] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:19,922] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.128 seconds
[2022-10-19 18:38:20,438] {logging_mixin.py:115} INFO - [2022-10-19 18:38:20,434] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:38:20,440] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:20,495] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.608 seconds
[2022-10-19 18:38:50,091] {processor.py:153} INFO - Started process (PID=41722) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:50,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:38:50,096] {logging_mixin.py:115} INFO - [2022-10-19 18:38:50,096] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:50,567] {processor.py:153} INFO - Started process (PID=30172) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:50,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:38:50,571] {logging_mixin.py:115} INFO - [2022-10-19 18:38:50,570] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:51,148] {logging_mixin.py:115} INFO - [2022-10-19 18:38:51,146] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:38:51,150] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:51,188] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.628 seconds
[2022-10-19 18:38:55,399] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:38:55,436] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:38:55,532] {logging_mixin.py:115} INFO - [2022-10-19 18:38:55,531] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:38:55,562] {logging_mixin.py:115} INFO - [2022-10-19 18:38:55,562] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:38:55.434339+00:00, run_after=2022-10-20T18:38:55.434339+00:00
[2022-10-19 18:38:55,583] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.501 seconds
[2022-10-19 18:39:21,269] {processor.py:153} INFO - Started process (PID=30209) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:21,271] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:39:21,272] {logging_mixin.py:115} INFO - [2022-10-19 18:39:21,272] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:21,811] {logging_mixin.py:115} INFO - [2022-10-19 18:39:21,807] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:39:21,813] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:21,843] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.580 seconds
[2022-10-19 18:39:25,957] {processor.py:153} INFO - Started process (PID=41873) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:25,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:39:25,960] {logging_mixin.py:115} INFO - [2022-10-19 18:39:25,960] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:31,442] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:39:31,460] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:31,565] {logging_mixin.py:115} INFO - [2022-10-19 18:39:31,563] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:39:31,601] {logging_mixin.py:115} INFO - [2022-10-19 18:39:31,601] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:39:31.458122+00:00, run_after=2022-10-20T18:39:31.458122+00:00
[2022-10-19 18:39:31,621] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.669 seconds
[2022-10-19 18:39:52,241] {processor.py:153} INFO - Started process (PID=30255) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:52,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:39:52,249] {logging_mixin.py:115} INFO - [2022-10-19 18:39:52,248] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:52,926] {logging_mixin.py:115} INFO - [2022-10-19 18:39:52,923] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:39:52,931] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:39:52,974] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.741 seconds
[2022-10-19 18:40:02,516] {processor.py:153} INFO - Started process (PID=42155) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:02,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:40:02,522] {logging_mixin.py:115} INFO - [2022-10-19 18:40:02,522] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:09,355] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:40:09,390] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:09,627] {logging_mixin.py:115} INFO - [2022-10-19 18:40:09,624] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:40:09,698] {logging_mixin.py:115} INFO - [2022-10-19 18:40:09,697] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:40:09.386996+00:00, run_after=2022-10-20T18:40:09.386996+00:00
[2022-10-19 18:40:09,742] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.231 seconds
[2022-10-19 18:40:23,558] {processor.py:153} INFO - Started process (PID=30293) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:23,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:40:23,560] {logging_mixin.py:115} INFO - [2022-10-19 18:40:23,560] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:24,058] {logging_mixin.py:115} INFO - [2022-10-19 18:40:24,055] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:40:24,061] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:24,091] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.538 seconds
[2022-10-19 18:40:40,276] {processor.py:153} INFO - Started process (PID=42307) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:40,278] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:40:40,280] {logging_mixin.py:115} INFO - [2022-10-19 18:40:40,280] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:46,110] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:40:46,130] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:46,239] {logging_mixin.py:115} INFO - [2022-10-19 18:40:46,237] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:40:46,277] {logging_mixin.py:115} INFO - [2022-10-19 18:40:46,277] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:40:46.127277+00:00, run_after=2022-10-20T18:40:46.127277+00:00
[2022-10-19 18:40:46,307] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.037 seconds
[2022-10-19 18:40:54,242] {processor.py:153} INFO - Started process (PID=30341) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:54,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:40:54,245] {logging_mixin.py:115} INFO - [2022-10-19 18:40:54,245] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:54,808] {logging_mixin.py:115} INFO - [2022-10-19 18:40:54,805] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:40:54,810] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:40:54,846] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.609 seconds
[2022-10-19 18:41:16,645] {processor.py:153} INFO - Started process (PID=42469) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:16,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:41:16,647] {logging_mixin.py:115} INFO - [2022-10-19 18:41:16,647] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:21,716] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:41:21,734] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:21,829] {logging_mixin.py:115} INFO - [2022-10-19 18:41:21,827] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:41:21,861] {logging_mixin.py:115} INFO - [2022-10-19 18:41:21,861] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:41:21.732446+00:00, run_after=2022-10-20T18:41:21.732446+00:00
[2022-10-19 18:41:21,882] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.242 seconds
[2022-10-19 18:41:25,009] {processor.py:153} INFO - Started process (PID=30388) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:25,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:41:25,012] {logging_mixin.py:115} INFO - [2022-10-19 18:41:25,012] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:25,589] {logging_mixin.py:115} INFO - [2022-10-19 18:41:25,587] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:41:25,593] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:25,629] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.628 seconds
[2022-10-19 18:41:52,461] {processor.py:153} INFO - Started process (PID=42633) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:52,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:41:52,465] {logging_mixin.py:115} INFO - [2022-10-19 18:41:52,465] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:56,433] {processor.py:153} INFO - Started process (PID=30425) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:56,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:41:56,439] {logging_mixin.py:115} INFO - [2022-10-19 18:41:56,438] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:57,107] {logging_mixin.py:115} INFO - [2022-10-19 18:41:57,104] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:41:57,110] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:57,153] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.732 seconds
[2022-10-19 18:41:58,140] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:41:58,164] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:41:58,305] {logging_mixin.py:115} INFO - [2022-10-19 18:41:58,304] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:41:58,351] {logging_mixin.py:115} INFO - [2022-10-19 18:41:58,351] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:41:58.158478+00:00, run_after=2022-10-20T18:41:58.158478+00:00
[2022-10-19 18:41:58,380] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.925 seconds
[2022-10-19 18:42:27,654] {processor.py:153} INFO - Started process (PID=30472) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:27,658] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:42:27,660] {logging_mixin.py:115} INFO - [2022-10-19 18:42:27,660] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:28,303] {logging_mixin.py:115} INFO - [2022-10-19 18:42:28,299] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:42:28,307] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:28,348] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.700 seconds
[2022-10-19 18:42:28,861] {processor.py:153} INFO - Started process (PID=42910) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:28,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:42:28,866] {logging_mixin.py:115} INFO - [2022-10-19 18:42:28,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:35,295] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:42:35,316] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:35,455] {logging_mixin.py:115} INFO - [2022-10-19 18:42:35,452] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:42:35,497] {logging_mixin.py:115} INFO - [2022-10-19 18:42:35,497] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:42:35.313480+00:00, run_after=2022-10-20T18:42:35.313480+00:00
[2022-10-19 18:42:35,525] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.671 seconds
[2022-10-19 18:42:58,601] {processor.py:153} INFO - Started process (PID=30510) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:58,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:42:58,603] {logging_mixin.py:115} INFO - [2022-10-19 18:42:58,603] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:59,106] {logging_mixin.py:115} INFO - [2022-10-19 18:42:59,104] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:42:59,109] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:42:59,139] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.542 seconds
[2022-10-19 18:43:06,098] {processor.py:153} INFO - Started process (PID=43073) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:06,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:43:06,100] {logging_mixin.py:115} INFO - [2022-10-19 18:43:06,100] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:10,838] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:43:10,852] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:10,959] {logging_mixin.py:115} INFO - [2022-10-19 18:43:10,957] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:43:10,993] {logging_mixin.py:115} INFO - [2022-10-19 18:43:10,993] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:43:10.849935+00:00, run_after=2022-10-20T18:43:10.849935+00:00
[2022-10-19 18:43:11,014] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.921 seconds
[2022-10-19 18:43:29,872] {processor.py:153} INFO - Started process (PID=30556) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:29,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:43:29,875] {logging_mixin.py:115} INFO - [2022-10-19 18:43:29,875] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:30,363] {logging_mixin.py:115} INFO - [2022-10-19 18:43:30,360] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:43:30,365] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:30,398] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.531 seconds
[2022-10-19 18:43:41,908] {processor.py:153} INFO - Started process (PID=43225) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:41,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:43:41,910] {logging_mixin.py:115} INFO - [2022-10-19 18:43:41,910] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:46,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:43:46,972] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:43:47,106] {logging_mixin.py:115} INFO - [2022-10-19 18:43:47,105] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:43:47,146] {logging_mixin.py:115} INFO - [2022-10-19 18:43:47,146] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:43:46.970340+00:00, run_after=2022-10-20T18:43:46.970340+00:00
[2022-10-19 18:43:47,172] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.291 seconds
[2022-10-19 18:44:01,137] {processor.py:153} INFO - Started process (PID=30593) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:01,139] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:44:01,141] {logging_mixin.py:115} INFO - [2022-10-19 18:44:01,140] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:01,744] {logging_mixin.py:115} INFO - [2022-10-19 18:44:01,741] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:44:01,746] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:01,781] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.656 seconds
[2022-10-19 18:44:18,066] {processor.py:153} INFO - Started process (PID=43390) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:18,069] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:44:18,072] {logging_mixin.py:115} INFO - [2022-10-19 18:44:18,072] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:32,294] {processor.py:153} INFO - Started process (PID=30639) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:32,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:44:32,300] {logging_mixin.py:115} INFO - [2022-10-19 18:44:32,300] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:32,453] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:44:32,476] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:32,614] {logging_mixin.py:115} INFO - [2022-10-19 18:44:32,612] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:44:32,684] {logging_mixin.py:115} INFO - [2022-10-19 18:44:32,684] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:44:32.473687+00:00, run_after=2022-10-20T18:44:32.473687+00:00
[2022-10-19 18:44:32,752] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.701 seconds
[2022-10-19 18:44:33,060] {logging_mixin.py:115} INFO - [2022-10-19 18:44:33,053] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:44:33,062] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:44:33,106] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.823 seconds
[2022-10-19 18:45:03,089] {processor.py:153} INFO - Started process (PID=43675) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:03,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:45:03,092] {logging_mixin.py:115} INFO - [2022-10-19 18:45:03,092] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:03,160] {processor.py:153} INFO - Started process (PID=30675) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:03,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:45:03,164] {logging_mixin.py:115} INFO - [2022-10-19 18:45:03,164] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:03,690] {logging_mixin.py:115} INFO - [2022-10-19 18:45:03,687] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:45:03,692] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:03,728] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.572 seconds
[2022-10-19 18:45:10,640] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:45:10,664] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:10,779] {logging_mixin.py:115} INFO - [2022-10-19 18:45:10,778] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:45:10,814] {logging_mixin.py:115} INFO - [2022-10-19 18:45:10,813] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:45:10.661683+00:00, run_after=2022-10-20T18:45:10.661683+00:00
[2022-10-19 18:45:10,848] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.765 seconds
[2022-10-19 18:45:34,320] {processor.py:153} INFO - Started process (PID=30724) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:34,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:45:34,324] {logging_mixin.py:115} INFO - [2022-10-19 18:45:34,324] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:35,015] {logging_mixin.py:115} INFO - [2022-10-19 18:45:35,012] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:45:35,018] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:35,057] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.743 seconds
[2022-10-19 18:45:41,647] {processor.py:153} INFO - Started process (PID=43841) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:41,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:45:41,651] {logging_mixin.py:115} INFO - [2022-10-19 18:45:41,650] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:51,305] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:45:51,342] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:45:51,520] {logging_mixin.py:115} INFO - [2022-10-19 18:45:51,518] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:45:51,579] {logging_mixin.py:115} INFO - [2022-10-19 18:45:51,579] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:45:51.339330+00:00, run_after=2022-10-20T18:45:51.339330+00:00
[2022-10-19 18:45:51,609] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 9.991 seconds
[2022-10-19 18:46:05,122] {processor.py:153} INFO - Started process (PID=30761) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:05,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:46:05,127] {logging_mixin.py:115} INFO - [2022-10-19 18:46:05,127] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:05,704] {logging_mixin.py:115} INFO - [2022-10-19 18:46:05,700] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:46:05,707] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:05,741] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.627 seconds
[2022-10-19 18:46:21,880] {processor.py:153} INFO - Started process (PID=44000) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:21,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:46:21,886] {logging_mixin.py:115} INFO - [2022-10-19 18:46:21,886] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:29,076] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:46:29,095] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:29,235] {logging_mixin.py:115} INFO - [2022-10-19 18:46:29,233] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:46:29,308] {logging_mixin.py:115} INFO - [2022-10-19 18:46:29,308] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:46:29.092428+00:00, run_after=2022-10-20T18:46:29.092428+00:00
[2022-10-19 18:46:29,350] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.475 seconds
[2022-10-19 18:46:35,814] {processor.py:153} INFO - Started process (PID=30808) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:35,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:46:35,818] {logging_mixin.py:115} INFO - [2022-10-19 18:46:35,818] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:36,477] {logging_mixin.py:115} INFO - [2022-10-19 18:46:36,473] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:46:36,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:36,522] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.716 seconds
[2022-10-19 18:46:59,545] {processor.py:153} INFO - Started process (PID=44163) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:46:59,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:46:59,547] {logging_mixin.py:115} INFO - [2022-10-19 18:46:59,547] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:06,991] {processor.py:153} INFO - Started process (PID=30845) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:06,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:47:07,004] {logging_mixin.py:115} INFO - [2022-10-19 18:47:07,003] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:07,895] {logging_mixin.py:115} INFO - [2022-10-19 18:47:07,891] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:47:07,900] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:07,912] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:47:07,947] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:07,985] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.007 seconds
[2022-10-19 18:47:08,194] {logging_mixin.py:115} INFO - [2022-10-19 18:47:08,192] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:47:08,282] {logging_mixin.py:115} INFO - [2022-10-19 18:47:08,282] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:47:07.944634+00:00, run_after=2022-10-20T18:47:07.944634+00:00
[2022-10-19 18:47:08,316] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 8.779 seconds
[2022-10-19 18:47:38,607] {processor.py:153} INFO - Started process (PID=30891) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:38,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:47:38,612] {logging_mixin.py:115} INFO - [2022-10-19 18:47:38,612] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:38,710] {processor.py:153} INFO - Started process (PID=44329) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:38,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:47:38,714] {logging_mixin.py:115} INFO - [2022-10-19 18:47:38,713] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:39,313] {logging_mixin.py:115} INFO - [2022-10-19 18:47:39,310] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:47:39,316] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:39,382] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.786 seconds
[2022-10-19 18:47:49,232] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:47:49,290] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:47:49,464] {logging_mixin.py:115} INFO - [2022-10-19 18:47:49,462] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:47:49,517] {logging_mixin.py:115} INFO - [2022-10-19 18:47:49,517] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:47:49.278657+00:00, run_after=2022-10-20T18:47:49.278657+00:00
[2022-10-19 18:47:49,554] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 10.874 seconds
[2022-10-19 18:48:09,438] {processor.py:153} INFO - Started process (PID=30928) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:09,440] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:48:09,442] {logging_mixin.py:115} INFO - [2022-10-19 18:48:09,441] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:10,298] {logging_mixin.py:115} INFO - [2022-10-19 18:48:10,292] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:48:10,305] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:10,355] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.923 seconds
[2022-10-19 18:48:20,094] {processor.py:153} INFO - Started process (PID=44641) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:20,097] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:48:20,099] {logging_mixin.py:115} INFO - [2022-10-19 18:48:20,099] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:26,021] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:48:26,060] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:26,171] {logging_mixin.py:115} INFO - [2022-10-19 18:48:26,170] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:48:26,208] {logging_mixin.py:115} INFO - [2022-10-19 18:48:26,208] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:48:26.057404+00:00, run_after=2022-10-20T18:48:26.057404+00:00
[2022-10-19 18:48:26,233] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.149 seconds
[2022-10-19 18:48:40,638] {processor.py:153} INFO - Started process (PID=30974) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:40,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:48:40,641] {logging_mixin.py:115} INFO - [2022-10-19 18:48:40,641] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:41,253] {logging_mixin.py:115} INFO - [2022-10-19 18:48:41,250] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:48:41,256] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:41,304] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.671 seconds
[2022-10-19 18:48:56,577] {processor.py:153} INFO - Started process (PID=44796) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:48:56,581] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:48:56,582] {logging_mixin.py:115} INFO - [2022-10-19 18:48:56,582] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:01,710] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:49:01,726] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:01,832] {logging_mixin.py:115} INFO - [2022-10-19 18:49:01,831] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:49:01,876] {logging_mixin.py:115} INFO - [2022-10-19 18:49:01,876] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:49:01.723911+00:00, run_after=2022-10-20T18:49:01.723911+00:00
[2022-10-19 18:49:01,908] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.336 seconds
[2022-10-19 18:49:11,746] {processor.py:153} INFO - Started process (PID=31011) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:11,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:49:11,749] {logging_mixin.py:115} INFO - [2022-10-19 18:49:11,749] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:12,245] {logging_mixin.py:115} INFO - [2022-10-19 18:49:12,243] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:49:12,248] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:12,282] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.541 seconds
[2022-10-19 18:49:32,131] {processor.py:153} INFO - Started process (PID=45009) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:32,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:49:32,144] {logging_mixin.py:115} INFO - [2022-10-19 18:49:32,144] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:43,008] {processor.py:153} INFO - Started process (PID=31057) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:43,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:49:43,018] {logging_mixin.py:115} INFO - [2022-10-19 18:49:43,017] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:43,852] {logging_mixin.py:115} INFO - [2022-10-19 18:49:43,848] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:49:43,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:43,902] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.910 seconds
[2022-10-19 18:49:44,071] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:49:44,095] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:49:44,276] {logging_mixin.py:115} INFO - [2022-10-19 18:49:44,273] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:49:44,322] {logging_mixin.py:115} INFO - [2022-10-19 18:49:44,322] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:49:44.093290+00:00, run_after=2022-10-20T18:49:44.093290+00:00
[2022-10-19 18:49:44,365] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 12.243 seconds
[2022-10-19 18:50:14,663] {processor.py:153} INFO - Started process (PID=31093) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:14,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:50:14,672] {logging_mixin.py:115} INFO - [2022-10-19 18:50:14,671] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:14,981] {processor.py:153} INFO - Started process (PID=45403) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:14,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:50:14,985] {logging_mixin.py:115} INFO - [2022-10-19 18:50:14,985] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:15,496] {logging_mixin.py:115} INFO - [2022-10-19 18:50:15,493] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:50:15,498] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:15,546] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.918 seconds
[2022-10-19 18:50:24,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:50:24,163] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:24,312] {logging_mixin.py:115} INFO - [2022-10-19 18:50:24,310] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:50:24,355] {logging_mixin.py:115} INFO - [2022-10-19 18:50:24,355] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:50:24.158238+00:00, run_after=2022-10-20T18:50:24.158238+00:00
[2022-10-19 18:50:24,388] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 9.436 seconds
[2022-10-19 18:50:46,034] {processor.py:153} INFO - Started process (PID=31139) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:46,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:50:46,036] {logging_mixin.py:115} INFO - [2022-10-19 18:50:46,036] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:46,499] {logging_mixin.py:115} INFO - [2022-10-19 18:50:46,492] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:50:46,502] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:46,538] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.509 seconds
[2022-10-19 18:50:55,142] {processor.py:153} INFO - Started process (PID=45567) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:50:55,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:50:55,144] {logging_mixin.py:115} INFO - [2022-10-19 18:50:55,144] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:00,382] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:51:00,398] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:00,513] {logging_mixin.py:115} INFO - [2022-10-19 18:51:00,511] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:51:00,545] {logging_mixin.py:115} INFO - [2022-10-19 18:51:00,545] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:51:00.395575+00:00, run_after=2022-10-20T18:51:00.395575+00:00
[2022-10-19 18:51:00,571] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.434 seconds
[2022-10-19 18:51:16,687] {processor.py:153} INFO - Started process (PID=31176) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:16,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:51:16,689] {logging_mixin.py:115} INFO - [2022-10-19 18:51:16,689] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:17,192] {logging_mixin.py:115} INFO - [2022-10-19 18:51:17,190] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:51:17,195] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:17,232] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.550 seconds
[2022-10-19 18:51:30,676] {processor.py:153} INFO - Started process (PID=45720) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:30,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:51:30,680] {logging_mixin.py:115} INFO - [2022-10-19 18:51:30,680] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:35,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:51:35,228] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:35,307] {logging_mixin.py:115} INFO - [2022-10-19 18:51:35,306] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:51:35,332] {logging_mixin.py:115} INFO - [2022-10-19 18:51:35,332] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:51:35.226931+00:00, run_after=2022-10-20T18:51:35.226931+00:00
[2022-10-19 18:51:35,350] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.680 seconds
[2022-10-19 18:51:47,618] {processor.py:153} INFO - Started process (PID=31222) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:47,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:51:47,621] {logging_mixin.py:115} INFO - [2022-10-19 18:51:47,620] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:48,085] {logging_mixin.py:115} INFO - [2022-10-19 18:51:48,082] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:51:48,088] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:51:48,120] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.507 seconds
[2022-10-19 18:52:05,557] {processor.py:153} INFO - Started process (PID=45878) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:05,558] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:52:05,559] {logging_mixin.py:115} INFO - [2022-10-19 18:52:05,559] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:10,019] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:52:10,033] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:10,120] {logging_mixin.py:115} INFO - [2022-10-19 18:52:10,119] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:52:10,152] {logging_mixin.py:115} INFO - [2022-10-19 18:52:10,152] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:52:10.031837+00:00, run_after=2022-10-20T18:52:10.031837+00:00
[2022-10-19 18:52:10,168] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.616 seconds
[2022-10-19 18:52:18,418] {processor.py:153} INFO - Started process (PID=31269) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:18,419] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:52:18,421] {logging_mixin.py:115} INFO - [2022-10-19 18:52:18,421] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:18,884] {logging_mixin.py:115} INFO - [2022-10-19 18:52:18,881] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:52:18,886] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:18,915] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.502 seconds
[2022-10-19 18:52:40,315] {processor.py:153} INFO - Started process (PID=46032) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:40,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:52:40,317] {logging_mixin.py:115} INFO - [2022-10-19 18:52:40,317] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:45,170] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:52:45,210] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:45,288] {logging_mixin.py:115} INFO - [2022-10-19 18:52:45,286] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:52:45,315] {logging_mixin.py:115} INFO - [2022-10-19 18:52:45,315] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:52:45.208728+00:00, run_after=2022-10-20T18:52:45.208728+00:00
[2022-10-19 18:52:45,334] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.024 seconds
[2022-10-19 18:52:49,208] {processor.py:153} INFO - Started process (PID=31306) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:49,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:52:49,211] {logging_mixin.py:115} INFO - [2022-10-19 18:52:49,211] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:49,692] {logging_mixin.py:115} INFO - [2022-10-19 18:52:49,690] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:52:49,694] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:52:49,724] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.520 seconds
[2022-10-19 18:53:15,525] {processor.py:153} INFO - Started process (PID=46193) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:15,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:53:15,530] {logging_mixin.py:115} INFO - [2022-10-19 18:53:15,530] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:19,931] {processor.py:153} INFO - Started process (PID=31352) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:19,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:53:19,934] {logging_mixin.py:115} INFO - [2022-10-19 18:53:19,934] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:20,200] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:53:20,219] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:20,306] {logging_mixin.py:115} INFO - [2022-10-19 18:53:20,304] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:53:20,340] {logging_mixin.py:115} INFO - [2022-10-19 18:53:20,340] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:53:20.217661+00:00, run_after=2022-10-20T18:53:20.217661+00:00
[2022-10-19 18:53:20,358] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.860 seconds
[2022-10-19 18:53:20,425] {logging_mixin.py:115} INFO - [2022-10-19 18:53:20,423] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:53:20,427] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:20,462] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.535 seconds
[2022-10-19 18:53:50,741] {processor.py:153} INFO - Started process (PID=31398) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:50,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:53:50,745] {logging_mixin.py:115} INFO - [2022-10-19 18:53:50,745] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:50,803] {processor.py:153} INFO - Started process (PID=46344) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:50,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:53:50,806] {logging_mixin.py:115} INFO - [2022-10-19 18:53:50,806] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:51,221] {logging_mixin.py:115} INFO - [2022-10-19 18:53:51,219] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:53:51,222] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:51,253] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.518 seconds
[2022-10-19 18:53:55,668] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:53:55,681] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:53:55,761] {logging_mixin.py:115} INFO - [2022-10-19 18:53:55,760] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:53:55,788] {logging_mixin.py:115} INFO - [2022-10-19 18:53:55,788] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:53:55.679652+00:00, run_after=2022-10-20T18:53:55.679652+00:00
[2022-10-19 18:53:55,806] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.012 seconds
[2022-10-19 18:54:21,419] {processor.py:153} INFO - Started process (PID=31435) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:21,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:54:21,424] {logging_mixin.py:115} INFO - [2022-10-19 18:54:21,423] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:21,897] {logging_mixin.py:115} INFO - [2022-10-19 18:54:21,895] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:54:21,900] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:21,936] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.522 seconds
[2022-10-19 18:54:26,505] {processor.py:153} INFO - Started process (PID=46506) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:26,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:54:26,512] {logging_mixin.py:115} INFO - [2022-10-19 18:54:26,512] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:31,287] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:54:31,299] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:31,374] {logging_mixin.py:115} INFO - [2022-10-19 18:54:31,373] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:54:31,401] {logging_mixin.py:115} INFO - [2022-10-19 18:54:31,400] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:54:31.297621+00:00, run_after=2022-10-20T18:54:31.297621+00:00
[2022-10-19 18:54:31,420] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.920 seconds
[2022-10-19 18:54:52,315] {processor.py:153} INFO - Started process (PID=31481) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:52,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:54:52,318] {logging_mixin.py:115} INFO - [2022-10-19 18:54:52,318] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:52,813] {logging_mixin.py:115} INFO - [2022-10-19 18:54:52,811] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:54:52,815] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:54:52,846] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.536 seconds
[2022-10-19 18:55:01,609] {processor.py:153} INFO - Started process (PID=46658) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:01,611] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:55:01,614] {logging_mixin.py:115} INFO - [2022-10-19 18:55:01,613] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:06,710] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:55:06,737] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:06,827] {logging_mixin.py:115} INFO - [2022-10-19 18:55:06,826] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:55:06,854] {logging_mixin.py:115} INFO - [2022-10-19 18:55:06,854] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:55:06.735671+00:00, run_after=2022-10-20T18:55:06.735671+00:00
[2022-10-19 18:55:06,874] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.272 seconds
[2022-10-19 18:55:23,093] {processor.py:153} INFO - Started process (PID=31528) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:23,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:55:23,096] {logging_mixin.py:115} INFO - [2022-10-19 18:55:23,096] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:23,586] {logging_mixin.py:115} INFO - [2022-10-19 18:55:23,584] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:55:23,590] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:23,627] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.540 seconds
[2022-10-19 18:55:37,638] {processor.py:153} INFO - Started process (PID=46819) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:37,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:55:37,640] {logging_mixin.py:115} INFO - [2022-10-19 18:55:37,640] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:42,280] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:55:42,292] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:42,374] {logging_mixin.py:115} INFO - [2022-10-19 18:55:42,373] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:55:42,400] {logging_mixin.py:115} INFO - [2022-10-19 18:55:42,400] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:55:42.290826+00:00, run_after=2022-10-20T18:55:42.290826+00:00
[2022-10-19 18:55:42,416] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.783 seconds
[2022-10-19 18:55:53,936] {processor.py:153} INFO - Started process (PID=31565) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:53,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:55:53,938] {logging_mixin.py:115} INFO - [2022-10-19 18:55:53,938] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:54,422] {logging_mixin.py:115} INFO - [2022-10-19 18:55:54,419] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData_and_Transform
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:55:54,423] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:55:54,454] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.523 seconds
[2022-10-19 18:56:13,053] {processor.py:153} INFO - Started process (PID=46970) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:13,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:56:13,058] {logging_mixin.py:115} INFO - [2022-10-19 18:56:13,057] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:15,131] {processor.py:153} INFO - Started process (PID=31600) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:15,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:56:15,134] {logging_mixin.py:115} INFO - [2022-10-19 18:56:15,134] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:15,674] {logging_mixin.py:115} INFO - [2022-10-19 18:56:15,672] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:56:15,676] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:15,713] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.601 seconds
[2022-10-19 18:56:18,122] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:56:18,157] {logging_mixin.py:115} INFO - [2022-10-19 18:56:18,144] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
ImportError: cannot import name 'loadJsonData_and_Transform' from 'data_extraction_pyspark' (/opt/airflow/dags/data_extraction_pyspark.py)
[2022-10-19 18:56:18,164] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:18,251] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.226 seconds
[2022-10-19 18:56:45,952] {processor.py:153} INFO - Started process (PID=31646) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:45,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:56:45,958] {logging_mixin.py:115} INFO - [2022-10-19 18:56:45,958] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:46,836] {logging_mixin.py:115} INFO - [2022-10-19 18:56:46,833] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:56:46,841] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:46,902] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.956 seconds
[2022-10-19 18:56:48,642] {processor.py:153} INFO - Started process (PID=47133) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:48,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:56:48,645] {logging_mixin.py:115} INFO - [2022-10-19 18:56:48,644] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:55,026] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:56:55,067] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:56:55,188] {logging_mixin.py:115} INFO - [2022-10-19 18:56:55,187] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:56:55,227] {logging_mixin.py:115} INFO - [2022-10-19 18:56:55,227] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:56:55.063721+00:00, run_after=2022-10-20T18:56:55.063721+00:00
[2022-10-19 18:56:55,275] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.642 seconds
[2022-10-19 18:57:17,554] {processor.py:153} INFO - Started process (PID=31685) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:17,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:57:17,556] {logging_mixin.py:115} INFO - [2022-10-19 18:57:17,556] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:18,128] {logging_mixin.py:115} INFO - [2022-10-19 18:57:18,125] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:57:18,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:18,173] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.628 seconds
[2022-10-19 18:57:25,391] {processor.py:153} INFO - Started process (PID=47296) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:25,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:57:25,393] {logging_mixin.py:115} INFO - [2022-10-19 18:57:25,393] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:31,147] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:57:31,212] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:31,328] {logging_mixin.py:115} INFO - [2022-10-19 18:57:31,326] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:57:31,366] {logging_mixin.py:115} INFO - [2022-10-19 18:57:31,365] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:57:31.208337+00:00, run_after=2022-10-20T18:57:31.208337+00:00
[2022-10-19 18:57:31,395] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.009 seconds
[2022-10-19 18:57:48,342] {processor.py:153} INFO - Started process (PID=31731) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:48,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:57:48,344] {logging_mixin.py:115} INFO - [2022-10-19 18:57:48,344] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:48,843] {logging_mixin.py:115} INFO - [2022-10-19 18:57:48,840] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:57:48,845] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:57:48,875] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.539 seconds
[2022-10-19 18:58:01,712] {processor.py:153} INFO - Started process (PID=47452) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:01,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:58:01,715] {logging_mixin.py:115} INFO - [2022-10-19 18:58:01,715] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:07,443] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:58:07,459] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:07,542] {logging_mixin.py:115} INFO - [2022-10-19 18:58:07,541] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:58:07,568] {logging_mixin.py:115} INFO - [2022-10-19 18:58:07,568] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:58:07.457659+00:00, run_after=2022-10-20T18:58:07.457659+00:00
[2022-10-19 18:58:07,587] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.881 seconds
[2022-10-19 18:58:19,199] {processor.py:153} INFO - Started process (PID=31778) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:19,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:58:19,201] {logging_mixin.py:115} INFO - [2022-10-19 18:58:19,201] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:19,705] {logging_mixin.py:115} INFO - [2022-10-19 18:58:19,702] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:58:19,708] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:19,739] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.545 seconds
[2022-10-19 18:58:38,248] {processor.py:153} INFO - Started process (PID=47612) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:38,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:58:38,250] {logging_mixin.py:115} INFO - [2022-10-19 18:58:38,250] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:44,031] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:58:44,047] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:44,134] {logging_mixin.py:115} INFO - [2022-10-19 18:58:44,133] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:58:44,164] {logging_mixin.py:115} INFO - [2022-10-19 18:58:44,164] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:58:44.045164+00:00, run_after=2022-10-20T18:58:44.045164+00:00
[2022-10-19 18:58:44,185] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.943 seconds
[2022-10-19 18:58:50,452] {processor.py:153} INFO - Started process (PID=31815) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:50,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:58:50,455] {logging_mixin.py:115} INFO - [2022-10-19 18:58:50,455] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:50,948] {logging_mixin.py:115} INFO - [2022-10-19 18:58:50,944] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:58:50,950] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:58:50,982] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.534 seconds
[2022-10-19 18:59:14,928] {processor.py:153} INFO - Started process (PID=47765) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:14,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:59:14,932] {logging_mixin.py:115} INFO - [2022-10-19 18:59:14,932] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:20,235] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:59:20,250] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:20,332] {logging_mixin.py:115} INFO - [2022-10-19 18:59:20,331] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:59:20,358] {logging_mixin.py:115} INFO - [2022-10-19 18:59:20,357] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:59:20.248272+00:00, run_after=2022-10-20T18:59:20.248272+00:00
[2022-10-19 18:59:20,373] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.472 seconds
[2022-10-19 18:59:21,837] {processor.py:153} INFO - Started process (PID=31860) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:21,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:59:21,840] {logging_mixin.py:115} INFO - [2022-10-19 18:59:21,840] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:22,309] {logging_mixin.py:115} INFO - [2022-10-19 18:59:22,304] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:59:22,310] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:22,342] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.510 seconds
[2022-10-19 18:59:51,278] {processor.py:153} INFO - Started process (PID=47926) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:51,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:59:51,282] {logging_mixin.py:115} INFO - [2022-10-19 18:59:51,282] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:53,001] {processor.py:153} INFO - Started process (PID=31905) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:53,002] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 18:59:53,003] {logging_mixin.py:115} INFO - [2022-10-19 18:59:53,003] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:53,599] {logging_mixin.py:115} INFO - [2022-10-19 18:59:53,597] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 18:59:53,600] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:53,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.636 seconds
[2022-10-19 18:59:56,548] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 18:59:56,564] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 18:59:56,642] {logging_mixin.py:115} INFO - [2022-10-19 18:59:56,641] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 18:59:56,668] {logging_mixin.py:115} INFO - [2022-10-19 18:59:56,668] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T18:59:56.562755+00:00, run_after=2022-10-20T18:59:56.562755+00:00
[2022-10-19 18:59:56,686] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.416 seconds
[2022-10-19 19:00:24,346] {processor.py:153} INFO - Started process (PID=31942) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:24,348] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:00:24,349] {logging_mixin.py:115} INFO - [2022-10-19 19:00:24,349] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:24,824] {logging_mixin.py:115} INFO - [2022-10-19 19:00:24,821] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:00:24,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:24,858] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.517 seconds
[2022-10-19 19:00:27,018] {processor.py:153} INFO - Started process (PID=48088) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:27,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:00:27,021] {logging_mixin.py:115} INFO - [2022-10-19 19:00:27,021] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:31,647] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:00:31,658] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:31,734] {logging_mixin.py:115} INFO - [2022-10-19 19:00:31,733] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:00:31,760] {logging_mixin.py:115} INFO - [2022-10-19 19:00:31,760] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:00:31.656614+00:00, run_after=2022-10-20T19:00:31.656614+00:00
[2022-10-19 19:00:31,778] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.764 seconds
[2022-10-19 19:00:55,610] {processor.py:153} INFO - Started process (PID=31988) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:55,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:00:55,613] {logging_mixin.py:115} INFO - [2022-10-19 19:00:55,613] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:56,085] {logging_mixin.py:115} INFO - [2022-10-19 19:00:56,083] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:00:56,088] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:00:56,118] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.513 seconds
[2022-10-19 19:01:02,215] {processor.py:153} INFO - Started process (PID=48239) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:02,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:01:02,218] {logging_mixin.py:115} INFO - [2022-10-19 19:01:02,218] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:07,027] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:01:07,041] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:07,119] {logging_mixin.py:115} INFO - [2022-10-19 19:01:07,117] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:01:07,144] {logging_mixin.py:115} INFO - [2022-10-19 19:01:07,144] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:01:07.039533+00:00, run_after=2022-10-20T19:01:07.039533+00:00
[2022-10-19 19:01:07,162] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.952 seconds
[2022-10-19 19:01:26,795] {processor.py:153} INFO - Started process (PID=32034) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:26,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:01:26,799] {logging_mixin.py:115} INFO - [2022-10-19 19:01:26,799] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:27,320] {logging_mixin.py:115} INFO - [2022-10-19 19:01:27,317] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:01:27,321] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:27,355] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.569 seconds
[2022-10-19 19:01:37,216] {processor.py:153} INFO - Started process (PID=48400) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:37,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:01:37,219] {logging_mixin.py:115} INFO - [2022-10-19 19:01:37,219] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:42,316] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:01:42,331] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:42,408] {logging_mixin.py:115} INFO - [2022-10-19 19:01:42,407] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:01:42,439] {logging_mixin.py:115} INFO - [2022-10-19 19:01:42,439] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:01:42.329149+00:00, run_after=2022-10-20T19:01:42.329149+00:00
[2022-10-19 19:01:42,456] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.245 seconds
[2022-10-19 19:01:58,102] {processor.py:153} INFO - Started process (PID=32071) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:58,104] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:01:58,105] {logging_mixin.py:115} INFO - [2022-10-19 19:01:58,105] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:58,587] {logging_mixin.py:115} INFO - [2022-10-19 19:01:58,585] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:01:58,591] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:01:58,634] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.538 seconds
[2022-10-19 19:02:12,890] {processor.py:153} INFO - Started process (PID=48554) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:12,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:02:12,897] {logging_mixin.py:115} INFO - [2022-10-19 19:02:12,897] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:17,791] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:02:17,807] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:17,905] {logging_mixin.py:115} INFO - [2022-10-19 19:02:17,903] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:02:17,933] {logging_mixin.py:115} INFO - [2022-10-19 19:02:17,933] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:02:17.805324+00:00, run_after=2022-10-20T19:02:17.805324+00:00
[2022-10-19 19:02:17,955] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.091 seconds
[2022-10-19 19:02:28,759] {processor.py:153} INFO - Started process (PID=32117) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:28,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:02:28,762] {logging_mixin.py:115} INFO - [2022-10-19 19:02:28,762] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:29,258] {logging_mixin.py:115} INFO - [2022-10-19 19:02:29,256] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:02:29,261] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:29,289] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.535 seconds
[2022-10-19 19:02:48,230] {processor.py:153} INFO - Started process (PID=48712) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:48,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:02:48,233] {logging_mixin.py:115} INFO - [2022-10-19 19:02:48,233] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:52,626] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:02:52,647] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:02:52,739] {logging_mixin.py:115} INFO - [2022-10-19 19:02:52,738] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:02:52,768] {logging_mixin.py:115} INFO - [2022-10-19 19:02:52,768] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:02:52.645164+00:00, run_after=2022-10-20T19:02:52.645164+00:00
[2022-10-19 19:02:52,785] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.559 seconds
[2022-10-19 19:03:00,015] {processor.py:153} INFO - Started process (PID=32163) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:00,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:03:00,022] {logging_mixin.py:115} INFO - [2022-10-19 19:03:00,021] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:00,553] {logging_mixin.py:115} INFO - [2022-10-19 19:03:00,551] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:03:00,555] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:00,589] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.593 seconds
[2022-10-19 19:03:22,948] {processor.py:153} INFO - Started process (PID=48866) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:22,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:03:22,950] {logging_mixin.py:115} INFO - [2022-10-19 19:03:22,950] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:27,426] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:03:27,444] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:27,529] {logging_mixin.py:115} INFO - [2022-10-19 19:03:27,528] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:03:27,554] {logging_mixin.py:115} INFO - [2022-10-19 19:03:27,554] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:03:27.442511+00:00, run_after=2022-10-20T19:03:27.442511+00:00
[2022-10-19 19:03:27,574] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.631 seconds
[2022-10-19 19:03:31,258] {processor.py:153} INFO - Started process (PID=32200) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:31,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:03:31,260] {logging_mixin.py:115} INFO - [2022-10-19 19:03:31,260] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:31,744] {logging_mixin.py:115} INFO - [2022-10-19 19:03:31,741] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:03:31,746] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:31,780] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.528 seconds
[2022-10-19 19:03:57,680] {processor.py:153} INFO - Started process (PID=49018) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:03:57,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:03:57,683] {logging_mixin.py:115} INFO - [2022-10-19 19:03:57,683] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:02,006] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:04:02,018] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:02,102] {logging_mixin.py:115} INFO - [2022-10-19 19:04:02,100] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:04:02,127] {logging_mixin.py:115} INFO - [2022-10-19 19:04:02,127] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:04:02.016269+00:00, run_after=2022-10-20T19:04:02.016269+00:00
[2022-10-19 19:04:02,146] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.470 seconds
[2022-10-19 19:04:02,471] {processor.py:153} INFO - Started process (PID=32246) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:02,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:04:02,474] {logging_mixin.py:115} INFO - [2022-10-19 19:04:02,474] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:02,955] {logging_mixin.py:115} INFO - [2022-10-19 19:04:02,953] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:04:02,959] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:02,988] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.521 seconds
[2022-10-19 19:04:32,897] {processor.py:153} INFO - Started process (PID=49178) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:32,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:04:32,901] {logging_mixin.py:115} INFO - [2022-10-19 19:04:32,901] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:33,693] {processor.py:153} INFO - Started process (PID=32292) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:33,694] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:04:33,696] {logging_mixin.py:115} INFO - [2022-10-19 19:04:33,696] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:34,206] {logging_mixin.py:115} INFO - [2022-10-19 19:04:34,204] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:04:34,209] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:34,248] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.559 seconds
[2022-10-19 19:04:37,527] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:04:37,543] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:04:37,624] {logging_mixin.py:115} INFO - [2022-10-19 19:04:37,623] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:04:37,649] {logging_mixin.py:115} INFO - [2022-10-19 19:04:37,649] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:04:37.540923+00:00, run_after=2022-10-20T19:04:37.540923+00:00
[2022-10-19 19:04:37,667] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.775 seconds
[2022-10-19 19:05:04,974] {processor.py:153} INFO - Started process (PID=32336) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:04,975] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:05:04,976] {logging_mixin.py:115} INFO - [2022-10-19 19:05:04,976] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:05,453] {logging_mixin.py:115} INFO - [2022-10-19 19:05:05,451] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:05:05,454] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:05,483] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.514 seconds
[2022-10-19 19:05:08,126] {processor.py:153} INFO - Started process (PID=49331) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:08,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:05:08,128] {logging_mixin.py:115} INFO - [2022-10-19 19:05:08,128] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:12,716] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:05:12,732] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:12,815] {logging_mixin.py:115} INFO - [2022-10-19 19:05:12,814] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:05:12,840] {logging_mixin.py:115} INFO - [2022-10-19 19:05:12,840] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:05:12.730661+00:00, run_after=2022-10-20T19:05:12.730661+00:00
[2022-10-19 19:05:12,862] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.742 seconds
[2022-10-19 19:05:36,223] {processor.py:153} INFO - Started process (PID=32375) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:36,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:05:36,225] {logging_mixin.py:115} INFO - [2022-10-19 19:05:36,225] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:36,745] {logging_mixin.py:115} INFO - [2022-10-19 19:05:36,743] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:05:36,746] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:36,774] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.557 seconds
[2022-10-19 19:05:43,037] {processor.py:153} INFO - Started process (PID=49493) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:43,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:05:43,039] {logging_mixin.py:115} INFO - [2022-10-19 19:05:43,039] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:47,526] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:05:47,541] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:05:47,632] {logging_mixin.py:115} INFO - [2022-10-19 19:05:47,630] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:05:47,658] {logging_mixin.py:115} INFO - [2022-10-19 19:05:47,658] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:05:47.539457+00:00, run_after=2022-10-20T19:05:47.539457+00:00
[2022-10-19 19:05:47,676] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.667 seconds
[2022-10-19 19:06:07,464] {processor.py:153} INFO - Started process (PID=32421) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:07,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:06:07,466] {logging_mixin.py:115} INFO - [2022-10-19 19:06:07,466] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:07,960] {logging_mixin.py:115} INFO - [2022-10-19 19:06:07,958] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:06:07,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:07,991] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.533 seconds
[2022-10-19 19:06:17,876] {processor.py:153} INFO - Started process (PID=49646) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:17,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:06:17,878] {logging_mixin.py:115} INFO - [2022-10-19 19:06:17,878] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:22,225] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:06:22,238] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:22,318] {logging_mixin.py:115} INFO - [2022-10-19 19:06:22,317] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:06:22,343] {logging_mixin.py:115} INFO - [2022-10-19 19:06:22,343] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:06:22.236634+00:00, run_after=2022-10-20T19:06:22.236634+00:00
[2022-10-19 19:06:22,362] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.491 seconds
[2022-10-19 19:06:38,688] {processor.py:153} INFO - Started process (PID=32467) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:38,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:06:38,690] {logging_mixin.py:115} INFO - [2022-10-19 19:06:38,690] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:39,160] {logging_mixin.py:115} INFO - [2022-10-19 19:06:39,157] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:06:39,162] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:39,190] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.506 seconds
[2022-10-19 19:06:53,071] {processor.py:153} INFO - Started process (PID=49803) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:53,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:06:53,073] {logging_mixin.py:115} INFO - [2022-10-19 19:06:53,073] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:57,675] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:06:57,689] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:06:57,766] {logging_mixin.py:115} INFO - [2022-10-19 19:06:57,765] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:06:57,790] {logging_mixin.py:115} INFO - [2022-10-19 19:06:57,789] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:06:57.686988+00:00, run_after=2022-10-20T19:06:57.686988+00:00
[2022-10-19 19:06:57,807] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.741 seconds
[2022-10-19 19:07:09,998] {processor.py:153} INFO - Started process (PID=32504) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:10,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:07:10,002] {logging_mixin.py:115} INFO - [2022-10-19 19:07:10,002] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:10,531] {logging_mixin.py:115} INFO - [2022-10-19 19:07:10,529] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:07:10,534] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:10,565] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.577 seconds
[2022-10-19 19:07:28,308] {processor.py:153} INFO - Started process (PID=49959) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:28,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:07:28,311] {logging_mixin.py:115} INFO - [2022-10-19 19:07:28,311] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:32,685] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:07:32,710] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:32,793] {logging_mixin.py:115} INFO - [2022-10-19 19:07:32,792] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:07:32,828] {logging_mixin.py:115} INFO - [2022-10-19 19:07:32,828] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:07:32.708075+00:00, run_after=2022-10-20T19:07:32.708075+00:00
[2022-10-19 19:07:32,849] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.548 seconds
[2022-10-19 19:07:40,643] {processor.py:153} INFO - Started process (PID=32550) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:40,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:07:40,646] {logging_mixin.py:115} INFO - [2022-10-19 19:07:40,646] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:41,115] {logging_mixin.py:115} INFO - [2022-10-19 19:07:41,112] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:07:41,117] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:07:41,150] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.512 seconds
[2022-10-19 19:08:03,059] {processor.py:153} INFO - Started process (PID=50119) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:03,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:08:03,062] {logging_mixin.py:115} INFO - [2022-10-19 19:08:03,062] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:07,416] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:08:07,429] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:07,525] {logging_mixin.py:115} INFO - [2022-10-19 19:08:07,524] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:08:07,552] {logging_mixin.py:115} INFO - [2022-10-19 19:08:07,552] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:08:07.427066+00:00, run_after=2022-10-20T19:08:07.427066+00:00
[2022-10-19 19:08:07,570] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.516 seconds
[2022-10-19 19:08:11,645] {processor.py:153} INFO - Started process (PID=32598) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:11,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:08:11,648] {logging_mixin.py:115} INFO - [2022-10-19 19:08:11,648] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:12,116] {logging_mixin.py:115} INFO - [2022-10-19 19:08:12,114] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:08:12,118] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:12,153] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.512 seconds
[2022-10-19 19:08:37,762] {processor.py:153} INFO - Started process (PID=50272) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:37,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:08:37,764] {logging_mixin.py:115} INFO - [2022-10-19 19:08:37,764] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:42,270] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:08:42,284] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:42,377] {logging_mixin.py:115} INFO - [2022-10-19 19:08:42,376] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:08:42,403] {logging_mixin.py:115} INFO - [2022-10-19 19:08:42,403] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:08:42.282072+00:00, run_after=2022-10-20T19:08:42.282072+00:00
[2022-10-19 19:08:42,422] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.665 seconds
[2022-10-19 19:08:42,906] {processor.py:153} INFO - Started process (PID=32635) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:42,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:08:42,911] {logging_mixin.py:115} INFO - [2022-10-19 19:08:42,911] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:43,402] {logging_mixin.py:115} INFO - [2022-10-19 19:08:43,399] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:08:43,404] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:08:43,444] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.552 seconds
[2022-10-19 19:09:12,497] {processor.py:153} INFO - Started process (PID=50432) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:12,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:09:12,500] {logging_mixin.py:115} INFO - [2022-10-19 19:09:12,500] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:14,170] {processor.py:153} INFO - Started process (PID=32681) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:14,172] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:09:14,174] {logging_mixin.py:115} INFO - [2022-10-19 19:09:14,173] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:14,657] {logging_mixin.py:115} INFO - [2022-10-19 19:09:14,654] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:09:14,658] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:14,698] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.532 seconds
[2022-10-19 19:09:17,211] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:09:17,243] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:17,334] {logging_mixin.py:115} INFO - [2022-10-19 19:09:17,333] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:09:17,363] {logging_mixin.py:115} INFO - [2022-10-19 19:09:17,363] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:09:17.241477+00:00, run_after=2022-10-20T19:09:17.241477+00:00
[2022-10-19 19:09:17,385] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.914 seconds
[2022-10-19 19:09:45,488] {processor.py:153} INFO - Started process (PID=32727) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:45,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:09:45,490] {logging_mixin.py:115} INFO - [2022-10-19 19:09:45,490] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:45,974] {logging_mixin.py:115} INFO - [2022-10-19 19:09:45,971] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:09:45,976] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:46,008] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.526 seconds
[2022-10-19 19:09:47,938] {processor.py:153} INFO - Started process (PID=50583) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:47,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:09:47,940] {logging_mixin.py:115} INFO - [2022-10-19 19:09:47,940] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:52,303] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:09:52,314] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:09:52,396] {logging_mixin.py:115} INFO - [2022-10-19 19:09:52,395] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:09:52,423] {logging_mixin.py:115} INFO - [2022-10-19 19:09:52,423] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:09:52.312315+00:00, run_after=2022-10-20T19:09:52.312315+00:00
[2022-10-19 19:09:52,445] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.512 seconds
[2022-10-19 19:10:16,732] {processor.py:153} INFO - Started process (PID=32773) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:16,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:10:16,737] {logging_mixin.py:115} INFO - [2022-10-19 19:10:16,737] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:17,256] {logging_mixin.py:115} INFO - [2022-10-19 19:10:17,254] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:10:17,260] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:17,293] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.571 seconds
[2022-10-19 19:10:22,525] {processor.py:153} INFO - Started process (PID=50747) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:22,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:10:22,528] {logging_mixin.py:115} INFO - [2022-10-19 19:10:22,528] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:27,044] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:10:27,075] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:27,157] {logging_mixin.py:115} INFO - [2022-10-19 19:10:27,156] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:10:27,182] {logging_mixin.py:115} INFO - [2022-10-19 19:10:27,182] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:10:27.072921+00:00, run_after=2022-10-20T19:10:27.072921+00:00
[2022-10-19 19:10:27,204] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.685 seconds
[2022-10-19 19:10:47,983] {processor.py:153} INFO - Started process (PID=32810) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:47,984] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:10:47,985] {logging_mixin.py:115} INFO - [2022-10-19 19:10:47,985] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:48,449] {logging_mixin.py:115} INFO - [2022-10-19 19:10:48,446] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:10:48,451] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:48,483] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.505 seconds
[2022-10-19 19:10:57,628] {processor.py:153} INFO - Started process (PID=50899) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:10:57,630] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:10:57,631] {logging_mixin.py:115} INFO - [2022-10-19 19:10:57,631] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:02,238] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:11:02,253] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:02,340] {logging_mixin.py:115} INFO - [2022-10-19 19:11:02,339] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:11:02,367] {logging_mixin.py:115} INFO - [2022-10-19 19:11:02,367] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:11:02.251900+00:00, run_after=2022-10-20T19:11:02.251900+00:00
[2022-10-19 19:11:02,387] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.767 seconds
[2022-10-19 19:11:19,224] {processor.py:153} INFO - Started process (PID=32856) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:19,226] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:11:19,228] {logging_mixin.py:115} INFO - [2022-10-19 19:11:19,227] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:19,699] {logging_mixin.py:115} INFO - [2022-10-19 19:11:19,697] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:11:19,701] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:19,733] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.517 seconds
[2022-10-19 19:11:32,509] {processor.py:153} INFO - Started process (PID=51061) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:32,510] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:11:32,511] {logging_mixin.py:115} INFO - [2022-10-19 19:11:32,511] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:37,395] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:11:37,410] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:37,494] {logging_mixin.py:115} INFO - [2022-10-19 19:11:37,492] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:11:37,523] {logging_mixin.py:115} INFO - [2022-10-19 19:11:37,522] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:11:37.408974+00:00, run_after=2022-10-20T19:11:37.408974+00:00
[2022-10-19 19:11:37,544] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.040 seconds
[2022-10-19 19:11:50,519] {processor.py:153} INFO - Started process (PID=32903) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:50,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:11:50,523] {logging_mixin.py:115} INFO - [2022-10-19 19:11:50,523] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:51,008] {logging_mixin.py:115} INFO - [2022-10-19 19:11:51,006] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:11:51,010] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:11:51,042] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.531 seconds
[2022-10-19 19:12:07,738] {processor.py:153} INFO - Started process (PID=51212) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:07,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:12:07,741] {logging_mixin.py:115} INFO - [2022-10-19 19:12:07,741] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:12,638] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:12:12,651] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:12,738] {logging_mixin.py:115} INFO - [2022-10-19 19:12:12,736] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:12:12,776] {logging_mixin.py:115} INFO - [2022-10-19 19:12:12,776] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:12:12.649810+00:00, run_after=2022-10-20T19:12:12.649810+00:00
[2022-10-19 19:12:12,806] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.072 seconds
[2022-10-19 19:12:21,957] {processor.py:153} INFO - Started process (PID=32941) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:21,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:12:21,960] {logging_mixin.py:115} INFO - [2022-10-19 19:12:21,960] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:22,445] {logging_mixin.py:115} INFO - [2022-10-19 19:12:22,442] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:12:22,448] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:22,485] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.536 seconds
[2022-10-19 19:12:42,870] {processor.py:153} INFO - Started process (PID=51365) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:42,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:12:42,873] {logging_mixin.py:115} INFO - [2022-10-19 19:12:42,873] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:47,624] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:12:47,642] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:47,723] {logging_mixin.py:115} INFO - [2022-10-19 19:12:47,722] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:12:47,749] {logging_mixin.py:115} INFO - [2022-10-19 19:12:47,749] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:12:47.639995+00:00, run_after=2022-10-20T19:12:47.639995+00:00
[2022-10-19 19:12:47,767] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.921 seconds
[2022-10-19 19:12:53,339] {processor.py:153} INFO - Started process (PID=32987) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:53,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:12:53,342] {logging_mixin.py:115} INFO - [2022-10-19 19:12:53,342] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:53,819] {logging_mixin.py:115} INFO - [2022-10-19 19:12:53,817] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:12:53,821] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:12:53,851] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.518 seconds
[2022-10-19 19:13:18,534] {processor.py:153} INFO - Started process (PID=51522) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:18,535] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:13:18,536] {logging_mixin.py:115} INFO - [2022-10-19 19:13:18,536] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:23,632] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:13:23,644] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:23,722] {logging_mixin.py:115} INFO - [2022-10-19 19:13:23,721] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:13:23,745] {logging_mixin.py:115} INFO - [2022-10-19 19:13:23,745] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:13:23.642262+00:00, run_after=2022-10-20T19:13:23.642262+00:00
[2022-10-19 19:13:23,764] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.234 seconds
[2022-10-19 19:13:24,274] {processor.py:153} INFO - Started process (PID=33033) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:24,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:13:24,277] {logging_mixin.py:115} INFO - [2022-10-19 19:13:24,277] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:24,761] {logging_mixin.py:115} INFO - [2022-10-19 19:13:24,758] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:13:24,763] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:24,794] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.524 seconds
[2022-10-19 19:13:53,827] {processor.py:153} INFO - Started process (PID=51683) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:53,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:13:53,832] {logging_mixin.py:115} INFO - [2022-10-19 19:13:53,832] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:55,585] {processor.py:153} INFO - Started process (PID=33069) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:55,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:13:55,594] {logging_mixin.py:115} INFO - [2022-10-19 19:13:55,594] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:56,773] {logging_mixin.py:115} INFO - [2022-10-19 19:13:56,771] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:13:56,777] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:56,868] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.304 seconds
[2022-10-19 19:13:59,504] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:13:59,520] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:13:59,600] {logging_mixin.py:115} INFO - [2022-10-19 19:13:59,599] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:13:59,625] {logging_mixin.py:115} INFO - [2022-10-19 19:13:59,624] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:13:59.518114+00:00, run_after=2022-10-20T19:13:59.518114+00:00
[2022-10-19 19:13:59,643] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.821 seconds
[2022-10-19 19:14:27,520] {processor.py:153} INFO - Started process (PID=33115) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:27,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:14:27,525] {logging_mixin.py:115} INFO - [2022-10-19 19:14:27,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:28,020] {logging_mixin.py:115} INFO - [2022-10-19 19:14:28,016] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:14:28,024] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:28,057] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.541 seconds
[2022-10-19 19:14:30,020] {processor.py:153} INFO - Started process (PID=51838) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:30,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:14:30,023] {logging_mixin.py:115} INFO - [2022-10-19 19:14:30,023] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:35,207] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:14:35,224] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:35,304] {logging_mixin.py:115} INFO - [2022-10-19 19:14:35,303] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:14:35,328] {logging_mixin.py:115} INFO - [2022-10-19 19:14:35,328] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:14:35.222378+00:00, run_after=2022-10-20T19:14:35.222378+00:00
[2022-10-19 19:14:35,353] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.337 seconds
[2022-10-19 19:14:58,771] {processor.py:153} INFO - Started process (PID=33161) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:58,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:14:58,773] {logging_mixin.py:115} INFO - [2022-10-19 19:14:58,773] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:59,247] {logging_mixin.py:115} INFO - [2022-10-19 19:14:59,245] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:14:59,249] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:14:59,280] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.516 seconds
[2022-10-19 19:15:05,558] {processor.py:153} INFO - Started process (PID=52001) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:05,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:15:05,560] {logging_mixin.py:115} INFO - [2022-10-19 19:15:05,560] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:10,330] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:15:10,352] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:10,448] {logging_mixin.py:115} INFO - [2022-10-19 19:15:10,446] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:15:10,472] {logging_mixin.py:115} INFO - [2022-10-19 19:15:10,472] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:15:10.349674+00:00, run_after=2022-10-20T19:15:10.349674+00:00
[2022-10-19 19:15:10,491] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.938 seconds
[2022-10-19 19:15:30,011] {processor.py:153} INFO - Started process (PID=33207) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:30,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:15:30,014] {logging_mixin.py:115} INFO - [2022-10-19 19:15:30,014] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:30,535] {logging_mixin.py:115} INFO - [2022-10-19 19:15:30,532] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:15:30,540] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:30,609] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.604 seconds
[2022-10-19 19:15:41,406] {processor.py:153} INFO - Started process (PID=52153) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:41,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:15:41,409] {logging_mixin.py:115} INFO - [2022-10-19 19:15:41,409] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:46,479] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:15:46,493] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:15:46,572] {logging_mixin.py:115} INFO - [2022-10-19 19:15:46,571] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:15:46,596] {logging_mixin.py:115} INFO - [2022-10-19 19:15:46,595] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:15:46.491330+00:00, run_after=2022-10-20T19:15:46.491330+00:00
[2022-10-19 19:15:46,616] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.239 seconds
[2022-10-19 19:16:00,797] {processor.py:153} INFO - Started process (PID=33245) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:00,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:16:00,800] {logging_mixin.py:115} INFO - [2022-10-19 19:16:00,800] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:01,384] {logging_mixin.py:115} INFO - [2022-10-19 19:16:01,382] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:16:01,386] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:01,422] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.630 seconds
[2022-10-19 19:16:17,506] {processor.py:153} INFO - Started process (PID=52312) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:17,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:16:17,509] {logging_mixin.py:115} INFO - [2022-10-19 19:16:17,509] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:22,324] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:16:22,342] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:22,436] {logging_mixin.py:115} INFO - [2022-10-19 19:16:22,435] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:16:22,469] {logging_mixin.py:115} INFO - [2022-10-19 19:16:22,469] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:16:22.340064+00:00, run_after=2022-10-20T19:16:22.340064+00:00
[2022-10-19 19:16:22,493] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.993 seconds
[2022-10-19 19:16:32,189] {processor.py:153} INFO - Started process (PID=33293) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:32,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:16:32,195] {logging_mixin.py:115} INFO - [2022-10-19 19:16:32,195] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:32,692] {logging_mixin.py:115} INFO - [2022-10-19 19:16:32,689] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:16:32,694] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:32,733] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.553 seconds
[2022-10-19 19:16:53,425] {processor.py:153} INFO - Started process (PID=52463) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:53,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:16:53,428] {logging_mixin.py:115} INFO - [2022-10-19 19:16:53,428] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:58,106] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:16:58,120] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:16:58,200] {logging_mixin.py:115} INFO - [2022-10-19 19:16:58,198] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:16:58,224] {logging_mixin.py:115} INFO - [2022-10-19 19:16:58,224] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:16:58.117930+00:00, run_after=2022-10-20T19:16:58.117930+00:00
[2022-10-19 19:16:58,241] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.822 seconds
[2022-10-19 19:17:03,410] {processor.py:153} INFO - Started process (PID=33339) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:03,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:17:03,414] {logging_mixin.py:115} INFO - [2022-10-19 19:17:03,414] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:03,928] {logging_mixin.py:115} INFO - [2022-10-19 19:17:03,926] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:17:03,931] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:03,964] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.561 seconds
[2022-10-19 19:17:28,661] {processor.py:153} INFO - Started process (PID=52624) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:28,663] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:17:28,665] {logging_mixin.py:115} INFO - [2022-10-19 19:17:28,664] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:33,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:17:33,223] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:33,302] {logging_mixin.py:115} INFO - [2022-10-19 19:17:33,300] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:17:33,327] {logging_mixin.py:115} INFO - [2022-10-19 19:17:33,327] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:17:33.221816+00:00, run_after=2022-10-20T19:17:33.221816+00:00
[2022-10-19 19:17:33,347] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.691 seconds
[2022-10-19 19:17:34,869] {processor.py:153} INFO - Started process (PID=33376) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:34,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:17:34,873] {logging_mixin.py:115} INFO - [2022-10-19 19:17:34,873] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:35,393] {logging_mixin.py:115} INFO - [2022-10-19 19:17:35,391] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:17:35,395] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:17:35,432] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.568 seconds
[2022-10-19 19:18:03,554] {processor.py:153} INFO - Started process (PID=52776) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:03,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:18:03,557] {logging_mixin.py:115} INFO - [2022-10-19 19:18:03,556] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:05,510] {processor.py:153} INFO - Started process (PID=33422) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:05,512] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:18:05,513] {logging_mixin.py:115} INFO - [2022-10-19 19:18:05,513] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:06,024] {logging_mixin.py:115} INFO - [2022-10-19 19:18:06,021] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:18:06,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:06,061] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.555 seconds
[2022-10-19 19:18:08,710] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:18:08,721] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:08,799] {logging_mixin.py:115} INFO - [2022-10-19 19:18:08,798] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:18:08,823] {logging_mixin.py:115} INFO - [2022-10-19 19:18:08,823] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:18:08.719435+00:00, run_after=2022-10-20T19:18:08.719435+00:00
[2022-10-19 19:18:08,842] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.293 seconds
[2022-10-19 19:18:36,136] {processor.py:153} INFO - Started process (PID=33468) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:36,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:18:36,139] {logging_mixin.py:115} INFO - [2022-10-19 19:18:36,139] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:36,634] {logging_mixin.py:115} INFO - [2022-10-19 19:18:36,632] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:18:36,636] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:36,666] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.535 seconds
[2022-10-19 19:18:39,091] {processor.py:153} INFO - Started process (PID=52942) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:39,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:18:39,093] {logging_mixin.py:115} INFO - [2022-10-19 19:18:39,093] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:43,678] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:18:43,696] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:18:43,779] {logging_mixin.py:115} INFO - [2022-10-19 19:18:43,778] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:18:43,803] {logging_mixin.py:115} INFO - [2022-10-19 19:18:43,803] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:18:43.694352+00:00, run_after=2022-10-20T19:18:43.694352+00:00
[2022-10-19 19:18:43,821] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.735 seconds
[2022-10-19 19:19:07,578] {processor.py:153} INFO - Started process (PID=33505) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:07,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:19:07,581] {logging_mixin.py:115} INFO - [2022-10-19 19:19:07,581] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:08,097] {logging_mixin.py:115} INFO - [2022-10-19 19:19:08,095] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:19:08,100] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:08,139] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.565 seconds
[2022-10-19 19:19:14,393] {processor.py:153} INFO - Started process (PID=53093) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:14,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:19:14,399] {logging_mixin.py:115} INFO - [2022-10-19 19:19:14,398] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:18,877] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:19:18,889] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:18,974] {logging_mixin.py:115} INFO - [2022-10-19 19:19:18,973] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:19:18,999] {logging_mixin.py:115} INFO - [2022-10-19 19:19:18,999] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:19:18.887820+00:00, run_after=2022-10-20T19:19:18.887820+00:00
[2022-10-19 19:19:19,020] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.655 seconds
[2022-10-19 19:19:38,920] {processor.py:153} INFO - Started process (PID=33552) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:38,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:19:38,924] {logging_mixin.py:115} INFO - [2022-10-19 19:19:38,923] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:39,452] {logging_mixin.py:115} INFO - [2022-10-19 19:19:39,450] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:19:39,454] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:39,492] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.577 seconds
[2022-10-19 19:19:49,516] {processor.py:153} INFO - Started process (PID=53251) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:49,517] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:19:49,518] {logging_mixin.py:115} INFO - [2022-10-19 19:19:49,518] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:54,138] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:19:54,154] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:19:54,240] {logging_mixin.py:115} INFO - [2022-10-19 19:19:54,239] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:19:54,265] {logging_mixin.py:115} INFO - [2022-10-19 19:19:54,265] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:19:54.152000+00:00, run_after=2022-10-20T19:19:54.152000+00:00
[2022-10-19 19:19:54,282] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.771 seconds
[2022-10-19 19:20:10,229] {processor.py:153} INFO - Started process (PID=33598) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:10,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:20:10,234] {logging_mixin.py:115} INFO - [2022-10-19 19:20:10,233] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:10,729] {logging_mixin.py:115} INFO - [2022-10-19 19:20:10,727] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:20:10,731] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:10,763] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.539 seconds
[2022-10-19 19:20:24,454] {processor.py:153} INFO - Started process (PID=53403) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:24,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:20:24,456] {logging_mixin.py:115} INFO - [2022-10-19 19:20:24,456] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:28,965] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:20:28,986] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:29,066] {logging_mixin.py:115} INFO - [2022-10-19 19:20:29,065] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:20:29,091] {logging_mixin.py:115} INFO - [2022-10-19 19:20:29,091] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:20:28.984089+00:00, run_after=2022-10-20T19:20:28.984089+00:00
[2022-10-19 19:20:29,109] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.660 seconds
[2022-10-19 19:20:41,471] {processor.py:153} INFO - Started process (PID=33636) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:41,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:20:41,474] {logging_mixin.py:115} INFO - [2022-10-19 19:20:41,474] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:42,177] {logging_mixin.py:115} INFO - [2022-10-19 19:20:42,174] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:20:42,178] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:42,213] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.751 seconds
[2022-10-19 19:20:59,372] {processor.py:153} INFO - Started process (PID=53562) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:20:59,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:20:59,375] {logging_mixin.py:115} INFO - [2022-10-19 19:20:59,374] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:03,897] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:21:03,943] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:04,055] {logging_mixin.py:115} INFO - [2022-10-19 19:21:04,053] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:21:04,085] {logging_mixin.py:115} INFO - [2022-10-19 19:21:04,085] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:21:03.941543+00:00, run_after=2022-10-20T19:21:03.941543+00:00
[2022-10-19 19:21:04,106] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.739 seconds
[2022-10-19 19:21:13,067] {processor.py:153} INFO - Started process (PID=33682) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:13,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:21:13,069] {logging_mixin.py:115} INFO - [2022-10-19 19:21:13,069] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:13,576] {logging_mixin.py:115} INFO - [2022-10-19 19:21:13,574] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:21:13,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:13,614] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.554 seconds
[2022-10-19 19:21:34,925] {processor.py:153} INFO - Started process (PID=53716) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:34,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:21:34,928] {logging_mixin.py:115} INFO - [2022-10-19 19:21:34,928] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:40,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:21:40,373] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:40,464] {logging_mixin.py:115} INFO - [2022-10-19 19:21:40,463] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:21:40,492] {logging_mixin.py:115} INFO - [2022-10-19 19:21:40,492] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:21:40.371364+00:00, run_after=2022-10-20T19:21:40.371364+00:00
[2022-10-19 19:21:40,514] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.593 seconds
[2022-10-19 19:21:44,310] {processor.py:153} INFO - Started process (PID=33728) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:44,311] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:21:44,313] {logging_mixin.py:115} INFO - [2022-10-19 19:21:44,313] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:44,761] {logging_mixin.py:115} INFO - [2022-10-19 19:21:44,759] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:21:44,763] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:21:44,798] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.515 seconds
[2022-10-19 19:22:11,261] {processor.py:153} INFO - Started process (PID=53881) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:11,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:22:11,266] {logging_mixin.py:115} INFO - [2022-10-19 19:22:11,266] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:15,461] {processor.py:153} INFO - Started process (PID=33774) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:15,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:22:15,468] {logging_mixin.py:115} INFO - [2022-10-19 19:22:15,468] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:16,327] {logging_mixin.py:115} INFO - [2022-10-19 19:22:16,325] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:22:16,329] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:16,398] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.940 seconds
[2022-10-19 19:22:17,211] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:22:17,225] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:17,303] {logging_mixin.py:115} INFO - [2022-10-19 19:22:17,302] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:22:17,327] {logging_mixin.py:115} INFO - [2022-10-19 19:22:17,327] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:22:17.222931+00:00, run_after=2022-10-20T19:22:17.222931+00:00
[2022-10-19 19:22:17,345] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.111 seconds
[2022-10-19 19:22:47,383] {processor.py:153} INFO - Started process (PID=33811) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:47,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:22:47,388] {logging_mixin.py:115} INFO - [2022-10-19 19:22:47,387] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:47,538] {processor.py:153} INFO - Started process (PID=54036) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:47,539] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:22:47,541] {logging_mixin.py:115} INFO - [2022-10-19 19:22:47,541] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:47,903] {logging_mixin.py:115} INFO - [2022-10-19 19:22:47,901] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:22:47,907] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:47,940] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.562 seconds
[2022-10-19 19:22:52,705] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:22:52,719] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:22:52,810] {logging_mixin.py:115} INFO - [2022-10-19 19:22:52,809] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:22:52,833] {logging_mixin.py:115} INFO - [2022-10-19 19:22:52,833] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:22:52.717541+00:00, run_after=2022-10-20T19:22:52.717541+00:00
[2022-10-19 19:22:52,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.319 seconds
[2022-10-19 19:23:18,627] {processor.py:153} INFO - Started process (PID=33857) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:18,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:23:18,630] {logging_mixin.py:115} INFO - [2022-10-19 19:23:18,630] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:19,108] {logging_mixin.py:115} INFO - [2022-10-19 19:23:19,104] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:23:19,110] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:19,140] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.518 seconds
[2022-10-19 19:23:22,966] {processor.py:153} INFO - Started process (PID=54196) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:22,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:23:22,969] {logging_mixin.py:115} INFO - [2022-10-19 19:23:22,969] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:27,620] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:23:27,634] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:27,730] {logging_mixin.py:115} INFO - [2022-10-19 19:23:27,729] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:23:27,754] {logging_mixin.py:115} INFO - [2022-10-19 19:23:27,754] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:23:27.632965+00:00, run_after=2022-10-20T19:23:27.632965+00:00
[2022-10-19 19:23:27,772] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.810 seconds
[2022-10-19 19:23:49,794] {processor.py:153} INFO - Started process (PID=33903) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:49,795] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:23:49,796] {logging_mixin.py:115} INFO - [2022-10-19 19:23:49,796] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:50,265] {logging_mixin.py:115} INFO - [2022-10-19 19:23:50,262] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:23:50,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:50,299] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.510 seconds
[2022-10-19 19:23:58,309] {processor.py:153} INFO - Started process (PID=54347) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:23:58,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:23:58,312] {logging_mixin.py:115} INFO - [2022-10-19 19:23:58,312] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:03,156] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:24:03,168] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:03,252] {logging_mixin.py:115} INFO - [2022-10-19 19:24:03,249] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:24:03,276] {logging_mixin.py:115} INFO - [2022-10-19 19:24:03,276] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:24:03.166076+00:00, run_after=2022-10-20T19:24:03.166076+00:00
[2022-10-19 19:24:03,292] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.987 seconds
[2022-10-19 19:24:21,160] {processor.py:153} INFO - Started process (PID=33940) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:21,163] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:24:21,166] {logging_mixin.py:115} INFO - [2022-10-19 19:24:21,166] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:21,640] {logging_mixin.py:115} INFO - [2022-10-19 19:24:21,638] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:24:21,641] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:21,683] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.527 seconds
[2022-10-19 19:24:34,117] {processor.py:153} INFO - Started process (PID=54506) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:34,120] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:24:34,121] {logging_mixin.py:115} INFO - [2022-10-19 19:24:34,121] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:38,708] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:24:38,722] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:38,803] {logging_mixin.py:115} INFO - [2022-10-19 19:24:38,802] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:24:38,831] {logging_mixin.py:115} INFO - [2022-10-19 19:24:38,831] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:24:38.720525+00:00, run_after=2022-10-20T19:24:38.720525+00:00
[2022-10-19 19:24:38,848] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.736 seconds
[2022-10-19 19:24:52,366] {processor.py:153} INFO - Started process (PID=33987) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:52,367] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:24:52,368] {logging_mixin.py:115} INFO - [2022-10-19 19:24:52,368] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:52,860] {logging_mixin.py:115} INFO - [2022-10-19 19:24:52,857] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:24:52,862] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:24:52,891] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.530 seconds
[2022-10-19 19:25:09,511] {processor.py:153} INFO - Started process (PID=54659) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:09,512] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:25:09,514] {logging_mixin.py:115} INFO - [2022-10-19 19:25:09,514] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:14,061] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:25:14,094] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:14,193] {logging_mixin.py:115} INFO - [2022-10-19 19:25:14,192] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:25:14,218] {logging_mixin.py:115} INFO - [2022-10-19 19:25:14,217] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:25:14.092308+00:00, run_after=2022-10-20T19:25:14.092308+00:00
[2022-10-19 19:25:14,236] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.730 seconds
[2022-10-19 19:25:23,558] {processor.py:153} INFO - Started process (PID=34033) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:23,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:25:23,561] {logging_mixin.py:115} INFO - [2022-10-19 19:25:23,561] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:24,036] {logging_mixin.py:115} INFO - [2022-10-19 19:25:24,034] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:25:24,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:24,083] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.533 seconds
[2022-10-19 19:25:44,322] {processor.py:153} INFO - Started process (PID=54822) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:44,323] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:25:44,325] {logging_mixin.py:115} INFO - [2022-10-19 19:25:44,324] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:48,920] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:25:48,934] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:49,020] {logging_mixin.py:115} INFO - [2022-10-19 19:25:49,018] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:25:49,046] {logging_mixin.py:115} INFO - [2022-10-19 19:25:49,045] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:25:48.932331+00:00, run_after=2022-10-20T19:25:48.932331+00:00
[2022-10-19 19:25:49,062] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.769 seconds
[2022-10-19 19:25:54,825] {processor.py:153} INFO - Started process (PID=34070) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:54,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:25:54,827] {logging_mixin.py:115} INFO - [2022-10-19 19:25:54,827] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:55,322] {logging_mixin.py:115} INFO - [2022-10-19 19:25:55,320] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:25:55,325] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:25:55,354] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.535 seconds
[2022-10-19 19:26:19,331] {processor.py:153} INFO - Started process (PID=54973) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:19,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:26:19,334] {logging_mixin.py:115} INFO - [2022-10-19 19:26:19,334] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:24,152] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:26:24,165] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:24,254] {logging_mixin.py:115} INFO - [2022-10-19 19:26:24,253] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:26:24,281] {logging_mixin.py:115} INFO - [2022-10-19 19:26:24,281] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:26:24.162969+00:00, run_after=2022-10-20T19:26:24.162969+00:00
[2022-10-19 19:26:24,303] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.980 seconds
[2022-10-19 19:26:26,027] {processor.py:153} INFO - Started process (PID=34116) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:26,028] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:26:26,030] {logging_mixin.py:115} INFO - [2022-10-19 19:26:26,030] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:26,514] {logging_mixin.py:115} INFO - [2022-10-19 19:26:26,511] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:26:26,517] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:26,547] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.528 seconds
[2022-10-19 19:26:54,385] {processor.py:153} INFO - Started process (PID=55138) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:54,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:26:54,388] {logging_mixin.py:115} INFO - [2022-10-19 19:26:54,388] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:57,247] {processor.py:153} INFO - Started process (PID=34163) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:57,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:26:57,251] {logging_mixin.py:115} INFO - [2022-10-19 19:26:57,251] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:57,782] {logging_mixin.py:115} INFO - [2022-10-19 19:26:57,777] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:26:57,784] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:57,831] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.591 seconds
[2022-10-19 19:26:58,873] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:26:58,886] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:26:58,981] {logging_mixin.py:115} INFO - [2022-10-19 19:26:58,980] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:26:59,008] {logging_mixin.py:115} INFO - [2022-10-19 19:26:59,008] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:26:58.884061+00:00, run_after=2022-10-20T19:26:58.884061+00:00
[2022-10-19 19:26:59,031] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.652 seconds
[2022-10-19 19:27:28,696] {processor.py:153} INFO - Started process (PID=34210) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:27:28,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:27:28,699] {logging_mixin.py:115} INFO - [2022-10-19 19:27:28,698] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:27:29,190] {logging_mixin.py:115} INFO - [2022-10-19 19:27:29,188] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:27:29,192] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:27:29,219] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.528 seconds
[2022-10-19 19:27:29,322] {processor.py:153} INFO - Started process (PID=55290) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:27:29,323] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:27:29,324] {logging_mixin.py:115} INFO - [2022-10-19 19:27:29,324] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:27:33,870] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:27:33,887] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:27:33,965] {logging_mixin.py:115} INFO - [2022-10-19 19:27:33,964] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:27:33,989] {logging_mixin.py:115} INFO - [2022-10-19 19:27:33,989] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:27:33.885683+00:00, run_after=2022-10-20T19:27:33.885683+00:00
[2022-10-19 19:27:34,009] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.693 seconds
[2022-10-19 19:28:00,111] {processor.py:153} INFO - Started process (PID=34247) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:00,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:28:00,114] {logging_mixin.py:115} INFO - [2022-10-19 19:28:00,114] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:00,591] {logging_mixin.py:115} INFO - [2022-10-19 19:28:00,589] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:28:00,593] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:00,625] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.518 seconds
[2022-10-19 19:28:04,248] {processor.py:153} INFO - Started process (PID=55448) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:04,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:28:04,254] {logging_mixin.py:115} INFO - [2022-10-19 19:28:04,253] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:08,784] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:28:08,799] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:08,878] {logging_mixin.py:115} INFO - [2022-10-19 19:28:08,877] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:28:08,906] {logging_mixin.py:115} INFO - [2022-10-19 19:28:08,906] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:28:08.797443+00:00, run_after=2022-10-20T19:28:08.797443+00:00
[2022-10-19 19:28:08,922] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.682 seconds
[2022-10-19 19:28:31,427] {processor.py:153} INFO - Started process (PID=34293) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:31,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:28:31,429] {logging_mixin.py:115} INFO - [2022-10-19 19:28:31,429] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:31,898] {logging_mixin.py:115} INFO - [2022-10-19 19:28:31,891] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:28:31,900] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:31,934] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.512 seconds
[2022-10-19 19:28:39,127] {processor.py:153} INFO - Started process (PID=55601) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:39,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:28:39,130] {logging_mixin.py:115} INFO - [2022-10-19 19:28:39,130] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:43,881] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:28:43,894] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:28:43,972] {logging_mixin.py:115} INFO - [2022-10-19 19:28:43,971] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:28:43,996] {logging_mixin.py:115} INFO - [2022-10-19 19:28:43,996] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:28:43.892520+00:00, run_after=2022-10-20T19:28:43.892520+00:00
[2022-10-19 19:28:44,014] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.892 seconds
[2022-10-19 19:29:02,539] {processor.py:153} INFO - Started process (PID=34339) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:02,540] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:29:02,542] {logging_mixin.py:115} INFO - [2022-10-19 19:29:02,542] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:03,017] {logging_mixin.py:115} INFO - [2022-10-19 19:29:03,014] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:29:03,020] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:03,053] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.518 seconds
[2022-10-19 19:29:18,546] {processor.py:153} INFO - Started process (PID=55763) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:18,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:29:18,551] {logging_mixin.py:115} INFO - [2022-10-19 19:29:18,551] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:23,878] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:29:23,894] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:23,979] {logging_mixin.py:115} INFO - [2022-10-19 19:29:23,978] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:29:24,007] {logging_mixin.py:115} INFO - [2022-10-19 19:29:24,007] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:29:23.892191+00:00, run_after=2022-10-20T19:29:23.892191+00:00
[2022-10-19 19:29:24,029] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.488 seconds
[2022-10-19 19:29:33,506] {processor.py:153} INFO - Started process (PID=34376) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:33,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:29:33,509] {logging_mixin.py:115} INFO - [2022-10-19 19:29:33,509] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:33,992] {logging_mixin.py:115} INFO - [2022-10-19 19:29:33,989] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:29:33,994] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:34,026] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.525 seconds
[2022-10-19 19:29:54,771] {processor.py:153} INFO - Started process (PID=55919) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:54,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:29:54,774] {logging_mixin.py:115} INFO - [2022-10-19 19:29:54,774] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:59,368] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:29:59,384] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:29:59,466] {logging_mixin.py:115} INFO - [2022-10-19 19:29:59,464] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:29:59,496] {logging_mixin.py:115} INFO - [2022-10-19 19:29:59,496] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:29:59.382102+00:00, run_after=2022-10-20T19:29:59.382102+00:00
[2022-10-19 19:29:59,513] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.746 seconds
[2022-10-19 19:30:04,672] {processor.py:153} INFO - Started process (PID=34422) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:04,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:30:04,675] {logging_mixin.py:115} INFO - [2022-10-19 19:30:04,675] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:05,174] {logging_mixin.py:115} INFO - [2022-10-19 19:30:05,172] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:30:05,176] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:05,206] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.540 seconds
[2022-10-19 19:30:30,207] {processor.py:153} INFO - Started process (PID=56082) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:30,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:30:30,210] {logging_mixin.py:115} INFO - [2022-10-19 19:30:30,209] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:34,819] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:30:34,836] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:34,930] {logging_mixin.py:115} INFO - [2022-10-19 19:30:34,928] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:30:34,954] {logging_mixin.py:115} INFO - [2022-10-19 19:30:34,954] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:30:34.834446+00:00, run_after=2022-10-20T19:30:34.834446+00:00
[2022-10-19 19:30:34,974] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.771 seconds
[2022-10-19 19:30:35,906] {processor.py:153} INFO - Started process (PID=34459) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:35,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:30:35,911] {logging_mixin.py:115} INFO - [2022-10-19 19:30:35,911] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:36,451] {logging_mixin.py:115} INFO - [2022-10-19 19:30:36,449] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:30:36,452] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:30:36,494] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.596 seconds
[2022-10-19 19:31:05,661] {processor.py:153} INFO - Started process (PID=56237) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:05,663] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:31:05,665] {logging_mixin.py:115} INFO - [2022-10-19 19:31:05,664] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:07,158] {processor.py:153} INFO - Started process (PID=34505) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:07,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:31:07,164] {logging_mixin.py:115} INFO - [2022-10-19 19:31:07,161] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:07,745] {logging_mixin.py:115} INFO - [2022-10-19 19:31:07,743] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:31:07,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:07,776] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.622 seconds
[2022-10-19 19:31:10,601] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:31:10,612] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:10,694] {logging_mixin.py:115} INFO - [2022-10-19 19:31:10,693] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:31:10,720] {logging_mixin.py:115} INFO - [2022-10-19 19:31:10,720] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:31:10.610408+00:00, run_after=2022-10-20T19:31:10.610408+00:00
[2022-10-19 19:31:10,738] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.082 seconds
[2022-10-19 19:31:38,574] {processor.py:153} INFO - Started process (PID=34551) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:38,576] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:31:38,577] {logging_mixin.py:115} INFO - [2022-10-19 19:31:38,577] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:39,126] {logging_mixin.py:115} INFO - [2022-10-19 19:31:39,122] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:31:39,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:39,162] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.593 seconds
[2022-10-19 19:31:40,993] {processor.py:153} INFO - Started process (PID=56393) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:40,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:31:40,996] {logging_mixin.py:115} INFO - [2022-10-19 19:31:40,996] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:45,621] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:31:45,648] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:31:45,736] {logging_mixin.py:115} INFO - [2022-10-19 19:31:45,735] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:31:45,761] {logging_mixin.py:115} INFO - [2022-10-19 19:31:45,761] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:31:45.646281+00:00, run_after=2022-10-20T19:31:45.646281+00:00
[2022-10-19 19:31:45,783] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.794 seconds
[2022-10-19 19:32:09,933] {processor.py:153} INFO - Started process (PID=34588) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:09,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:32:09,937] {logging_mixin.py:115} INFO - [2022-10-19 19:32:09,937] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:10,439] {logging_mixin.py:115} INFO - [2022-10-19 19:32:10,436] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:32:10,444] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:10,482] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.557 seconds
[2022-10-19 19:32:16,497] {processor.py:153} INFO - Started process (PID=56547) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:16,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:32:16,499] {logging_mixin.py:115} INFO - [2022-10-19 19:32:16,499] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:21,216] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:32:21,229] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:21,315] {logging_mixin.py:115} INFO - [2022-10-19 19:32:21,314] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:32:21,340] {logging_mixin.py:115} INFO - [2022-10-19 19:32:21,340] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:32:21.227737+00:00, run_after=2022-10-20T19:32:21.227737+00:00
[2022-10-19 19:32:21,359] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.888 seconds
[2022-10-19 19:32:41,326] {processor.py:153} INFO - Started process (PID=34635) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:41,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:32:41,330] {logging_mixin.py:115} INFO - [2022-10-19 19:32:41,330] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:41,816] {logging_mixin.py:115} INFO - [2022-10-19 19:32:41,814] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:32:41,819] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:41,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.530 seconds
[2022-10-19 19:32:52,183] {processor.py:153} INFO - Started process (PID=56709) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:52,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:32:52,186] {logging_mixin.py:115} INFO - [2022-10-19 19:32:52,186] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:56,962] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:32:56,980] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:32:57,066] {logging_mixin.py:115} INFO - [2022-10-19 19:32:57,064] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:32:57,093] {logging_mixin.py:115} INFO - [2022-10-19 19:32:57,093] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:32:56.978748+00:00, run_after=2022-10-20T19:32:56.978748+00:00
[2022-10-19 19:32:57,110] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.936 seconds
[2022-10-19 19:33:12,568] {processor.py:153} INFO - Started process (PID=34682) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:12,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:33:12,571] {logging_mixin.py:115} INFO - [2022-10-19 19:33:12,570] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:13,063] {logging_mixin.py:115} INFO - [2022-10-19 19:33:13,060] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:33:13,065] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:13,109] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.548 seconds
[2022-10-19 19:33:27,478] {processor.py:153} INFO - Started process (PID=56860) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:27,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:33:27,481] {logging_mixin.py:115} INFO - [2022-10-19 19:33:27,481] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:32,533] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:33:32,551] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:32,636] {logging_mixin.py:115} INFO - [2022-10-19 19:33:32,635] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:33:32,662] {logging_mixin.py:115} INFO - [2022-10-19 19:33:32,662] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:33:32.549640+00:00, run_after=2022-10-20T19:33:32.549640+00:00
[2022-10-19 19:33:32,681] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.209 seconds
[2022-10-19 19:33:43,938] {processor.py:153} INFO - Started process (PID=34719) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:43,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:33:43,944] {logging_mixin.py:115} INFO - [2022-10-19 19:33:43,944] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:44,522] {logging_mixin.py:115} INFO - [2022-10-19 19:33:44,519] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:33:44,523] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:33:44,557] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.640 seconds
[2022-10-19 19:34:02,823] {processor.py:153} INFO - Started process (PID=57022) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:02,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:34:02,825] {logging_mixin.py:115} INFO - [2022-10-19 19:34:02,825] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:08,067] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:34:08,091] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:08,240] {logging_mixin.py:115} INFO - [2022-10-19 19:34:08,238] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:34:08,266] {logging_mixin.py:115} INFO - [2022-10-19 19:34:08,266] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:34:08.088182+00:00, run_after=2022-10-20T19:34:08.088182+00:00
[2022-10-19 19:34:08,287] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.471 seconds
[2022-10-19 19:34:14,997] {processor.py:153} INFO - Started process (PID=34767) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:14,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:34:14,999] {logging_mixin.py:115} INFO - [2022-10-19 19:34:14,999] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:15,489] {logging_mixin.py:115} INFO - [2022-10-19 19:34:15,486] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:34:15,491] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:15,523] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.531 seconds
[2022-10-19 19:34:38,435] {processor.py:153} INFO - Started process (PID=57183) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:38,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:34:38,440] {logging_mixin.py:115} INFO - [2022-10-19 19:34:38,440] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:45,973] {processor.py:153} INFO - Started process (PID=34813) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:45,975] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:34:45,977] {logging_mixin.py:115} INFO - [2022-10-19 19:34:45,977] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:46,147] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:34:46,179] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:46,382] {logging_mixin.py:115} INFO - [2022-10-19 19:34:46,381] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:34:46,443] {logging_mixin.py:115} INFO - [2022-10-19 19:34:46,443] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:34:46.174787+00:00, run_after=2022-10-20T19:34:46.174787+00:00
[2022-10-19 19:34:46,467] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 8.040 seconds
[2022-10-19 19:34:46,910] {logging_mixin.py:115} INFO - [2022-10-19 19:34:46,906] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:34:46,918] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:34:47,054] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.091 seconds
[2022-10-19 19:35:16,759] {processor.py:153} INFO - Started process (PID=57339) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:16,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:35:16,762] {logging_mixin.py:115} INFO - [2022-10-19 19:35:16,762] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:17,200] {processor.py:153} INFO - Started process (PID=34850) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:17,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:35:17,203] {logging_mixin.py:115} INFO - [2022-10-19 19:35:17,203] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:17,841] {logging_mixin.py:115} INFO - [2022-10-19 19:35:17,838] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:35:17,845] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:17,891] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.716 seconds
[2022-10-19 19:35:22,493] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:35:22,511] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:22,605] {logging_mixin.py:115} INFO - [2022-10-19 19:35:22,603] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:35:22,631] {logging_mixin.py:115} INFO - [2022-10-19 19:35:22,631] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:35:22.509140+00:00, run_after=2022-10-20T19:35:22.509140+00:00
[2022-10-19 19:35:22,652] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.916 seconds
[2022-10-19 19:35:48,403] {processor.py:153} INFO - Started process (PID=34898) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:48,404] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:35:48,405] {logging_mixin.py:115} INFO - [2022-10-19 19:35:48,405] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:48,886] {logging_mixin.py:115} INFO - [2022-10-19 19:35:48,883] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:35:48,888] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:48,918] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.519 seconds
[2022-10-19 19:35:53,458] {processor.py:153} INFO - Started process (PID=57500) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:53,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:35:53,460] {logging_mixin.py:115} INFO - [2022-10-19 19:35:53,460] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:58,618] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:35:58,631] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:35:58,709] {logging_mixin.py:115} INFO - [2022-10-19 19:35:58,708] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:35:58,734] {logging_mixin.py:115} INFO - [2022-10-19 19:35:58,734] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:35:58.629083+00:00, run_after=2022-10-20T19:35:58.629083+00:00
[2022-10-19 19:35:58,752] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.299 seconds
[2022-10-19 19:36:19,181] {processor.py:153} INFO - Started process (PID=34947) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:19,183] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:36:19,185] {logging_mixin.py:115} INFO - [2022-10-19 19:36:19,185] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:19,844] {logging_mixin.py:115} INFO - [2022-10-19 19:36:19,841] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:36:19,846] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:19,879] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.703 seconds
[2022-10-19 19:36:28,883] {processor.py:153} INFO - Started process (PID=57651) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:28,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:36:28,887] {logging_mixin.py:115} INFO - [2022-10-19 19:36:28,887] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:33,578] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:36:33,591] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:33,672] {logging_mixin.py:115} INFO - [2022-10-19 19:36:33,671] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:36:33,697] {logging_mixin.py:115} INFO - [2022-10-19 19:36:33,697] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:36:33.589544+00:00, run_after=2022-10-20T19:36:33.589544+00:00
[2022-10-19 19:36:33,713] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.835 seconds
[2022-10-19 19:36:50,052] {processor.py:153} INFO - Started process (PID=34985) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:50,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:36:50,054] {logging_mixin.py:115} INFO - [2022-10-19 19:36:50,054] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:50,532] {logging_mixin.py:115} INFO - [2022-10-19 19:36:50,529] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:36:50,533] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:36:50,561] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.514 seconds
[2022-10-19 19:37:04,597] {processor.py:153} INFO - Started process (PID=57811) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:04,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:37:04,599] {logging_mixin.py:115} INFO - [2022-10-19 19:37:04,599] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:09,313] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:37:09,330] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:09,412] {logging_mixin.py:115} INFO - [2022-10-19 19:37:09,411] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:37:09,437] {logging_mixin.py:115} INFO - [2022-10-19 19:37:09,436] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:37:09.328315+00:00, run_after=2022-10-20T19:37:09.328315+00:00
[2022-10-19 19:37:09,455] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.864 seconds
[2022-10-19 19:37:20,705] {processor.py:153} INFO - Started process (PID=35031) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:20,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:37:20,708] {logging_mixin.py:115} INFO - [2022-10-19 19:37:20,708] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:21,190] {logging_mixin.py:115} INFO - [2022-10-19 19:37:21,186] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:37:21,192] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:21,222] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.522 seconds
[2022-10-19 19:37:39,872] {processor.py:153} INFO - Started process (PID=57967) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:39,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:37:39,875] {logging_mixin.py:115} INFO - [2022-10-19 19:37:39,875] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:44,249] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:37:44,262] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:44,341] {logging_mixin.py:115} INFO - [2022-10-19 19:37:44,340] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:37:44,369] {logging_mixin.py:115} INFO - [2022-10-19 19:37:44,369] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:37:44.259809+00:00, run_after=2022-10-20T19:37:44.259809+00:00
[2022-10-19 19:37:44,387] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.520 seconds
[2022-10-19 19:37:51,360] {processor.py:153} INFO - Started process (PID=35073) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:51,362] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:37:51,363] {logging_mixin.py:115} INFO - [2022-10-19 19:37:51,363] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:51,840] {logging_mixin.py:115} INFO - [2022-10-19 19:37:51,838] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:37:51,842] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:37:51,870] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.515 seconds
[2022-10-19 19:38:14,537] {processor.py:153} INFO - Started process (PID=58127) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:14,540] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:38:14,543] {logging_mixin.py:115} INFO - [2022-10-19 19:38:14,543] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:18,994] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:38:19,008] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:19,090] {logging_mixin.py:115} INFO - [2022-10-19 19:38:19,088] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:38:19,118] {logging_mixin.py:115} INFO - [2022-10-19 19:38:19,118] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:38:19.006705+00:00, run_after=2022-10-20T19:38:19.006705+00:00
[2022-10-19 19:38:19,133] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.624 seconds
[2022-10-19 19:38:22,322] {processor.py:153} INFO - Started process (PID=35112) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:22,323] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:38:22,324] {logging_mixin.py:115} INFO - [2022-10-19 19:38:22,324] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:22,780] {logging_mixin.py:115} INFO - [2022-10-19 19:38:22,776] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:38:22,783] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:22,815] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.498 seconds
[2022-10-19 19:38:49,851] {processor.py:153} INFO - Started process (PID=58279) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:49,852] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:38:49,853] {logging_mixin.py:115} INFO - [2022-10-19 19:38:49,853] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:53,088] {processor.py:153} INFO - Started process (PID=35156) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:53,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:38:53,091] {logging_mixin.py:115} INFO - [2022-10-19 19:38:53,091] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:53,628] {logging_mixin.py:115} INFO - [2022-10-19 19:38:53,626] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:38:53,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:53,667] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.587 seconds
[2022-10-19 19:38:54,870] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:38:54,882] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:38:54,972] {logging_mixin.py:115} INFO - [2022-10-19 19:38:54,971] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:38:54,999] {logging_mixin.py:115} INFO - [2022-10-19 19:38:54,998] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:38:54.880292+00:00, run_after=2022-10-20T19:38:54.880292+00:00
[2022-10-19 19:38:55,016] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.171 seconds
[2022-10-19 19:39:24,489] {processor.py:153} INFO - Started process (PID=35201) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:24,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:39:24,495] {logging_mixin.py:115} INFO - [2022-10-19 19:39:24,494] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:25,016] {logging_mixin.py:115} INFO - [2022-10-19 19:39:25,014] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:39:25,017] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:25,061] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.577 seconds
[2022-10-19 19:39:25,778] {processor.py:153} INFO - Started process (PID=58439) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:25,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:39:25,781] {logging_mixin.py:115} INFO - [2022-10-19 19:39:25,781] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:30,101] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:39:30,115] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:30,197] {logging_mixin.py:115} INFO - [2022-10-19 19:39:30,196] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:39:30,225] {logging_mixin.py:115} INFO - [2022-10-19 19:39:30,224] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:39:30.113053+00:00, run_after=2022-10-20T19:39:30.113053+00:00
[2022-10-19 19:39:30,246] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.473 seconds
[2022-10-19 19:39:55,806] {processor.py:153} INFO - Started process (PID=35239) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:55,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:39:55,810] {logging_mixin.py:115} INFO - [2022-10-19 19:39:55,810] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:56,348] {logging_mixin.py:115} INFO - [2022-10-19 19:39:56,345] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:39:56,349] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:39:56,379] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.578 seconds
[2022-10-19 19:40:00,449] {processor.py:153} INFO - Started process (PID=58591) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:00,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:40:00,452] {logging_mixin.py:115} INFO - [2022-10-19 19:40:00,451] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:04,975] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:40:04,990] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:05,070] {logging_mixin.py:115} INFO - [2022-10-19 19:40:05,069] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:40:05,097] {logging_mixin.py:115} INFO - [2022-10-19 19:40:05,097] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:40:04.987965+00:00, run_after=2022-10-20T19:40:04.987965+00:00
[2022-10-19 19:40:05,113] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.669 seconds
[2022-10-19 19:40:27,181] {processor.py:153} INFO - Started process (PID=35287) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:27,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:40:27,186] {logging_mixin.py:115} INFO - [2022-10-19 19:40:27,186] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:27,663] {logging_mixin.py:115} INFO - [2022-10-19 19:40:27,661] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:40:27,666] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:27,698] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.522 seconds
[2022-10-19 19:40:35,200] {processor.py:153} INFO - Started process (PID=58750) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:35,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:40:35,204] {logging_mixin.py:115} INFO - [2022-10-19 19:40:35,203] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:39,692] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:40:39,706] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:39,784] {logging_mixin.py:115} INFO - [2022-10-19 19:40:39,783] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:40:39,808] {logging_mixin.py:115} INFO - [2022-10-19 19:40:39,808] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:40:39.704183+00:00, run_after=2022-10-20T19:40:39.704183+00:00
[2022-10-19 19:40:39,824] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.628 seconds
[2022-10-19 19:40:58,050] {processor.py:153} INFO - Started process (PID=35334) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:58,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:40:58,055] {logging_mixin.py:115} INFO - [2022-10-19 19:40:58,055] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:58,560] {logging_mixin.py:115} INFO - [2022-10-19 19:40:58,556] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:40:58,562] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:40:58,601] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.555 seconds
[2022-10-19 19:41:10,820] {processor.py:153} INFO - Started process (PID=58900) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:10,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:41:10,822] {logging_mixin.py:115} INFO - [2022-10-19 19:41:10,822] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:15,295] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:41:15,309] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:15,388] {logging_mixin.py:115} INFO - [2022-10-19 19:41:15,387] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:41:15,412] {logging_mixin.py:115} INFO - [2022-10-19 19:41:15,412] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:41:15.307807+00:00, run_after=2022-10-20T19:41:15.307807+00:00
[2022-10-19 19:41:15,433] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.618 seconds
[2022-10-19 19:41:29,332] {processor.py:153} INFO - Started process (PID=35371) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:29,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:41:29,336] {logging_mixin.py:115} INFO - [2022-10-19 19:41:29,335] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:29,832] {logging_mixin.py:115} INFO - [2022-10-19 19:41:29,830] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:41:29,835] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:29,864] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.537 seconds
[2022-10-19 19:41:45,594] {processor.py:153} INFO - Started process (PID=59064) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:45,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:41:45,597] {logging_mixin.py:115} INFO - [2022-10-19 19:41:45,597] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:50,685] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:41:50,703] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:41:50,805] {logging_mixin.py:115} INFO - [2022-10-19 19:41:50,803] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:41:50,831] {logging_mixin.py:115} INFO - [2022-10-19 19:41:50,831] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:41:50.701111+00:00, run_after=2022-10-20T19:41:50.701111+00:00
[2022-10-19 19:41:50,849] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.285 seconds
[2022-10-19 19:42:00,594] {processor.py:153} INFO - Started process (PID=35417) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:00,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:42:00,597] {logging_mixin.py:115} INFO - [2022-10-19 19:42:00,597] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:01,128] {logging_mixin.py:115} INFO - [2022-10-19 19:42:01,125] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:42:01,130] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:01,164] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.577 seconds
[2022-10-19 19:42:21,040] {processor.py:153} INFO - Started process (PID=59216) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:21,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:42:21,045] {logging_mixin.py:115} INFO - [2022-10-19 19:42:21,045] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:26,929] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:42:26,943] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:27,019] {logging_mixin.py:115} INFO - [2022-10-19 19:42:27,018] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:42:27,046] {logging_mixin.py:115} INFO - [2022-10-19 19:42:27,046] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:42:26.942006+00:00, run_after=2022-10-20T19:42:26.942006+00:00
[2022-10-19 19:42:27,062] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.027 seconds
[2022-10-19 19:42:31,332] {processor.py:153} INFO - Started process (PID=35464) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:31,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:42:31,335] {logging_mixin.py:115} INFO - [2022-10-19 19:42:31,334] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:31,840] {logging_mixin.py:115} INFO - [2022-10-19 19:42:31,837] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:42:31,842] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:31,884] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.557 seconds
[2022-10-19 19:42:57,388] {processor.py:153} INFO - Started process (PID=59377) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:42:57,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:42:57,392] {logging_mixin.py:115} INFO - [2022-10-19 19:42:57,392] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:02,584] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:43:02,594] {processor.py:153} INFO - Started process (PID=35501) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:02,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:43:02,599] {logging_mixin.py:115} INFO - [2022-10-19 19:43:02,599] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:02,628] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:02,740] {logging_mixin.py:115} INFO - [2022-10-19 19:43:02,738] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:43:02,769] {logging_mixin.py:115} INFO - [2022-10-19 19:43:02,769] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:43:02.625698+00:00, run_after=2022-10-20T19:43:02.625698+00:00
[2022-10-19 19:43:02,788] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.404 seconds
[2022-10-19 19:43:03,282] {logging_mixin.py:115} INFO - [2022-10-19 19:43:03,280] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:43:03,284] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:03,316] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.726 seconds
[2022-10-19 19:43:33,230] {processor.py:153} INFO - Started process (PID=59531) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:33,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:43:33,233] {logging_mixin.py:115} INFO - [2022-10-19 19:43:33,233] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:33,934] {processor.py:153} INFO - Started process (PID=35547) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:33,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:43:33,939] {logging_mixin.py:115} INFO - [2022-10-19 19:43:33,939] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:34,707] {logging_mixin.py:115} INFO - [2022-10-19 19:43:34,703] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:43:34,709] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:34,748] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.822 seconds
[2022-10-19 19:43:39,020] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:43:39,041] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:43:39,129] {logging_mixin.py:115} INFO - [2022-10-19 19:43:39,128] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:43:39,157] {logging_mixin.py:115} INFO - [2022-10-19 19:43:39,157] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:43:39.038823+00:00, run_after=2022-10-20T19:43:39.038823+00:00
[2022-10-19 19:43:39,176] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.950 seconds
[2022-10-19 19:44:05,496] {processor.py:153} INFO - Started process (PID=35593) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:05,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:44:05,499] {logging_mixin.py:115} INFO - [2022-10-19 19:44:05,498] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:06,042] {logging_mixin.py:115} INFO - [2022-10-19 19:44:06,039] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:44:06,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:06,092] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.605 seconds
[2022-10-19 19:44:09,966] {processor.py:153} INFO - Started process (PID=59693) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:09,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:44:09,975] {logging_mixin.py:115} INFO - [2022-10-19 19:44:09,975] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:15,748] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:44:15,760] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:15,849] {logging_mixin.py:115} INFO - [2022-10-19 19:44:15,848] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:44:15,876] {logging_mixin.py:115} INFO - [2022-10-19 19:44:15,876] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:44:15.758640+00:00, run_after=2022-10-20T19:44:15.758640+00:00
[2022-10-19 19:44:15,896] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.937 seconds
[2022-10-19 19:44:36,251] {processor.py:153} INFO - Started process (PID=35629) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:36,255] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:44:36,256] {logging_mixin.py:115} INFO - [2022-10-19 19:44:36,256] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:36,730] {logging_mixin.py:115} INFO - [2022-10-19 19:44:36,728] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:44:36,732] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:36,773] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.526 seconds
[2022-10-19 19:44:46,821] {processor.py:153} INFO - Started process (PID=59853) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:46,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:44:46,824] {logging_mixin.py:115} INFO - [2022-10-19 19:44:46,824] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:51,631] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:44:51,642] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:44:51,725] {logging_mixin.py:115} INFO - [2022-10-19 19:44:51,724] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:44:51,749] {logging_mixin.py:115} INFO - [2022-10-19 19:44:51,749] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:44:51.640771+00:00, run_after=2022-10-20T19:44:51.640771+00:00
[2022-10-19 19:44:51,767] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.973 seconds
[2022-10-19 19:45:07,540] {processor.py:153} INFO - Started process (PID=35675) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:07,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:45:07,544] {logging_mixin.py:115} INFO - [2022-10-19 19:45:07,544] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:08,043] {logging_mixin.py:115} INFO - [2022-10-19 19:45:08,041] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:45:08,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:08,076] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.546 seconds
[2022-10-19 19:45:22,546] {processor.py:153} INFO - Started process (PID=60011) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:22,547] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:45:22,548] {logging_mixin.py:115} INFO - [2022-10-19 19:45:22,548] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:27,388] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:45:27,405] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:27,482] {logging_mixin.py:115} INFO - [2022-10-19 19:45:27,481] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:45:27,506] {logging_mixin.py:115} INFO - [2022-10-19 19:45:27,505] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:45:27.403447+00:00, run_after=2022-10-20T19:45:27.403447+00:00
[2022-10-19 19:45:27,526] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.986 seconds
[2022-10-19 19:45:38,779] {processor.py:153} INFO - Started process (PID=35721) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:38,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:45:38,782] {logging_mixin.py:115} INFO - [2022-10-19 19:45:38,782] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:39,318] {logging_mixin.py:115} INFO - [2022-10-19 19:45:39,315] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:45:39,323] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:39,356] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.581 seconds
[2022-10-19 19:45:57,860] {processor.py:153} INFO - Started process (PID=60169) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:45:57,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:45:57,864] {logging_mixin.py:115} INFO - [2022-10-19 19:45:57,864] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:03,580] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:46:03,595] {logging_mixin.py:115} INFO - [2022-10-19 19:46:03,593] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import loadJsonData
ImportError: cannot import name 'loadJsonData' from 'data_extraction_pyspark' (/opt/airflow/dags/data_extraction_pyspark.py)
[2022-10-19 19:46:03,596] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:03,626] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.771 seconds
[2022-10-19 19:46:10,232] {processor.py:153} INFO - Started process (PID=35759) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:10,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:46:10,235] {logging_mixin.py:115} INFO - [2022-10-19 19:46:10,235] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:10,714] {processor.py:153} INFO - Started process (PID=60303) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:10,715] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:46:10,717] {logging_mixin.py:115} INFO - [2022-10-19 19:46:10,717] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:10,922] {logging_mixin.py:115} INFO - [2022-10-19 19:46:10,918] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:46:10,925] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:10,991] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.765 seconds
[2022-10-19 19:46:16,466] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:46:16,478] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:16,556] {logging_mixin.py:115} INFO - [2022-10-19 19:46:16,555] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:46:16,582] {logging_mixin.py:115} INFO - [2022-10-19 19:46:16,581] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:46:16.476687+00:00, run_after=2022-10-20T19:46:16.476687+00:00
[2022-10-19 19:46:16,604] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.898 seconds
[2022-10-19 19:46:41,770] {processor.py:153} INFO - Started process (PID=35806) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:41,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:46:41,774] {logging_mixin.py:115} INFO - [2022-10-19 19:46:41,774] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:42,257] {logging_mixin.py:115} INFO - [2022-10-19 19:46:42,255] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:46:42,261] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:42,288] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.524 seconds
[2022-10-19 19:46:46,891] {processor.py:153} INFO - Started process (PID=60461) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:46,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:46:46,894] {logging_mixin.py:115} INFO - [2022-10-19 19:46:46,893] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:51,513] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:46:51,536] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:46:51,616] {logging_mixin.py:115} INFO - [2022-10-19 19:46:51,615] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:46:51,641] {logging_mixin.py:115} INFO - [2022-10-19 19:46:51,641] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:46:51.533812+00:00, run_after=2022-10-20T19:46:51.533812+00:00
[2022-10-19 19:46:51,660] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.795 seconds
[2022-10-19 19:47:13,073] {processor.py:153} INFO - Started process (PID=35852) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:13,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:47:13,077] {logging_mixin.py:115} INFO - [2022-10-19 19:47:13,077] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:13,558] {logging_mixin.py:115} INFO - [2022-10-19 19:47:13,556] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:47:13,560] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:13,591] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.524 seconds
[2022-10-19 19:47:22,337] {processor.py:153} INFO - Started process (PID=60613) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:22,339] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:47:22,340] {logging_mixin.py:115} INFO - [2022-10-19 19:47:22,340] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:27,096] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:47:27,110] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:27,188] {logging_mixin.py:115} INFO - [2022-10-19 19:47:27,187] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:47:27,211] {logging_mixin.py:115} INFO - [2022-10-19 19:47:27,211] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:47:27.108920+00:00, run_after=2022-10-20T19:47:27.108920+00:00
[2022-10-19 19:47:27,229] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.896 seconds
[2022-10-19 19:47:44,131] {processor.py:153} INFO - Started process (PID=35891) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:44,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:47:44,136] {logging_mixin.py:115} INFO - [2022-10-19 19:47:44,136] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:44,600] {logging_mixin.py:115} INFO - [2022-10-19 19:47:44,598] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:47:44,601] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:44,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.505 seconds
[2022-10-19 19:47:57,324] {processor.py:153} INFO - Started process (PID=60775) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:47:57,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:47:57,326] {logging_mixin.py:115} INFO - [2022-10-19 19:47:57,326] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:01,908] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:48:01,922] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:01,998] {logging_mixin.py:115} INFO - [2022-10-19 19:48:01,997] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:48:02,024] {logging_mixin.py:115} INFO - [2022-10-19 19:48:02,024] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:48:01.920221+00:00, run_after=2022-10-20T19:48:01.920221+00:00
[2022-10-19 19:48:02,042] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.722 seconds
[2022-10-19 19:48:14,903] {processor.py:153} INFO - Started process (PID=35938) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:14,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:48:14,906] {logging_mixin.py:115} INFO - [2022-10-19 19:48:14,905] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:15,360] {logging_mixin.py:115} INFO - [2022-10-19 19:48:15,356] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:48:15,362] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:15,392] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.494 seconds
[2022-10-19 19:48:32,954] {processor.py:153} INFO - Started process (PID=60928) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:32,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:48:32,958] {logging_mixin.py:115} INFO - [2022-10-19 19:48:32,958] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:37,769] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:48:37,781] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:37,859] {logging_mixin.py:115} INFO - [2022-10-19 19:48:37,858] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:48:37,884] {logging_mixin.py:115} INFO - [2022-10-19 19:48:37,884] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:48:37.779750+00:00, run_after=2022-10-20T19:48:37.779750+00:00
[2022-10-19 19:48:37,904] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.954 seconds
[2022-10-19 19:48:45,618] {processor.py:153} INFO - Started process (PID=35985) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:45,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:48:45,620] {logging_mixin.py:115} INFO - [2022-10-19 19:48:45,620] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:46,074] {logging_mixin.py:115} INFO - [2022-10-19 19:48:46,070] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:48:46,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:48:46,116] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.503 seconds
[2022-10-19 19:49:08,201] {processor.py:153} INFO - Started process (PID=61093) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:08,203] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:49:08,205] {logging_mixin.py:115} INFO - [2022-10-19 19:49:08,204] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:12,843] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:49:12,859] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:12,942] {logging_mixin.py:115} INFO - [2022-10-19 19:49:12,941] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:49:12,975] {logging_mixin.py:115} INFO - [2022-10-19 19:49:12,975] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:49:12.857651+00:00, run_after=2022-10-20T19:49:12.857651+00:00
[2022-10-19 19:49:12,991] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.796 seconds
[2022-10-19 19:49:16,390] {processor.py:153} INFO - Started process (PID=36022) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:16,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:49:16,392] {logging_mixin.py:115} INFO - [2022-10-19 19:49:16,392] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:16,907] {logging_mixin.py:115} INFO - [2022-10-19 19:49:16,905] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:49:16,910] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:16,940] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.555 seconds
[2022-10-19 19:49:43,912] {processor.py:153} INFO - Started process (PID=61244) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:43,915] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:49:43,917] {logging_mixin.py:115} INFO - [2022-10-19 19:49:43,917] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:47,213] {processor.py:153} INFO - Started process (PID=36068) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:47,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:49:47,215] {logging_mixin.py:115} INFO - [2022-10-19 19:49:47,215] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:47,651] {logging_mixin.py:115} INFO - [2022-10-19 19:49:47,649] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:49:47,653] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:47,681] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.495 seconds
[2022-10-19 19:49:48,563] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:49:48,579] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:49:48,657] {logging_mixin.py:115} INFO - [2022-10-19 19:49:48,655] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:49:48,682] {logging_mixin.py:115} INFO - [2022-10-19 19:49:48,681] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:49:48.577172+00:00, run_after=2022-10-20T19:49:48.577172+00:00
[2022-10-19 19:49:48,698] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.816 seconds
[2022-10-19 19:50:17,930] {processor.py:153} INFO - Started process (PID=36114) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:17,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:50:17,933] {logging_mixin.py:115} INFO - [2022-10-19 19:50:17,933] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:18,392] {logging_mixin.py:115} INFO - [2022-10-19 19:50:18,388] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:50:18,394] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:18,425] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.499 seconds
[2022-10-19 19:50:19,270] {processor.py:153} INFO - Started process (PID=61403) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:19,271] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:50:19,272] {logging_mixin.py:115} INFO - [2022-10-19 19:50:19,272] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:23,637] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:50:23,649] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:23,726] {logging_mixin.py:115} INFO - [2022-10-19 19:50:23,725] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:50:23,754] {logging_mixin.py:115} INFO - [2022-10-19 19:50:23,754] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:50:23.647104+00:00, run_after=2022-10-20T19:50:23.647104+00:00
[2022-10-19 19:50:23,771] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.506 seconds
[2022-10-19 19:50:48,693] {processor.py:153} INFO - Started process (PID=36151) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:48,695] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:50:48,696] {logging_mixin.py:115} INFO - [2022-10-19 19:50:48,696] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:49,167] {logging_mixin.py:115} INFO - [2022-10-19 19:50:49,165] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:50:49,169] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:49,199] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.510 seconds
[2022-10-19 19:50:54,543] {processor.py:153} INFO - Started process (PID=61554) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:54,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:50:54,545] {logging_mixin.py:115} INFO - [2022-10-19 19:50:54,545] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:59,281] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:50:59,298] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:50:59,379] {logging_mixin.py:115} INFO - [2022-10-19 19:50:59,377] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:50:59,404] {logging_mixin.py:115} INFO - [2022-10-19 19:50:59,404] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:50:59.296273+00:00, run_after=2022-10-20T19:50:59.296273+00:00
[2022-10-19 19:50:59,423] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.885 seconds
[2022-10-19 19:51:19,545] {processor.py:153} INFO - Started process (PID=36198) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:19,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:51:19,548] {logging_mixin.py:115} INFO - [2022-10-19 19:51:19,548] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:20,018] {logging_mixin.py:115} INFO - [2022-10-19 19:51:20,014] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:51:20,021] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:20,051] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.511 seconds
[2022-10-19 19:51:29,718] {processor.py:153} INFO - Started process (PID=61713) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:29,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:51:29,721] {logging_mixin.py:115} INFO - [2022-10-19 19:51:29,721] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:34,366] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:51:34,377] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:34,454] {logging_mixin.py:115} INFO - [2022-10-19 19:51:34,452] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:51:34,486] {logging_mixin.py:115} INFO - [2022-10-19 19:51:34,486] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:51:34.375876+00:00, run_after=2022-10-20T19:51:34.375876+00:00
[2022-10-19 19:51:34,501] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.788 seconds
[2022-10-19 19:51:50,295] {processor.py:153} INFO - Started process (PID=36245) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:50,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:51:50,297] {logging_mixin.py:115} INFO - [2022-10-19 19:51:50,297] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:50,770] {logging_mixin.py:115} INFO - [2022-10-19 19:51:50,766] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:51:50,772] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:51:50,802] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.512 seconds
[2022-10-19 19:52:04,993] {processor.py:153} INFO - Started process (PID=61869) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:04,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:52:04,996] {logging_mixin.py:115} INFO - [2022-10-19 19:52:04,995] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:09,858] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:52:09,875] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:09,953] {logging_mixin.py:115} INFO - [2022-10-19 19:52:09,952] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:52:09,984] {logging_mixin.py:115} INFO - [2022-10-19 19:52:09,983] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:52:09.873868+00:00, run_after=2022-10-20T19:52:09.873868+00:00
[2022-10-19 19:52:10,000] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.012 seconds
[2022-10-19 19:52:21,074] {processor.py:153} INFO - Started process (PID=36283) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:21,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:52:21,077] {logging_mixin.py:115} INFO - [2022-10-19 19:52:21,076] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:21,532] {logging_mixin.py:115} INFO - [2022-10-19 19:52:21,530] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:52:21,535] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:21,565] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.495 seconds
[2022-10-19 19:52:40,837] {processor.py:153} INFO - Started process (PID=62031) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:40,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:52:40,840] {logging_mixin.py:115} INFO - [2022-10-19 19:52:40,840] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:45,567] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:52:45,582] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:45,661] {logging_mixin.py:115} INFO - [2022-10-19 19:52:45,660] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:52:45,689] {logging_mixin.py:115} INFO - [2022-10-19 19:52:45,689] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:52:45.579512+00:00, run_after=2022-10-20T19:52:45.579512+00:00
[2022-10-19 19:52:45,707] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.875 seconds
[2022-10-19 19:52:51,758] {processor.py:153} INFO - Started process (PID=36329) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:51,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:52:51,760] {logging_mixin.py:115} INFO - [2022-10-19 19:52:51,760] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:52,214] {logging_mixin.py:115} INFO - [2022-10-19 19:52:52,211] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:52:52,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:52:52,246] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.492 seconds
[2022-10-19 19:53:16,123] {processor.py:153} INFO - Started process (PID=62186) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:16,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:53:16,126] {logging_mixin.py:115} INFO - [2022-10-19 19:53:16,126] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:20,613] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:53:20,628] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:20,708] {logging_mixin.py:115} INFO - [2022-10-19 19:53:20,707] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:53:20,737] {logging_mixin.py:115} INFO - [2022-10-19 19:53:20,737] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:53:20.626181+00:00, run_after=2022-10-20T19:53:20.626181+00:00
[2022-10-19 19:53:20,753] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.656 seconds
[2022-10-19 19:53:22,584] {processor.py:153} INFO - Started process (PID=36376) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:22,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:53:22,587] {logging_mixin.py:115} INFO - [2022-10-19 19:53:22,587] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:23,061] {logging_mixin.py:115} INFO - [2022-10-19 19:53:23,058] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:53:23,063] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:23,096] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.517 seconds
[2022-10-19 19:53:50,826] {processor.py:153} INFO - Started process (PID=62346) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:50,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:53:50,829] {logging_mixin.py:115} INFO - [2022-10-19 19:53:50,829] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:53,392] {processor.py:153} INFO - Started process (PID=36414) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:53,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:53:53,394] {logging_mixin.py:115} INFO - [2022-10-19 19:53:53,394] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:53,963] {logging_mixin.py:115} INFO - [2022-10-19 19:53:53,960] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:53:53,964] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:53,996] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.609 seconds
[2022-10-19 19:53:55,756] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:53:55,773] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:53:55,856] {logging_mixin.py:115} INFO - [2022-10-19 19:53:55,855] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:53:55,883] {logging_mixin.py:115} INFO - [2022-10-19 19:53:55,883] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:53:55.771103+00:00, run_after=2022-10-20T19:53:55.771103+00:00
[2022-10-19 19:53:55,900] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.081 seconds
[2022-10-19 19:54:24,214] {processor.py:153} INFO - Started process (PID=36459) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:24,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:54:24,217] {logging_mixin.py:115} INFO - [2022-10-19 19:54:24,217] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:24,705] {logging_mixin.py:115} INFO - [2022-10-19 19:54:24,702] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:54:24,708] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:24,736] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.526 seconds
[2022-10-19 19:54:26,081] {processor.py:153} INFO - Started process (PID=62497) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:26,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:54:26,084] {logging_mixin.py:115} INFO - [2022-10-19 19:54:26,084] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:31,062] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:54:31,108] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:31,196] {logging_mixin.py:115} INFO - [2022-10-19 19:54:31,194] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:54:31,271] {logging_mixin.py:115} INFO - [2022-10-19 19:54:31,271] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:54:31.106670+00:00, run_after=2022-10-20T19:54:31.106670+00:00
[2022-10-19 19:54:31,302] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.226 seconds
[2022-10-19 19:54:54,795] {processor.py:153} INFO - Started process (PID=36503) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:54,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:54:54,798] {logging_mixin.py:115} INFO - [2022-10-19 19:54:54,798] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:55,276] {logging_mixin.py:115} INFO - [2022-10-19 19:54:55,273] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:54:55,282] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:54:55,313] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.523 seconds
[2022-10-19 19:55:01,596] {processor.py:153} INFO - Started process (PID=62656) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:01,597] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:55:01,598] {logging_mixin.py:115} INFO - [2022-10-19 19:55:01,598] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:06,807] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:55:06,820] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:06,901] {logging_mixin.py:115} INFO - [2022-10-19 19:55:06,899] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:55:06,929] {logging_mixin.py:115} INFO - [2022-10-19 19:55:06,929] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:55:06.818533+00:00, run_after=2022-10-20T19:55:06.818533+00:00
[2022-10-19 19:55:06,947] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.356 seconds
[2022-10-19 19:55:26,067] {processor.py:153} INFO - Started process (PID=36541) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:26,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:55:26,070] {logging_mixin.py:115} INFO - [2022-10-19 19:55:26,070] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:26,550] {logging_mixin.py:115} INFO - [2022-10-19 19:55:26,548] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:55:26,553] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:26,607] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.545 seconds
[2022-10-19 19:55:37,343] {processor.py:153} INFO - Started process (PID=62807) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:37,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:55:37,346] {logging_mixin.py:115} INFO - [2022-10-19 19:55:37,346] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:42,782] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:55:42,797] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:42,876] {logging_mixin.py:115} INFO - [2022-10-19 19:55:42,875] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:55:42,902] {logging_mixin.py:115} INFO - [2022-10-19 19:55:42,902] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:55:42.795019+00:00, run_after=2022-10-20T19:55:42.795019+00:00
[2022-10-19 19:55:42,923] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.587 seconds
[2022-10-19 19:55:57,419] {processor.py:153} INFO - Started process (PID=36587) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:57,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:55:57,422] {logging_mixin.py:115} INFO - [2022-10-19 19:55:57,422] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:57,893] {logging_mixin.py:115} INFO - [2022-10-19 19:55:57,890] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:55:57,894] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:55:57,925] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.511 seconds
[2022-10-19 19:56:13,180] {processor.py:153} INFO - Started process (PID=62974) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:13,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:56:13,182] {logging_mixin.py:115} INFO - [2022-10-19 19:56:13,182] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:18,185] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:56:18,199] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:18,283] {logging_mixin.py:115} INFO - [2022-10-19 19:56:18,281] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:56:18,312] {logging_mixin.py:115} INFO - [2022-10-19 19:56:18,312] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:56:18.197568+00:00, run_after=2022-10-20T19:56:18.197568+00:00
[2022-10-19 19:56:18,328] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.175 seconds
[2022-10-19 19:56:28,632] {processor.py:153} INFO - Started process (PID=36634) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:28,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:56:28,635] {logging_mixin.py:115} INFO - [2022-10-19 19:56:28,635] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:29,099] {logging_mixin.py:115} INFO - [2022-10-19 19:56:29,097] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:56:29,101] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:29,132] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.506 seconds
[2022-10-19 19:56:48,514] {processor.py:153} INFO - Started process (PID=63126) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:48,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:56:48,517] {logging_mixin.py:115} INFO - [2022-10-19 19:56:48,517] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:53,377] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:56:53,394] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:53,488] {logging_mixin.py:115} INFO - [2022-10-19 19:56:53,486] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:56:53,519] {logging_mixin.py:115} INFO - [2022-10-19 19:56:53,519] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:56:53.392314+00:00, run_after=2022-10-20T19:56:53.392314+00:00
[2022-10-19 19:56:53,537] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.027 seconds
[2022-10-19 19:56:59,920] {processor.py:153} INFO - Started process (PID=36671) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:56:59,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:56:59,922] {logging_mixin.py:115} INFO - [2022-10-19 19:56:59,922] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:57:00,410] {logging_mixin.py:115} INFO - [2022-10-19 19:57:00,407] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:57:00,411] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:57:00,448] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.532 seconds
[2022-10-19 19:57:24,343] {processor.py:153} INFO - Started process (PID=63287) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:57:24,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:57:24,378] {logging_mixin.py:115} INFO - [2022-10-19 19:57:24,377] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:57:31,224] {processor.py:153} INFO - Started process (PID=36715) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:57:31,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 19:57:31,237] {logging_mixin.py:115} INFO - [2022-10-19 19:57:31,237] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:57:32,582] {logging_mixin.py:115} INFO - [2022-10-19 19:57:32,579] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 19:57:32,585] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:57:32,647] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.448 seconds
[2022-10-19 19:57:37,171] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 19:57:37,186] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 19:57:37,265] {logging_mixin.py:115} INFO - [2022-10-19 19:57:37,264] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 19:57:37,294] {logging_mixin.py:115} INFO - [2022-10-19 19:57:37,294] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T19:57:37.184160+00:00, run_after=2022-10-20T19:57:37.184160+00:00
[2022-10-19 19:57:37,315] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.138 seconds
[2022-10-19 20:02:18,805] {processor.py:153} INFO - Started process (PID=63429) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:18,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:02:18,808] {logging_mixin.py:115} INFO - [2022-10-19 20:02:18,808] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:19,074] {processor.py:153} INFO - Started process (PID=36745) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:19,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:02:19,081] {logging_mixin.py:115} INFO - [2022-10-19 20:02:19,081] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:19,722] {logging_mixin.py:115} INFO - [2022-10-19 20:02:19,720] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:02:19,725] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:19,771] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.702 seconds
[2022-10-19 20:02:27,737] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:02:27,766] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:27,846] {logging_mixin.py:115} INFO - [2022-10-19 20:02:27,845] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:02:27,871] {logging_mixin.py:115} INFO - [2022-10-19 20:02:27,871] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:02:27.764723+00:00, run_after=2022-10-20T20:02:27.764723+00:00
[2022-10-19 20:02:27,888] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 9.095 seconds
[2022-10-19 20:02:49,896] {processor.py:153} INFO - Started process (PID=36782) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:49,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:02:49,899] {logging_mixin.py:115} INFO - [2022-10-19 20:02:49,899] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:50,399] {logging_mixin.py:115} INFO - [2022-10-19 20:02:50,397] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:02:50,402] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:50,440] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.550 seconds
[2022-10-19 20:02:58,237] {processor.py:153} INFO - Started process (PID=63607) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:02:58,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:02:58,240] {logging_mixin.py:115} INFO - [2022-10-19 20:02:58,240] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:03:02,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:03:02,831] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:03:02,920] {logging_mixin.py:115} INFO - [2022-10-19 20:03:02,919] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:03:02,945] {logging_mixin.py:115} INFO - [2022-10-19 20:03:02,945] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:03:02.829574+00:00, run_after=2022-10-20T20:03:02.829574+00:00
[2022-10-19 20:03:02,964] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.734 seconds
[2022-10-19 20:07:50,657] {processor.py:153} INFO - Started process (PID=63742) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:07:50,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:07:50,662] {logging_mixin.py:115} INFO - [2022-10-19 20:07:50,662] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:07:50,691] {processor.py:153} INFO - Started process (PID=36827) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:07:50,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:07:50,696] {logging_mixin.py:115} INFO - [2022-10-19 20:07:50,695] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:07:51,231] {logging_mixin.py:115} INFO - [2022-10-19 20:07:51,229] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:07:51,234] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:07:51,273] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.595 seconds
[2022-10-19 20:07:59,602] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:07:59,619] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:07:59,704] {logging_mixin.py:115} INFO - [2022-10-19 20:07:59,703] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:07:59,732] {logging_mixin.py:115} INFO - [2022-10-19 20:07:59,732] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:07:59.617262+00:00, run_after=2022-10-20T20:07:59.617262+00:00
[2022-10-19 20:07:59,748] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 9.097 seconds
[2022-10-19 20:08:21,570] {processor.py:153} INFO - Started process (PID=36873) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:21,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:08:21,572] {logging_mixin.py:115} INFO - [2022-10-19 20:08:21,572] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:22,061] {logging_mixin.py:115} INFO - [2022-10-19 20:08:22,057] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:08:22,063] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:22,115] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.549 seconds
[2022-10-19 20:08:30,027] {processor.py:153} INFO - Started process (PID=63918) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:30,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:08:30,030] {logging_mixin.py:115} INFO - [2022-10-19 20:08:30,030] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:34,519] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:08:34,532] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:34,609] {logging_mixin.py:115} INFO - [2022-10-19 20:08:34,607] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:08:34,633] {logging_mixin.py:115} INFO - [2022-10-19 20:08:34,632] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:08:34.530059+00:00, run_after=2022-10-20T20:08:34.530059+00:00
[2022-10-19 20:08:34,651] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.630 seconds
[2022-10-19 20:08:52,264] {processor.py:153} INFO - Started process (PID=36911) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:52,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:08:52,267] {logging_mixin.py:115} INFO - [2022-10-19 20:08:52,267] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:53,971] {logging_mixin.py:115} INFO - [2022-10-19 20:08:53,968] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:08:54,995] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:08:55,142] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.883 seconds
[2022-10-19 20:09:04,894] {processor.py:153} INFO - Started process (PID=64071) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:09:04,901] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:09:04,916] {logging_mixin.py:115} INFO - [2022-10-19 20:09:04,913] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:14:23,768] {processor.py:153} INFO - Started process (PID=36948) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:14:23,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:14:23,823] {logging_mixin.py:115} INFO - [2022-10-19 20:14:23,822] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:14:27,190] {processor.py:153} INFO - Started process (PID=64139) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:14:27,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:14:27,216] {logging_mixin.py:115} INFO - [2022-10-19 20:14:27,215] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:14:28,353] {logging_mixin.py:115} INFO - [2022-10-19 20:14:28,331] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:14:28,359] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:14:28,492] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.769 seconds
[2022-10-19 20:14:57,361] {logging_mixin.py:115} INFO - [2022-10-19 20:14:57,251] {timeout.py:67} ERROR - Process timed out, PID: 64139
[2022-10-19 20:14:57,489] {logging_mixin.py:115} INFO - [2022-10-19 20:14:57,439] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 64139
[2022-10-19 20:14:57,539] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:14:57,689] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.675 seconds
[2022-10-19 20:14:58,848] {processor.py:153} INFO - Started process (PID=36985) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:14:58,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:14:58,861] {logging_mixin.py:115} INFO - [2022-10-19 20:14:58,861] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:15:04,162] {logging_mixin.py:115} INFO - [2022-10-19 20:15:04,146] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:15:04,180] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:15:04,385] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.577 seconds
[2022-10-19 20:19:52,989] {processor.py:153} INFO - Started process (PID=64242) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:19:52,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:19:52,996] {logging_mixin.py:115} INFO - [2022-10-19 20:19:52,996] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:19:53,084] {processor.py:153} INFO - Started process (PID=37013) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:19:53,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:19:53,086] {logging_mixin.py:115} INFO - [2022-10-19 20:19:53,086] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:19:55,859] {logging_mixin.py:115} INFO - [2022-10-19 20:19:55,823] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:19:55,884] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:19:56,217] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.137 seconds
[2022-10-19 20:20:23,008] {logging_mixin.py:115} INFO - [2022-10-19 20:20:22,985] {timeout.py:67} ERROR - Process timed out, PID: 64242
[2022-10-19 20:20:23,049] {logging_mixin.py:115} INFO - [2022-10-19 20:20:23,022] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 64242
[2022-10-19 20:20:23,107] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:20:24,127] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.167 seconds
[2022-10-19 20:20:26,806] {processor.py:153} INFO - Started process (PID=37050) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:20:26,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:20:26,834] {logging_mixin.py:115} INFO - [2022-10-19 20:20:26,834] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:20:33,538] {logging_mixin.py:115} INFO - [2022-10-19 20:20:33,512] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:20:33,559] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:20:33,829] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.102 seconds
[2022-10-19 20:20:58,305] {processor.py:153} INFO - Started process (PID=64339) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:20:58,331] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:20:58,374] {logging_mixin.py:115} INFO - [2022-10-19 20:20:58,354] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:21:04,723] {processor.py:153} INFO - Started process (PID=37087) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:21:04,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:21:04,731] {logging_mixin.py:115} INFO - [2022-10-19 20:21:04,731] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:21:05,339] {logging_mixin.py:115} INFO - [2022-10-19 20:21:05,335] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:21:05,343] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:21:05,387] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.679 seconds
[2022-10-19 20:21:10,048] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:21:10,063] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:21:10,146] {logging_mixin.py:115} INFO - [2022-10-19 20:21:10,144] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:21:10,171] {logging_mixin.py:115} INFO - [2022-10-19 20:21:10,171] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:21:10.061405+00:00, run_after=2022-10-20T20:21:10.061405+00:00
[2022-10-19 20:21:10,187] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 12.114 seconds
[2022-10-19 20:25:56,697] {processor.py:153} INFO - Started process (PID=37115) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:25:56,732] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:25:56,817] {logging_mixin.py:115} INFO - [2022-10-19 20:25:56,816] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:25:58,072] {processor.py:153} INFO - Started process (PID=64492) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:25:58,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:25:58,136] {logging_mixin.py:115} INFO - [2022-10-19 20:25:58,136] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:26:01,752] {logging_mixin.py:115} INFO - [2022-10-19 20:26:01,723] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:26:01,773] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:26:02,094] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.472 seconds
[2022-10-19 20:26:28,195] {logging_mixin.py:115} INFO - [2022-10-19 20:26:28,186] {timeout.py:67} ERROR - Process timed out, PID: 64492
[2022-10-19 20:26:28,249] {logging_mixin.py:115} INFO - [2022-10-19 20:26:28,235] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 64492
[2022-10-19 20:26:28,272] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:26:29,396] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.562 seconds
[2022-10-19 20:26:33,118] {processor.py:153} INFO - Started process (PID=37151) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:26:33,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:26:33,145] {logging_mixin.py:115} INFO - [2022-10-19 20:26:33,144] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:26:39,908] {logging_mixin.py:115} INFO - [2022-10-19 20:26:39,888] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:26:39,918] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:26:40,136] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.071 seconds
[2022-10-19 20:28:18,731] {processor.py:153} INFO - Started process (PID=37179) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:18,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:28:18,735] {logging_mixin.py:115} INFO - [2022-10-19 20:28:18,734] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:19,386] {processor.py:153} INFO - Started process (PID=64571) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:19,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:28:19,411] {logging_mixin.py:115} INFO - [2022-10-19 20:28:19,405] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:19,871] {logging_mixin.py:115} INFO - [2022-10-19 20:28:19,866] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:28:19,875] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:20,140] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.431 seconds
[2022-10-19 20:28:33,120] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:28:33,144] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:33,232] {logging_mixin.py:115} INFO - [2022-10-19 20:28:33,231] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:28:33,263] {logging_mixin.py:115} INFO - [2022-10-19 20:28:33,263] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:28:33.141095+00:00, run_after=2022-10-20T20:28:33.141095+00:00
[2022-10-19 20:28:33,280] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.963 seconds
[2022-10-19 20:28:50,378] {processor.py:153} INFO - Started process (PID=37215) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:50,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:28:50,380] {logging_mixin.py:115} INFO - [2022-10-19 20:28:50,380] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:50,861] {logging_mixin.py:115} INFO - [2022-10-19 20:28:50,857] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 17, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:28:50,863] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:28:50,893] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.522 seconds
[2022-10-19 20:29:03,731] {processor.py:153} INFO - Started process (PID=64753) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:03,732] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:29:03,733] {logging_mixin.py:115} INFO - [2022-10-19 20:29:03,733] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:09,630] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:29:09,647] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:09,736] {logging_mixin.py:115} INFO - [2022-10-19 20:29:09,734] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:29:09,763] {logging_mixin.py:115} INFO - [2022-10-19 20:29:09,763] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:29:09.645383+00:00, run_after=2022-10-20T20:29:09.645383+00:00
[2022-10-19 20:29:09,781] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.055 seconds
[2022-10-19 20:29:21,342] {processor.py:153} INFO - Started process (PID=37262) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:21,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:29:21,345] {logging_mixin.py:115} INFO - [2022-10-19 20:29:21,345] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:21,562] {logging_mixin.py:115} INFO - [2022-10-19 20:29:21,561] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:29:21,564] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:21,595] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.259 seconds
[2022-10-19 20:29:40,586] {processor.py:153} INFO - Started process (PID=64902) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:40,587] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:29:40,588] {logging_mixin.py:115} INFO - [2022-10-19 20:29:40,588] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:45,500] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:29:45,515] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:45,613] {logging_mixin.py:115} INFO - [2022-10-19 20:29:45,613] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:29:45,647] {logging_mixin.py:115} INFO - [2022-10-19 20:29:45,646] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:29:45.513500+00:00, run_after=2022-10-20T20:29:45.513500+00:00
[2022-10-19 20:29:45,670] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.088 seconds
[2022-10-19 20:29:51,927] {processor.py:153} INFO - Started process (PID=37298) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:51,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:29:51,932] {logging_mixin.py:115} INFO - [2022-10-19 20:29:51,932] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:52,192] {logging_mixin.py:115} INFO - [2022-10-19 20:29:52,191] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:29:52,194] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:29:52,223] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.305 seconds
[2022-10-19 20:30:16,122] {processor.py:153} INFO - Started process (PID=65061) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:16,124] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:30:16,126] {logging_mixin.py:115} INFO - [2022-10-19 20:30:16,126] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:21,085] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:30:21,110] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:21,193] {logging_mixin.py:115} INFO - [2022-10-19 20:30:21,193] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:30:21,221] {logging_mixin.py:115} INFO - [2022-10-19 20:30:21,221] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:30:21.108595+00:00, run_after=2022-10-20T20:30:21.108595+00:00
[2022-10-19 20:30:21,238] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.144 seconds
[2022-10-19 20:30:23,179] {processor.py:153} INFO - Started process (PID=37345) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:23,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:30:23,182] {logging_mixin.py:115} INFO - [2022-10-19 20:30:23,182] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:23,400] {logging_mixin.py:115} INFO - [2022-10-19 20:30:23,399] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:30:23,403] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:23,429] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.254 seconds
[2022-10-19 20:30:51,798] {processor.py:153} INFO - Started process (PID=65211) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:51,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:30:51,801] {logging_mixin.py:115} INFO - [2022-10-19 20:30:51,801] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:53,618] {processor.py:153} INFO - Started process (PID=37390) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:53,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:30:53,621] {logging_mixin.py:115} INFO - [2022-10-19 20:30:53,621] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:53,862] {logging_mixin.py:115} INFO - [2022-10-19 20:30:53,862] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:30:53,865] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:53,897] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.284 seconds
[2022-10-19 20:30:56,805] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:30:56,831] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:30:56,931] {logging_mixin.py:115} INFO - [2022-10-19 20:30:56,931] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:30:56,976] {logging_mixin.py:115} INFO - [2022-10-19 20:30:56,976] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:30:56.828514+00:00, run_after=2022-10-20T20:30:56.828514+00:00
[2022-10-19 20:30:56,994] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.200 seconds
[2022-10-19 20:31:24,114] {processor.py:153} INFO - Started process (PID=37426) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:24,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:31:24,116] {logging_mixin.py:115} INFO - [2022-10-19 20:31:24,116] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:24,323] {logging_mixin.py:115} INFO - [2022-10-19 20:31:24,321] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:31:24,326] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:24,357] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.248 seconds
[2022-10-19 20:31:27,470] {processor.py:153} INFO - Started process (PID=65367) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:27,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:31:27,474] {logging_mixin.py:115} INFO - [2022-10-19 20:31:27,474] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:32,139] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:31:32,152] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:32,248] {logging_mixin.py:115} INFO - [2022-10-19 20:31:32,248] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:31:32,276] {logging_mixin.py:115} INFO - [2022-10-19 20:31:32,276] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:31:32.150271+00:00, run_after=2022-10-20T20:31:32.150271+00:00
[2022-10-19 20:31:32,294] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.831 seconds
[2022-10-19 20:31:54,552] {processor.py:153} INFO - Started process (PID=37471) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:54,553] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:31:54,555] {logging_mixin.py:115} INFO - [2022-10-19 20:31:54,554] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:54,759] {logging_mixin.py:115} INFO - [2022-10-19 20:31:54,758] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:31:54,760] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:31:54,789] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.241 seconds
[2022-10-19 20:32:02,484] {processor.py:153} INFO - Started process (PID=65523) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:02,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:32:02,494] {logging_mixin.py:115} INFO - [2022-10-19 20:32:02,493] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:06,718] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:32:06,733] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:06,829] {logging_mixin.py:115} INFO - [2022-10-19 20:32:06,829] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:32:06,856] {logging_mixin.py:115} INFO - [2022-10-19 20:32:06,856] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:32:06.730727+00:00, run_after=2022-10-20T20:32:06.730727+00:00
[2022-10-19 20:32:06,876] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.397 seconds
[2022-10-19 20:32:25,138] {processor.py:153} INFO - Started process (PID=37516) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:25,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:32:25,142] {logging_mixin.py:115} INFO - [2022-10-19 20:32:25,142] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:25,370] {logging_mixin.py:115} INFO - [2022-10-19 20:32:25,368] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:32:25,373] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:25,406] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.274 seconds
[2022-10-19 20:32:37,775] {processor.py:153} INFO - Started process (PID=65684) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:37,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:32:37,779] {logging_mixin.py:115} INFO - [2022-10-19 20:32:37,778] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:42,335] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:32:42,349] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:32:42,434] {logging_mixin.py:115} INFO - [2022-10-19 20:32:42,434] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:32:42,460] {logging_mixin.py:115} INFO - [2022-10-19 20:32:42,460] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:32:42.347430+00:00, run_after=2022-10-20T20:32:42.347430+00:00
[2022-10-19 20:32:42,481] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.711 seconds
[2022-10-19 20:35:55,162] {processor.py:153} INFO - Started process (PID=37540) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:35:55,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:35:55,170] {logging_mixin.py:115} INFO - [2022-10-19 20:35:55,170] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:35:55,465] {processor.py:153} INFO - Started process (PID=65817) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:35:55,476] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:35:55,477] {logging_mixin.py:115} INFO - [2022-10-19 20:35:55,477] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:35:55,771] {logging_mixin.py:115} INFO - [2022-10-19 20:35:55,770] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:35:55,776] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:35:55,858] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.706 seconds
[2022-10-19 20:36:04,926] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:36:05,022] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:36:05,757] {logging_mixin.py:115} INFO - [2022-10-19 20:36:05,757] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:36:05,788] {logging_mixin.py:115} INFO - [2022-10-19 20:36:05,788] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:36:04.993034+00:00, run_after=2022-10-20T20:36:04.993034+00:00
[2022-10-19 20:36:05,810] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 10.359 seconds
[2022-10-19 20:40:56,867] {processor.py:153} INFO - Started process (PID=37584) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:40:56,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:40:56,870] {logging_mixin.py:115} INFO - [2022-10-19 20:40:56,869] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:40:57,011] {processor.py:153} INFO - Started process (PID=65968) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:40:57,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:40:57,016] {logging_mixin.py:115} INFO - [2022-10-19 20:40:57,016] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:40:57,157] {logging_mixin.py:115} INFO - [2022-10-19 20:40:57,157] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:40:57,160] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:40:57,201] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.339 seconds
[2022-10-19 20:41:27,000] {logging_mixin.py:115} INFO - [2022-10-19 20:41:27,000] {timeout.py:67} ERROR - Process timed out, PID: 65968
[2022-10-19 20:41:27,009] {logging_mixin.py:115} INFO - [2022-10-19 20:41:27,006] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 65968
[2022-10-19 20:41:27,015] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:41:27,761] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.837 seconds
[2022-10-19 20:41:27,816] {processor.py:153} INFO - Started process (PID=37619) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:41:27,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:41:27,865] {logging_mixin.py:115} INFO - [2022-10-19 20:41:27,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:41:29,735] {logging_mixin.py:115} INFO - [2022-10-19 20:41:29,731] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:41:29,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:41:30,069] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.310 seconds
[2022-10-19 20:46:27,310] {processor.py:153} INFO - Started process (PID=37647) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:46:27,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:46:27,317] {logging_mixin.py:115} INFO - [2022-10-19 20:46:27,317] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:46:27,499] {processor.py:153} INFO - Started process (PID=66065) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:46:27,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:46:27,510] {logging_mixin.py:115} INFO - [2022-10-19 20:46:27,509] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:46:27,682] {logging_mixin.py:115} INFO - [2022-10-19 20:46:27,681] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:46:27,684] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:46:27,721] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.434 seconds
[2022-10-19 20:46:57,500] {logging_mixin.py:115} INFO - [2022-10-19 20:46:57,499] {timeout.py:67} ERROR - Process timed out, PID: 66065
[2022-10-19 20:46:57,510] {logging_mixin.py:115} INFO - [2022-10-19 20:46:57,506] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 66065
[2022-10-19 20:46:57,516] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:46:58,302] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.860 seconds
[2022-10-19 20:46:58,423] {processor.py:153} INFO - Started process (PID=37682) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:46:58,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:46:58,442] {logging_mixin.py:115} INFO - [2022-10-19 20:46:58,441] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:47:00,047] {logging_mixin.py:115} INFO - [2022-10-19 20:47:00,030] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:47:00,056] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:47:00,473] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.137 seconds
[2022-10-19 20:51:57,526] {processor.py:153} INFO - Started process (PID=37708) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:51:57,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:51:57,531] {logging_mixin.py:115} INFO - [2022-10-19 20:51:57,530] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:51:57,594] {processor.py:153} INFO - Started process (PID=66164) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:51:57,597] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:51:57,600] {logging_mixin.py:115} INFO - [2022-10-19 20:51:57,600] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:51:57,816] {logging_mixin.py:115} INFO - [2022-10-19 20:51:57,815] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:51:57,819] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:51:57,867] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.351 seconds
[2022-10-19 20:52:28,155] {processor.py:153} INFO - Started process (PID=37742) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:52:28,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:52:28,181] {logging_mixin.py:115} INFO - [2022-10-19 20:52:28,180] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:52:28,881] {logging_mixin.py:115} INFO - [2022-10-19 20:52:28,880] {timeout.py:67} ERROR - Process timed out, PID: 66164
[2022-10-19 20:52:28,985] {logging_mixin.py:115} INFO - [2022-10-19 20:52:28,888] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 66164
[2022-10-19 20:52:28,995] {logging_mixin.py:115} INFO - [2022-10-19 20:52:28,995] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-19 20:52:29,111] {logging_mixin.py:115} INFO - [2022-10-19 20:52:29,004] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 66164

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-19 20:52:29,124] {logging_mixin.py:115} INFO - [2022-10-19 20:52:29,114] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-19 20:52:29,265] {logging_mixin.py:115} INFO - [2022-10-19 20:52:29,144] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-19 20:52:29,330] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:52:30,512] {logging_mixin.py:115} INFO - [2022-10-19 20:52:30,499] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:52:30,531] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:52:30,705] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.902 seconds
[2022-10-19 20:52:30,989] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.910 seconds
[2022-10-19 20:57:30,348] {processor.py:153} INFO - Started process (PID=37771) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:57:30,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:57:30,354] {logging_mixin.py:115} INFO - [2022-10-19 20:57:30,354] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:57:30,380] {processor.py:153} INFO - Started process (PID=66269) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:57:30,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:57:30,384] {logging_mixin.py:115} INFO - [2022-10-19 20:57:30,384] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:57:30,678] {logging_mixin.py:115} INFO - [2022-10-19 20:57:30,677] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:57:30,681] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:57:30,724] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.385 seconds
[2022-10-19 20:57:46,525] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-19 20:57:46,650] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:58:10,369] {processor.py:153} INFO - Started process (PID=37798) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:58:10,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 20:58:10,436] {logging_mixin.py:115} INFO - [2022-10-19 20:58:10,435] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:58:11,912] {logging_mixin.py:115} INFO - [2022-10-19 20:58:11,906] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-19 20:58:12,070] {logging_mixin.py:115} INFO - [2022-10-19 20:58:12,070] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-19T20:57:46.612668+00:00, run_after=2022-10-20T20:57:46.612668+00:00
[2022-10-19 20:58:12,179] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 41.822 seconds
[2022-10-19 20:58:12,647] {logging_mixin.py:115} INFO - [2022-10-19 20:58:12,641] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 20:58:12,690] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 20:58:13,742] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.608 seconds
[2022-10-19 21:09:27,365] {processor.py:153} INFO - Started process (PID=37825) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:09:27,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 21:09:27,377] {logging_mixin.py:115} INFO - [2022-10-19 21:09:27,377] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:09:27,886] {processor.py:153} INFO - Started process (PID=66443) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:09:27,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 21:09:27,908] {logging_mixin.py:115} INFO - [2022-10-19 21:09:27,908] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:09:27,997] {logging_mixin.py:115} INFO - [2022-10-19 21:09:27,996] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 21:09:28,000] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:09:28,051] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.703 seconds
[2022-10-19 21:09:57,626] {logging_mixin.py:115} INFO - [2022-10-19 21:09:57,485] {timeout.py:67} ERROR - Process timed out, PID: 66443
[2022-10-19 21:09:58,233] {logging_mixin.py:115} INFO - [2022-10-19 21:09:58,135] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 66443
[2022-10-19 21:09:58,276] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:09:59,396] {processor.py:153} INFO - Started process (PID=37859) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:09:59,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 21:09:59,512] {logging_mixin.py:115} INFO - [2022-10-19 21:09:59,502] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:10:01,447] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 33.994 seconds
[2022-10-19 21:10:06,332] {logging_mixin.py:115} INFO - [2022-10-19 21:10:06,270] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 21:10:06,459] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 21:10:07,497] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 8.271 seconds
[2022-10-19 22:32:27,384] {processor.py:153} INFO - Started process (PID=66547) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 22:32:27,390] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 22:32:27,392] {logging_mixin.py:115} INFO - [2022-10-19 22:32:27,392] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 22:32:27,623] {processor.py:153} INFO - Started process (PID=37887) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 22:32:27,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-19 22:32:27,635] {logging_mixin.py:115} INFO - [2022-10-19 22:32:27,635] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 22:32:28,545] {logging_mixin.py:115} INFO - [2022-10-19 22:32:28,543] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-19 22:32:28,554] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-19 22:32:28,658] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.069 seconds
[2022-10-20 01:39:36,325] {logging_mixin.py:115} INFO - [2022-10-20 01:39:36,068] {timeout.py:67} ERROR - Process timed out, PID: 66547
[2022-10-20 01:39:36,692] {logging_mixin.py:115} INFO - [2022-10-20 01:39:36,576] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    from data_extraction_pyspark import load_and_prepare_json_data
  File "/opt/airflow/dags/data_extraction_pyspark.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/Users/gonzo/Downloads/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 66547
[2022-10-20 01:39:36,833] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-20 01:39:41,736] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 68.360 seconds
