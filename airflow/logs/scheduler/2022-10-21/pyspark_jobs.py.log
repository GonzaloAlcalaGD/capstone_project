[2022-10-21 00:00:02,112] {processor.py:153} INFO - Started process (PID=71782) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:02,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:00:02,120] {logging_mixin.py:115} INFO - [2022-10-21 00:00:02,119] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:02,444] {logging_mixin.py:115} INFO - [2022-10-21 00:00:02,443] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:00:02,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:02,496] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.399 seconds
[2022-10-21 00:00:31,189] {processor.py:153} INFO - Started process (PID=39158) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:31,191] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:00:31,192] {logging_mixin.py:115} INFO - [2022-10-21 00:00:31,192] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:32,834] {processor.py:153} INFO - Started process (PID=71835) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:32,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:00:32,836] {logging_mixin.py:115} INFO - [2022-10-21 00:00:32,836] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:33,060] {logging_mixin.py:115} INFO - [2022-10-21 00:00:33,059] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:00:33,063] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:33,100] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.271 seconds
[2022-10-21 00:00:36,469] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:00:36,486] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:00:36,601] {logging_mixin.py:115} INFO - [2022-10-21 00:00:36,601] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:00:36,635] {logging_mixin.py:115} INFO - [2022-10-21 00:00:36,635] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:00:36.482830+00:00, run_after=2022-10-22T00:00:36.482830+00:00
[2022-10-21 00:00:36,658] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.474 seconds
[2022-10-21 00:01:03,382] {processor.py:153} INFO - Started process (PID=71880) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:03,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:01:03,386] {logging_mixin.py:115} INFO - [2022-10-21 00:01:03,385] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:03,601] {logging_mixin.py:115} INFO - [2022-10-21 00:01:03,600] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:01:03,602] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:03,635] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.260 seconds
[2022-10-21 00:01:07,045] {processor.py:153} INFO - Started process (PID=39435) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:07,047] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:01:07,049] {logging_mixin.py:115} INFO - [2022-10-21 00:01:07,048] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:12,364] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:01:12,398] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:12,542] {logging_mixin.py:115} INFO - [2022-10-21 00:01:12,542] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:01:12,582] {logging_mixin.py:115} INFO - [2022-10-21 00:01:12,582] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:01:12.395646+00:00, run_after=2022-10-22T00:01:12.395646+00:00
[2022-10-21 00:01:12,610] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.570 seconds
[2022-10-21 00:01:33,718] {processor.py:153} INFO - Started process (PID=71932) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:33,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:01:33,721] {logging_mixin.py:115} INFO - [2022-10-21 00:01:33,721] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:33,955] {logging_mixin.py:115} INFO - [2022-10-21 00:01:33,954] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:01:33,957] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:33,995] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.282 seconds
[2022-10-21 00:01:42,969] {processor.py:153} INFO - Started process (PID=39705) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:42,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:01:42,971] {logging_mixin.py:115} INFO - [2022-10-21 00:01:42,971] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:47,851] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:01:47,872] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:01:47,981] {logging_mixin.py:115} INFO - [2022-10-21 00:01:47,980] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:01:48,017] {logging_mixin.py:115} INFO - [2022-10-21 00:01:48,017] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:01:47.869328+00:00, run_after=2022-10-22T00:01:47.869328+00:00
[2022-10-21 00:01:48,039] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.075 seconds
[2022-10-21 00:02:04,158] {processor.py:153} INFO - Started process (PID=71975) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:04,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:02:04,165] {logging_mixin.py:115} INFO - [2022-10-21 00:02:04,165] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:04,602] {logging_mixin.py:115} INFO - [2022-10-21 00:02:04,600] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:02:04,606] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:04,674] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.527 seconds
[2022-10-21 00:02:18,108] {processor.py:153} INFO - Started process (PID=39986) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:18,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:02:18,121] {logging_mixin.py:115} INFO - [2022-10-21 00:02:18,119] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:24,513] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:02:24,537] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:24,671] {logging_mixin.py:115} INFO - [2022-10-21 00:02:24,671] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:02:24,713] {logging_mixin.py:115} INFO - [2022-10-21 00:02:24,713] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:02:24.533486+00:00, run_after=2022-10-22T00:02:24.533486+00:00
[2022-10-21 00:02:24,744] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.662 seconds
[2022-10-21 00:02:35,342] {processor.py:153} INFO - Started process (PID=72027) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:35,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:02:35,345] {logging_mixin.py:115} INFO - [2022-10-21 00:02:35,345] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:35,568] {logging_mixin.py:115} INFO - [2022-10-21 00:02:35,567] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:02:35,571] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:35,606] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.269 seconds
[2022-10-21 00:02:55,335] {processor.py:153} INFO - Started process (PID=40263) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:02:55,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:02:55,342] {logging_mixin.py:115} INFO - [2022-10-21 00:02:55,341] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:00,816] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:03:00,836] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:00,946] {logging_mixin.py:115} INFO - [2022-10-21 00:03:00,946] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:03:00,978] {logging_mixin.py:115} INFO - [2022-10-21 00:03:00,978] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:03:00.833079+00:00, run_after=2022-10-22T00:03:00.833079+00:00
[2022-10-21 00:03:01,002] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.674 seconds
[2022-10-21 00:03:06,444] {processor.py:153} INFO - Started process (PID=72071) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:06,445] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:03:06,447] {logging_mixin.py:115} INFO - [2022-10-21 00:03:06,447] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:06,663] {logging_mixin.py:115} INFO - [2022-10-21 00:03:06,662] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:03:06,667] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:06,699] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.260 seconds
[2022-10-21 00:03:31,848] {processor.py:153} INFO - Started process (PID=40543) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:31,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:03:31,850] {logging_mixin.py:115} INFO - [2022-10-21 00:03:31,850] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:37,049] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:03:37,067] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:37,177] {logging_mixin.py:115} INFO - [2022-10-21 00:03:37,177] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:03:37,209] {logging_mixin.py:115} INFO - [2022-10-21 00:03:37,209] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:03:37.064668+00:00, run_after=2022-10-22T00:03:37.064668+00:00
[2022-10-21 00:03:37,232] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.392 seconds
[2022-10-21 00:03:37,386] {processor.py:153} INFO - Started process (PID=72123) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:37,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:03:37,397] {logging_mixin.py:115} INFO - [2022-10-21 00:03:37,397] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:37,683] {logging_mixin.py:115} INFO - [2022-10-21 00:03:37,680] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:03:37,689] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:03:37,741] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.375 seconds
[2022-10-21 00:04:07,879] {processor.py:153} INFO - Started process (PID=40818) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:07,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:04:07,882] {logging_mixin.py:115} INFO - [2022-10-21 00:04:07,882] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:08,499] {processor.py:153} INFO - Started process (PID=72176) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:08,501] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:04:08,504] {logging_mixin.py:115} INFO - [2022-10-21 00:04:08,504] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:08,718] {logging_mixin.py:115} INFO - [2022-10-21 00:04:08,717] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:04:08,720] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:08,758] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.274 seconds
[2022-10-21 00:04:13,202] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:04:13,222] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:13,336] {logging_mixin.py:115} INFO - [2022-10-21 00:04:13,336] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:04:13,368] {logging_mixin.py:115} INFO - [2022-10-21 00:04:13,368] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:04:13.219126+00:00, run_after=2022-10-22T00:04:13.219126+00:00
[2022-10-21 00:04:13,387] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.513 seconds
[2022-10-21 00:04:38,879] {processor.py:153} INFO - Started process (PID=72220) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:38,880] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:04:38,881] {logging_mixin.py:115} INFO - [2022-10-21 00:04:38,881] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:39,089] {logging_mixin.py:115} INFO - [2022-10-21 00:04:39,088] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:04:39,090] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:39,123] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.250 seconds
[2022-10-21 00:04:43,455] {processor.py:153} INFO - Started process (PID=41097) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:43,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:04:43,458] {logging_mixin.py:115} INFO - [2022-10-21 00:04:43,457] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:48,821] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:04:48,839] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:04:48,951] {logging_mixin.py:115} INFO - [2022-10-21 00:04:48,951] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:04:48,985] {logging_mixin.py:115} INFO - [2022-10-21 00:04:48,985] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:04:48.835438+00:00, run_after=2022-10-22T00:04:48.835438+00:00
[2022-10-21 00:04:49,011] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.583 seconds
[2022-10-21 00:05:09,383] {processor.py:153} INFO - Started process (PID=72273) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:09,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:05:09,392] {logging_mixin.py:115} INFO - [2022-10-21 00:05:09,392] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:09,655] {logging_mixin.py:115} INFO - [2022-10-21 00:05:09,654] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:05:09,659] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:09,700] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.337 seconds
[2022-10-21 00:05:19,987] {processor.py:153} INFO - Started process (PID=41375) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:19,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:05:19,991] {logging_mixin.py:115} INFO - [2022-10-21 00:05:19,990] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:25,519] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:05:25,538] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:25,646] {logging_mixin.py:115} INFO - [2022-10-21 00:05:25,646] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:05:25,683] {logging_mixin.py:115} INFO - [2022-10-21 00:05:25,682] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:05:25.535268+00:00, run_after=2022-10-22T00:05:25.535268+00:00
[2022-10-21 00:05:25,705] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.724 seconds
[2022-10-21 00:05:39,795] {processor.py:153} INFO - Started process (PID=72318) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:39,804] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:05:39,806] {logging_mixin.py:115} INFO - [2022-10-21 00:05:39,806] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:40,058] {logging_mixin.py:115} INFO - [2022-10-21 00:05:40,057] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:05:40,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:40,103] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.316 seconds
[2022-10-21 00:05:56,307] {processor.py:153} INFO - Started process (PID=41648) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:05:56,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:05:56,310] {logging_mixin.py:115} INFO - [2022-10-21 00:05:56,310] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:01,447] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:06:01,467] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:01,579] {logging_mixin.py:115} INFO - [2022-10-21 00:06:01,578] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:06:01,616] {logging_mixin.py:115} INFO - [2022-10-21 00:06:01,616] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:06:01.464240+00:00, run_after=2022-10-22T00:06:01.464240+00:00
[2022-10-21 00:06:01,641] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.339 seconds
[2022-10-21 00:06:10,207] {processor.py:153} INFO - Started process (PID=72370) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:10,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:06:10,210] {logging_mixin.py:115} INFO - [2022-10-21 00:06:10,210] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:10,415] {logging_mixin.py:115} INFO - [2022-10-21 00:06:10,414] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:06:10,417] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:10,447] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.246 seconds
[2022-10-21 00:06:31,952] {processor.py:153} INFO - Started process (PID=41932) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:31,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:06:31,955] {logging_mixin.py:115} INFO - [2022-10-21 00:06:31,955] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:37,351] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:06:37,380] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:37,490] {logging_mixin.py:115} INFO - [2022-10-21 00:06:37,490] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:06:37,525] {logging_mixin.py:115} INFO - [2022-10-21 00:06:37,525] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:06:37.377254+00:00, run_after=2022-10-22T00:06:37.377254+00:00
[2022-10-21 00:06:37,548] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.600 seconds
[2022-10-21 00:06:41,025] {processor.py:153} INFO - Started process (PID=72413) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:41,026] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:06:41,028] {logging_mixin.py:115} INFO - [2022-10-21 00:06:41,028] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:41,264] {logging_mixin.py:115} INFO - [2022-10-21 00:06:41,261] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:06:41,267] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:06:41,313] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.300 seconds
[2022-10-21 00:07:07,650] {processor.py:153} INFO - Started process (PID=42206) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:07,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:07:07,652] {logging_mixin.py:115} INFO - [2022-10-21 00:07:07,652] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:11,722] {processor.py:153} INFO - Started process (PID=72466) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:11,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:07:11,728] {logging_mixin.py:115} INFO - [2022-10-21 00:07:11,727] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:12,021] {logging_mixin.py:115} INFO - [2022-10-21 00:07:12,020] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:07:12,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:12,058] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.342 seconds
[2022-10-21 00:07:13,018] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:07:13,055] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:13,183] {logging_mixin.py:115} INFO - [2022-10-21 00:07:13,182] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:07:13,219] {logging_mixin.py:115} INFO - [2022-10-21 00:07:13,219] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:07:13.052620+00:00, run_after=2022-10-22T00:07:13.052620+00:00
[2022-10-21 00:07:13,246] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.601 seconds
[2022-10-21 00:07:42,324] {processor.py:153} INFO - Started process (PID=72519) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:42,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:07:42,329] {logging_mixin.py:115} INFO - [2022-10-21 00:07:42,329] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:42,576] {logging_mixin.py:115} INFO - [2022-10-21 00:07:42,575] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:07:42,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:42,611] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.292 seconds
[2022-10-21 00:07:43,962] {processor.py:153} INFO - Started process (PID=42485) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:43,963] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:07:43,965] {logging_mixin.py:115} INFO - [2022-10-21 00:07:43,965] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:49,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:07:49,335] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:07:49,453] {logging_mixin.py:115} INFO - [2022-10-21 00:07:49,453] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:07:49,494] {logging_mixin.py:115} INFO - [2022-10-21 00:07:49,494] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:07:49.331975+00:00, run_after=2022-10-22T00:07:49.331975+00:00
[2022-10-21 00:07:49,520] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.586 seconds
[2022-10-21 00:08:13,545] {processor.py:153} INFO - Started process (PID=72563) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:13,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:08:13,548] {logging_mixin.py:115} INFO - [2022-10-21 00:08:13,548] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:13,754] {logging_mixin.py:115} INFO - [2022-10-21 00:08:13,753] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:08:13,756] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:13,790] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.250 seconds
[2022-10-21 00:08:19,596] {processor.py:153} INFO - Started process (PID=42759) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:19,597] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:08:19,599] {logging_mixin.py:115} INFO - [2022-10-21 00:08:19,598] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:24,621] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:08:24,667] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:24,779] {logging_mixin.py:115} INFO - [2022-10-21 00:08:24,779] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:08:24,816] {logging_mixin.py:115} INFO - [2022-10-21 00:08:24,816] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:08:24.663521+00:00, run_after=2022-10-22T00:08:24.663521+00:00
[2022-10-21 00:08:24,840] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.249 seconds
[2022-10-21 00:08:44,724] {processor.py:153} INFO - Started process (PID=72617) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:44,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:08:44,727] {logging_mixin.py:115} INFO - [2022-10-21 00:08:44,727] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:44,965] {logging_mixin.py:115} INFO - [2022-10-21 00:08:44,963] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:08:44,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:45,002] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.284 seconds
[2022-10-21 00:08:55,601] {processor.py:153} INFO - Started process (PID=43038) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:08:55,603] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:08:55,604] {logging_mixin.py:115} INFO - [2022-10-21 00:08:55,604] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:00,384] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:09:00,421] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:00,533] {logging_mixin.py:115} INFO - [2022-10-21 00:09:00,532] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:09:00,568] {logging_mixin.py:115} INFO - [2022-10-21 00:09:00,567] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:09:00.418176+00:00, run_after=2022-10-22T00:09:00.418176+00:00
[2022-10-21 00:09:00,589] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.992 seconds
[2022-10-21 00:09:15,135] {processor.py:153} INFO - Started process (PID=72664) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:15,137] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:09:15,142] {logging_mixin.py:115} INFO - [2022-10-21 00:09:15,142] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:15,392] {logging_mixin.py:115} INFO - [2022-10-21 00:09:15,391] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:09:15,395] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:15,435] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.320 seconds
[2022-10-21 00:09:30,831] {processor.py:153} INFO - Started process (PID=43312) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:30,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:09:30,834] {logging_mixin.py:115} INFO - [2022-10-21 00:09:30,834] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:35,551] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:09:35,578] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:35,677] {logging_mixin.py:115} INFO - [2022-10-21 00:09:35,677] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:09:35,708] {logging_mixin.py:115} INFO - [2022-10-21 00:09:35,707] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:09:35.575416+00:00, run_after=2022-10-22T00:09:35.575416+00:00
[2022-10-21 00:09:35,730] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.906 seconds
[2022-10-21 00:09:45,557] {processor.py:153} INFO - Started process (PID=72716) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:45,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:09:45,561] {logging_mixin.py:115} INFO - [2022-10-21 00:09:45,560] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:45,780] {logging_mixin.py:115} INFO - [2022-10-21 00:09:45,778] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:09:45,783] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:09:45,815] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.264 seconds
[2022-10-21 00:10:06,464] {processor.py:153} INFO - Started process (PID=43589) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:06,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:10:06,466] {logging_mixin.py:115} INFO - [2022-10-21 00:10:06,466] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:11,169] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:10:11,194] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:11,305] {logging_mixin.py:115} INFO - [2022-10-21 00:10:11,304] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:10:11,340] {logging_mixin.py:115} INFO - [2022-10-21 00:10:11,340] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:10:11.191201+00:00, run_after=2022-10-22T00:10:11.191201+00:00
[2022-10-21 00:10:11,364] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.906 seconds
[2022-10-21 00:10:16,827] {processor.py:153} INFO - Started process (PID=72768) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:16,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:10:16,833] {logging_mixin.py:115} INFO - [2022-10-21 00:10:16,833] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:17,076] {logging_mixin.py:115} INFO - [2022-10-21 00:10:17,075] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:10:17,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:17,112] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.295 seconds
[2022-10-21 00:10:41,857] {processor.py:153} INFO - Started process (PID=43861) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:41,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:10:41,859] {logging_mixin.py:115} INFO - [2022-10-21 00:10:41,859] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:46,902] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:10:46,923] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:47,027] {logging_mixin.py:115} INFO - [2022-10-21 00:10:47,027] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:10:47,058] {logging_mixin.py:115} INFO - [2022-10-21 00:10:47,058] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:10:46.919918+00:00, run_after=2022-10-22T00:10:46.919918+00:00
[2022-10-21 00:10:47,082] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.232 seconds
[2022-10-21 00:10:47,936] {processor.py:153} INFO - Started process (PID=72817) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:47,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:10:47,939] {logging_mixin.py:115} INFO - [2022-10-21 00:10:47,939] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:48,167] {logging_mixin.py:115} INFO - [2022-10-21 00:10:48,166] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:10:48,170] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:10:48,208] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.278 seconds
[2022-10-21 00:11:17,739] {processor.py:153} INFO - Started process (PID=44137) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:17,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:11:17,742] {logging_mixin.py:115} INFO - [2022-10-21 00:11:17,742] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:19,171] {processor.py:153} INFO - Started process (PID=72871) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:19,173] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:11:19,174] {logging_mixin.py:115} INFO - [2022-10-21 00:11:19,174] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:19,405] {logging_mixin.py:115} INFO - [2022-10-21 00:11:19,404] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:11:19,408] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:19,443] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.276 seconds
[2022-10-21 00:11:22,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:11:22,977] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:23,083] {logging_mixin.py:115} INFO - [2022-10-21 00:11:23,083] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:11:23,117] {logging_mixin.py:115} INFO - [2022-10-21 00:11:23,117] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:11:22.974288+00:00, run_after=2022-10-22T00:11:22.974288+00:00
[2022-10-21 00:11:23,142] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.407 seconds
[2022-10-21 00:11:50,387] {processor.py:153} INFO - Started process (PID=72915) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:50,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:11:50,390] {logging_mixin.py:115} INFO - [2022-10-21 00:11:50,390] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:50,589] {logging_mixin.py:115} INFO - [2022-10-21 00:11:50,588] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:11:50,591] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:50,618] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.234 seconds
[2022-10-21 00:11:53,731] {processor.py:153} INFO - Started process (PID=44415) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:53,732] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:11:53,733] {logging_mixin.py:115} INFO - [2022-10-21 00:11:53,733] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:59,083] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:11:59,103] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:11:59,208] {logging_mixin.py:115} INFO - [2022-10-21 00:11:59,208] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:11:59,241] {logging_mixin.py:115} INFO - [2022-10-21 00:11:59,241] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:11:59.100421+00:00, run_after=2022-10-22T00:11:59.100421+00:00
[2022-10-21 00:11:59,264] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.538 seconds
[2022-10-21 00:12:21,289] {processor.py:153} INFO - Started process (PID=72968) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:21,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:12:21,292] {logging_mixin.py:115} INFO - [2022-10-21 00:12:21,292] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:21,506] {logging_mixin.py:115} INFO - [2022-10-21 00:12:21,505] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:12:21,509] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:21,545] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.262 seconds
[2022-10-21 00:12:29,617] {processor.py:153} INFO - Started process (PID=44687) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:29,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:12:29,619] {logging_mixin.py:115} INFO - [2022-10-21 00:12:29,619] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:36,351] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:12:36,385] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:36,528] {logging_mixin.py:115} INFO - [2022-10-21 00:12:36,528] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:12:36,570] {logging_mixin.py:115} INFO - [2022-10-21 00:12:36,570] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:12:36.379989+00:00, run_after=2022-10-22T00:12:36.379989+00:00
[2022-10-21 00:12:36,601] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.989 seconds
[2022-10-21 00:12:52,165] {processor.py:153} INFO - Started process (PID=73018) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:52,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:12:52,184] {logging_mixin.py:115} INFO - [2022-10-21 00:12:52,183] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:52,678] {logging_mixin.py:115} INFO - [2022-10-21 00:12:52,676] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:12:52,680] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:12:52,766] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.618 seconds
[2022-10-21 00:13:06,858] {processor.py:153} INFO - Started process (PID=45053) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:06,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:13:06,870] {logging_mixin.py:115} INFO - [2022-10-21 00:13:06,869] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:23,635] {processor.py:153} INFO - Started process (PID=73055) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:23,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:13:23,647] {logging_mixin.py:115} INFO - [2022-10-21 00:13:23,647] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:24,167] {logging_mixin.py:115} INFO - [2022-10-21 00:13:24,164] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:13:24,174] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:24,279] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.671 seconds
[2022-10-21 00:13:33,000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:13:33,023] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:33,195] {logging_mixin.py:115} INFO - [2022-10-21 00:13:33,194] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:13:33,250] {logging_mixin.py:115} INFO - [2022-10-21 00:13:33,249] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:13:33.018829+00:00, run_after=2022-10-22T00:13:33.018829+00:00
[2022-10-21 00:13:33,285] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 26.466 seconds
[2022-10-21 00:13:54,464] {processor.py:153} INFO - Started process (PID=73108) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:54,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:13:54,472] {logging_mixin.py:115} INFO - [2022-10-21 00:13:54,471] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:55,360] {logging_mixin.py:115} INFO - [2022-10-21 00:13:55,358] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:13:55,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:13:55,589] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.148 seconds
[2022-10-21 00:14:04,379] {processor.py:153} INFO - Started process (PID=45454) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:04,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:14:04,389] {logging_mixin.py:115} INFO - [2022-10-21 00:14:04,389] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:13,027] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:14:13,078] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:13,230] {logging_mixin.py:115} INFO - [2022-10-21 00:14:13,230] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:14:13,274] {logging_mixin.py:115} INFO - [2022-10-21 00:14:13,274] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:14:13.072572+00:00, run_after=2022-10-22T00:14:13.072572+00:00
[2022-10-21 00:14:13,305] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 8.961 seconds
[2022-10-21 00:14:26,546] {processor.py:153} INFO - Started process (PID=73151) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:26,547] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:14:26,548] {logging_mixin.py:115} INFO - [2022-10-21 00:14:26,548] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:26,761] {logging_mixin.py:115} INFO - [2022-10-21 00:14:26,760] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:14:26,764] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:26,791] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.249 seconds
[2022-10-21 00:14:43,653] {processor.py:153} INFO - Started process (PID=45741) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:43,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:14:43,661] {logging_mixin.py:115} INFO - [2022-10-21 00:14:43,659] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:48,934] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:14:48,955] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:49,075] {logging_mixin.py:115} INFO - [2022-10-21 00:14:49,075] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:14:49,112] {logging_mixin.py:115} INFO - [2022-10-21 00:14:49,111] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:14:48.951441+00:00, run_after=2022-10-22T00:14:48.951441+00:00
[2022-10-21 00:14:49,138] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.515 seconds
[2022-10-21 00:14:56,938] {processor.py:153} INFO - Started process (PID=73204) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:56,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:14:56,941] {logging_mixin.py:115} INFO - [2022-10-21 00:14:56,941] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:57,148] {logging_mixin.py:115} INFO - [2022-10-21 00:14:57,147] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:14:57,150] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:14:57,183] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.249 seconds
[2022-10-21 00:15:19,619] {processor.py:153} INFO - Started process (PID=46017) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:19,621] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:15:19,623] {logging_mixin.py:115} INFO - [2022-10-21 00:15:19,623] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:25,102] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:15:25,122] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:25,249] {logging_mixin.py:115} INFO - [2022-10-21 00:15:25,248] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:15:25,289] {logging_mixin.py:115} INFO - [2022-10-21 00:15:25,289] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:15:25.117870+00:00, run_after=2022-10-22T00:15:25.117870+00:00
[2022-10-21 00:15:25,315] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.705 seconds
[2022-10-21 00:15:28,099] {processor.py:153} INFO - Started process (PID=73250) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:28,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:15:28,109] {logging_mixin.py:115} INFO - [2022-10-21 00:15:28,109] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:28,518] {logging_mixin.py:115} INFO - [2022-10-21 00:15:28,517] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:15:28,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:28,567] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.478 seconds
[2022-10-21 00:15:56,062] {processor.py:153} INFO - Started process (PID=46330) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:56,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:15:56,079] {logging_mixin.py:115} INFO - [2022-10-21 00:15:56,078] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:59,600] {processor.py:153} INFO - Started process (PID=73301) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:15:59,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:15:59,642] {logging_mixin.py:115} INFO - [2022-10-21 00:15:59,641] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:16:00,473] {logging_mixin.py:115} INFO - [2022-10-21 00:16:00,466] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:16:00,482] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:16:00,720] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.188 seconds
[2022-10-21 00:16:15,105] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:16:15,131] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:16:15,324] {logging_mixin.py:115} INFO - [2022-10-21 00:16:15,323] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:16:15,376] {logging_mixin.py:115} INFO - [2022-10-21 00:16:15,375] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:16:15.126762+00:00, run_after=2022-10-22T00:16:15.126762+00:00
[2022-10-21 00:16:15,408] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.389 seconds
[2022-10-21 00:16:30,971] {processor.py:153} INFO - Started process (PID=73345) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:16:30,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:16:30,976] {logging_mixin.py:115} INFO - [2022-10-21 00:16:30,976] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:16:31,467] {logging_mixin.py:115} INFO - [2022-10-21 00:16:31,465] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:16:31,474] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:16:31,536] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.583 seconds
[2022-10-21 00:16:55,388] {processor.py:153} INFO - Started process (PID=46916) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:16:55,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:16:55,401] {logging_mixin.py:115} INFO - [2022-10-21 00:16:55,400] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:02,396] {processor.py:153} INFO - Started process (PID=73381) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:02,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:17:02,405] {logging_mixin.py:115} INFO - [2022-10-21 00:17:02,405] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:02,720] {logging_mixin.py:115} INFO - [2022-10-21 00:17:02,718] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:17:02,725] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:02,779] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.395 seconds
[2022-10-21 00:17:12,437] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:17:12,466] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:12,631] {logging_mixin.py:115} INFO - [2022-10-21 00:17:12,631] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:17:12,687] {logging_mixin.py:115} INFO - [2022-10-21 00:17:12,687] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:17:12.461238+00:00, run_after=2022-10-22T00:17:12.461238+00:00
[2022-10-21 00:17:12,724] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.360 seconds
[2022-10-21 00:17:32,827] {processor.py:153} INFO - Started process (PID=73434) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:32,831] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:17:32,834] {logging_mixin.py:115} INFO - [2022-10-21 00:17:32,833] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:33,077] {logging_mixin.py:115} INFO - [2022-10-21 00:17:33,076] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:17:33,080] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:33,130] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.312 seconds
[2022-10-21 00:17:43,057] {processor.py:153} INFO - Started process (PID=47267) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:43,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:17:43,070] {logging_mixin.py:115} INFO - [2022-10-21 00:17:43,070] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:58,992] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:17:59,030] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:17:59,255] {logging_mixin.py:115} INFO - [2022-10-21 00:17:59,255] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:17:59,335] {logging_mixin.py:115} INFO - [2022-10-21 00:17:59,334] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:17:59.025573+00:00, run_after=2022-10-22T00:17:59.025573+00:00
[2022-10-21 00:17:59,378] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 16.370 seconds
[2022-10-21 00:18:03,292] {processor.py:153} INFO - Started process (PID=73478) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:03,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:18:03,307] {logging_mixin.py:115} INFO - [2022-10-21 00:18:03,307] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:03,614] {logging_mixin.py:115} INFO - [2022-10-21 00:18:03,612] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:18:03,617] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:03,661] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.384 seconds
[2022-10-21 00:18:29,954] {processor.py:153} INFO - Started process (PID=47581) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:29,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:18:29,964] {logging_mixin.py:115} INFO - [2022-10-21 00:18:29,963] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:33,739] {processor.py:153} INFO - Started process (PID=73522) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:33,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:18:33,743] {logging_mixin.py:115} INFO - [2022-10-21 00:18:33,743] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:34,035] {logging_mixin.py:115} INFO - [2022-10-21 00:18:34,034] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:18:34,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:34,081] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.349 seconds
[2022-10-21 00:18:36,948] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:18:36,977] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:18:37,102] {logging_mixin.py:115} INFO - [2022-10-21 00:18:37,102] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:18:37,144] {logging_mixin.py:115} INFO - [2022-10-21 00:18:37,144] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:18:36.973301+00:00, run_after=2022-10-22T00:18:36.973301+00:00
[2022-10-21 00:18:37,172] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.255 seconds
[2022-10-21 00:19:04,263] {processor.py:153} INFO - Started process (PID=73576) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:04,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:19:04,269] {logging_mixin.py:115} INFO - [2022-10-21 00:19:04,269] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:04,690] {logging_mixin.py:115} INFO - [2022-10-21 00:19:04,682] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:19:04,697] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:04,761] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.522 seconds
[2022-10-21 00:19:07,652] {processor.py:153} INFO - Started process (PID=48017) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:07,669] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:19:07,673] {logging_mixin.py:115} INFO - [2022-10-21 00:19:07,673] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:35,151] {processor.py:153} INFO - Started process (PID=73618) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:35,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:19:35,174] {logging_mixin.py:115} INFO - [2022-10-21 00:19:35,173] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:36,223] {logging_mixin.py:115} INFO - [2022-10-21 00:19:36,220] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:19:36,228] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:36,360] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.295 seconds
[2022-10-21 00:19:37,676] {logging_mixin.py:115} INFO - [2022-10-21 00:19:37,671] {timeout.py:67} ERROR - Process timed out, PID: 48017
[2022-10-21 00:19:37,723] {logging_mixin.py:115} INFO - [2022-10-21 00:19:37,701] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 48017
[2022-10-21 00:19:37,738] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:19:38,305] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.691 seconds
[2022-10-21 00:20:06,900] {processor.py:153} INFO - Started process (PID=73655) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:06,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:20:06,906] {logging_mixin.py:115} INFO - [2022-10-21 00:20:06,906] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:07,625] {logging_mixin.py:115} INFO - [2022-10-21 00:20:07,623] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:20:07,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:07,751] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.869 seconds
[2022-10-21 00:20:08,914] {processor.py:153} INFO - Started process (PID=48290) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:08,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:20:08,920] {logging_mixin.py:115} INFO - [2022-10-21 00:20:08,920] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:30,924] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:20:30,954] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:31,148] {logging_mixin.py:115} INFO - [2022-10-21 00:20:31,148] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:20:31,215] {logging_mixin.py:115} INFO - [2022-10-21 00:20:31,214] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:20:30.949679+00:00, run_after=2022-10-22T00:20:30.949679+00:00
[2022-10-21 00:20:31,252] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 22.388 seconds
[2022-10-21 00:20:37,917] {processor.py:153} INFO - Started process (PID=73697) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:37,919] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:20:37,922] {logging_mixin.py:115} INFO - [2022-10-21 00:20:37,922] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:38,188] {logging_mixin.py:115} INFO - [2022-10-21 00:20:38,187] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:20:38,192] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:20:38,235] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.326 seconds
[2022-10-21 00:21:01,545] {processor.py:153} INFO - Started process (PID=48630) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:01,549] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:21:01,551] {logging_mixin.py:115} INFO - [2022-10-21 00:21:01,551] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:08,467] {processor.py:153} INFO - Started process (PID=73741) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:08,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:21:08,472] {logging_mixin.py:115} INFO - [2022-10-21 00:21:08,472] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:08,904] {logging_mixin.py:115} INFO - [2022-10-21 00:21:08,902] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:21:08,908] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:09,031] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.576 seconds
[2022-10-21 00:21:12,245] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:21:12,383] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:12,641] {logging_mixin.py:115} INFO - [2022-10-21 00:21:12,640] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:21:12,725] {logging_mixin.py:115} INFO - [2022-10-21 00:21:12,725] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:21:12.377905+00:00, run_after=2022-10-22T00:21:12.377905+00:00
[2022-10-21 00:21:12,910] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 11.373 seconds
[2022-10-21 00:21:39,411] {processor.py:153} INFO - Started process (PID=73794) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:39,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:21:39,415] {logging_mixin.py:115} INFO - [2022-10-21 00:21:39,414] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:39,635] {logging_mixin.py:115} INFO - [2022-10-21 00:21:39,634] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:21:39,639] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:39,669] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.264 seconds
[2022-10-21 00:21:43,141] {processor.py:153} INFO - Started process (PID=48914) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:43,142] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:21:43,144] {logging_mixin.py:115} INFO - [2022-10-21 00:21:43,144] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:47,988] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:21:48,009] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:21:48,109] {logging_mixin.py:115} INFO - [2022-10-21 00:21:48,109] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:21:48,140] {logging_mixin.py:115} INFO - [2022-10-21 00:21:48,140] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:21:48.005591+00:00, run_after=2022-10-22T00:21:48.005591+00:00
[2022-10-21 00:21:48,164] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.051 seconds
[2022-10-21 00:22:09,837] {processor.py:153} INFO - Started process (PID=73838) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:09,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:22:09,839] {logging_mixin.py:115} INFO - [2022-10-21 00:22:09,839] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:10,049] {logging_mixin.py:115} INFO - [2022-10-21 00:22:10,047] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:22:10,052] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:10,082] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.250 seconds
[2022-10-21 00:22:18,859] {processor.py:153} INFO - Started process (PID=49196) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:18,860] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:22:18,861] {logging_mixin.py:115} INFO - [2022-10-21 00:22:18,861] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:23,439] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:22:23,457] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:23,549] {logging_mixin.py:115} INFO - [2022-10-21 00:22:23,549] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:22:23,578] {logging_mixin.py:115} INFO - [2022-10-21 00:22:23,578] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:22:23.454368+00:00, run_after=2022-10-22T00:22:23.454368+00:00
[2022-10-21 00:22:23,603] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.749 seconds
[2022-10-21 00:22:40,205] {processor.py:153} INFO - Started process (PID=73891) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:40,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:22:40,209] {logging_mixin.py:115} INFO - [2022-10-21 00:22:40,208] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:40,433] {logging_mixin.py:115} INFO - [2022-10-21 00:22:40,432] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:22:40,435] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:40,472] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.272 seconds
[2022-10-21 00:22:53,714] {processor.py:153} INFO - Started process (PID=49465) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:53,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:22:53,717] {logging_mixin.py:115} INFO - [2022-10-21 00:22:53,717] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:58,733] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:22:58,754] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:22:58,878] {logging_mixin.py:115} INFO - [2022-10-21 00:22:58,877] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:22:58,912] {logging_mixin.py:115} INFO - [2022-10-21 00:22:58,912] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:22:58.751315+00:00, run_after=2022-10-22T00:22:58.751315+00:00
[2022-10-21 00:22:58,933] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.224 seconds
[2022-10-21 00:23:10,579] {processor.py:153} INFO - Started process (PID=73935) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:10,581] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:23:10,583] {logging_mixin.py:115} INFO - [2022-10-21 00:23:10,582] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:10,818] {logging_mixin.py:115} INFO - [2022-10-21 00:23:10,817] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:23:10,825] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:10,861] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.288 seconds
[2022-10-21 00:23:29,315] {processor.py:153} INFO - Started process (PID=49746) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:29,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:23:29,317] {logging_mixin.py:115} INFO - [2022-10-21 00:23:29,317] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:34,653] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:23:34,669] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:34,768] {logging_mixin.py:115} INFO - [2022-10-21 00:23:34,768] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:23:34,801] {logging_mixin.py:115} INFO - [2022-10-21 00:23:34,801] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:23:34.665832+00:00, run_after=2022-10-22T00:23:34.665832+00:00
[2022-10-21 00:23:34,824] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.514 seconds
[2022-10-21 00:23:40,938] {processor.py:153} INFO - Started process (PID=73987) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:40,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:23:40,940] {logging_mixin.py:115} INFO - [2022-10-21 00:23:40,940] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:41,148] {logging_mixin.py:115} INFO - [2022-10-21 00:23:41,147] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:23:41,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:23:41,197] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.265 seconds
[2022-10-21 00:24:05,009] {processor.py:153} INFO - Started process (PID=50016) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:05,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:24:05,011] {logging_mixin.py:115} INFO - [2022-10-21 00:24:05,011] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:09,866] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:24:09,885] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:09,987] {logging_mixin.py:115} INFO - [2022-10-21 00:24:09,986] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:24:10,019] {logging_mixin.py:115} INFO - [2022-10-21 00:24:10,019] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:24:09.882703+00:00, run_after=2022-10-22T00:24:09.882703+00:00
[2022-10-21 00:24:10,042] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.038 seconds
[2022-10-21 00:24:11,460] {processor.py:153} INFO - Started process (PID=74031) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:11,461] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:24:11,463] {logging_mixin.py:115} INFO - [2022-10-21 00:24:11,463] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:11,683] {logging_mixin.py:115} INFO - [2022-10-21 00:24:11,682] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:24:11,686] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:11,719] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.265 seconds
[2022-10-21 00:24:40,667] {processor.py:153} INFO - Started process (PID=50295) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:40,669] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:24:40,671] {logging_mixin.py:115} INFO - [2022-10-21 00:24:40,671] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:42,430] {processor.py:153} INFO - Started process (PID=74086) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:42,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:24:42,434] {logging_mixin.py:115} INFO - [2022-10-21 00:24:42,433] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:42,680] {logging_mixin.py:115} INFO - [2022-10-21 00:24:42,679] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:24:42,684] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:42,729] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.307 seconds
[2022-10-21 00:24:47,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:24:47,061] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:24:47,180] {logging_mixin.py:115} INFO - [2022-10-21 00:24:47,179] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:24:47,224] {logging_mixin.py:115} INFO - [2022-10-21 00:24:47,224] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:24:47.057896+00:00, run_after=2022-10-22T00:24:47.057896+00:00
[2022-10-21 00:24:47,231] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.591 seconds
[2022-10-21 00:25:12,814] {processor.py:153} INFO - Started process (PID=74130) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:12,818] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:25:12,820] {logging_mixin.py:115} INFO - [2022-10-21 00:25:12,820] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:13,024] {logging_mixin.py:115} INFO - [2022-10-21 00:25:13,023] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:25:13,025] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:13,058] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.249 seconds
[2022-10-21 00:25:17,571] {processor.py:153} INFO - Started process (PID=50567) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:17,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:25:17,574] {logging_mixin.py:115} INFO - [2022-10-21 00:25:17,574] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:22,993] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:25:23,014] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:23,133] {logging_mixin.py:115} INFO - [2022-10-21 00:25:23,133] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:25:23,173] {logging_mixin.py:115} INFO - [2022-10-21 00:25:23,172] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:25:23.010437+00:00, run_after=2022-10-22T00:25:23.010437+00:00
[2022-10-21 00:25:23,201] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.638 seconds
[2022-10-21 00:25:43,388] {processor.py:153} INFO - Started process (PID=74183) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:43,390] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:25:43,391] {logging_mixin.py:115} INFO - [2022-10-21 00:25:43,391] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:43,614] {logging_mixin.py:115} INFO - [2022-10-21 00:25:43,613] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:25:43,616] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:43,650] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.268 seconds
[2022-10-21 00:25:53,409] {processor.py:153} INFO - Started process (PID=50850) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:53,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:25:53,412] {logging_mixin.py:115} INFO - [2022-10-21 00:25:53,411] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:59,389] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:25:59,416] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:25:59,537] {logging_mixin.py:115} INFO - [2022-10-21 00:25:59,536] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:25:59,574] {logging_mixin.py:115} INFO - [2022-10-21 00:25:59,574] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:25:59.412264+00:00, run_after=2022-10-22T00:25:59.412264+00:00
[2022-10-21 00:25:59,598] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.195 seconds
[2022-10-21 00:26:14,166] {processor.py:153} INFO - Started process (PID=74234) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:14,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:26:14,172] {logging_mixin.py:115} INFO - [2022-10-21 00:26:14,171] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:14,425] {logging_mixin.py:115} INFO - [2022-10-21 00:26:14,424] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:26:14,427] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:14,471] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.313 seconds
[2022-10-21 00:26:30,428] {processor.py:153} INFO - Started process (PID=51122) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:30,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:26:30,431] {logging_mixin.py:115} INFO - [2022-10-21 00:26:30,431] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:35,479] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:26:35,499] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:35,633] {logging_mixin.py:115} INFO - [2022-10-21 00:26:35,633] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:26:35,671] {logging_mixin.py:115} INFO - [2022-10-21 00:26:35,671] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:26:35.495992+00:00, run_after=2022-10-22T00:26:35.495992+00:00
[2022-10-21 00:26:35,696] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.273 seconds
[2022-10-21 00:26:44,682] {processor.py:153} INFO - Started process (PID=74280) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:44,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:26:44,685] {logging_mixin.py:115} INFO - [2022-10-21 00:26:44,685] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:44,910] {logging_mixin.py:115} INFO - [2022-10-21 00:26:44,909] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:26:44,911] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:26:44,942] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.265 seconds
[2022-10-21 00:27:06,275] {processor.py:153} INFO - Started process (PID=51402) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:06,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:27:06,277] {logging_mixin.py:115} INFO - [2022-10-21 00:27:06,277] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:11,459] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:27:11,483] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:11,597] {logging_mixin.py:115} INFO - [2022-10-21 00:27:11,597] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:27:11,637] {logging_mixin.py:115} INFO - [2022-10-21 00:27:11,636] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:27:11.480079+00:00, run_after=2022-10-22T00:27:11.480079+00:00
[2022-10-21 00:27:11,664] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.394 seconds
[2022-10-21 00:27:15,037] {processor.py:153} INFO - Started process (PID=74333) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:15,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:27:15,040] {logging_mixin.py:115} INFO - [2022-10-21 00:27:15,040] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:15,271] {logging_mixin.py:115} INFO - [2022-10-21 00:27:15,270] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:27:15,273] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:15,312] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.281 seconds
[2022-10-21 00:27:41,942] {processor.py:153} INFO - Started process (PID=51679) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:41,944] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:27:41,945] {logging_mixin.py:115} INFO - [2022-10-21 00:27:41,945] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:45,548] {processor.py:153} INFO - Started process (PID=74377) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:45,549] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:27:45,552] {logging_mixin.py:115} INFO - [2022-10-21 00:27:45,551] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:45,806] {logging_mixin.py:115} INFO - [2022-10-21 00:27:45,805] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:27:45,811] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:45,850] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.310 seconds
[2022-10-21 00:27:48,082] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:27:48,113] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:27:48,288] {logging_mixin.py:115} INFO - [2022-10-21 00:27:48,288] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:27:48,349] {logging_mixin.py:115} INFO - [2022-10-21 00:27:48,349] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:27:48.106502+00:00, run_after=2022-10-22T00:27:48.106502+00:00
[2022-10-21 00:27:48,426] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.510 seconds
[2022-10-21 00:28:15,920] {processor.py:153} INFO - Started process (PID=74414) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:15,923] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:28:15,924] {logging_mixin.py:115} INFO - [2022-10-21 00:28:15,924] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:16,165] {logging_mixin.py:115} INFO - [2022-10-21 00:28:16,164] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:28:16,168] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:16,220] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.306 seconds
[2022-10-21 00:28:18,630] {processor.py:153} INFO - Started process (PID=51950) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:18,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:28:18,633] {logging_mixin.py:115} INFO - [2022-10-21 00:28:18,633] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:25,442] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:28:25,466] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:25,612] {logging_mixin.py:115} INFO - [2022-10-21 00:28:25,611] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:28:25,651] {logging_mixin.py:115} INFO - [2022-10-21 00:28:25,651] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:28:25.461536+00:00, run_after=2022-10-22T00:28:25.461536+00:00
[2022-10-21 00:28:25,681] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.057 seconds
[2022-10-21 00:28:47,447] {processor.py:153} INFO - Started process (PID=74467) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:47,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:28:47,459] {logging_mixin.py:115} INFO - [2022-10-21 00:28:47,459] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:48,037] {logging_mixin.py:115} INFO - [2022-10-21 00:28:48,034] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:28:48,043] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:48,159] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.733 seconds
[2022-10-21 00:28:55,764] {processor.py:153} INFO - Started process (PID=52305) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:28:55,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:28:55,785] {logging_mixin.py:115} INFO - [2022-10-21 00:28:55,785] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:07,579] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:29:07,608] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:07,752] {logging_mixin.py:115} INFO - [2022-10-21 00:29:07,752] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:29:07,797] {logging_mixin.py:115} INFO - [2022-10-21 00:29:07,796] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:29:07.603983+00:00, run_after=2022-10-22T00:29:07.603983+00:00
[2022-10-21 00:29:07,830] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 12.083 seconds
[2022-10-21 00:29:18,382] {processor.py:153} INFO - Started process (PID=74511) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:18,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:29:18,385] {logging_mixin.py:115} INFO - [2022-10-21 00:29:18,385] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:18,619] {logging_mixin.py:115} INFO - [2022-10-21 00:29:18,618] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:29:18,621] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:18,659] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.284 seconds
[2022-10-21 00:29:38,351] {processor.py:153} INFO - Started process (PID=52648) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:38,357] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:29:38,361] {logging_mixin.py:115} INFO - [2022-10-21 00:29:38,360] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:46,522] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:29:46,553] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:46,773] {logging_mixin.py:115} INFO - [2022-10-21 00:29:46,773] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:29:46,871] {logging_mixin.py:115} INFO - [2022-10-21 00:29:46,870] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:29:46.548113+00:00, run_after=2022-10-22T00:29:46.548113+00:00
[2022-10-21 00:29:46,920] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 8.580 seconds
[2022-10-21 00:29:50,429] {processor.py:153} INFO - Started process (PID=74563) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:50,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:29:50,445] {logging_mixin.py:115} INFO - [2022-10-21 00:29:50,445] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:50,988] {logging_mixin.py:115} INFO - [2022-10-21 00:29:50,987] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:29:50,997] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:29:51,209] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.808 seconds
[2022-10-21 00:30:17,228] {processor.py:153} INFO - Started process (PID=52934) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:17,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:30:17,231] {logging_mixin.py:115} INFO - [2022-10-21 00:30:17,231] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:21,461] {processor.py:153} INFO - Started process (PID=74616) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:21,462] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:30:21,464] {logging_mixin.py:115} INFO - [2022-10-21 00:30:21,464] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:21,774] {logging_mixin.py:115} INFO - [2022-10-21 00:30:21,773] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:30:21,778] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:21,829] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.375 seconds
[2022-10-21 00:30:24,334] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:30:24,384] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:24,564] {logging_mixin.py:115} INFO - [2022-10-21 00:30:24,564] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:30:24,613] {logging_mixin.py:115} INFO - [2022-10-21 00:30:24,612] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:30:24.367735+00:00, run_after=2022-10-22T00:30:24.367735+00:00
[2022-10-21 00:30:24,644] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.421 seconds
[2022-10-21 00:30:51,955] {processor.py:153} INFO - Started process (PID=74656) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:51,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:30:51,964] {logging_mixin.py:115} INFO - [2022-10-21 00:30:51,963] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:52,419] {logging_mixin.py:115} INFO - [2022-10-21 00:30:52,416] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:30:52,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:52,519] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.585 seconds
[2022-10-21 00:30:55,237] {processor.py:153} INFO - Started process (PID=53416) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:30:55,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:30:55,249] {logging_mixin.py:115} INFO - [2022-10-21 00:30:55,249] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:22,710] {processor.py:153} INFO - Started process (PID=74700) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:22,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:31:22,723] {logging_mixin.py:115} INFO - [2022-10-21 00:31:22,722] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:23,420] {logging_mixin.py:115} INFO - [2022-10-21 00:31:23,395] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:31:23,435] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:23,541] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.848 seconds
[2022-10-21 00:31:25,252] {logging_mixin.py:115} INFO - [2022-10-21 00:31:25,250] {timeout.py:67} ERROR - Process timed out, PID: 53416
[2022-10-21 00:31:25,305] {logging_mixin.py:115} INFO - [2022-10-21 00:31:25,261] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 53416
[2022-10-21 00:31:25,324] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:26,269] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.096 seconds
[2022-10-21 00:31:53,783] {processor.py:153} INFO - Started process (PID=74744) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:53,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:31:53,789] {logging_mixin.py:115} INFO - [2022-10-21 00:31:53,789] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:54,027] {logging_mixin.py:115} INFO - [2022-10-21 00:31:54,025] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:31:54,028] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:54,066] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.289 seconds
[2022-10-21 00:31:56,995] {processor.py:153} INFO - Started process (PID=53747) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:31:56,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:31:56,998] {logging_mixin.py:115} INFO - [2022-10-21 00:31:56,998] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:04,315] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:32:04,353] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:04,481] {logging_mixin.py:115} INFO - [2022-10-21 00:32:04,481] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:32:04,526] {logging_mixin.py:115} INFO - [2022-10-21 00:32:04,526] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:32:04.349648+00:00, run_after=2022-10-22T00:32:04.349648+00:00
[2022-10-21 00:32:04,590] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.601 seconds
[2022-10-21 00:32:24,977] {processor.py:153} INFO - Started process (PID=74798) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:24,980] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:32:24,983] {logging_mixin.py:115} INFO - [2022-10-21 00:32:24,983] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:25,281] {logging_mixin.py:115} INFO - [2022-10-21 00:32:25,280] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:32:25,284] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:25,322] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.353 seconds
[2022-10-21 00:32:34,710] {processor.py:153} INFO - Started process (PID=54033) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:34,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:32:34,713] {logging_mixin.py:115} INFO - [2022-10-21 00:32:34,713] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:44,513] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:32:44,551] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:44,746] {logging_mixin.py:115} INFO - [2022-10-21 00:32:44,745] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:32:44,828] {logging_mixin.py:115} INFO - [2022-10-21 00:32:44,828] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:32:44.543617+00:00, run_after=2022-10-22T00:32:44.543617+00:00
[2022-10-21 00:32:44,875] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 10.172 seconds
[2022-10-21 00:32:56,332] {processor.py:153} INFO - Started process (PID=74843) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:56,337] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:32:56,350] {logging_mixin.py:115} INFO - [2022-10-21 00:32:56,350] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:56,947] {logging_mixin.py:115} INFO - [2022-10-21 00:32:56,936] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:32:56,958] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:32:57,106] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.797 seconds
[2022-10-21 00:33:15,192] {processor.py:153} INFO - Started process (PID=54322) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:33:15,194] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:33:15,195] {logging_mixin.py:115} INFO - [2022-10-21 00:33:15,195] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:33:23,990] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 00:33:24,019] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:33:24,220] {logging_mixin.py:115} INFO - [2022-10-21 00:33:24,219] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 00:33:24,286] {logging_mixin.py:115} INFO - [2022-10-21 00:33:24,286] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T00:33:24.015052+00:00, run_after=2022-10-22T00:33:24.015052+00:00
[2022-10-21 00:33:24,327] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 9.164 seconds
[2022-10-21 00:33:27,652] {processor.py:153} INFO - Started process (PID=74889) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:33:27,658] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:33:27,662] {logging_mixin.py:115} INFO - [2022-10-21 00:33:27,661] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:33:28,051] {logging_mixin.py:115} INFO - [2022-10-21 00:33:28,049] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:33:28,058] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:33:28,115] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.475 seconds
[2022-10-21 00:33:58,463] {processor.py:153} INFO - Started process (PID=74933) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:33:58,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:33:58,474] {logging_mixin.py:115} INFO - [2022-10-21 00:33:58,474] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:34:00,367] {processor.py:153} INFO - Started process (PID=54673) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:34:00,399] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:34:00,423] {logging_mixin.py:115} INFO - [2022-10-21 00:34:00,423] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:34:20,101] {logging_mixin.py:115} INFO - [2022-10-21 00:34:20,048] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:34:20,137] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:34:20,960] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 22.187 seconds
[2022-10-21 00:34:30,920] {logging_mixin.py:115} INFO - [2022-10-21 00:34:30,919] {timeout.py:67} ERROR - Process timed out, PID: 54673
[2022-10-21 00:34:31,046] {logging_mixin.py:115} INFO - [2022-10-21 00:34:30,942] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 54673
[2022-10-21 00:34:31,062] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:34:31,574] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.202 seconds
[2022-10-21 00:35:11,694] {processor.py:153} INFO - Started process (PID=74986) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:11,698] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:35:11,711] {logging_mixin.py:115} INFO - [2022-10-21 00:35:11,711] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:13,044] {logging_mixin.py:115} INFO - [2022-10-21 00:35:13,039] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:35:13,052] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:13,249] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.623 seconds
[2022-10-21 00:35:19,174] {processor.py:153} INFO - Started process (PID=54769) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:19,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:35:19,189] {logging_mixin.py:115} INFO - [2022-10-21 00:35:19,188] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:49,172] {processor.py:153} INFO - Started process (PID=75028) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:49,176] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:35:49,182] {logging_mixin.py:115} INFO - [2022-10-21 00:35:49,181] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:49,198] {logging_mixin.py:115} INFO - [2022-10-21 00:35:49,197] {timeout.py:67} ERROR - Process timed out, PID: 54769
[2022-10-21 00:35:49,228] {logging_mixin.py:115} INFO - [2022-10-21 00:35:49,209] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 54769
[2022-10-21 00:35:49,233] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:50,263] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.151 seconds
[2022-10-21 00:35:59,338] {logging_mixin.py:115} INFO - [2022-10-21 00:35:59,320] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:35:59,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:35:59,446] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 10.376 seconds
[2022-10-21 00:36:29,899] {processor.py:153} INFO - Started process (PID=75063) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:36:29,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:36:29,913] {logging_mixin.py:115} INFO - [2022-10-21 00:36:29,913] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:36:31,809] {logging_mixin.py:115} INFO - [2022-10-21 00:36:31,787] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:36:31,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:36:32,242] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.399 seconds
[2022-10-21 00:37:14,666] {processor.py:153} INFO - Started process (PID=75087) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:37:14,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:37:14,684] {logging_mixin.py:115} INFO - [2022-10-21 00:37:14,684] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:37:15,479] {logging_mixin.py:115} INFO - [2022-10-21 00:37:15,473] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:37:15,483] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:37:15,685] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.032 seconds
[2022-10-21 00:37:31,848] {processor.py:153} INFO - Started process (PID=54921) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:37:31,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:37:31,862] {logging_mixin.py:115} INFO - [2022-10-21 00:37:31,862] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:38:05,361] {logging_mixin.py:115} INFO - [2022-10-21 00:38:05,359] {timeout.py:67} ERROR - Process timed out, PID: 54921
[2022-10-21 00:46:40,199] {logging_mixin.py:115} INFO - [2022-10-21 00:38:05,527] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 102, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/subprocess.py", line 991, in poll
    return self._internal_poll()
  File "/usr/local/lib/python3.7/subprocess.py", line 1590, in _internal_poll
    pid, sts = _waitpid(self.pid, _WNOHANG)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 54921
[2022-10-21 00:46:40,345] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:46:53,218] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 47.306 seconds
[2022-10-21 00:46:53,396] {processor.py:153} INFO - Started process (PID=75130) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:46:53,405] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:46:53,416] {logging_mixin.py:115} INFO - [2022-10-21 00:46:53,414] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:47:09,033] {logging_mixin.py:115} INFO - [2022-10-21 00:47:08,986] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:47:10,947] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:47:19,929] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 26.055 seconds
[2022-10-21 00:47:20,524] {processor.py:153} INFO - Started process (PID=55017) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:47:20,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:47:20,535] {logging_mixin.py:115} INFO - [2022-10-21 00:47:20,534] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:47:50,870] {logging_mixin.py:115} INFO - [2022-10-21 00:47:50,869] {timeout.py:67} ERROR - Process timed out, PID: 55017
[2022-10-21 00:47:51,135] {logging_mixin.py:115} INFO - [2022-10-21 00:47:50,979] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpsdgh06o3/tmp76t4rpzd'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 102, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 55017
[2022-10-21 00:47:51,148] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:47:57,093] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 36.634 seconds
[2022-10-21 00:57:06,752] {processor.py:153} INFO - Started process (PID=75179) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:06,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:57:06,759] {logging_mixin.py:115} INFO - [2022-10-21 00:57:06,759] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:08,249] {logging_mixin.py:115} INFO - [2022-10-21 00:57:08,234] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:57:08,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:08,403] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.666 seconds
[2022-10-21 00:57:13,342] {processor.py:153} INFO - Started process (PID=55189) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:13,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:57:13,347] {logging_mixin.py:115} INFO - [2022-10-21 00:57:13,347] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:41,154] {processor.py:153} INFO - Started process (PID=75228) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:41,158] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 00:57:41,160] {logging_mixin.py:115} INFO - [2022-10-21 00:57:41,160] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:41,670] {logging_mixin.py:115} INFO - [2022-10-21 00:57:41,662] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 00:57:41,675] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:41,716] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.582 seconds
[2022-10-21 00:57:44,682] {logging_mixin.py:115} INFO - [2022-10-21 00:57:44,682] {timeout.py:67} ERROR - Process timed out, PID: 55189
[2022-10-21 00:57:44,703] {logging_mixin.py:115} INFO - [2022-10-21 00:57:44,697] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmptev0fp3i/tmp_r1hadxr'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 102, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 55189
[2022-10-21 00:57:44,716] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 00:57:44,987] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.542 seconds
[2022-10-21 01:02:07,087] {processor.py:153} INFO - Started process (PID=55304) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:02:07,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 01:02:07,093] {logging_mixin.py:115} INFO - [2022-10-21 01:02:07,093] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:02:07,427] {processor.py:153} INFO - Started process (PID=75258) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:02:07,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 01:02:07,430] {logging_mixin.py:115} INFO - [2022-10-21 01:02:07,430] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:02:07,679] {logging_mixin.py:115} INFO - [2022-10-21 01:02:07,678] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 01:02:07,683] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:02:07,738] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.319 seconds
[2022-10-21 01:02:40,331] {logging_mixin.py:115} INFO - [2022-10-21 01:02:38,678] {timeout.py:67} ERROR - Process timed out, PID: 55304
[2022-10-21 01:03:05,747] {logging_mixin.py:115} INFO - [2022-10-21 01:02:50,144] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpjyyzpf9p/tmpbrb1nqdw'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 102, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 55304
[2022-10-21 01:03:23,834] {processor.py:153} INFO - Started process (PID=75276) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:03:23,841] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:03:23,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 01:03:23,851] {logging_mixin.py:115} INFO - [2022-10-21 01:03:23,848] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:03:24,155] {logging_mixin.py:115} INFO - [2022-10-21 01:03:24,154] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 01:03:24,157] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:03:24,192] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 18.509 seconds
[2022-10-21 01:03:26,220] {processor.py:153} INFO - Started process (PID=55443) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:03:26,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 01:03:26,223] {logging_mixin.py:115} INFO - [2022-10-21 01:03:26,223] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:12:30,650] {logging_mixin.py:115} INFO - [2022-10-21 01:12:30,648] {timeout.py:67} ERROR - Process timed out, PID: 55443
[2022-10-21 01:12:39,948] {logging_mixin.py:115} INFO - [2022-10-21 01:12:33,703] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpn6vine9q/tmp6rwtawwy'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 102, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 55443
[2022-10-21 01:12:44,807] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:17:30,965] {processor.py:153} INFO - Started process (PID=75312) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:17:30,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 01:17:31,381] {logging_mixin.py:115} INFO - [2022-10-21 01:17:31,261] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:17:34,963] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 79.068 seconds
[2022-10-21 01:17:36,494] {logging_mixin.py:115} INFO - [2022-10-21 01:17:36,485] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 01:17:36,499] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:17:36,651] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.878 seconds
[2022-10-21 01:18:13,919] {processor.py:153} INFO - Started process (PID=55527) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:18:13,999] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 01:18:14,125] {logging_mixin.py:115} INFO - [2022-10-21 01:18:14,124] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:18:44,711] {logging_mixin.py:115} INFO - [2022-10-21 01:18:44,711] {timeout.py:67} ERROR - Process timed out, PID: 55527
[2022-10-21 01:18:47,368] {processor.py:153} INFO - Started process (PID=75368) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:18:47,424] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 01:18:47,461] {logging_mixin.py:115} INFO - [2022-10-21 01:18:47,461] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 01:23:34,483] {logging_mixin.py:115} INFO - [2022-10-21 01:23:34,474] {timeout.py:67} ERROR - Process timed out, PID: 75368
[2022-10-21 01:23:41,445] {logging_mixin.py:115} INFO - [2022-10-21 01:23:38,290] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 102, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/subprocess.py", line 991, in poll
    return self._internal_poll()
  File "/usr/local/lib/python3.7/subprocess.py", line 1590, in _internal_poll
    pid, sts = _waitpid(self.pid, _WNOHANG)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 75368
[2022-10-21 01:23:41,562] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:07:54,664] {processor.py:153} INFO - Started process (PID=75558) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:07:54,715] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:07:54,718] {logging_mixin.py:115} INFO - [2022-10-21 02:07:54,718] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:17:56,835] {processor.py:153} INFO - Started process (PID=75618) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:17:57,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:17:57,397] {logging_mixin.py:115} INFO - [2022-10-21 02:17:57,311] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:18:24,809] {logging_mixin.py:115} INFO - [2022-10-21 02:18:24,686] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:18:25,174] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:18:28,256] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 32.540 seconds
[2022-10-21 02:23:51,269] {processor.py:153} INFO - Started process (PID=75689) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:23:51,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:23:51,360] {logging_mixin.py:115} INFO - [2022-10-21 02:23:51,335] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:24:01,499] {logging_mixin.py:115} INFO - [2022-10-21 02:24:01,478] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:24:01,579] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:24:02,840] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 11.902 seconds
[2022-10-21 02:24:34,464] {processor.py:153} INFO - Started process (PID=75741) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:24:34,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:24:34,475] {logging_mixin.py:115} INFO - [2022-10-21 02:24:34,475] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:24:34,770] {logging_mixin.py:115} INFO - [2022-10-21 02:24:34,769] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:24:34,772] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:24:34,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.400 seconds
[2022-10-21 02:28:54,461] {processor.py:153} INFO - Started process (PID=75750) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:28:54,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:28:54,472] {logging_mixin.py:115} INFO - [2022-10-21 02:28:54,472] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:28:54,691] {logging_mixin.py:115} INFO - [2022-10-21 02:28:54,690] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:28:54,693] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:28:54,726] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.270 seconds
[2022-10-21 02:29:25,211] {processor.py:153} INFO - Started process (PID=75794) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:29:25,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:29:25,232] {logging_mixin.py:115} INFO - [2022-10-21 02:29:25,231] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:29:27,894] {logging_mixin.py:115} INFO - [2022-10-21 02:29:27,884] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:29:27,909] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:29:28,248] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.129 seconds
[2022-10-21 02:29:59,147] {processor.py:153} INFO - Started process (PID=75835) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:29:59,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:29:59,167] {logging_mixin.py:115} INFO - [2022-10-21 02:29:59,167] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:30:05,420] {logging_mixin.py:115} INFO - [2022-10-21 02:30:05,419] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:30:05,427] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:30:05,537] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.470 seconds
[2022-10-21 02:34:42,447] {processor.py:153} INFO - Started process (PID=75870) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:34:42,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:34:42,457] {logging_mixin.py:115} INFO - [2022-10-21 02:34:42,456] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:34:43,287] {logging_mixin.py:115} INFO - [2022-10-21 02:34:43,284] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:34:43,292] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:34:43,648] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.231 seconds
[2022-10-21 02:35:22,512] {processor.py:153} INFO - Started process (PID=75920) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:35:22,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:35:22,594] {logging_mixin.py:115} INFO - [2022-10-21 02:35:22,576] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:35:27,347] {logging_mixin.py:115} INFO - [2022-10-21 02:35:27,290] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:35:27,381] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:35:28,117] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.841 seconds
[2022-10-21 02:36:11,503] {processor.py:153} INFO - Started process (PID=75962) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:36:11,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:36:11,513] {logging_mixin.py:115} INFO - [2022-10-21 02:36:11,510] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:44:48,636] {logging_mixin.py:115} INFO - [2022-10-21 02:44:48,635] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:44:48,639] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:44:48,757] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.259 seconds
[2022-10-21 02:44:51,170] {processor.py:153} INFO - Started process (PID=75990) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:44:51,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:44:51,182] {logging_mixin.py:115} INFO - [2022-10-21 02:44:51,182] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:44:51,619] {logging_mixin.py:115} INFO - [2022-10-21 02:44:51,618] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:44:51,620] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:44:51,738] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.580 seconds
[2022-10-21 02:45:24,475] {processor.py:153} INFO - Started process (PID=76030) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:45:24,488] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:45:24,518] {logging_mixin.py:115} INFO - [2022-10-21 02:45:24,518] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:45:25,914] {logging_mixin.py:115} INFO - [2022-10-21 02:45:25,908] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:45:25,933] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:45:26,195] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.757 seconds
[2022-10-21 02:45:57,820] {processor.py:153} INFO - Started process (PID=76066) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:45:57,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:45:57,853] {logging_mixin.py:115} INFO - [2022-10-21 02:45:57,850] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:45:59,246] {logging_mixin.py:115} INFO - [2022-10-21 02:45:59,239] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:45:59,255] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:45:59,698] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.919 seconds
[2022-10-21 02:50:38,137] {processor.py:153} INFO - Started process (PID=76101) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:50:38,155] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:50:38,185] {logging_mixin.py:115} INFO - [2022-10-21 02:50:38,184] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:50:40,470] {logging_mixin.py:115} INFO - [2022-10-21 02:50:40,468] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:50:40,477] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:50:40,633] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.614 seconds
[2022-10-21 02:51:11,102] {processor.py:153} INFO - Started process (PID=76136) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:51:11,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:51:11,126] {logging_mixin.py:115} INFO - [2022-10-21 02:51:11,125] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:51:12,580] {logging_mixin.py:115} INFO - [2022-10-21 02:51:12,575] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:51:12,605] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:51:12,894] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.866 seconds
[2022-10-21 02:51:43,294] {processor.py:153} INFO - Started process (PID=76179) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:51:43,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 02:51:43,307] {logging_mixin.py:115} INFO - [2022-10-21 02:51:43,307] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:51:44,827] {logging_mixin.py:115} INFO - [2022-10-21 02:51:44,810] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 02:51:44,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 02:51:45,141] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.912 seconds
[2022-10-21 03:00:41,127] {processor.py:153} INFO - Started process (PID=76212) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:00:41,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:00:41,132] {logging_mixin.py:115} INFO - [2022-10-21 03:00:41,132] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:00:41,590] {logging_mixin.py:115} INFO - [2022-10-21 03:00:41,589] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:00:41,592] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:00:41,641] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.521 seconds
[2022-10-21 03:01:12,579] {processor.py:153} INFO - Started process (PID=76256) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:01:12,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:01:12,620] {logging_mixin.py:115} INFO - [2022-10-21 03:01:12,619] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:01:14,671] {logging_mixin.py:115} INFO - [2022-10-21 03:01:14,662] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:01:14,696] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:01:15,124] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.710 seconds
[2022-10-21 03:01:46,326] {processor.py:153} INFO - Started process (PID=76297) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:01:46,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:01:46,352] {logging_mixin.py:115} INFO - [2022-10-21 03:01:46,351] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:01:49,773] {logging_mixin.py:115} INFO - [2022-10-21 03:01:49,771] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:01:49,776] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:01:49,822] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.555 seconds
[2022-10-21 03:06:29,122] {processor.py:153} INFO - Started process (PID=76332) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:06:29,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:06:29,129] {logging_mixin.py:115} INFO - [2022-10-21 03:06:29,129] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:06:29,553] {logging_mixin.py:115} INFO - [2022-10-21 03:06:29,550] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:06:29,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:06:29,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.524 seconds
[2022-10-21 03:07:00,191] {processor.py:153} INFO - Started process (PID=76375) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:07:00,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:07:00,211] {logging_mixin.py:115} INFO - [2022-10-21 03:07:00,211] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:07:00,907] {logging_mixin.py:115} INFO - [2022-10-21 03:07:00,904] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:07:00,920] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:07:01,104] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.978 seconds
[2022-10-21 03:11:48,464] {processor.py:153} INFO - Started process (PID=76420) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:11:48,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:11:48,469] {logging_mixin.py:115} INFO - [2022-10-21 03:11:48,469] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:11:48,784] {logging_mixin.py:115} INFO - [2022-10-21 03:11:48,783] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:11:48,786] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:11:48,851] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.396 seconds
[2022-10-21 03:12:19,924] {processor.py:153} INFO - Started process (PID=76456) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:12:19,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:12:19,937] {logging_mixin.py:115} INFO - [2022-10-21 03:12:19,937] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:12:22,250] {logging_mixin.py:115} INFO - [2022-10-21 03:12:22,241] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:12:22,259] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:12:22,821] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.976 seconds
[2022-10-21 03:12:53,176] {processor.py:153} INFO - Started process (PID=76500) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:12:53,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:12:53,219] {logging_mixin.py:115} INFO - [2022-10-21 03:12:53,218] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:12:54,230] {logging_mixin.py:115} INFO - [2022-10-21 03:12:54,226] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:12:54,247] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:12:54,375] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.237 seconds
[2022-10-21 03:17:35,705] {processor.py:153} INFO - Started process (PID=76544) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:17:35,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:17:35,721] {logging_mixin.py:115} INFO - [2022-10-21 03:17:35,720] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:17:36,529] {logging_mixin.py:115} INFO - [2022-10-21 03:17:36,527] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:17:36,538] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:17:36,696] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.005 seconds
[2022-10-21 03:18:07,494] {processor.py:153} INFO - Started process (PID=76579) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:18:07,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:18:07,524] {logging_mixin.py:115} INFO - [2022-10-21 03:18:07,523] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:18:09,869] {logging_mixin.py:115} INFO - [2022-10-21 03:18:09,855] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:18:09,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:18:10,328] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.918 seconds
[2022-10-21 03:18:41,470] {processor.py:153} INFO - Started process (PID=76623) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:18:41,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:18:41,475] {logging_mixin.py:115} INFO - [2022-10-21 03:18:41,475] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:18:41,696] {logging_mixin.py:115} INFO - [2022-10-21 03:18:41,695] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:18:42,598] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:18:42,637] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.175 seconds
[2022-10-21 03:23:23,175] {processor.py:153} INFO - Started process (PID=76667) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:23:23,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:23:23,209] {logging_mixin.py:115} INFO - [2022-10-21 03:23:23,209] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:23:24,571] {logging_mixin.py:115} INFO - [2022-10-21 03:23:24,561] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:23:24,579] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:23:24,780] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.629 seconds
[2022-10-21 03:23:56,018] {processor.py:153} INFO - Started process (PID=76712) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:23:56,060] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:23:56,074] {logging_mixin.py:115} INFO - [2022-10-21 03:23:56,072] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:23:57,640] {logging_mixin.py:115} INFO - [2022-10-21 03:23:57,636] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:23:57,674] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:23:58,020] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.124 seconds
[2022-10-21 03:28:40,423] {processor.py:153} INFO - Started process (PID=76746) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:28:40,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:28:40,426] {logging_mixin.py:115} INFO - [2022-10-21 03:28:40,426] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:28:40,663] {logging_mixin.py:115} INFO - [2022-10-21 03:28:40,662] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:28:40,665] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:28:40,700] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.284 seconds
[2022-10-21 03:29:11,456] {processor.py:153} INFO - Started process (PID=76791) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:29:11,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:29:11,498] {logging_mixin.py:115} INFO - [2022-10-21 03:29:11,497] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:29:13,854] {logging_mixin.py:115} INFO - [2022-10-21 03:29:13,850] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:29:13,875] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:29:14,553] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.181 seconds
[2022-10-21 03:29:45,970] {processor.py:153} INFO - Started process (PID=76841) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:29:45,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:29:45,987] {logging_mixin.py:115} INFO - [2022-10-21 03:29:45,987] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:29:46,890] {logging_mixin.py:115} INFO - [2022-10-21 03:29:46,886] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:29:46,914] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:29:47,145] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.238 seconds
[2022-10-21 03:34:28,707] {processor.py:153} INFO - Started process (PID=76870) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:34:28,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:34:28,712] {logging_mixin.py:115} INFO - [2022-10-21 03:34:28,712] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:34:29,052] {logging_mixin.py:115} INFO - [2022-10-21 03:34:29,050] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:34:29,067] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:34:29,172] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.472 seconds
[2022-10-21 03:35:00,216] {processor.py:153} INFO - Started process (PID=76913) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:35:00,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:35:00,265] {logging_mixin.py:115} INFO - [2022-10-21 03:35:00,249] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:35:04,467] {logging_mixin.py:115} INFO - [2022-10-21 03:35:04,464] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:35:04,475] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:35:05,054] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.014 seconds
[2022-10-21 03:39:46,448] {processor.py:153} INFO - Started process (PID=76950) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:39:46,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:39:46,451] {logging_mixin.py:115} INFO - [2022-10-21 03:39:46,451] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:39:46,739] {logging_mixin.py:115} INFO - [2022-10-21 03:39:46,738] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:39:46,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:39:46,785] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.358 seconds
[2022-10-21 03:40:17,568] {processor.py:153} INFO - Started process (PID=76994) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:40:17,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:40:17,601] {logging_mixin.py:115} INFO - [2022-10-21 03:40:17,600] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:40:18,673] {logging_mixin.py:115} INFO - [2022-10-21 03:40:18,666] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:40:18,716] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:40:18,937] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.488 seconds
[2022-10-21 03:40:49,553] {processor.py:153} INFO - Started process (PID=77029) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:40:49,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:40:49,567] {logging_mixin.py:115} INFO - [2022-10-21 03:40:49,566] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:40:50,417] {logging_mixin.py:115} INFO - [2022-10-21 03:40:50,408] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:40:50,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:40:50,544] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.013 seconds
[2022-10-21 03:49:52,855] {processor.py:153} INFO - Started process (PID=77074) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:49:52,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:49:52,872] {logging_mixin.py:115} INFO - [2022-10-21 03:49:52,872] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:49:53,714] {logging_mixin.py:115} INFO - [2022-10-21 03:49:53,711] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:49:53,718] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:49:53,805] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.976 seconds
[2022-10-21 03:50:25,085] {processor.py:153} INFO - Started process (PID=77115) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:50:25,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:50:25,099] {logging_mixin.py:115} INFO - [2022-10-21 03:50:25,099] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:50:26,227] {logging_mixin.py:115} INFO - [2022-10-21 03:50:26,222] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:50:26,235] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:50:26,497] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.562 seconds
[2022-10-21 03:55:10,406] {processor.py:153} INFO - Started process (PID=77153) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:55:10,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:55:10,410] {logging_mixin.py:115} INFO - [2022-10-21 03:55:10,410] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:55:10,626] {logging_mixin.py:115} INFO - [2022-10-21 03:55:10,625] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:55:10,628] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:55:10,695] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.299 seconds
[2022-10-21 03:55:40,945] {processor.py:153} INFO - Started process (PID=77194) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:55:40,957] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:55:40,968] {logging_mixin.py:115} INFO - [2022-10-21 03:55:40,968] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:55:42,416] {logging_mixin.py:115} INFO - [2022-10-21 03:55:42,409] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:55:42,438] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:55:42,743] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.825 seconds
[2022-10-21 03:56:13,753] {processor.py:153} INFO - Started process (PID=77231) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:56:13,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 03:56:13,766] {logging_mixin.py:115} INFO - [2022-10-21 03:56:13,766] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:56:14,467] {logging_mixin.py:115} INFO - [2022-10-21 03:56:14,463] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 03:56:14,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 03:56:14,598] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.868 seconds
[2022-10-21 04:00:59,073] {processor.py:153} INFO - Started process (PID=77275) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:00:59,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:00:59,105] {logging_mixin.py:115} INFO - [2022-10-21 04:00:59,104] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:01:01,491] {logging_mixin.py:115} INFO - [2022-10-21 04:01:01,483] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:01:01,501] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:01:01,780] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.775 seconds
[2022-10-21 04:01:32,531] {processor.py:153} INFO - Started process (PID=77310) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:01:32,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:01:32,545] {logging_mixin.py:115} INFO - [2022-10-21 04:01:32,544] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:01:33,348] {logging_mixin.py:115} INFO - [2022-10-21 04:01:33,333] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:01:33,355] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:01:33,701] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.195 seconds
[2022-10-21 04:02:04,831] {processor.py:153} INFO - Started process (PID=77354) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:02:04,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:02:04,837] {logging_mixin.py:115} INFO - [2022-10-21 04:02:04,837] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:02:05,058] {logging_mixin.py:115} INFO - [2022-10-21 04:02:05,057] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:02:05,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:02:05,089] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.263 seconds
[2022-10-21 04:06:45,377] {processor.py:153} INFO - Started process (PID=77388) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:06:45,381] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:06:45,398] {logging_mixin.py:115} INFO - [2022-10-21 04:06:45,397] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:06:46,397] {logging_mixin.py:115} INFO - [2022-10-21 04:06:46,394] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:06:46,403] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:06:46,563] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.258 seconds
[2022-10-21 04:07:17,667] {processor.py:153} INFO - Started process (PID=77430) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:07:17,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:07:17,743] {logging_mixin.py:115} INFO - [2022-10-21 04:07:17,743] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:07:22,299] {logging_mixin.py:115} INFO - [2022-10-21 04:07:22,294] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:07:22,317] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:07:23,035] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.483 seconds
[2022-10-21 04:07:54,178] {processor.py:153} INFO - Started process (PID=77476) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:07:54,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:07:54,192] {logging_mixin.py:115} INFO - [2022-10-21 04:07:54,192] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:07:54,392] {logging_mixin.py:115} INFO - [2022-10-21 04:07:54,392] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:07:54,394] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:07:54,422] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.249 seconds
[2022-10-21 04:12:32,500] {processor.py:153} INFO - Started process (PID=77503) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:12:32,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:12:32,504] {logging_mixin.py:115} INFO - [2022-10-21 04:12:32,504] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:12:32,780] {logging_mixin.py:115} INFO - [2022-10-21 04:12:32,779] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:12:32,784] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:12:32,835] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.344 seconds
[2022-10-21 04:13:03,480] {processor.py:153} INFO - Started process (PID=77545) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:13:03,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:13:03,523] {logging_mixin.py:115} INFO - [2022-10-21 04:13:03,522] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:13:07,584] {logging_mixin.py:115} INFO - [2022-10-21 04:13:07,573] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:13:07,611] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:13:08,204] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.861 seconds
[2022-10-21 04:17:50,835] {processor.py:153} INFO - Started process (PID=77582) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:17:50,837] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:17:50,839] {logging_mixin.py:115} INFO - [2022-10-21 04:17:50,839] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:17:51,120] {logging_mixin.py:115} INFO - [2022-10-21 04:17:51,119] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:17:51,122] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:17:51,167] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.338 seconds
[2022-10-21 04:18:21,801] {processor.py:153} INFO - Started process (PID=77626) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:18:21,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:18:21,848] {logging_mixin.py:115} INFO - [2022-10-21 04:18:21,847] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:18:24,881] {logging_mixin.py:115} INFO - [2022-10-21 04:18:24,847] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:18:24,902] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:18:25,440] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.748 seconds
[2022-10-21 04:19:01,662] {processor.py:153} INFO - Started process (PID=77676) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:19:01,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:19:01,686] {logging_mixin.py:115} INFO - [2022-10-21 04:19:01,686] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:19:02,194] {logging_mixin.py:115} INFO - [2022-10-21 04:19:02,193] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:19:02,196] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:19:02,258] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.622 seconds
[2022-10-21 04:23:48,369] {processor.py:153} INFO - Started process (PID=77701) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:23:48,383] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:23:48,410] {logging_mixin.py:115} INFO - [2022-10-21 04:23:48,409] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:23:52,103] {logging_mixin.py:115} INFO - [2022-10-21 04:23:52,071] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:23:52,130] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:23:52,778] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.518 seconds
[2022-10-21 04:24:31,570] {processor.py:153} INFO - Started process (PID=77753) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:24:31,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:24:31,628] {logging_mixin.py:115} INFO - [2022-10-21 04:24:31,628] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:24:36,063] {logging_mixin.py:115} INFO - [2022-10-21 04:24:36,062] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:24:36,069] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:24:36,150] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.746 seconds
[2022-10-21 04:33:14,836] {processor.py:153} INFO - Started process (PID=77771) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:33:14,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:33:14,840] {logging_mixin.py:115} INFO - [2022-10-21 04:33:14,840] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:33:15,119] {logging_mixin.py:115} INFO - [2022-10-21 04:33:15,117] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:33:15,122] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:33:15,172] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.344 seconds
[2022-10-21 04:33:46,139] {processor.py:153} INFO - Started process (PID=77813) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:33:46,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:33:46,195] {logging_mixin.py:115} INFO - [2022-10-21 04:33:46,181] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:33:49,219] {logging_mixin.py:115} INFO - [2022-10-21 04:33:49,210] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:33:49,243] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:33:49,970] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.975 seconds
[2022-10-21 04:34:20,421] {processor.py:153} INFO - Started process (PID=77849) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:34:20,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:34:20,436] {logging_mixin.py:115} INFO - [2022-10-21 04:34:20,435] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:34:21,092] {logging_mixin.py:115} INFO - [2022-10-21 04:34:21,086] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:34:21,101] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:34:21,247] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.849 seconds
[2022-10-21 04:43:21,652] {processor.py:153} INFO - Started process (PID=77893) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:43:21,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:43:21,663] {logging_mixin.py:115} INFO - [2022-10-21 04:43:21,663] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:43:22,715] {logging_mixin.py:115} INFO - [2022-10-21 04:43:22,712] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:43:22,720] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:43:22,842] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.220 seconds
[2022-10-21 04:43:53,874] {processor.py:153} INFO - Started process (PID=77935) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:43:53,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:43:53,957] {logging_mixin.py:115} INFO - [2022-10-21 04:43:53,956] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:43:56,748] {logging_mixin.py:115} INFO - [2022-10-21 04:43:56,739] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:43:56,754] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:43:57,332] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.523 seconds
[2022-10-21 04:44:28,123] {processor.py:153} INFO - Started process (PID=77980) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:44:28,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:44:28,126] {logging_mixin.py:115} INFO - [2022-10-21 04:44:28,126] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:44:28,353] {logging_mixin.py:115} INFO - [2022-10-21 04:44:28,351] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:44:28,357] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:44:28,386] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.268 seconds
[2022-10-21 04:49:07,302] {processor.py:153} INFO - Started process (PID=78017) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:49:07,305] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:49:07,308] {logging_mixin.py:115} INFO - [2022-10-21 04:49:07,308] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:49:07,657] {logging_mixin.py:115} INFO - [2022-10-21 04:49:07,655] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:49:07,662] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:49:07,779] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.520 seconds
[2022-10-21 04:49:38,338] {processor.py:153} INFO - Started process (PID=78059) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:49:38,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:49:38,377] {logging_mixin.py:115} INFO - [2022-10-21 04:49:38,376] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:49:41,069] {logging_mixin.py:115} INFO - [2022-10-21 04:49:41,050] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:49:41,089] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:49:41,603] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.386 seconds
[2022-10-21 04:54:24,994] {processor.py:153} INFO - Started process (PID=78096) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:54:24,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:54:25,000] {logging_mixin.py:115} INFO - [2022-10-21 04:54:25,000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:54:25,264] {logging_mixin.py:115} INFO - [2022-10-21 04:54:25,263] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:54:25,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:54:25,307] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.319 seconds
[2022-10-21 04:54:56,089] {processor.py:153} INFO - Started process (PID=78140) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:54:56,095] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:54:56,115] {logging_mixin.py:115} INFO - [2022-10-21 04:54:56,115] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:54:58,619] {logging_mixin.py:115} INFO - [2022-10-21 04:54:58,616] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:54:58,643] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:54:58,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.886 seconds
[2022-10-21 04:55:29,270] {processor.py:153} INFO - Started process (PID=78189) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:55:29,277] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 04:55:29,290] {logging_mixin.py:115} INFO - [2022-10-21 04:55:29,288] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:55:30,263] {logging_mixin.py:115} INFO - [2022-10-21 04:55:30,258] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 04:55:30,275] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 04:55:30,518] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.274 seconds
[2022-10-21 05:00:12,627] {processor.py:153} INFO - Started process (PID=78219) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:00:12,638] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:00:12,643] {logging_mixin.py:115} INFO - [2022-10-21 05:00:12,643] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:00:13,417] {logging_mixin.py:115} INFO - [2022-10-21 05:00:13,413] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:00:13,456] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:00:13,569] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.988 seconds
[2022-10-21 05:00:44,365] {processor.py:153} INFO - Started process (PID=78261) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:00:44,372] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:00:44,383] {logging_mixin.py:115} INFO - [2022-10-21 05:00:44,383] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:00:47,312] {logging_mixin.py:115} INFO - [2022-10-21 05:00:47,303] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:00:47,333] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:00:47,719] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.484 seconds
[2022-10-21 05:05:29,592] {processor.py:153} INFO - Started process (PID=78298) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:05:29,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:05:29,595] {logging_mixin.py:115} INFO - [2022-10-21 05:05:29,595] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:05:29,890] {logging_mixin.py:115} INFO - [2022-10-21 05:05:29,889] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:05:29,892] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:05:29,941] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.354 seconds
[2022-10-21 05:06:00,532] {processor.py:153} INFO - Started process (PID=78343) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:06:00,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:06:00,545] {logging_mixin.py:115} INFO - [2022-10-21 05:06:00,545] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:06:01,875] {logging_mixin.py:115} INFO - [2022-10-21 05:06:01,859] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:06:01,888] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:06:02,160] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.692 seconds
[2022-10-21 05:06:32,555] {processor.py:153} INFO - Started process (PID=78378) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:06:32,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:06:32,570] {logging_mixin.py:115} INFO - [2022-10-21 05:06:32,569] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:06:33,159] {logging_mixin.py:115} INFO - [2022-10-21 05:06:33,154] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:06:33,174] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:06:33,294] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.766 seconds
[2022-10-21 05:11:19,213] {processor.py:153} INFO - Started process (PID=78423) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:11:19,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:11:19,216] {logging_mixin.py:115} INFO - [2022-10-21 05:11:19,216] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:11:19,789] {logging_mixin.py:115} INFO - [2022-10-21 05:11:19,787] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:11:19,793] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:11:19,886] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.714 seconds
[2022-10-21 05:11:50,429] {processor.py:153} INFO - Started process (PID=78458) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:11:50,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:11:50,445] {logging_mixin.py:115} INFO - [2022-10-21 05:11:50,444] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:11:51,182] {logging_mixin.py:115} INFO - [2022-10-21 05:11:51,166] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:11:51,197] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:11:51,629] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.223 seconds
[2022-10-21 05:16:35,305] {processor.py:153} INFO - Started process (PID=78501) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:16:35,308] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:16:35,310] {logging_mixin.py:115} INFO - [2022-10-21 05:16:35,310] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:16:35,592] {logging_mixin.py:115} INFO - [2022-10-21 05:16:35,590] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:16:35,594] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:16:35,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.335 seconds
[2022-10-21 05:17:06,755] {processor.py:153} INFO - Started process (PID=78544) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:17:06,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:17:06,784] {logging_mixin.py:115} INFO - [2022-10-21 05:17:06,784] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:17:08,557] {logging_mixin.py:115} INFO - [2022-10-21 05:17:08,551] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:17:08,589] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:17:08,858] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.200 seconds
[2022-10-21 05:17:39,479] {processor.py:153} INFO - Started process (PID=78581) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:17:39,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:17:39,495] {logging_mixin.py:115} INFO - [2022-10-21 05:17:39,495] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:17:40,705] {logging_mixin.py:115} INFO - [2022-10-21 05:17:40,671] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:17:40,722] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:17:40,969] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.534 seconds
[2022-10-21 05:22:24,517] {processor.py:153} INFO - Started process (PID=78625) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:22:24,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:22:24,552] {logging_mixin.py:115} INFO - [2022-10-21 05:22:24,552] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:22:26,840] {logging_mixin.py:115} INFO - [2022-10-21 05:22:26,839] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:22:26,849] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:22:26,975] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.625 seconds
[2022-10-21 05:22:57,241] {processor.py:153} INFO - Started process (PID=78660) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:22:57,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:22:57,272] {logging_mixin.py:115} INFO - [2022-10-21 05:22:57,271] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:22:58,360] {logging_mixin.py:115} INFO - [2022-10-21 05:22:58,349] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:22:58,369] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:22:58,649] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.454 seconds
[2022-10-21 05:27:42,602] {processor.py:153} INFO - Started process (PID=78704) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:27:42,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:27:42,613] {logging_mixin.py:115} INFO - [2022-10-21 05:27:42,612] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:27:43,121] {logging_mixin.py:115} INFO - [2022-10-21 05:27:43,120] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:27:43,125] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:27:43,240] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.644 seconds
[2022-10-21 05:28:13,593] {processor.py:153} INFO - Started process (PID=78739) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:28:13,636] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:28:13,658] {logging_mixin.py:115} INFO - [2022-10-21 05:28:13,657] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:28:15,196] {logging_mixin.py:115} INFO - [2022-10-21 05:28:15,180] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:28:15,212] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:28:15,554] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.077 seconds
[2022-10-21 05:28:45,804] {processor.py:153} INFO - Started process (PID=78784) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:28:45,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:28:45,822] {logging_mixin.py:115} INFO - [2022-10-21 05:28:45,820] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:28:46,419] {logging_mixin.py:115} INFO - [2022-10-21 05:28:46,415] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:28:46,426] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:28:46,553] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.775 seconds
[2022-10-21 05:33:31,552] {processor.py:153} INFO - Started process (PID=78828) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:33:31,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:33:31,568] {logging_mixin.py:115} INFO - [2022-10-21 05:33:31,567] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:33:33,597] {logging_mixin.py:115} INFO - [2022-10-21 05:33:33,578] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:33:33,664] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:33:34,164] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.688 seconds
[2022-10-21 05:34:04,624] {processor.py:153} INFO - Started process (PID=78862) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:34:04,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:34:04,641] {logging_mixin.py:115} INFO - [2022-10-21 05:34:04,640] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:34:05,542] {logging_mixin.py:115} INFO - [2022-10-21 05:34:05,535] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:34:05,564] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:34:05,736] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.153 seconds
[2022-10-21 05:34:35,956] {processor.py:153} INFO - Started process (PID=78907) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:34:35,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:34:35,960] {logging_mixin.py:115} INFO - [2022-10-21 05:34:35,960] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:34:36,159] {logging_mixin.py:115} INFO - [2022-10-21 05:34:36,158] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:34:36,162] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:34:36,193] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.241 seconds
[2022-10-21 05:39:17,694] {processor.py:153} INFO - Started process (PID=78941) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:39:17,703] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:39:17,708] {logging_mixin.py:115} INFO - [2022-10-21 05:39:17,708] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:39:18,036] {logging_mixin.py:115} INFO - [2022-10-21 05:39:18,034] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:39:18,040] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:39:18,142] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.470 seconds
[2022-10-21 05:39:48,732] {processor.py:153} INFO - Started process (PID=78985) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:39:48,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:39:48,778] {logging_mixin.py:115} INFO - [2022-10-21 05:39:48,774] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:39:51,056] {logging_mixin.py:115} INFO - [2022-10-21 05:39:51,047] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:39:51,066] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:39:51,335] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.728 seconds
[2022-10-21 05:48:54,850] {processor.py:153} INFO - Started process (PID=79025) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:48:54,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:48:54,877] {logging_mixin.py:115} INFO - [2022-10-21 05:48:54,876] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:48:56,528] {logging_mixin.py:115} INFO - [2022-10-21 05:48:56,507] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:48:56,551] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:48:56,912] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.139 seconds
[2022-10-21 05:49:27,391] {processor.py:153} INFO - Started process (PID=79060) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:49:27,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:49:27,410] {logging_mixin.py:115} INFO - [2022-10-21 05:49:27,409] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:49:30,301] {logging_mixin.py:115} INFO - [2022-10-21 05:49:30,291] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:49:30,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:49:30,761] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.432 seconds
[2022-10-21 05:50:01,449] {processor.py:153} INFO - Started process (PID=79105) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:50:01,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:50:01,474] {logging_mixin.py:115} INFO - [2022-10-21 05:50:01,474] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:50:03,269] {logging_mixin.py:115} INFO - [2022-10-21 05:50:03,265] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:50:03,292] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:50:03,426] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.044 seconds
[2022-10-21 05:59:00,122] {processor.py:153} INFO - Started process (PID=79136) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:59:00,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:59:00,186] {logging_mixin.py:115} INFO - [2022-10-21 05:59:00,186] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:59:02,698] {logging_mixin.py:115} INFO - [2022-10-21 05:59:02,692] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:59:02,707] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:59:02,931] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.998 seconds
[2022-10-21 05:59:36,835] {processor.py:153} INFO - Started process (PID=79186) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:59:36,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 05:59:36,861] {logging_mixin.py:115} INFO - [2022-10-21 05:59:36,860] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:59:37,896] {logging_mixin.py:115} INFO - [2022-10-21 05:59:37,885] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 05:59:37,916] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 05:59:38,231] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.454 seconds
[2022-10-21 06:00:08,812] {processor.py:153} INFO - Started process (PID=79229) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:00:08,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:00:08,817] {logging_mixin.py:115} INFO - [2022-10-21 06:00:08,817] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:00:09,015] {logging_mixin.py:115} INFO - [2022-10-21 06:00:09,014] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:00:09,017] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:00:09,047] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.240 seconds
[2022-10-21 06:04:45,784] {processor.py:153} INFO - Started process (PID=79255) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:04:45,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:04:45,793] {logging_mixin.py:115} INFO - [2022-10-21 06:04:45,793] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:04:46,198] {logging_mixin.py:115} INFO - [2022-10-21 06:04:46,196] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:04:46,209] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:04:46,334] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.574 seconds
[2022-10-21 06:05:17,022] {processor.py:153} INFO - Started process (PID=79300) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:05:17,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:05:17,042] {logging_mixin.py:115} INFO - [2022-10-21 06:05:17,042] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:05:18,638] {logging_mixin.py:115} INFO - [2022-10-21 06:05:18,634] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:05:18,649] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:05:19,106] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.159 seconds
[2022-10-21 06:10:04,550] {processor.py:153} INFO - Started process (PID=79342) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:10:04,567] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:10:04,598] {logging_mixin.py:115} INFO - [2022-10-21 06:10:04,597] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:10:06,690] {logging_mixin.py:115} INFO - [2022-10-21 06:10:06,687] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:10:06,713] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:10:07,257] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.876 seconds
[2022-10-21 06:10:38,618] {processor.py:153} INFO - Started process (PID=79379) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:10:38,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:10:38,669] {logging_mixin.py:115} INFO - [2022-10-21 06:10:38,668] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:10:40,089] {logging_mixin.py:115} INFO - [2022-10-21 06:10:40,070] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:10:40,099] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:10:40,287] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.748 seconds
[2022-10-21 06:11:10,432] {processor.py:153} INFO - Started process (PID=79422) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:11:10,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:11:10,434] {logging_mixin.py:115} INFO - [2022-10-21 06:11:10,434] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:11:10,631] {logging_mixin.py:115} INFO - [2022-10-21 06:11:10,630] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:11:10,633] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:11:10,664] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.236 seconds
[2022-10-21 06:15:52,540] {processor.py:153} INFO - Started process (PID=79459) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:15:52,550] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:15:52,562] {logging_mixin.py:115} INFO - [2022-10-21 06:15:52,560] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:15:53,421] {logging_mixin.py:115} INFO - [2022-10-21 06:15:53,417] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:15:53,484] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:15:53,977] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.485 seconds
[2022-10-21 06:16:29,212] {processor.py:153} INFO - Started process (PID=79511) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:16:29,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:16:29,252] {logging_mixin.py:115} INFO - [2022-10-21 06:16:29,243] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:16:32,434] {logging_mixin.py:115} INFO - [2022-10-21 06:16:32,410] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:16:32,471] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:16:33,079] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.007 seconds
[2022-10-21 06:17:03,570] {processor.py:153} INFO - Started process (PID=79554) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:17:03,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:17:03,575] {logging_mixin.py:115} INFO - [2022-10-21 06:17:03,574] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:17:03,780] {logging_mixin.py:115} INFO - [2022-10-21 06:17:03,778] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:17:03,783] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:17:03,812] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.247 seconds
[2022-10-21 06:21:39,991] {processor.py:153} INFO - Started process (PID=79572) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:21:39,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:21:40,005] {logging_mixin.py:115} INFO - [2022-10-21 06:21:40,004] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:21:40,575] {logging_mixin.py:115} INFO - [2022-10-21 06:21:40,572] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:21:40,583] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:21:40,715] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.756 seconds
[2022-10-21 06:22:11,537] {processor.py:153} INFO - Started process (PID=79617) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:22:11,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:22:11,559] {logging_mixin.py:115} INFO - [2022-10-21 06:22:11,559] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:22:13,623] {logging_mixin.py:115} INFO - [2022-10-21 06:22:13,616] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:22:13,633] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:22:14,144] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.733 seconds
[2022-10-21 06:26:57,802] {processor.py:153} INFO - Started process (PID=79652) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:26:57,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:26:57,827] {logging_mixin.py:115} INFO - [2022-10-21 06:26:57,827] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:27:00,230] {logging_mixin.py:115} INFO - [2022-10-21 06:27:00,226] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:27:00,240] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:27:00,485] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.761 seconds
[2022-10-21 06:27:31,265] {processor.py:153} INFO - Started process (PID=79695) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:27:31,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:27:31,281] {logging_mixin.py:115} INFO - [2022-10-21 06:27:31,280] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:27:32,661] {logging_mixin.py:115} INFO - [2022-10-21 06:27:32,658] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:27:32,670] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:27:32,978] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.744 seconds
[2022-10-21 06:28:03,287] {processor.py:153} INFO - Started process (PID=79738) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:28:03,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:28:03,291] {logging_mixin.py:115} INFO - [2022-10-21 06:28:03,290] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:28:03,531] {logging_mixin.py:115} INFO - [2022-10-21 06:28:03,530] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:28:03,535] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:28:03,570] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.290 seconds
[2022-10-21 06:37:03,065] {processor.py:153} INFO - Started process (PID=79775) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:37:03,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:37:03,070] {logging_mixin.py:115} INFO - [2022-10-21 06:37:03,070] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:37:03,416] {logging_mixin.py:115} INFO - [2022-10-21 06:37:03,414] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:37:03,419] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:37:03,475] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.426 seconds
[2022-10-21 06:37:34,304] {processor.py:153} INFO - Started process (PID=79818) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:37:34,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:37:34,323] {logging_mixin.py:115} INFO - [2022-10-21 06:37:34,322] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:37:36,839] {logging_mixin.py:115} INFO - [2022-10-21 06:37:36,830] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:37:36,851] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:37:37,103] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.903 seconds
[2022-10-21 06:42:19,771] {processor.py:153} INFO - Started process (PID=79854) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:42:19,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:42:19,774] {logging_mixin.py:115} INFO - [2022-10-21 06:42:19,773] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:42:20,037] {logging_mixin.py:115} INFO - [2022-10-21 06:42:20,036] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:42:20,039] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:42:20,071] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.308 seconds
[2022-10-21 06:42:50,865] {processor.py:153} INFO - Started process (PID=79898) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:42:50,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:42:50,918] {logging_mixin.py:115} INFO - [2022-10-21 06:42:50,916] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:42:53,073] {logging_mixin.py:115} INFO - [2022-10-21 06:42:53,065] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:42:53,102] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:42:53,623] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.794 seconds
[2022-10-21 06:43:24,018] {processor.py:153} INFO - Started process (PID=79940) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:43:24,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:43:24,041] {logging_mixin.py:115} INFO - [2022-10-21 06:43:24,040] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:43:25,049] {logging_mixin.py:115} INFO - [2022-10-21 06:43:25,045] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:43:25,074] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:43:25,222] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.245 seconds
[2022-10-21 06:48:06,719] {processor.py:153} INFO - Started process (PID=79977) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:48:06,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:48:06,724] {logging_mixin.py:115} INFO - [2022-10-21 06:48:06,724] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:48:07,011] {logging_mixin.py:115} INFO - [2022-10-21 06:48:07,010] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:48:07,015] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:48:07,108] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.402 seconds
[2022-10-21 06:48:37,727] {processor.py:153} INFO - Started process (PID=80020) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:48:37,758] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:48:37,773] {logging_mixin.py:115} INFO - [2022-10-21 06:48:37,772] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:48:40,883] {logging_mixin.py:115} INFO - [2022-10-21 06:48:40,869] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:48:40,909] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:48:41,336] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.775 seconds
[2022-10-21 06:53:25,331] {processor.py:153} INFO - Started process (PID=80057) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:53:25,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:53:25,335] {logging_mixin.py:115} INFO - [2022-10-21 06:53:25,334] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:53:25,614] {logging_mixin.py:115} INFO - [2022-10-21 06:53:25,614] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:53:25,617] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:53:25,664] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.343 seconds
[2022-10-21 06:53:56,743] {processor.py:153} INFO - Started process (PID=80101) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:53:56,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:53:56,762] {logging_mixin.py:115} INFO - [2022-10-21 06:53:56,761] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:53:57,924] {logging_mixin.py:115} INFO - [2022-10-21 06:53:57,920] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:53:57,947] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:53:58,160] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.474 seconds
[2022-10-21 06:54:28,605] {processor.py:153} INFO - Started process (PID=80135) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:54:28,611] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:54:28,618] {logging_mixin.py:115} INFO - [2022-10-21 06:54:28,617] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:54:29,227] {logging_mixin.py:115} INFO - [2022-10-21 06:54:29,224] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:54:29,233] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:54:29,356] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.772 seconds
[2022-10-21 06:59:13,323] {processor.py:153} INFO - Started process (PID=80180) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:59:13,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:59:13,341] {logging_mixin.py:115} INFO - [2022-10-21 06:59:13,339] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:59:13,922] {logging_mixin.py:115} INFO - [2022-10-21 06:59:13,921] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:59:13,927] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:59:14,082] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.807 seconds
[2022-10-21 06:59:44,733] {processor.py:153} INFO - Started process (PID=80215) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:59:44,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 06:59:44,757] {logging_mixin.py:115} INFO - [2022-10-21 06:59:44,756] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:59:48,342] {logging_mixin.py:115} INFO - [2022-10-21 06:59:48,337] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 06:59:48,375] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 06:59:48,844] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.225 seconds
[2022-10-21 07:04:30,218] {processor.py:153} INFO - Started process (PID=80260) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:04:30,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:04:30,223] {logging_mixin.py:115} INFO - [2022-10-21 07:04:30,223] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:04:30,468] {logging_mixin.py:115} INFO - [2022-10-21 07:04:30,467] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:04:30,469] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:04:30,499] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.290 seconds
[2022-10-21 07:05:00,906] {processor.py:153} INFO - Started process (PID=80305) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:05:00,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:05:00,943] {logging_mixin.py:115} INFO - [2022-10-21 07:05:00,943] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:05:02,660] {logging_mixin.py:115} INFO - [2022-10-21 07:05:02,641] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:05:02,686] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:05:02,819] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.968 seconds
[2022-10-21 07:05:33,021] {processor.py:153} INFO - Started process (PID=80340) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:05:33,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:05:33,038] {logging_mixin.py:115} INFO - [2022-10-21 07:05:33,038] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:05:33,742] {logging_mixin.py:115} INFO - [2022-10-21 07:05:33,738] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:05:33,749] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:05:33,906] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.913 seconds
[2022-10-21 07:10:19,208] {processor.py:153} INFO - Started process (PID=80384) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:10:19,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:10:19,242] {logging_mixin.py:115} INFO - [2022-10-21 07:10:19,235] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:10:19,946] {logging_mixin.py:115} INFO - [2022-10-21 07:10:19,945] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:10:19,951] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:10:20,117] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.059 seconds
[2022-10-21 07:10:50,889] {processor.py:153} INFO - Started process (PID=80419) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:10:50,907] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:10:50,959] {logging_mixin.py:115} INFO - [2022-10-21 07:10:50,958] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:10:53,502] {logging_mixin.py:115} INFO - [2022-10-21 07:10:53,495] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:10:53,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:10:53,819] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.184 seconds
[2022-10-21 07:15:34,375] {processor.py:153} INFO - Started process (PID=80462) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:15:34,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:15:34,379] {logging_mixin.py:115} INFO - [2022-10-21 07:15:34,379] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:15:34,660] {logging_mixin.py:115} INFO - [2022-10-21 07:15:34,658] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:15:34,662] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:15:35,193] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.831 seconds
[2022-10-21 07:16:05,770] {processor.py:153} INFO - Started process (PID=80497) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:16:05,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:16:05,778] {logging_mixin.py:115} INFO - [2022-10-21 07:16:05,777] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:16:06,139] {logging_mixin.py:115} INFO - [2022-10-21 07:16:06,137] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:16:06,145] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:16:06,208] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.450 seconds
[2022-10-21 07:16:36,650] {processor.py:153} INFO - Started process (PID=80541) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:16:36,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:16:36,661] {logging_mixin.py:115} INFO - [2022-10-21 07:16:36,661] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:16:37,126] {logging_mixin.py:115} INFO - [2022-10-21 07:16:37,120] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:16:37,130] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:16:37,208] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.574 seconds
[2022-10-21 07:21:24,926] {processor.py:153} INFO - Started process (PID=80592) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:21:24,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:21:24,962] {logging_mixin.py:115} INFO - [2022-10-21 07:21:24,962] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:21:26,800] {logging_mixin.py:115} INFO - [2022-10-21 07:21:26,794] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:21:26,826] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:21:27,360] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.524 seconds
[2022-10-21 07:21:58,864] {processor.py:153} INFO - Started process (PID=80630) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:21:58,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:21:58,888] {logging_mixin.py:115} INFO - [2022-10-21 07:21:58,888] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:22:00,929] {logging_mixin.py:115} INFO - [2022-10-21 07:22:00,925] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:22:00,945] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:22:01,142] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.354 seconds
[2022-10-21 07:22:31,407] {processor.py:153} INFO - Started process (PID=80675) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:22:31,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:22:31,413] {logging_mixin.py:115} INFO - [2022-10-21 07:22:31,413] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:22:31,627] {logging_mixin.py:115} INFO - [2022-10-21 07:22:31,626] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:22:31,629] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:22:31,675] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.272 seconds
[2022-10-21 07:27:12,723] {processor.py:153} INFO - Started process (PID=80709) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:27:12,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:27:12,774] {logging_mixin.py:115} INFO - [2022-10-21 07:27:12,774] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:27:13,475] {logging_mixin.py:115} INFO - [2022-10-21 07:27:13,471] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:27:13,481] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:27:13,672] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.990 seconds
[2022-10-21 07:27:44,278] {processor.py:153} INFO - Started process (PID=80753) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:27:44,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:27:44,298] {logging_mixin.py:115} INFO - [2022-10-21 07:27:44,298] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:27:46,648] {logging_mixin.py:115} INFO - [2022-10-21 07:27:46,636] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:27:46,667] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:27:46,913] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.717 seconds
[2022-10-21 07:32:30,687] {processor.py:153} INFO - Started process (PID=80788) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:32:30,704] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:32:30,728] {logging_mixin.py:115} INFO - [2022-10-21 07:32:30,727] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:32:32,639] {logging_mixin.py:115} INFO - [2022-10-21 07:32:32,621] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:32:32,654] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:32:32,934] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.354 seconds
[2022-10-21 07:33:03,297] {processor.py:153} INFO - Started process (PID=80830) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:33:03,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:33:03,303] {logging_mixin.py:115} INFO - [2022-10-21 07:33:03,303] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:33:03,638] {logging_mixin.py:115} INFO - [2022-10-21 07:33:03,636] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:33:03,642] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:33:03,702] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.416 seconds
[2022-10-21 07:33:34,161] {processor.py:153} INFO - Started process (PID=80876) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:33:34,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:33:34,167] {logging_mixin.py:115} INFO - [2022-10-21 07:33:34,167] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:33:34,420] {logging_mixin.py:115} INFO - [2022-10-21 07:33:34,418] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:33:34,425] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:33:35,285] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.131 seconds
[2022-10-21 07:38:21,481] {processor.py:153} INFO - Started process (PID=80920) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:38:21,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:38:21,509] {logging_mixin.py:115} INFO - [2022-10-21 07:38:21,508] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:38:23,245] {logging_mixin.py:115} INFO - [2022-10-21 07:38:23,211] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:38:23,279] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:38:23,639] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.248 seconds
[2022-10-21 07:38:54,483] {processor.py:153} INFO - Started process (PID=80964) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:38:54,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:38:54,522] {logging_mixin.py:115} INFO - [2022-10-21 07:38:54,514] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:38:57,161] {logging_mixin.py:115} INFO - [2022-10-21 07:38:57,089] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:38:57,180] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:38:57,526] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.178 seconds
[2022-10-21 07:39:28,455] {processor.py:153} INFO - Started process (PID=81008) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:39:28,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:39:28,491] {logging_mixin.py:115} INFO - [2022-10-21 07:39:28,490] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:39:31,223] {logging_mixin.py:115} INFO - [2022-10-21 07:39:31,212] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:39:31,246] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:39:31,599] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.236 seconds
[2022-10-21 07:40:01,887] {processor.py:153} INFO - Started process (PID=81043) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:40:01,895] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:40:01,902] {logging_mixin.py:115} INFO - [2022-10-21 07:40:01,902] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:40:02,490] {logging_mixin.py:115} INFO - [2022-10-21 07:40:02,486] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:40:02,496] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:40:02,655] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.809 seconds
[2022-10-21 07:40:34,470] {processor.py:153} INFO - Started process (PID=81094) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:40:34,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:40:34,492] {logging_mixin.py:115} INFO - [2022-10-21 07:40:34,492] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:40:35,412] {logging_mixin.py:115} INFO - [2022-10-21 07:40:35,408] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:40:35,421] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:40:35,555] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.114 seconds
[2022-10-21 07:41:06,969] {processor.py:153} INFO - Started process (PID=81136) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:41:06,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:41:07,000] {logging_mixin.py:115} INFO - [2022-10-21 07:41:06,999] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:41:08,201] {logging_mixin.py:115} INFO - [2022-10-21 07:41:08,197] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:41:08,208] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:41:08,520] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.582 seconds
[2022-10-21 07:41:39,278] {processor.py:153} INFO - Started process (PID=81169) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:41:39,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:41:39,290] {logging_mixin.py:115} INFO - [2022-10-21 07:41:39,289] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:41:40,262] {logging_mixin.py:115} INFO - [2022-10-21 07:41:40,258] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:41:40,292] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:41:40,484] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.233 seconds
[2022-10-21 07:42:10,964] {processor.py:153} INFO - Started process (PID=81213) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:42:10,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:42:10,983] {logging_mixin.py:115} INFO - [2022-10-21 07:42:10,982] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:42:11,832] {logging_mixin.py:115} INFO - [2022-10-21 07:42:11,827] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:42:11,843] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:42:12,089] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.148 seconds
[2022-10-21 07:42:42,672] {processor.py:153} INFO - Started process (PID=81255) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:42:42,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:42:42,697] {logging_mixin.py:115} INFO - [2022-10-21 07:42:42,694] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:42:43,780] {logging_mixin.py:115} INFO - [2022-10-21 07:42:43,776] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:42:43,801] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:42:43,969] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.329 seconds
[2022-10-21 07:43:14,613] {processor.py:153} INFO - Started process (PID=81290) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:43:14,621] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:43:14,631] {logging_mixin.py:115} INFO - [2022-10-21 07:43:14,630] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:43:15,301] {logging_mixin.py:115} INFO - [2022-10-21 07:43:15,297] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:43:15,309] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:43:15,433] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.864 seconds
[2022-10-21 07:43:46,024] {processor.py:153} INFO - Started process (PID=81333) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:43:46,047] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:43:46,059] {logging_mixin.py:115} INFO - [2022-10-21 07:43:46,058] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:43:46,715] {logging_mixin.py:115} INFO - [2022-10-21 07:43:46,709] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:43:46,723] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:43:46,883] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.924 seconds
[2022-10-21 07:44:17,192] {processor.py:153} INFO - Started process (PID=81379) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:44:17,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:44:17,210] {logging_mixin.py:115} INFO - [2022-10-21 07:44:17,209] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:44:18,029] {logging_mixin.py:115} INFO - [2022-10-21 07:44:18,025] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:44:18,041] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:44:18,178] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.010 seconds
[2022-10-21 07:44:48,507] {processor.py:153} INFO - Started process (PID=81414) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:44:48,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:44:48,521] {logging_mixin.py:115} INFO - [2022-10-21 07:44:48,521] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:44:49,122] {logging_mixin.py:115} INFO - [2022-10-21 07:44:49,117] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:44:49,132] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:44:49,289] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.805 seconds
[2022-10-21 07:45:19,585] {processor.py:153} INFO - Started process (PID=81457) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:45:19,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:45:19,603] {logging_mixin.py:115} INFO - [2022-10-21 07:45:19,602] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:45:20,310] {logging_mixin.py:115} INFO - [2022-10-21 07:45:20,307] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:45:20,321] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:45:20,450] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.905 seconds
[2022-10-21 07:45:53,494] {processor.py:153} INFO - Started process (PID=81501) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:45:53,510] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:45:53,519] {logging_mixin.py:115} INFO - [2022-10-21 07:45:53,518] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:45:54,654] {logging_mixin.py:115} INFO - [2022-10-21 07:45:54,650] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:45:54,673] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:45:54,956] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.497 seconds
[2022-10-21 07:46:25,791] {processor.py:153} INFO - Started process (PID=81534) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:46:25,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:46:25,804] {logging_mixin.py:115} INFO - [2022-10-21 07:46:25,804] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:46:26,902] {logging_mixin.py:115} INFO - [2022-10-21 07:46:26,861] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:46:26,923] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:46:27,121] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.355 seconds
[2022-10-21 07:46:57,423] {processor.py:153} INFO - Started process (PID=81578) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:46:57,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:46:57,443] {logging_mixin.py:115} INFO - [2022-10-21 07:46:57,442] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:46:58,029] {logging_mixin.py:115} INFO - [2022-10-21 07:46:58,025] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:46:58,036] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:46:58,156] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.765 seconds
[2022-10-21 07:47:28,747] {processor.py:153} INFO - Started process (PID=81623) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:47:28,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:47:28,762] {logging_mixin.py:115} INFO - [2022-10-21 07:47:28,761] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:47:30,287] {logging_mixin.py:115} INFO - [2022-10-21 07:47:30,282] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:47:30,295] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:47:30,605] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.903 seconds
[2022-10-21 07:48:00,876] {processor.py:153} INFO - Started process (PID=81657) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:48:00,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:48:00,887] {logging_mixin.py:115} INFO - [2022-10-21 07:48:00,886] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:48:01,452] {logging_mixin.py:115} INFO - [2022-10-21 07:48:01,449] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:48:01,460] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:48:01,617] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.764 seconds
[2022-10-21 07:48:31,902] {processor.py:153} INFO - Started process (PID=81702) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:48:31,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 07:48:31,915] {logging_mixin.py:115} INFO - [2022-10-21 07:48:31,915] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:48:32,572] {logging_mixin.py:115} INFO - [2022-10-21 07:48:32,568] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 07:48:32,580] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 07:48:32,715] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.839 seconds
[2022-10-21 08:35:42,571] {processor.py:153} INFO - Started process (PID=81725) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:35:42,590] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:35:42,633] {logging_mixin.py:115} INFO - [2022-10-21 08:35:42,632] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:35:45,609] {logging_mixin.py:115} INFO - [2022-10-21 08:35:45,592] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:35:45,655] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:35:46,374] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.908 seconds
[2022-10-21 08:36:20,832] {processor.py:153} INFO - Started process (PID=81776) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:36:20,846] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:36:20,873] {logging_mixin.py:115} INFO - [2022-10-21 08:36:20,872] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:36:24,340] {logging_mixin.py:115} INFO - [2022-10-21 08:36:24,323] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:36:24,351] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:36:24,740] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.014 seconds
[2022-10-21 08:36:55,570] {processor.py:153} INFO - Started process (PID=81816) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:36:55,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:36:55,632] {logging_mixin.py:115} INFO - [2022-10-21 08:36:55,632] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:36:59,426] {logging_mixin.py:115} INFO - [2022-10-21 08:36:59,416] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:36:59,442] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:36:59,841] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.373 seconds
[2022-10-21 08:37:30,432] {processor.py:153} INFO - Started process (PID=81861) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:37:30,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:37:30,463] {logging_mixin.py:115} INFO - [2022-10-21 08:37:30,462] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:37:31,408] {logging_mixin.py:115} INFO - [2022-10-21 08:37:31,404] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:37:31,426] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:37:31,675] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.273 seconds
[2022-10-21 08:38:02,336] {processor.py:153} INFO - Started process (PID=81897) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:38:02,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:38:02,354] {logging_mixin.py:115} INFO - [2022-10-21 08:38:02,353] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:38:03,279] {logging_mixin.py:115} INFO - [2022-10-21 08:38:03,275] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:38:03,287] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:38:03,437] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.137 seconds
[2022-10-21 08:38:33,773] {processor.py:153} INFO - Started process (PID=81941) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:38:33,785] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:38:33,792] {logging_mixin.py:115} INFO - [2022-10-21 08:38:33,792] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:38:34,959] {logging_mixin.py:115} INFO - [2022-10-21 08:38:34,955] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:38:34,983] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:38:35,136] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.391 seconds
[2022-10-21 08:39:05,674] {processor.py:153} INFO - Started process (PID=81974) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:39:05,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:39:05,687] {logging_mixin.py:115} INFO - [2022-10-21 08:39:05,686] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:39:06,499] {logging_mixin.py:115} INFO - [2022-10-21 08:39:06,494] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:39:06,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:39:06,827] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.175 seconds
[2022-10-21 08:39:37,133] {processor.py:153} INFO - Started process (PID=82018) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:39:37,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:39:37,147] {logging_mixin.py:115} INFO - [2022-10-21 08:39:37,147] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:39:37,746] {logging_mixin.py:115} INFO - [2022-10-21 08:39:37,742] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:39:37,759] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:39:37,880] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.769 seconds
[2022-10-21 08:40:08,993] {processor.py:153} INFO - Started process (PID=82060) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:40:09,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:40:09,010] {logging_mixin.py:115} INFO - [2022-10-21 08:40:09,010] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:40:09,954] {logging_mixin.py:115} INFO - [2022-10-21 08:40:09,950] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:40:09,969] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:40:10,114] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.145 seconds
[2022-10-21 08:40:40,990] {processor.py:153} INFO - Started process (PID=82095) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:40:40,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:40:41,005] {logging_mixin.py:115} INFO - [2022-10-21 08:40:41,004] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:40:41,817] {logging_mixin.py:115} INFO - [2022-10-21 08:40:41,813] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:40:41,839] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:40:41,981] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.016 seconds
[2022-10-21 08:41:12,593] {processor.py:153} INFO - Started process (PID=82140) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:41:12,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:41:12,613] {logging_mixin.py:115} INFO - [2022-10-21 08:41:12,613] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:41:13,206] {logging_mixin.py:115} INFO - [2022-10-21 08:41:13,202] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:41:13,215] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:41:13,348] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.784 seconds
[2022-10-21 08:41:43,859] {processor.py:153} INFO - Started process (PID=82184) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:41:43,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:41:43,892] {logging_mixin.py:115} INFO - [2022-10-21 08:41:43,889] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:41:44,741] {logging_mixin.py:115} INFO - [2022-10-21 08:41:44,738] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:41:44,748] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:41:44,912] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.075 seconds
[2022-10-21 08:42:15,268] {processor.py:153} INFO - Started process (PID=82219) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:42:15,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:42:15,281] {logging_mixin.py:115} INFO - [2022-10-21 08:42:15,280] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:42:15,899] {logging_mixin.py:115} INFO - [2022-10-21 08:42:15,895] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:42:15,908] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:42:16,037] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.791 seconds
[2022-10-21 08:42:46,363] {processor.py:153} INFO - Started process (PID=82263) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:42:46,370] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:42:46,380] {logging_mixin.py:115} INFO - [2022-10-21 08:42:46,379] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:42:47,034] {logging_mixin.py:115} INFO - [2022-10-21 08:42:47,027] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:42:47,042] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:42:47,188] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.847 seconds
[2022-10-21 08:43:18,172] {processor.py:153} INFO - Started process (PID=82308) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:43:18,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:43:18,192] {logging_mixin.py:115} INFO - [2022-10-21 08:43:18,191] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:43:18,975] {logging_mixin.py:115} INFO - [2022-10-21 08:43:18,971] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:43:18,995] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:43:19,173] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.036 seconds
[2022-10-21 08:52:10,339] {processor.py:153} INFO - Started process (PID=82331) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:52:10,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:52:10,341] {logging_mixin.py:115} INFO - [2022-10-21 08:52:10,341] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:52:10,563] {logging_mixin.py:115} INFO - [2022-10-21 08:52:10,561] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:52:10,567] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:52:10,612] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.281 seconds
[2022-10-21 08:52:40,912] {processor.py:153} INFO - Started process (PID=82376) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:52:40,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:52:40,919] {logging_mixin.py:115} INFO - [2022-10-21 08:52:40,919] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:52:41,333] {logging_mixin.py:115} INFO - [2022-10-21 08:52:41,331] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:52:41,340] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:52:41,424] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.533 seconds
[2022-10-21 08:53:11,776] {processor.py:153} INFO - Started process (PID=82420) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:53:11,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 08:53:11,791] {logging_mixin.py:115} INFO - [2022-10-21 08:53:11,790] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:53:12,363] {logging_mixin.py:115} INFO - [2022-10-21 08:53:12,359] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 08:53:12,368] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 08:53:12,446] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.719 seconds
[2022-10-21 09:02:17,778] {processor.py:153} INFO - Started process (PID=82464) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:02:17,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:02:17,831] {logging_mixin.py:115} INFO - [2022-10-21 09:02:17,830] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:02:18,610] {logging_mixin.py:115} INFO - [2022-10-21 09:02:18,609] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:02:18,615] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:02:18,736] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.047 seconds
[2022-10-21 09:02:49,714] {processor.py:153} INFO - Started process (PID=82499) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:02:49,729] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:02:49,735] {logging_mixin.py:115} INFO - [2022-10-21 09:02:49,734] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:02:51,165] {logging_mixin.py:115} INFO - [2022-10-21 09:02:51,157] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:02:51,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:02:51,375] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.857 seconds
[2022-10-21 09:11:53,482] {processor.py:153} INFO - Started process (PID=82542) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:11:53,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:11:53,490] {logging_mixin.py:115} INFO - [2022-10-21 09:11:53,490] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:11:53,798] {logging_mixin.py:115} INFO - [2022-10-21 09:11:53,797] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:11:53,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:11:53,846] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.379 seconds
[2022-10-21 09:12:24,463] {processor.py:153} INFO - Started process (PID=82586) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:12:24,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:12:24,479] {logging_mixin.py:115} INFO - [2022-10-21 09:12:24,479] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:12:25,052] {logging_mixin.py:115} INFO - [2022-10-21 09:12:25,050] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:12:25,057] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:12:25,167] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.774 seconds
[2022-10-21 09:12:55,389] {processor.py:153} INFO - Started process (PID=82621) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:12:55,394] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:12:55,399] {logging_mixin.py:115} INFO - [2022-10-21 09:12:55,398] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:12:55,817] {logging_mixin.py:115} INFO - [2022-10-21 09:12:55,814] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:12:55,825] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:12:55,927] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.554 seconds
[2022-10-21 09:17:42,558] {processor.py:153} INFO - Started process (PID=82665) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:17:42,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:17:42,571] {logging_mixin.py:115} INFO - [2022-10-21 09:17:42,570] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:17:45,033] {logging_mixin.py:115} INFO - [2022-10-21 09:17:45,014] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:17:45,069] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:17:45,327] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.801 seconds
[2022-10-21 09:18:15,899] {processor.py:153} INFO - Started process (PID=82709) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:18:15,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:18:15,929] {logging_mixin.py:115} INFO - [2022-10-21 09:18:15,928] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:18:16,668] {logging_mixin.py:115} INFO - [2022-10-21 09:18:16,664] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:18:16,680] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:18:16,827] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.956 seconds
[2022-10-21 09:18:47,719] {processor.py:153} INFO - Started process (PID=82754) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:18:47,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:18:47,722] {logging_mixin.py:115} INFO - [2022-10-21 09:18:47,722] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:18:47,921] {logging_mixin.py:115} INFO - [2022-10-21 09:18:47,920] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:18:47,923] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:18:47,953] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.241 seconds
[2022-10-21 09:23:29,658] {processor.py:153} INFO - Started process (PID=82789) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:23:29,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:23:29,663] {logging_mixin.py:115} INFO - [2022-10-21 09:23:29,662] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:23:29,996] {logging_mixin.py:115} INFO - [2022-10-21 09:23:29,994] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:23:29,999] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:23:30,052] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.410 seconds
[2022-10-21 09:24:00,991] {processor.py:153} INFO - Started process (PID=82831) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:24:01,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:24:01,026] {logging_mixin.py:115} INFO - [2022-10-21 09:24:01,025] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:24:02,578] {logging_mixin.py:115} INFO - [2022-10-21 09:24:02,570] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:24:02,586] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:24:02,823] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.989 seconds
[2022-10-21 09:28:50,848] {processor.py:153} INFO - Started process (PID=82872) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:28:50,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:28:50,937] {logging_mixin.py:115} INFO - [2022-10-21 09:28:50,926] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:28:53,533] {logging_mixin.py:115} INFO - [2022-10-21 09:28:53,482] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:28:53,566] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:28:53,999] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.386 seconds
[2022-10-21 09:29:24,572] {processor.py:153} INFO - Started process (PID=82909) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:29:24,577] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:29:24,583] {logging_mixin.py:115} INFO - [2022-10-21 09:29:24,583] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:29:25,339] {logging_mixin.py:115} INFO - [2022-10-21 09:29:25,329] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:29:25,362] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:29:25,531] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.996 seconds
[2022-10-21 09:29:56,211] {processor.py:153} INFO - Started process (PID=82954) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:29:56,212] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:29:56,214] {logging_mixin.py:115} INFO - [2022-10-21 09:29:56,214] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:29:56,414] {logging_mixin.py:115} INFO - [2022-10-21 09:29:56,411] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:29:56,417] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:29:56,446] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.240 seconds
[2022-10-21 09:34:34,951] {processor.py:153} INFO - Started process (PID=82988) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:34:34,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:34:34,956] {logging_mixin.py:115} INFO - [2022-10-21 09:34:34,956] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:34:35,260] {logging_mixin.py:115} INFO - [2022-10-21 09:34:35,259] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:34:35,263] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:34:35,391] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.448 seconds
[2022-10-21 09:35:06,497] {processor.py:153} INFO - Started process (PID=83032) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:35:06,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:35:06,512] {logging_mixin.py:115} INFO - [2022-10-21 09:35:06,511] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:35:07,616] {logging_mixin.py:115} INFO - [2022-10-21 09:35:07,606] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:35:07,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:35:08,134] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.725 seconds
[2022-10-21 09:44:10,260] {processor.py:153} INFO - Started process (PID=83067) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:44:10,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:44:10,264] {logging_mixin.py:115} INFO - [2022-10-21 09:44:10,264] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:44:10,526] {logging_mixin.py:115} INFO - [2022-10-21 09:44:10,525] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:44:10,528] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:44:10,567] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.315 seconds
[2022-10-21 09:44:41,148] {processor.py:153} INFO - Started process (PID=83113) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:44:41,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:44:41,175] {logging_mixin.py:115} INFO - [2022-10-21 09:44:41,174] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:44:43,296] {logging_mixin.py:115} INFO - [2022-10-21 09:44:43,276] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:44:43,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:44:43,709] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.586 seconds
[2022-10-21 09:45:14,104] {processor.py:153} INFO - Started process (PID=83156) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:45:14,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:45:14,147] {logging_mixin.py:115} INFO - [2022-10-21 09:45:14,144] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:45:15,269] {logging_mixin.py:115} INFO - [2022-10-21 09:45:15,265] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:45:15,290] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:45:15,523] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.452 seconds
[2022-10-21 09:49:58,188] {processor.py:153} INFO - Started process (PID=83193) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:49:58,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:49:58,195] {logging_mixin.py:115} INFO - [2022-10-21 09:49:58,195] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:49:58,502] {logging_mixin.py:115} INFO - [2022-10-21 09:49:58,500] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:49:58,506] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:49:58,655] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.479 seconds
[2022-10-21 09:50:29,423] {processor.py:153} INFO - Started process (PID=83235) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:50:29,463] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:50:29,528] {logging_mixin.py:115} INFO - [2022-10-21 09:50:29,516] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:50:32,799] {logging_mixin.py:115} INFO - [2022-10-21 09:50:32,783] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:50:32,829] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:50:33,188] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.962 seconds
[2022-10-21 09:55:15,268] {processor.py:153} INFO - Started process (PID=83271) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:55:15,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:55:15,270] {logging_mixin.py:115} INFO - [2022-10-21 09:55:15,270] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:55:15,466] {logging_mixin.py:115} INFO - [2022-10-21 09:55:15,465] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:55:15,467] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:55:15,500] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.238 seconds
[2022-10-21 09:55:45,558] {processor.py:153} INFO - Started process (PID=83314) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:55:45,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:55:45,567] {logging_mixin.py:115} INFO - [2022-10-21 09:55:45,567] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:55:45,942] {logging_mixin.py:115} INFO - [2022-10-21 09:55:45,940] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:55:45,946] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:55:46,016] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.470 seconds
[2022-10-21 09:56:16,588] {processor.py:153} INFO - Started process (PID=83358) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:56:16,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 09:56:16,599] {logging_mixin.py:115} INFO - [2022-10-21 09:56:16,598] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:56:17,027] {logging_mixin.py:115} INFO - [2022-10-21 09:56:17,025] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 09:56:17,033] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 09:56:17,112] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.542 seconds
[2022-10-21 10:01:04,064] {processor.py:153} INFO - Started process (PID=83403) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:01:04,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:01:04,071] {logging_mixin.py:115} INFO - [2022-10-21 10:01:04,071] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:01:04,646] {logging_mixin.py:115} INFO - [2022-10-21 10:01:04,642] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:01:04,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:01:04,746] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.719 seconds
[2022-10-21 10:01:35,975] {processor.py:153} INFO - Started process (PID=83445) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:01:35,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:01:36,005] {logging_mixin.py:115} INFO - [2022-10-21 10:01:36,005] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:01:38,233] {logging_mixin.py:115} INFO - [2022-10-21 10:01:38,221] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:01:38,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:01:38,590] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.731 seconds
[2022-10-21 10:10:39,262] {processor.py:153} INFO - Started process (PID=83482) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:10:39,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:10:39,265] {logging_mixin.py:115} INFO - [2022-10-21 10:10:39,265] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:10:39,486] {logging_mixin.py:115} INFO - [2022-10-21 10:10:39,485] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:10:39,488] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:10:39,522] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.267 seconds
[2022-10-21 10:11:10,463] {processor.py:153} INFO - Started process (PID=83526) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:11:10,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:11:10,494] {logging_mixin.py:115} INFO - [2022-10-21 10:11:10,493] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:11:12,000] {logging_mixin.py:115} INFO - [2022-10-21 10:11:11,994] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:11:12,011] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:11:12,177] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.776 seconds
[2022-10-21 10:11:42,503] {processor.py:153} INFO - Started process (PID=83561) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:11:42,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:11:42,524] {logging_mixin.py:115} INFO - [2022-10-21 10:11:42,523] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:11:43,341] {logging_mixin.py:115} INFO - [2022-10-21 10:11:43,337] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:11:43,352] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:11:43,477] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.031 seconds
[2022-10-21 10:16:28,805] {processor.py:153} INFO - Started process (PID=83605) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:16:28,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:16:28,825] {logging_mixin.py:115} INFO - [2022-10-21 10:16:28,824] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:16:29,514] {logging_mixin.py:115} INFO - [2022-10-21 10:16:29,512] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:16:29,522] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:16:29,638] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.847 seconds
[2022-10-21 10:17:00,077] {processor.py:153} INFO - Started process (PID=83641) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:17:00,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:17:00,097] {logging_mixin.py:115} INFO - [2022-10-21 10:17:00,096] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:17:02,486] {logging_mixin.py:115} INFO - [2022-10-21 10:17:02,482] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:17:02,519] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:17:02,810] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.792 seconds
[2022-10-21 10:26:43,414] {processor.py:153} INFO - Started process (PID=83685) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:26:43,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:26:43,423] {logging_mixin.py:115} INFO - [2022-10-21 10:26:43,423] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:26:43,865] {logging_mixin.py:115} INFO - [2022-10-21 10:26:43,863] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:26:43,867] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:26:43,981] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.578 seconds
[2022-10-21 10:27:14,554] {processor.py:153} INFO - Started process (PID=83727) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:27:14,567] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:27:14,589] {logging_mixin.py:115} INFO - [2022-10-21 10:27:14,584] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:27:15,711] {logging_mixin.py:115} INFO - [2022-10-21 10:27:15,707] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:27:15,722] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:27:15,947] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.422 seconds
[2022-10-21 10:27:46,244] {processor.py:153} INFO - Started process (PID=83764) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:27:46,251] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:27:46,259] {logging_mixin.py:115} INFO - [2022-10-21 10:27:46,258] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:27:46,966] {logging_mixin.py:115} INFO - [2022-10-21 10:27:46,962] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:27:46,974] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:27:47,102] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.895 seconds
[2022-10-21 10:32:33,626] {processor.py:153} INFO - Started process (PID=83807) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:32:33,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:32:33,654] {logging_mixin.py:115} INFO - [2022-10-21 10:32:33,653] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:32:36,462] {logging_mixin.py:115} INFO - [2022-10-21 10:32:36,452] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:32:36,471] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:32:36,717] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.176 seconds
[2022-10-21 10:33:07,393] {processor.py:153} INFO - Started process (PID=83858) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:33:07,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:33:07,404] {logging_mixin.py:115} INFO - [2022-10-21 10:33:07,404] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:33:08,031] {logging_mixin.py:115} INFO - [2022-10-21 10:33:08,028] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:33:08,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:33:08,189] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.817 seconds
[2022-10-21 10:33:38,464] {processor.py:153} INFO - Started process (PID=83903) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:33:38,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:33:38,467] {logging_mixin.py:115} INFO - [2022-10-21 10:33:38,467] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:33:38,668] {logging_mixin.py:115} INFO - [2022-10-21 10:33:38,666] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:33:38,670] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:33:38,697] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.238 seconds
[2022-10-21 10:38:20,168] {processor.py:153} INFO - Started process (PID=83931) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:38:20,185] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:38:20,197] {logging_mixin.py:115} INFO - [2022-10-21 10:38:20,197] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:38:20,805] {logging_mixin.py:115} INFO - [2022-10-21 10:38:20,803] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:38:20,809] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:38:20,901] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.814 seconds
[2022-10-21 10:38:51,537] {processor.py:153} INFO - Started process (PID=83975) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:38:51,543] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:38:51,558] {logging_mixin.py:115} INFO - [2022-10-21 10:38:51,558] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:38:53,698] {logging_mixin.py:115} INFO - [2022-10-21 10:38:53,688] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:38:53,718] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:38:54,066] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.614 seconds
[2022-10-21 10:43:39,427] {processor.py:153} INFO - Started process (PID=84016) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:43:39,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:43:39,439] {logging_mixin.py:115} INFO - [2022-10-21 10:43:39,439] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:43:41,454] {logging_mixin.py:115} INFO - [2022-10-21 10:43:41,433] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:43:41,464] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:43:41,939] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.606 seconds
[2022-10-21 10:44:12,948] {processor.py:153} INFO - Started process (PID=84053) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:44:12,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:44:12,974] {logging_mixin.py:115} INFO - [2022-10-21 10:44:12,973] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:44:13,576] {logging_mixin.py:115} INFO - [2022-10-21 10:44:13,573] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:44:13,583] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:44:13,723] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.822 seconds
[2022-10-21 10:44:44,363] {processor.py:153} INFO - Started process (PID=84098) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:44:44,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:44:44,367] {logging_mixin.py:115} INFO - [2022-10-21 10:44:44,366] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:44:44,580] {logging_mixin.py:115} INFO - [2022-10-21 10:44:44,579] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:44:44,583] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:44:44,616] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.258 seconds
[2022-10-21 10:49:25,157] {processor.py:153} INFO - Started process (PID=84134) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:49:25,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:49:25,161] {logging_mixin.py:115} INFO - [2022-10-21 10:49:25,161] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:49:25,538] {logging_mixin.py:115} INFO - [2022-10-21 10:49:25,536] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:49:25,541] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:49:25,632] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.485 seconds
[2022-10-21 10:49:56,656] {processor.py:153} INFO - Started process (PID=84178) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:49:56,667] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:49:56,679] {logging_mixin.py:115} INFO - [2022-10-21 10:49:56,678] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:49:59,159] {logging_mixin.py:115} INFO - [2022-10-21 10:49:59,136] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:49:59,184] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:49:59,632] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.058 seconds
[2022-10-21 10:59:04,039] {processor.py:153} INFO - Started process (PID=84220) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:59:04,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:59:04,073] {logging_mixin.py:115} INFO - [2022-10-21 10:59:04,073] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:59:06,058] {logging_mixin.py:115} INFO - [2022-10-21 10:59:06,049] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:59:06,069] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:59:06,420] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.493 seconds
[2022-10-21 10:59:37,344] {processor.py:153} INFO - Started process (PID=84256) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:59:37,349] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 10:59:37,356] {logging_mixin.py:115} INFO - [2022-10-21 10:59:37,355] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:59:38,103] {logging_mixin.py:115} INFO - [2022-10-21 10:59:38,098] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 10:59:38,111] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 10:59:38,246] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.939 seconds
[2022-10-21 11:00:08,433] {processor.py:153} INFO - Started process (PID=84301) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:00:08,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:00:08,436] {logging_mixin.py:115} INFO - [2022-10-21 11:00:08,435] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:00:08,688] {logging_mixin.py:115} INFO - [2022-10-21 11:00:08,687] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:00:08,691] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:00:08,720] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.293 seconds
[2022-10-21 11:09:06,954] {processor.py:153} INFO - Started process (PID=84336) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:09:06,957] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:09:06,962] {logging_mixin.py:115} INFO - [2022-10-21 11:09:06,961] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:09:07,286] {logging_mixin.py:115} INFO - [2022-10-21 11:09:07,284] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:09:07,289] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:09:07,367] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.443 seconds
[2022-10-21 11:09:38,068] {processor.py:153} INFO - Started process (PID=84380) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:09:38,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:09:38,090] {logging_mixin.py:115} INFO - [2022-10-21 11:09:38,084] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:09:40,660] {logging_mixin.py:115} INFO - [2022-10-21 11:09:40,627] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:09:40,703] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:09:41,212] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.272 seconds
[2022-10-21 11:14:24,246] {processor.py:153} INFO - Started process (PID=84415) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:14:24,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:14:24,251] {logging_mixin.py:115} INFO - [2022-10-21 11:14:24,251] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:14:24,532] {logging_mixin.py:115} INFO - [2022-10-21 11:14:24,531] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:14:24,536] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:14:24,577] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.336 seconds
[2022-10-21 11:14:55,285] {processor.py:153} INFO - Started process (PID=84458) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:14:55,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:14:55,303] {logging_mixin.py:115} INFO - [2022-10-21 11:14:55,303] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:14:56,289] {logging_mixin.py:115} INFO - [2022-10-21 11:14:56,285] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:14:56,296] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:14:56,681] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.441 seconds
[2022-10-21 11:15:27,604] {processor.py:153} INFO - Started process (PID=84504) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:15:27,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:15:27,633] {logging_mixin.py:115} INFO - [2022-10-21 11:15:27,632] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:15:29,369] {logging_mixin.py:115} INFO - [2022-10-21 11:15:29,364] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:15:29,376] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:15:29,699] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.131 seconds
[2022-10-21 11:20:12,230] {processor.py:153} INFO - Started process (PID=84537) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:20:12,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:20:12,247] {logging_mixin.py:115} INFO - [2022-10-21 11:20:12,246] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:20:12,687] {logging_mixin.py:115} INFO - [2022-10-21 11:20:12,684] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:20:12,695] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:20:12,809] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.615 seconds
[2022-10-21 11:20:43,770] {processor.py:153} INFO - Started process (PID=84580) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:20:43,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:20:43,785] {logging_mixin.py:115} INFO - [2022-10-21 11:20:43,784] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:20:46,184] {logging_mixin.py:115} INFO - [2022-10-21 11:20:46,177] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:20:46,211] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:20:46,655] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.974 seconds
[2022-10-21 11:29:47,242] {processor.py:153} INFO - Started process (PID=84618) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:29:47,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:29:47,246] {logging_mixin.py:115} INFO - [2022-10-21 11:29:47,246] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:29:47,515] {logging_mixin.py:115} INFO - [2022-10-21 11:29:47,514] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:29:47,522] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:29:47,578] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.345 seconds
[2022-10-21 11:30:18,570] {processor.py:153} INFO - Started process (PID=84662) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:30:18,577] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:30:18,584] {logging_mixin.py:115} INFO - [2022-10-21 11:30:18,584] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:30:19,882] {logging_mixin.py:115} INFO - [2022-10-21 11:30:19,872] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:30:19,899] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:30:20,131] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.633 seconds
[2022-10-21 11:30:50,401] {processor.py:153} INFO - Started process (PID=84698) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:30:50,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:30:50,415] {logging_mixin.py:115} INFO - [2022-10-21 11:30:50,414] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:30:51,138] {logging_mixin.py:115} INFO - [2022-10-21 11:30:51,134] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:30:51,147] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:30:51,329] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.956 seconds
[2022-10-21 11:39:54,570] {processor.py:153} INFO - Started process (PID=84742) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:39:54,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:39:54,587] {logging_mixin.py:115} INFO - [2022-10-21 11:39:54,586] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:39:55,148] {logging_mixin.py:115} INFO - [2022-10-21 11:39:55,146] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:39:55,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:39:55,243] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.685 seconds
[2022-10-21 11:40:25,988] {processor.py:153} INFO - Started process (PID=84778) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:40:26,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:40:26,027] {logging_mixin.py:115} INFO - [2022-10-21 11:40:26,027] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:40:28,003] {logging_mixin.py:115} INFO - [2022-10-21 11:40:27,999] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:40:28,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:40:28,220] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.270 seconds
[2022-10-21 11:45:11,317] {processor.py:153} INFO - Started process (PID=84822) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:45:11,319] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:45:11,320] {logging_mixin.py:115} INFO - [2022-10-21 11:45:11,320] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:45:11,565] {logging_mixin.py:115} INFO - [2022-10-21 11:45:11,564] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:45:11,568] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:45:11,599] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.290 seconds
[2022-10-21 11:45:42,050] {processor.py:153} INFO - Started process (PID=84864) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:45:42,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:45:42,075] {logging_mixin.py:115} INFO - [2022-10-21 11:45:42,074] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:45:43,610] {logging_mixin.py:115} INFO - [2022-10-21 11:45:43,606] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:45:43,620] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:45:43,824] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.817 seconds
[2022-10-21 11:46:14,244] {processor.py:153} INFO - Started process (PID=84902) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:46:14,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:46:14,256] {logging_mixin.py:115} INFO - [2022-10-21 11:46:14,255] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:46:14,857] {logging_mixin.py:115} INFO - [2022-10-21 11:46:14,852] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:46:14,868] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:46:14,994] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.772 seconds
[2022-10-21 11:55:18,613] {processor.py:153} INFO - Started process (PID=84945) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:55:18,622] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:55:18,645] {logging_mixin.py:115} INFO - [2022-10-21 11:55:18,645] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:55:21,214] {logging_mixin.py:115} INFO - [2022-10-21 11:55:21,213] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:55:21,224] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:55:21,369] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.844 seconds
[2022-10-21 11:55:52,216] {processor.py:153} INFO - Started process (PID=84980) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:55:52,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:55:52,231] {logging_mixin.py:115} INFO - [2022-10-21 11:55:52,230] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:55:54,432] {logging_mixin.py:115} INFO - [2022-10-21 11:55:54,421] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:55:54,455] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:55:54,662] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.473 seconds
[2022-10-21 11:56:25,475] {processor.py:153} INFO - Started process (PID=85024) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:56:25,476] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 11:56:25,477] {logging_mixin.py:115} INFO - [2022-10-21 11:56:25,477] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:56:25,681] {logging_mixin.py:115} INFO - [2022-10-21 11:56:25,680] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 11:56:25,684] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 11:56:25,713] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.243 seconds
[2022-10-21 12:01:05,126] {processor.py:153} INFO - Started process (PID=85058) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:01:05,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:01:05,131] {logging_mixin.py:115} INFO - [2022-10-21 12:01:05,131] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:01:05,577] {logging_mixin.py:115} INFO - [2022-10-21 12:01:05,576] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:01:05,581] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:01:05,633] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.523 seconds
[2022-10-21 12:01:35,873] {processor.py:153} INFO - Started process (PID=85101) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:01:35,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:01:35,948] {logging_mixin.py:115} INFO - [2022-10-21 12:01:35,948] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:01:37,463] {logging_mixin.py:115} INFO - [2022-10-21 12:01:37,457] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:01:37,474] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:01:37,760] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.954 seconds
[2022-10-21 12:10:41,647] {processor.py:153} INFO - Started process (PID=85146) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:10:41,658] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:10:41,674] {logging_mixin.py:115} INFO - [2022-10-21 12:10:41,674] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:10:43,111] {logging_mixin.py:115} INFO - [2022-10-21 12:10:43,102] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:10:43,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:10:43,515] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.986 seconds
[2022-10-21 12:11:14,293] {processor.py:153} INFO - Started process (PID=85181) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:11:14,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:11:14,306] {logging_mixin.py:115} INFO - [2022-10-21 12:11:14,306] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:11:14,880] {logging_mixin.py:115} INFO - [2022-10-21 12:11:14,876] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:11:14,886] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:11:15,022] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.750 seconds
[2022-10-21 12:11:45,384] {processor.py:153} INFO - Started process (PID=85226) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:11:45,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:11:45,386] {logging_mixin.py:115} INFO - [2022-10-21 12:11:45,386] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:11:45,588] {logging_mixin.py:115} INFO - [2022-10-21 12:11:45,587] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:11:45,590] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:11:45,618] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.240 seconds
[2022-10-21 12:20:46,695] {processor.py:153} INFO - Started process (PID=85262) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:20:46,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:20:46,700] {logging_mixin.py:115} INFO - [2022-10-21 12:20:46,700] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:20:47,075] {logging_mixin.py:115} INFO - [2022-10-21 12:20:47,073] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:20:47,080] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:20:47,163] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.481 seconds
[2022-10-21 12:21:17,841] {processor.py:153} INFO - Started process (PID=85307) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:21:17,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:21:17,883] {logging_mixin.py:115} INFO - [2022-10-21 12:21:17,882] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:21:19,872] {logging_mixin.py:115} INFO - [2022-10-21 12:21:19,862] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:21:19,895] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:21:20,129] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.360 seconds
[2022-10-21 12:26:05,373] {processor.py:153} INFO - Started process (PID=85342) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:26:05,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:26:05,470] {logging_mixin.py:115} INFO - [2022-10-21 12:26:05,460] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:26:07,690] {logging_mixin.py:115} INFO - [2022-10-21 12:26:07,681] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:26:07,701] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:26:07,976] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.637 seconds
[2022-10-21 12:26:38,514] {processor.py:153} INFO - Started process (PID=85385) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:26:38,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:26:38,528] {logging_mixin.py:115} INFO - [2022-10-21 12:26:38,527] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:26:39,198] {logging_mixin.py:115} INFO - [2022-10-21 12:26:39,195] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:26:39,205] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:26:39,324] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.839 seconds
[2022-10-21 12:27:10,615] {processor.py:153} INFO - Started process (PID=85429) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:27:10,617] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:27:10,620] {logging_mixin.py:115} INFO - [2022-10-21 12:27:10,620] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:27:10,885] {logging_mixin.py:115} INFO - [2022-10-21 12:27:10,884] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:27:10,893] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:27:11,643] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.057 seconds
[2022-10-21 12:31:51,796] {processor.py:153} INFO - Started process (PID=85463) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:31:51,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:31:51,799] {logging_mixin.py:115} INFO - [2022-10-21 12:31:51,799] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:31:52,090] {logging_mixin.py:115} INFO - [2022-10-21 12:31:52,084] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:31:52,097] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:31:52,183] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.394 seconds
[2022-10-21 12:32:22,962] {processor.py:153} INFO - Started process (PID=85507) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:32:22,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:32:22,984] {logging_mixin.py:115} INFO - [2022-10-21 12:32:22,984] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:32:25,671] {logging_mixin.py:115} INFO - [2022-10-21 12:32:25,663] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:32:25,681] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:32:26,271] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.411 seconds
[2022-10-21 12:41:28,040] {processor.py:153} INFO - Started process (PID=85542) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:41:28,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:41:28,044] {logging_mixin.py:115} INFO - [2022-10-21 12:41:28,044] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:41:28,309] {logging_mixin.py:115} INFO - [2022-10-21 12:41:28,308] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:41:28,313] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:41:28,353] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.322 seconds
[2022-10-21 12:41:59,566] {processor.py:153} INFO - Started process (PID=85586) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:41:59,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:41:59,582] {logging_mixin.py:115} INFO - [2022-10-21 12:41:59,582] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:42:02,260] {logging_mixin.py:115} INFO - [2022-10-21 12:42:02,243] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:42:02,305] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:42:02,652] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.165 seconds
[2022-10-21 12:42:33,216] {processor.py:153} INFO - Started process (PID=85621) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:42:33,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:42:33,229] {logging_mixin.py:115} INFO - [2022-10-21 12:42:33,229] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:42:34,663] {logging_mixin.py:115} INFO - [2022-10-21 12:42:34,647] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:42:34,688] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:42:34,906] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.713 seconds
[2022-10-21 12:51:33,412] {processor.py:153} INFO - Started process (PID=85665) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:51:33,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:51:33,419] {logging_mixin.py:115} INFO - [2022-10-21 12:51:33,418] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:51:33,954] {logging_mixin.py:115} INFO - [2022-10-21 12:51:33,952] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:51:33,960] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:51:34,089] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.689 seconds
[2022-10-21 12:52:05,234] {processor.py:153} INFO - Started process (PID=85707) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:52:05,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:52:05,293] {logging_mixin.py:115} INFO - [2022-10-21 12:52:05,292] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:52:08,007] {logging_mixin.py:115} INFO - [2022-10-21 12:52:08,004] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:52:08,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:52:08,352] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.320 seconds
[2022-10-21 12:56:50,780] {processor.py:153} INFO - Started process (PID=85744) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:56:50,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:56:50,783] {logging_mixin.py:115} INFO - [2022-10-21 12:56:50,783] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:56:51,000] {logging_mixin.py:115} INFO - [2022-10-21 12:56:50,999] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:56:51,003] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:56:51,076] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.302 seconds
[2022-10-21 12:57:21,537] {processor.py:153} INFO - Started process (PID=85787) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:57:21,549] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:57:21,561] {logging_mixin.py:115} INFO - [2022-10-21 12:57:21,561] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:57:23,296] {logging_mixin.py:115} INFO - [2022-10-21 12:57:23,292] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:57:23,312] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:57:23,542] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.126 seconds
[2022-10-21 12:57:53,929] {processor.py:153} INFO - Started process (PID=85824) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:57:53,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 12:57:53,943] {logging_mixin.py:115} INFO - [2022-10-21 12:57:53,942] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:57:54,713] {logging_mixin.py:115} INFO - [2022-10-21 12:57:54,709] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 12:57:54,727] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 12:57:54,909] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.016 seconds
[2022-10-21 13:06:58,251] {processor.py:153} INFO - Started process (PID=85867) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:06:58,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:06:58,257] {logging_mixin.py:115} INFO - [2022-10-21 13:06:58,257] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:06:58,694] {logging_mixin.py:115} INFO - [2022-10-21 13:06:58,693] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:06:58,700] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:06:58,788] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.553 seconds
[2022-10-21 13:07:29,037] {processor.py:153} INFO - Started process (PID=85900) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:07:29,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:07:29,048] {logging_mixin.py:115} INFO - [2022-10-21 13:07:29,048] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:07:30,125] {logging_mixin.py:115} INFO - [2022-10-21 13:07:30,120] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:07:30,132] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:07:30,647] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.632 seconds
[2022-10-21 13:12:15,233] {processor.py:153} INFO - Started process (PID=85945) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:12:15,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:12:15,235] {logging_mixin.py:115} INFO - [2022-10-21 13:12:15,235] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:12:15,504] {logging_mixin.py:115} INFO - [2022-10-21 13:12:15,503] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:12:15,505] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:12:15,538] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.312 seconds
[2022-10-21 13:12:45,983] {processor.py:153} INFO - Started process (PID=85989) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:12:45,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:12:46,001] {logging_mixin.py:115} INFO - [2022-10-21 13:12:46,000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:12:46,669] {logging_mixin.py:115} INFO - [2022-10-21 13:12:46,667] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:12:46,677] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:12:46,774] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.834 seconds
[2022-10-21 13:13:17,495] {processor.py:153} INFO - Started process (PID=86034) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:13:17,501] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:13:17,507] {logging_mixin.py:115} INFO - [2022-10-21 13:13:17,507] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:13:18,079] {logging_mixin.py:115} INFO - [2022-10-21 13:13:18,076] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:13:18,110] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:13:18,285] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.823 seconds
[2022-10-21 13:18:06,914] {processor.py:153} INFO - Started process (PID=86079) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:18:06,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:18:06,925] {logging_mixin.py:115} INFO - [2022-10-21 13:18:06,924] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:18:07,822] {logging_mixin.py:115} INFO - [2022-10-21 13:18:07,821] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:18:07,829] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:18:07,983] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.102 seconds
[2022-10-21 13:18:38,685] {processor.py:153} INFO - Started process (PID=86115) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:18:38,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:18:38,723] {logging_mixin.py:115} INFO - [2022-10-21 13:18:38,722] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:18:39,443] {logging_mixin.py:115} INFO - [2022-10-21 13:18:39,439] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:18:39,450] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:18:39,586] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.946 seconds
[2022-10-21 13:27:40,693] {processor.py:153} INFO - Started process (PID=86158) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:27:40,695] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:27:40,697] {logging_mixin.py:115} INFO - [2022-10-21 13:27:40,697] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:27:40,996] {logging_mixin.py:115} INFO - [2022-10-21 13:27:40,995] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:27:40,999] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:27:41,064] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.379 seconds
[2022-10-21 13:28:11,359] {processor.py:153} INFO - Started process (PID=86193) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:28:11,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:28:11,374] {logging_mixin.py:115} INFO - [2022-10-21 13:28:11,373] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:28:12,570] {logging_mixin.py:115} INFO - [2022-10-21 13:28:12,565] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:28:12,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:28:13,007] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.670 seconds
[2022-10-21 13:28:43,500] {processor.py:153} INFO - Started process (PID=86238) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:28:43,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:28:43,515] {logging_mixin.py:115} INFO - [2022-10-21 13:28:43,515] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:28:44,298] {logging_mixin.py:115} INFO - [2022-10-21 13:28:44,294] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:28:44,311] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:28:44,440] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.965 seconds
[2022-10-21 13:33:29,088] {processor.py:153} INFO - Started process (PID=86283) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:33:29,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:33:29,154] {logging_mixin.py:115} INFO - [2022-10-21 13:33:29,136] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:33:32,233] {logging_mixin.py:115} INFO - [2022-10-21 13:33:32,225] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:33:32,248] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:33:32,731] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.766 seconds
[2022-10-21 13:34:03,841] {processor.py:153} INFO - Started process (PID=86325) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:34:03,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:34:03,856] {logging_mixin.py:115} INFO - [2022-10-21 13:34:03,855] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:34:04,641] {logging_mixin.py:115} INFO - [2022-10-21 13:34:04,637] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:34:04,648] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:34:04,790] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.988 seconds
[2022-10-21 13:34:35,053] {processor.py:153} INFO - Started process (PID=86369) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:34:35,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:34:35,055] {logging_mixin.py:115} INFO - [2022-10-21 13:34:35,055] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:34:35,279] {logging_mixin.py:115} INFO - [2022-10-21 13:34:35,277] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:34:35,282] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:34:35,311] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.264 seconds
[2022-10-21 13:39:14,888] {processor.py:153} INFO - Started process (PID=86397) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:39:14,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:39:14,893] {logging_mixin.py:115} INFO - [2022-10-21 13:39:14,893] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:39:15,204] {logging_mixin.py:115} INFO - [2022-10-21 13:39:15,200] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:39:15,207] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:39:15,290] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.409 seconds
[2022-10-21 13:39:45,608] {processor.py:153} INFO - Started process (PID=86441) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:39:45,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:39:45,627] {logging_mixin.py:115} INFO - [2022-10-21 13:39:45,627] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:39:46,965] {logging_mixin.py:115} INFO - [2022-10-21 13:39:46,952] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:39:46,980] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:39:47,287] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.735 seconds
[2022-10-21 13:42:49,399] {processor.py:153} INFO - Started process (PID=86476) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:42:49,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:42:49,420] {logging_mixin.py:115} INFO - [2022-10-21 13:42:49,419] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:42:52,403] {logging_mixin.py:115} INFO - [2022-10-21 13:42:52,393] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:42:52,428] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:42:52,870] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.595 seconds
[2022-10-21 13:47:37,222] {processor.py:153} INFO - Started process (PID=86520) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:47:37,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:47:37,225] {logging_mixin.py:115} INFO - [2022-10-21 13:47:37,225] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:47:37,444] {logging_mixin.py:115} INFO - [2022-10-21 13:47:37,443] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:47:37,446] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:47:37,484] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.268 seconds
[2022-10-21 13:48:08,033] {processor.py:153} INFO - Started process (PID=86563) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:48:08,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:48:08,069] {logging_mixin.py:115} INFO - [2022-10-21 13:48:08,068] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:48:09,551] {logging_mixin.py:115} INFO - [2022-10-21 13:48:09,536] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:48:09,588] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:48:09,922] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.988 seconds
[2022-10-21 13:57:13,228] {processor.py:153} INFO - Started process (PID=86600) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:57:13,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:57:13,233] {logging_mixin.py:115} INFO - [2022-10-21 13:57:13,233] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:57:13,561] {logging_mixin.py:115} INFO - [2022-10-21 13:57:13,560] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:57:13,562] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:57:13,605] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.382 seconds
[2022-10-21 13:57:43,891] {processor.py:153} INFO - Started process (PID=86644) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:57:43,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 13:57:43,912] {logging_mixin.py:115} INFO - [2022-10-21 13:57:43,911] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:57:45,019] {logging_mixin.py:115} INFO - [2022-10-21 13:57:45,015] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 13:57:45,029] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 13:57:45,341] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.520 seconds
[2022-10-21 14:02:30,273] {processor.py:153} INFO - Started process (PID=86679) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:02:30,274] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:02:30,276] {logging_mixin.py:115} INFO - [2022-10-21 14:02:30,276] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:02:30,545] {logging_mixin.py:115} INFO - [2022-10-21 14:02:30,544] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:02:30,548] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:02:30,593] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.336 seconds
[2022-10-21 14:03:00,871] {processor.py:153} INFO - Started process (PID=86723) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:03:00,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:03:00,891] {logging_mixin.py:115} INFO - [2022-10-21 14:03:00,889] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:03:01,953] {logging_mixin.py:115} INFO - [2022-10-21 14:03:01,928] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:03:01,990] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:03:02,193] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.356 seconds
[2022-10-21 14:12:06,588] {processor.py:153} INFO - Started process (PID=86767) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:12:06,590] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:12:06,592] {logging_mixin.py:115} INFO - [2022-10-21 14:12:06,592] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:12:06,966] {logging_mixin.py:115} INFO - [2022-10-21 14:12:06,965] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:12:06,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:12:07,049] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.482 seconds
[2022-10-21 14:12:37,355] {processor.py:153} INFO - Started process (PID=86809) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:12:37,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:12:37,376] {logging_mixin.py:115} INFO - [2022-10-21 14:12:37,375] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:12:38,374] {logging_mixin.py:115} INFO - [2022-10-21 14:12:38,371] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:12:38,429] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:12:38,734] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.412 seconds
[2022-10-21 14:23:53,742] {processor.py:153} INFO - Started process (PID=86846) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:23:53,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:23:53,746] {logging_mixin.py:115} INFO - [2022-10-21 14:23:53,746] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:23:53,999] {logging_mixin.py:115} INFO - [2022-10-21 14:23:53,997] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:23:54,004] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:23:54,055] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.324 seconds
[2022-10-21 14:24:24,546] {processor.py:153} INFO - Started process (PID=86890) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:24:24,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:24:24,551] {logging_mixin.py:115} INFO - [2022-10-21 14:24:24,550] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:24:24,769] {logging_mixin.py:115} INFO - [2022-10-21 14:24:24,768] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:24:24,771] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:24:24,806] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.271 seconds
[2022-10-21 14:24:55,051] {processor.py:153} INFO - Started process (PID=86935) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:24:55,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:24:55,054] {logging_mixin.py:115} INFO - [2022-10-21 14:24:55,054] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:24:55,258] {logging_mixin.py:115} INFO - [2022-10-21 14:24:55,257] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:24:55,260] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:24:55,291] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.246 seconds
[2022-10-21 14:25:25,636] {processor.py:153} INFO - Started process (PID=86988) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:25:25,638] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:25:25,640] {logging_mixin.py:115} INFO - [2022-10-21 14:25:25,640] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:25:25,871] {logging_mixin.py:115} INFO - [2022-10-21 14:25:25,870] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:25:25,872] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:25:25,912] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.282 seconds
[2022-10-21 14:25:56,209] {processor.py:153} INFO - Started process (PID=87032) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:25:56,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:25:56,212] {logging_mixin.py:115} INFO - [2022-10-21 14:25:56,212] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:25:56,418] {logging_mixin.py:115} INFO - [2022-10-21 14:25:56,416] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:25:56,420] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:25:56,477] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.273 seconds
[2022-10-21 14:26:26,626] {processor.py:153} INFO - Started process (PID=87085) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:26:26,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:26:26,629] {logging_mixin.py:115} INFO - [2022-10-21 14:26:26,629] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:26:26,832] {logging_mixin.py:115} INFO - [2022-10-21 14:26:26,831] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:26:26,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:26:26,874] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.253 seconds
[2022-10-21 14:26:56,996] {processor.py:153} INFO - Started process (PID=87137) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:26:56,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:26:56,999] {logging_mixin.py:115} INFO - [2022-10-21 14:26:56,999] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:26:57,215] {logging_mixin.py:115} INFO - [2022-10-21 14:26:57,214] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:26:57,216] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:26:57,245] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.255 seconds
[2022-10-21 14:27:27,589] {processor.py:153} INFO - Started process (PID=87183) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:27:27,590] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:27:27,592] {logging_mixin.py:115} INFO - [2022-10-21 14:27:27,592] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:27:27,802] {logging_mixin.py:115} INFO - [2022-10-21 14:27:27,801] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:27:27,805] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:27:27,848] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.264 seconds
[2022-10-21 14:27:57,995] {processor.py:153} INFO - Started process (PID=87237) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:27:57,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:27:57,998] {logging_mixin.py:115} INFO - [2022-10-21 14:27:57,998] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:27:58,203] {logging_mixin.py:115} INFO - [2022-10-21 14:27:58,201] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:27:58,206] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:27:58,236] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.246 seconds
[2022-10-21 14:28:28,570] {processor.py:153} INFO - Started process (PID=87281) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:28:28,572] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:28:28,573] {logging_mixin.py:115} INFO - [2022-10-21 14:28:28,573] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:28:28,838] {logging_mixin.py:115} INFO - [2022-10-21 14:28:28,837] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:28:28,840] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:28:28,877] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.313 seconds
[2022-10-21 14:28:59,247] {processor.py:153} INFO - Started process (PID=87335) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:28:59,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:28:59,250] {logging_mixin.py:115} INFO - [2022-10-21 14:28:59,250] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:28:59,491] {logging_mixin.py:115} INFO - [2022-10-21 14:28:59,490] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:28:59,494] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:28:59,536] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.297 seconds
[2022-10-21 14:29:08,871] {processor.py:153} INFO - Started process (PID=5486) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:08,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:29:08,876] {logging_mixin.py:115} INFO - [2022-10-21 14:29:08,875] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:16,452] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:29:16,471] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:16,607] {logging_mixin.py:115} INFO - [2022-10-21 14:29:16,607] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:29:16,646] {logging_mixin.py:115} INFO - [2022-10-21 14:29:16,646] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:29:16.468472+00:00, run_after=2022-10-22T14:29:16.468472+00:00
[2022-10-21 14:29:16,675] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.811 seconds
[2022-10-21 14:29:30,067] {processor.py:153} INFO - Started process (PID=87388) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:30,070] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:29:30,084] {logging_mixin.py:115} INFO - [2022-10-21 14:29:30,082] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:30,519] {logging_mixin.py:115} INFO - [2022-10-21 14:29:30,518] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:29:30,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:30,565] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.514 seconds
[2022-10-21 14:29:47,157] {processor.py:153} INFO - Started process (PID=5765) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:47,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:29:47,161] {logging_mixin.py:115} INFO - [2022-10-21 14:29:47,160] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:54,187] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:29:54,207] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:29:54,303] {logging_mixin.py:115} INFO - [2022-10-21 14:29:54,303] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:29:54,350] {logging_mixin.py:115} INFO - [2022-10-21 14:29:54,350] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:29:54.205111+00:00, run_after=2022-10-22T14:29:54.205111+00:00
[2022-10-21 14:29:54,373] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.245 seconds
[2022-10-21 14:30:00,671] {processor.py:153} INFO - Started process (PID=87432) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:00,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:30:00,676] {logging_mixin.py:115} INFO - [2022-10-21 14:30:00,676] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:00,924] {logging_mixin.py:115} INFO - [2022-10-21 14:30:00,923] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:30:00,929] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:00,958] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.291 seconds
[2022-10-21 14:30:24,686] {processor.py:153} INFO - Started process (PID=6166) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:24,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:30:24,690] {logging_mixin.py:115} INFO - [2022-10-21 14:30:24,690] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:31,345] {processor.py:153} INFO - Started process (PID=87492) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:31,349] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:30:31,351] {logging_mixin.py:115} INFO - [2022-10-21 14:30:31,351] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:31,603] {logging_mixin.py:115} INFO - [2022-10-21 14:30:31,602] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:30:31,606] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:31,645] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.306 seconds
[2022-10-21 14:30:32,218] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:30:32,232] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:30:32,315] {logging_mixin.py:115} INFO - [2022-10-21 14:30:32,315] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:30:32,360] {logging_mixin.py:115} INFO - [2022-10-21 14:30:32,360] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:30:32.230107+00:00, run_after=2022-10-22T14:30:32.230107+00:00
[2022-10-21 14:30:32,382] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.705 seconds
[2022-10-21 14:31:01,789] {processor.py:153} INFO - Started process (PID=87536) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:01,793] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:31:01,795] {logging_mixin.py:115} INFO - [2022-10-21 14:31:01,794] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:02,027] {logging_mixin.py:115} INFO - [2022-10-21 14:31:02,026] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:31:02,031] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:02,065] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.283 seconds
[2022-10-21 14:31:02,751] {processor.py:153} INFO - Started process (PID=6485) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:02,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:31:02,757] {logging_mixin.py:115} INFO - [2022-10-21 14:31:02,754] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:10,088] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:31:10,104] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:10,210] {logging_mixin.py:115} INFO - [2022-10-21 14:31:10,210] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:31:10,240] {logging_mixin.py:115} INFO - [2022-10-21 14:31:10,240] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:31:10.101780+00:00, run_after=2022-10-22T14:31:10.101780+00:00
[2022-10-21 14:31:10,258] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.514 seconds
[2022-10-21 14:31:32,348] {processor.py:153} INFO - Started process (PID=87590) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:32,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:31:32,351] {logging_mixin.py:115} INFO - [2022-10-21 14:31:32,351] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:32,563] {logging_mixin.py:115} INFO - [2022-10-21 14:31:32,561] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:31:32,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:32,597] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.254 seconds
[2022-10-21 14:31:40,374] {processor.py:153} INFO - Started process (PID=6762) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:40,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:31:40,378] {logging_mixin.py:115} INFO - [2022-10-21 14:31:40,378] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:49,666] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:31:49,686] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:31:49,786] {logging_mixin.py:115} INFO - [2022-10-21 14:31:49,785] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:31:49,822] {logging_mixin.py:115} INFO - [2022-10-21 14:31:49,822] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:31:49.684708+00:00, run_after=2022-10-22T14:31:49.684708+00:00
[2022-10-21 14:31:49,841] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 9.476 seconds
[2022-10-21 14:32:02,657] {processor.py:153} INFO - Started process (PID=87633) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:02,658] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:32:02,660] {logging_mixin.py:115} INFO - [2022-10-21 14:32:02,659] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:02,895] {logging_mixin.py:115} INFO - [2022-10-21 14:32:02,895] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:32:02,897] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:02,924] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.277 seconds
[2022-10-21 14:32:20,167] {processor.py:153} INFO - Started process (PID=7362) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:20,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:32:20,171] {logging_mixin.py:115} INFO - [2022-10-21 14:32:20,171] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:33,190] {processor.py:153} INFO - Started process (PID=87685) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:33,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:32:33,195] {logging_mixin.py:115} INFO - [2022-10-21 14:32:33,195] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:33,626] {logging_mixin.py:115} INFO - [2022-10-21 14:32:33,625] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:32:33,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:33,678] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.506 seconds
[2022-10-21 14:32:34,021] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:32:34,037] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:32:34,141] {logging_mixin.py:115} INFO - [2022-10-21 14:32:34,141] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:32:34,169] {logging_mixin.py:115} INFO - [2022-10-21 14:32:34,169] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:32:34.034616+00:00, run_after=2022-10-22T14:32:34.034616+00:00
[2022-10-21 14:32:34,201] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.071 seconds
[2022-10-21 14:33:03,787] {processor.py:153} INFO - Started process (PID=87729) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:03,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:33:03,790] {logging_mixin.py:115} INFO - [2022-10-21 14:33:03,790] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:03,995] {logging_mixin.py:115} INFO - [2022-10-21 14:33:03,992] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:33:03,998] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:04,034] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.252 seconds
[2022-10-21 14:33:04,476] {processor.py:153} INFO - Started process (PID=7758) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:04,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:33:04,479] {logging_mixin.py:115} INFO - [2022-10-21 14:33:04,479] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:11,923] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:33:11,945] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:12,060] {logging_mixin.py:115} INFO - [2022-10-21 14:33:12,060] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:33:12,098] {logging_mixin.py:115} INFO - [2022-10-21 14:33:12,098] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:33:11.942827+00:00, run_after=2022-10-22T14:33:11.942827+00:00
[2022-10-21 14:33:12,120] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.649 seconds
[2022-10-21 14:33:34,925] {processor.py:153} INFO - Started process (PID=87781) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:34,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:33:34,928] {logging_mixin.py:115} INFO - [2022-10-21 14:33:34,928] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:35,133] {logging_mixin.py:115} INFO - [2022-10-21 14:33:35,132] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:33:35,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:35,169] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.250 seconds
[2022-10-21 14:33:42,341] {processor.py:153} INFO - Started process (PID=8029) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:42,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:33:42,347] {logging_mixin.py:115} INFO - [2022-10-21 14:33:42,347] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:50,962] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:33:50,993] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:33:51,111] {logging_mixin.py:115} INFO - [2022-10-21 14:33:51,111] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:33:51,137] {logging_mixin.py:115} INFO - [2022-10-21 14:33:51,137] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:33:50.991464+00:00, run_after=2022-10-22T14:33:50.991464+00:00
[2022-10-21 14:33:51,165] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 8.833 seconds
[2022-10-21 14:34:05,410] {processor.py:153} INFO - Started process (PID=87825) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:05,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:34:05,412] {logging_mixin.py:115} INFO - [2022-10-21 14:34:05,412] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:05,645] {logging_mixin.py:115} INFO - [2022-10-21 14:34:05,644] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:34:05,647] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:05,682] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.282 seconds
[2022-10-21 14:34:21,334] {processor.py:153} INFO - Started process (PID=8309) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:21,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:34:21,350] {logging_mixin.py:115} INFO - [2022-10-21 14:34:21,350] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:29,583] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:34:29,598] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:29,673] {logging_mixin.py:115} INFO - [2022-10-21 14:34:29,672] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:34:29,698] {logging_mixin.py:115} INFO - [2022-10-21 14:34:29,698] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:34:29.596475+00:00, run_after=2022-10-22T14:34:29.596475+00:00
[2022-10-21 14:34:29,719] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 8.412 seconds
[2022-10-21 14:34:35,735] {processor.py:153} INFO - Started process (PID=87878) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:35,737] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:34:35,738] {logging_mixin.py:115} INFO - [2022-10-21 14:34:35,738] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:35,952] {logging_mixin.py:115} INFO - [2022-10-21 14:34:35,951] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:34:35,955] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:35,995] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.268 seconds
[2022-10-21 14:34:59,883] {processor.py:153} INFO - Started process (PID=8593) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:34:59,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:34:59,891] {logging_mixin.py:115} INFO - [2022-10-21 14:34:59,891] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:06,098] {processor.py:153} INFO - Started process (PID=87932) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:06,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:35:06,108] {logging_mixin.py:115} INFO - [2022-10-21 14:35:06,107] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:06,488] {logging_mixin.py:115} INFO - [2022-10-21 14:35:06,487] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:35:06,497] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:06,565] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.472 seconds
[2022-10-21 14:35:09,282] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:35:09,299] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:09,393] {logging_mixin.py:115} INFO - [2022-10-21 14:35:09,393] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:35:09,421] {logging_mixin.py:115} INFO - [2022-10-21 14:35:09,421] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:35:09.296410+00:00, run_after=2022-10-22T14:35:09.296410+00:00
[2022-10-21 14:35:09,440] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 9.565 seconds
[2022-10-21 14:35:36,999] {processor.py:153} INFO - Started process (PID=87991) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:37,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:35:37,002] {logging_mixin.py:115} INFO - [2022-10-21 14:35:37,002] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:37,231] {logging_mixin.py:115} INFO - [2022-10-21 14:35:37,230] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:35:37,233] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:37,267] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.276 seconds
[2022-10-21 14:35:39,607] {processor.py:153} INFO - Started process (PID=8989) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:39,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:35:39,611] {logging_mixin.py:115} INFO - [2022-10-21 14:35:39,610] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:44,524] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:35:44,538] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:35:44,635] {logging_mixin.py:115} INFO - [2022-10-21 14:35:44,635] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:35:44,659] {logging_mixin.py:115} INFO - [2022-10-21 14:35:44,659] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:35:44.536353+00:00, run_after=2022-10-22T14:35:44.536353+00:00
[2022-10-21 14:35:44,680] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.077 seconds
[2022-10-21 14:36:07,807] {processor.py:153} INFO - Started process (PID=88044) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:07,810] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:36:07,812] {logging_mixin.py:115} INFO - [2022-10-21 14:36:07,811] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:08,021] {logging_mixin.py:115} INFO - [2022-10-21 14:36:08,019] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:36:08,025] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:08,057] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.255 seconds
[2022-10-21 14:36:14,911] {processor.py:153} INFO - Started process (PID=9273) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:14,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:36:14,914] {logging_mixin.py:115} INFO - [2022-10-21 14:36:14,914] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:19,350] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:36:19,365] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:19,440] {logging_mixin.py:115} INFO - [2022-10-21 14:36:19,440] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:36:19,464] {logging_mixin.py:115} INFO - [2022-10-21 14:36:19,464] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:36:19.362804+00:00, run_after=2022-10-22T14:36:19.362804+00:00
[2022-10-21 14:36:19,481] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.574 seconds
[2022-10-21 14:36:38,621] {processor.py:153} INFO - Started process (PID=88088) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:38,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:36:38,624] {logging_mixin.py:115} INFO - [2022-10-21 14:36:38,624] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:38,831] {logging_mixin.py:115} INFO - [2022-10-21 14:36:38,829] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:36:38,833] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:38,866] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.251 seconds
[2022-10-21 14:36:50,254] {processor.py:153} INFO - Started process (PID=9594) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:50,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:36:50,260] {logging_mixin.py:115} INFO - [2022-10-21 14:36:50,260] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:57,061] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:36:57,074] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:36:57,161] {logging_mixin.py:115} INFO - [2022-10-21 14:36:57,161] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:36:57,191] {logging_mixin.py:115} INFO - [2022-10-21 14:36:57,191] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:36:57.072320+00:00, run_after=2022-10-22T14:36:57.072320+00:00
[2022-10-21 14:36:57,207] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.004 seconds
[2022-10-21 14:37:09,148] {processor.py:153} INFO - Started process (PID=88141) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:09,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:37:09,150] {logging_mixin.py:115} INFO - [2022-10-21 14:37:09,150] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:09,359] {logging_mixin.py:115} INFO - [2022-10-21 14:37:09,357] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:37:09,361] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:09,392] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.249 seconds
[2022-10-21 14:37:28,010] {processor.py:153} INFO - Started process (PID=9948) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:28,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:37:28,014] {logging_mixin.py:115} INFO - [2022-10-21 14:37:28,014] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:32,749] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:37:32,767] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:32,891] {logging_mixin.py:115} INFO - [2022-10-21 14:37:32,890] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:37:32,932] {logging_mixin.py:115} INFO - [2022-10-21 14:37:32,932] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:37:32.765112+00:00, run_after=2022-10-22T14:37:32.765112+00:00
[2022-10-21 14:37:32,952] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.948 seconds
[2022-10-21 14:37:39,528] {processor.py:153} INFO - Started process (PID=88186) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:39,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:37:39,531] {logging_mixin.py:115} INFO - [2022-10-21 14:37:39,531] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:39,753] {logging_mixin.py:115} INFO - [2022-10-21 14:37:39,751] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:37:39,757] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:37:39,796] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.275 seconds
[2022-10-21 14:38:03,664] {processor.py:153} INFO - Started process (PID=10217) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:03,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:38:03,668] {logging_mixin.py:115} INFO - [2022-10-21 14:38:03,668] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:08,807] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:38:08,825] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:08,910] {logging_mixin.py:115} INFO - [2022-10-21 14:38:08,909] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:38:08,941] {logging_mixin.py:115} INFO - [2022-10-21 14:38:08,941] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:38:08.823469+00:00, run_after=2022-10-22T14:38:08.823469+00:00
[2022-10-21 14:38:08,962] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.305 seconds
[2022-10-21 14:38:10,259] {processor.py:153} INFO - Started process (PID=88238) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:10,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:38:10,263] {logging_mixin.py:115} INFO - [2022-10-21 14:38:10,263] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:10,487] {logging_mixin.py:115} INFO - [2022-10-21 14:38:10,485] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:38:10,490] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:10,535] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.294 seconds
[2022-10-21 14:38:39,070] {processor.py:153} INFO - Started process (PID=10491) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:39,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:38:39,073] {logging_mixin.py:115} INFO - [2022-10-21 14:38:39,073] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:41,364] {processor.py:153} INFO - Started process (PID=88300) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:41,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:38:41,367] {logging_mixin.py:115} INFO - [2022-10-21 14:38:41,367] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:41,596] {logging_mixin.py:115} INFO - [2022-10-21 14:38:41,596] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:38:41,600] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:41,632] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.274 seconds
[2022-10-21 14:38:47,085] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:38:47,103] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:38:47,226] {logging_mixin.py:115} INFO - [2022-10-21 14:38:47,225] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:38:47,277] {logging_mixin.py:115} INFO - [2022-10-21 14:38:47,277] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:38:47.100652+00:00, run_after=2022-10-22T14:38:47.100652+00:00
[2022-10-21 14:38:47,299] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 8.237 seconds
[2022-10-21 14:39:12,565] {processor.py:153} INFO - Started process (PID=88344) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:12,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:39:12,568] {logging_mixin.py:115} INFO - [2022-10-21 14:39:12,568] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:12,810] {logging_mixin.py:115} INFO - [2022-10-21 14:39:12,809] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:39:12,812] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:12,847] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.288 seconds
[2022-10-21 14:39:17,798] {processor.py:153} INFO - Started process (PID=11233) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:17,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:39:17,801] {logging_mixin.py:115} INFO - [2022-10-21 14:39:17,801] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:23,834] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:39:23,852] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:23,946] {logging_mixin.py:115} INFO - [2022-10-21 14:39:23,946] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:39:23,971] {logging_mixin.py:115} INFO - [2022-10-21 14:39:23,971] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:39:23.849221+00:00, run_after=2022-10-22T14:39:23.849221+00:00
[2022-10-21 14:39:23,998] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.227 seconds
[2022-10-21 14:39:42,897] {processor.py:153} INFO - Started process (PID=88397) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:42,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:39:42,900] {logging_mixin.py:115} INFO - [2022-10-21 14:39:42,899] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:43,124] {logging_mixin.py:115} INFO - [2022-10-21 14:39:43,123] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:39:43,127] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:43,156] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.266 seconds
[2022-10-21 14:39:54,901] {processor.py:153} INFO - Started process (PID=11506) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:39:54,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:39:54,905] {logging_mixin.py:115} INFO - [2022-10-21 14:39:54,904] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:00,426] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:40:00,453] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:00,585] {logging_mixin.py:115} INFO - [2022-10-21 14:40:00,585] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:40:00,615] {logging_mixin.py:115} INFO - [2022-10-21 14:40:00,614] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:40:00.450557+00:00, run_after=2022-10-22T14:40:00.450557+00:00
[2022-10-21 14:40:00,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.734 seconds
[2022-10-21 14:40:13,525] {processor.py:153} INFO - Started process (PID=88441) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:13,539] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:40:13,559] {logging_mixin.py:115} INFO - [2022-10-21 14:40:13,559] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:13,838] {logging_mixin.py:115} INFO - [2022-10-21 14:40:13,836] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:40:13,841] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:13,880] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.363 seconds
[2022-10-21 14:40:30,687] {processor.py:153} INFO - Started process (PID=11782) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:30,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:40:30,690] {logging_mixin.py:115} INFO - [2022-10-21 14:40:30,690] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:35,983] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:40:36,004] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:36,095] {logging_mixin.py:115} INFO - [2022-10-21 14:40:36,095] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:40:36,123] {logging_mixin.py:115} INFO - [2022-10-21 14:40:36,123] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:40:36.001959+00:00, run_after=2022-10-22T14:40:36.001959+00:00
[2022-10-21 14:40:36,149] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.467 seconds
[2022-10-21 14:40:43,925] {processor.py:153} INFO - Started process (PID=88494) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:43,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:40:43,928] {logging_mixin.py:115} INFO - [2022-10-21 14:40:43,928] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:44,150] {logging_mixin.py:115} INFO - [2022-10-21 14:40:44,149] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:40:44,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:40:44,184] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.264 seconds
[2022-10-21 14:41:06,261] {processor.py:153} INFO - Started process (PID=12052) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:06,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:41:06,264] {logging_mixin.py:115} INFO - [2022-10-21 14:41:06,264] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:12,029] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:41:12,053] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:12,150] {logging_mixin.py:115} INFO - [2022-10-21 14:41:12,150] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:41:12,180] {logging_mixin.py:115} INFO - [2022-10-21 14:41:12,179] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:41:12.051191+00:00, run_after=2022-10-22T14:41:12.051191+00:00
[2022-10-21 14:41:12,200] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.944 seconds
[2022-10-21 14:41:14,335] {processor.py:153} INFO - Started process (PID=88548) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:14,337] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:41:14,339] {logging_mixin.py:115} INFO - [2022-10-21 14:41:14,339] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:14,569] {logging_mixin.py:115} INFO - [2022-10-21 14:41:14,568] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:41:14,570] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:14,601] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.273 seconds
[2022-10-21 14:41:42,638] {processor.py:153} INFO - Started process (PID=12327) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:42,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:41:42,640] {logging_mixin.py:115} INFO - [2022-10-21 14:41:42,640] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:44,829] {processor.py:153} INFO - Started process (PID=88592) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:44,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:41:44,837] {logging_mixin.py:115} INFO - [2022-10-21 14:41:44,837] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:45,114] {logging_mixin.py:115} INFO - [2022-10-21 14:41:45,113] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:41:45,117] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:45,153] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.335 seconds
[2022-10-21 14:41:48,328] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:41:48,356] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:41:48,498] {logging_mixin.py:115} INFO - [2022-10-21 14:41:48,498] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:41:48,529] {logging_mixin.py:115} INFO - [2022-10-21 14:41:48,529] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:41:48.353814+00:00, run_after=2022-10-22T14:41:48.353814+00:00
[2022-10-21 14:41:48,547] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.915 seconds
[2022-10-21 14:42:15,439] {processor.py:153} INFO - Started process (PID=88645) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:15,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:42:15,443] {logging_mixin.py:115} INFO - [2022-10-21 14:42:15,443] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:15,664] {logging_mixin.py:115} INFO - [2022-10-21 14:42:15,663] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:42:15,669] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:15,696] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.263 seconds
[2022-10-21 14:42:18,977] {processor.py:153} INFO - Started process (PID=12607) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:18,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:42:18,980] {logging_mixin.py:115} INFO - [2022-10-21 14:42:18,980] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:23,919] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:42:23,934] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:24,083] {logging_mixin.py:115} INFO - [2022-10-21 14:42:24,083] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:42:24,111] {logging_mixin.py:115} INFO - [2022-10-21 14:42:24,111] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:42:23.932027+00:00, run_after=2022-10-22T14:42:23.932027+00:00
[2022-10-21 14:42:24,142] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.191 seconds
[2022-10-21 14:42:46,194] {processor.py:153} INFO - Started process (PID=88689) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:46,195] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:42:46,196] {logging_mixin.py:115} INFO - [2022-10-21 14:42:46,196] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:46,404] {logging_mixin.py:115} INFO - [2022-10-21 14:42:46,403] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:42:46,407] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:46,439] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.250 seconds
[2022-10-21 14:42:54,455] {processor.py:153} INFO - Started process (PID=12878) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:42:54,457] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:42:54,459] {logging_mixin.py:115} INFO - [2022-10-21 14:42:54,459] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:00,448] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:43:00,464] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:00,564] {logging_mixin.py:115} INFO - [2022-10-21 14:43:00,564] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:43:00,593] {logging_mixin.py:115} INFO - [2022-10-21 14:43:00,593] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:43:00.462154+00:00, run_after=2022-10-22T14:43:00.462154+00:00
[2022-10-21 14:43:00,612] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.162 seconds
[2022-10-21 14:43:16,523] {processor.py:153} INFO - Started process (PID=88741) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:16,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:43:16,525] {logging_mixin.py:115} INFO - [2022-10-21 14:43:16,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:16,739] {logging_mixin.py:115} INFO - [2022-10-21 14:43:16,737] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:43:16,741] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:16,773] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.255 seconds
[2022-10-21 14:43:30,930] {processor.py:153} INFO - Started process (PID=13158) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:30,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:43:30,932] {logging_mixin.py:115} INFO - [2022-10-21 14:43:30,932] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:36,194] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:43:36,207] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:36,285] {logging_mixin.py:115} INFO - [2022-10-21 14:43:36,285] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:43:36,309] {logging_mixin.py:115} INFO - [2022-10-21 14:43:36,309] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:43:36.205231+00:00, run_after=2022-10-22T14:43:36.205231+00:00
[2022-10-21 14:43:36,326] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.401 seconds
[2022-10-21 14:43:47,638] {processor.py:153} INFO - Started process (PID=88794) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:47,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:43:47,641] {logging_mixin.py:115} INFO - [2022-10-21 14:43:47,641] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:47,871] {logging_mixin.py:115} INFO - [2022-10-21 14:43:47,871] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:43:47,874] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:43:47,915] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.282 seconds
[2022-10-21 14:44:06,561] {processor.py:153} INFO - Started process (PID=13428) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:06,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:44:06,565] {logging_mixin.py:115} INFO - [2022-10-21 14:44:06,565] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:12,390] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:44:12,421] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:12,513] {logging_mixin.py:115} INFO - [2022-10-21 14:44:12,513] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:44:12,542] {logging_mixin.py:115} INFO - [2022-10-21 14:44:12,542] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:44:12.418861+00:00, run_after=2022-10-22T14:44:12.418861+00:00
[2022-10-21 14:44:12,559] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.002 seconds
[2022-10-21 14:44:18,289] {processor.py:153} INFO - Started process (PID=88840) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:18,291] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:44:18,293] {logging_mixin.py:115} INFO - [2022-10-21 14:44:18,293] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:18,506] {logging_mixin.py:115} INFO - [2022-10-21 14:44:18,505] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:44:18,508] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:18,538] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.256 seconds
[2022-10-21 14:44:42,867] {processor.py:153} INFO - Started process (PID=13710) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:42,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:44:42,870] {logging_mixin.py:115} INFO - [2022-10-21 14:44:42,870] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:48,980] {processor.py:153} INFO - Started process (PID=88893) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:48,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:44:48,995] {logging_mixin.py:115} INFO - [2022-10-21 14:44:48,995] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:49,267] {logging_mixin.py:115} INFO - [2022-10-21 14:44:49,266] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:44:49,270] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:49,303] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.329 seconds
[2022-10-21 14:44:49,738] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:44:49,755] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:44:49,857] {logging_mixin.py:115} INFO - [2022-10-21 14:44:49,857] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:44:49,893] {logging_mixin.py:115} INFO - [2022-10-21 14:44:49,893] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:44:49.752017+00:00, run_after=2022-10-22T14:44:49.752017+00:00
[2022-10-21 14:44:49,913] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 7.050 seconds
[2022-10-21 14:45:20,038] {processor.py:153} INFO - Started process (PID=13982) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:20,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:45:20,041] {logging_mixin.py:115} INFO - [2022-10-21 14:45:20,041] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:20,056] {processor.py:153} INFO - Started process (PID=88944) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:20,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:45:20,060] {logging_mixin.py:115} INFO - [2022-10-21 14:45:20,060] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:20,288] {logging_mixin.py:115} INFO - [2022-10-21 14:45:20,286] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:45:20,290] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:20,329] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.281 seconds
[2022-10-21 14:45:25,194] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:45:25,208] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:25,304] {logging_mixin.py:115} INFO - [2022-10-21 14:45:25,303] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:45:25,333] {logging_mixin.py:115} INFO - [2022-10-21 14:45:25,333] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:45:25.205721+00:00, run_after=2022-10-22T14:45:25.205721+00:00
[2022-10-21 14:45:25,350] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.341 seconds
[2022-10-21 14:45:50,490] {processor.py:153} INFO - Started process (PID=88990) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:50,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:45:50,493] {logging_mixin.py:115} INFO - [2022-10-21 14:45:50,493] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:50,708] {logging_mixin.py:115} INFO - [2022-10-21 14:45:50,707] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:45:50,709] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:50,754] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.269 seconds
[2022-10-21 14:45:55,995] {processor.py:153} INFO - Started process (PID=14261) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:45:55,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:45:55,998] {logging_mixin.py:115} INFO - [2022-10-21 14:45:55,998] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:01,482] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:46:01,510] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:01,608] {logging_mixin.py:115} INFO - [2022-10-21 14:46:01,608] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:46:01,639] {logging_mixin.py:115} INFO - [2022-10-21 14:46:01,639] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:46:01.508250+00:00, run_after=2022-10-22T14:46:01.508250+00:00
[2022-10-21 14:46:01,663] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.672 seconds
[2022-10-21 14:46:20,977] {processor.py:153} INFO - Started process (PID=89034) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:20,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:46:20,980] {logging_mixin.py:115} INFO - [2022-10-21 14:46:20,980] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:21,185] {logging_mixin.py:115} INFO - [2022-10-21 14:46:21,184] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:46:21,187] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:21,228] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.258 seconds
[2022-10-21 14:46:32,512] {processor.py:153} INFO - Started process (PID=14539) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:32,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:46:32,515] {logging_mixin.py:115} INFO - [2022-10-21 14:46:32,515] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:38,391] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:46:38,408] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:38,490] {logging_mixin.py:115} INFO - [2022-10-21 14:46:38,490] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:46:38,534] {logging_mixin.py:115} INFO - [2022-10-21 14:46:38,534] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:46:38.406384+00:00, run_after=2022-10-22T14:46:38.406384+00:00
[2022-10-21 14:46:38,561] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.054 seconds
[2022-10-21 14:46:52,040] {processor.py:153} INFO - Started process (PID=89079) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:52,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:46:52,044] {logging_mixin.py:115} INFO - [2022-10-21 14:46:52,044] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:52,287] {logging_mixin.py:115} INFO - [2022-10-21 14:46:52,285] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:46:52,290] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:46:52,334] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.300 seconds
[2022-10-21 14:47:08,726] {processor.py:153} INFO - Started process (PID=14809) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:08,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:47:08,729] {logging_mixin.py:115} INFO - [2022-10-21 14:47:08,728] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:14,991] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:47:15,044] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:15,293] {logging_mixin.py:115} INFO - [2022-10-21 14:47:15,293] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:47:15,347] {logging_mixin.py:115} INFO - [2022-10-21 14:47:15,347] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:47:15.039032+00:00, run_after=2022-10-22T14:47:15.039032+00:00
[2022-10-21 14:47:15,398] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.677 seconds
[2022-10-21 14:47:22,478] {processor.py:153} INFO - Started process (PID=89133) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:22,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:47:22,482] {logging_mixin.py:115} INFO - [2022-10-21 14:47:22,482] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:22,720] {logging_mixin.py:115} INFO - [2022-10-21 14:47:22,718] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:47:22,724] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:22,760] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.293 seconds
[2022-10-21 14:47:45,933] {processor.py:153} INFO - Started process (PID=15092) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:45,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:47:45,936] {logging_mixin.py:115} INFO - [2022-10-21 14:47:45,936] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:50,799] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:47:50,815] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:50,935] {logging_mixin.py:115} INFO - [2022-10-21 14:47:50,934] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:47:50,974] {logging_mixin.py:115} INFO - [2022-10-21 14:47:50,973] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:47:50.811431+00:00, run_after=2022-10-22T14:47:50.811431+00:00
[2022-10-21 14:47:50,992] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.063 seconds
[2022-10-21 14:47:53,873] {processor.py:153} INFO - Started process (PID=89187) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:53,880] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:47:53,888] {logging_mixin.py:115} INFO - [2022-10-21 14:47:53,888] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:54,112] {logging_mixin.py:115} INFO - [2022-10-21 14:47:54,111] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:47:54,114] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:47:54,161] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.294 seconds
[2022-10-21 14:48:21,060] {processor.py:153} INFO - Started process (PID=15362) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:48:21,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:48:21,062] {logging_mixin.py:115} INFO - [2022-10-21 14:48:21,062] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:48:24,508] {processor.py:153} INFO - Started process (PID=89228) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:48:24,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:48:24,511] {logging_mixin.py:115} INFO - [2022-10-21 14:48:24,510] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:48:24,746] {logging_mixin.py:115} INFO - [2022-10-21 14:48:24,745] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:48:24,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:48:24,778] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.276 seconds
[2022-10-21 14:48:25,721] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:48:25,745] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:48:25,849] {logging_mixin.py:115} INFO - [2022-10-21 14:48:25,848] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:48:25,926] {logging_mixin.py:115} INFO - [2022-10-21 14:48:25,926] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:48:25.743188+00:00, run_after=2022-10-22T14:48:25.743188+00:00
[2022-10-21 14:48:25,952] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.919 seconds
[2022-10-21 14:48:56,225] {processor.py:153} INFO - Started process (PID=15645) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:48:56,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:48:56,230] {logging_mixin.py:115} INFO - [2022-10-21 14:48:56,230] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:49:18,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:49:18,297] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:49:18,782] {logging_mixin.py:115} INFO - [2022-10-21 14:49:18,782] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:49:18,859] {logging_mixin.py:115} INFO - [2022-10-21 14:49:18,859] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:49:18.270988+00:00, run_after=2022-10-22T14:49:18.270988+00:00
[2022-10-21 14:49:18,915] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 22.697 seconds
[2022-10-21 14:49:27,055] {processor.py:153} INFO - Started process (PID=89290) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:49:27,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:49:27,073] {logging_mixin.py:115} INFO - [2022-10-21 14:49:27,073] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:49:28,051] {logging_mixin.py:115} INFO - [2022-10-21 14:49:28,048] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:49:28,055] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:49:28,240] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.215 seconds
[2022-10-21 14:49:59,165] {processor.py:153} INFO - Started process (PID=89332) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:49:59,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:49:59,172] {logging_mixin.py:115} INFO - [2022-10-21 14:49:59,172] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:49:59,823] {logging_mixin.py:115} INFO - [2022-10-21 14:49:59,810] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:49:59,843] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:50:00,229] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.086 seconds
[2022-10-21 14:50:11,236] {processor.py:153} INFO - Started process (PID=15955) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:50:11,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:50:11,240] {logging_mixin.py:115} INFO - [2022-10-21 14:50:11,240] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:50:28,514] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:50:28,567] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:50:28,881] {logging_mixin.py:115} INFO - [2022-10-21 14:50:28,880] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:50:28,983] {logging_mixin.py:115} INFO - [2022-10-21 14:50:28,982] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:50:28.557729+00:00, run_after=2022-10-22T14:50:28.557729+00:00
[2022-10-21 14:50:29,043] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.837 seconds
[2022-10-21 14:50:30,767] {processor.py:153} INFO - Started process (PID=89370) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:50:30,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:50:30,773] {logging_mixin.py:115} INFO - [2022-10-21 14:50:30,772] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:50:31,150] {logging_mixin.py:115} INFO - [2022-10-21 14:50:31,145] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:50:31,157] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:50:31,243] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.486 seconds
[2022-10-21 14:51:01,978] {processor.py:153} INFO - Started process (PID=89413) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:01,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:51:02,012] {logging_mixin.py:115} INFO - [2022-10-21 14:51:02,012] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:05,502] {logging_mixin.py:115} INFO - [2022-10-21 14:51:05,498] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:51:05,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:06,400] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 4.634 seconds
[2022-10-21 14:51:17,851] {processor.py:153} INFO - Started process (PID=16191) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:17,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:51:18,016] {logging_mixin.py:115} INFO - [2022-10-21 14:51:17,944] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:37,283] {processor.py:153} INFO - Started process (PID=89459) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:37,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:51:37,293] {logging_mixin.py:115} INFO - [2022-10-21 14:51:37,292] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:37,950] {logging_mixin.py:115} INFO - [2022-10-21 14:51:37,945] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:51:37,955] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:38,076] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.864 seconds
[2022-10-21 14:51:48,058] {logging_mixin.py:115} INFO - [2022-10-21 14:51:48,058] {timeout.py:67} ERROR - Process timed out, PID: 16191
[2022-10-21 14:51:48,066] {logging_mixin.py:115} INFO - [2022-10-21 14:51:48,064] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 16191
[2022-10-21 14:51:48,082] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:51:48,377] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.785 seconds
[2022-10-21 14:52:08,463] {processor.py:153} INFO - Started process (PID=89493) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:08,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:52:08,478] {logging_mixin.py:115} INFO - [2022-10-21 14:52:08,477] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:09,239] {logging_mixin.py:115} INFO - [2022-10-21 14:52:09,237] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:52:09,243] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:09,354] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.915 seconds
[2022-10-21 14:52:18,778] {processor.py:153} INFO - Started process (PID=16442) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:18,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:52:18,784] {logging_mixin.py:115} INFO - [2022-10-21 14:52:18,784] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:30,061] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:52:30,094] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:30,218] {logging_mixin.py:115} INFO - [2022-10-21 14:52:30,217] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:52:30,254] {logging_mixin.py:115} INFO - [2022-10-21 14:52:30,254] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:52:30.090880+00:00, run_after=2022-10-22T14:52:30.090880+00:00
[2022-10-21 14:52:30,280] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 11.534 seconds
[2022-10-21 14:52:39,532] {processor.py:153} INFO - Started process (PID=89542) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:39,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:52:39,535] {logging_mixin.py:115} INFO - [2022-10-21 14:52:39,535] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:39,744] {logging_mixin.py:115} INFO - [2022-10-21 14:52:39,743] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:52:39,745] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:52:39,772] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.245 seconds
[2022-10-21 14:53:00,823] {processor.py:153} INFO - Started process (PID=16724) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:00,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:53:00,825] {logging_mixin.py:115} INFO - [2022-10-21 14:53:00,825] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:07,497] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:53:07,517] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:07,626] {logging_mixin.py:115} INFO - [2022-10-21 14:53:07,625] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:53:07,659] {logging_mixin.py:115} INFO - [2022-10-21 14:53:07,659] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:53:07.513533+00:00, run_after=2022-10-22T14:53:07.513533+00:00
[2022-10-21 14:53:07,680] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 6.862 seconds
[2022-10-21 14:53:10,544] {processor.py:153} INFO - Started process (PID=89589) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:10,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:53:10,548] {logging_mixin.py:115} INFO - [2022-10-21 14:53:10,548] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:10,812] {logging_mixin.py:115} INFO - [2022-10-21 14:53:10,810] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:53:10,814] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:10,854] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.317 seconds
[2022-10-21 14:53:37,976] {processor.py:153} INFO - Started process (PID=17004) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:37,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:53:37,978] {logging_mixin.py:115} INFO - [2022-10-21 14:53:37,978] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:41,528] {processor.py:153} INFO - Started process (PID=89641) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:41,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:53:41,531] {logging_mixin.py:115} INFO - [2022-10-21 14:53:41,531] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:41,806] {logging_mixin.py:115} INFO - [2022-10-21 14:53:41,805] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:53:41,811] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:41,887] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.370 seconds
[2022-10-21 14:53:43,324] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:53:43,343] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:53:43,443] {logging_mixin.py:115} INFO - [2022-10-21 14:53:43,443] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:53:43,470] {logging_mixin.py:115} INFO - [2022-10-21 14:53:43,470] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:53:43.339478+00:00, run_after=2022-10-22T14:53:43.339478+00:00
[2022-10-21 14:53:43,490] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 5.520 seconds
[2022-10-21 14:55:21,457] {processor.py:153} INFO - Started process (PID=89726) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:55:21,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:55:21,461] {logging_mixin.py:115} INFO - [2022-10-21 14:55:21,461] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:55:21,713] {logging_mixin.py:115} INFO - [2022-10-21 14:55:21,712] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:55:21,715] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:55:21,762] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.333 seconds
[2022-10-21 14:55:37,410] {processor.py:153} INFO - Started process (PID=17341) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:55:37,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:55:37,460] {logging_mixin.py:115} INFO - [2022-10-21 14:55:37,460] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:56:02,678] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:56:02,717] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:56:03,024] {logging_mixin.py:115} INFO - [2022-10-21 14:56:03,024] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:56:03,425] {logging_mixin.py:115} INFO - [2022-10-21 14:56:03,425] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:56:02.713139+00:00, run_after=2022-10-22T14:56:02.713139+00:00
[2022-10-21 14:56:03,469] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 26.106 seconds
[2022-10-21 14:56:24,834] {processor.py:153} INFO - Started process (PID=90264) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:56:24,837] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:56:24,842] {logging_mixin.py:115} INFO - [2022-10-21 14:56:24,842] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:56:25,326] {logging_mixin.py:115} INFO - [2022-10-21 14:56:25,323] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:56:25,329] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:56:25,430] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.613 seconds
[2022-10-21 14:56:57,801] {processor.py:153} INFO - Started process (PID=90535) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:56:57,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:56:57,809] {logging_mixin.py:115} INFO - [2022-10-21 14:56:57,808] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:56:58,466] {logging_mixin.py:115} INFO - [2022-10-21 14:56:58,462] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:56:58,470] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:56:58,557] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.774 seconds
[2022-10-21 14:57:01,458] {processor.py:153} INFO - Started process (PID=18137) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:57:01,463] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:57:01,466] {logging_mixin.py:115} INFO - [2022-10-21 14:57:01,466] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:57:28,319] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:57:28,397] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:57:29,063] {logging_mixin.py:115} INFO - [2022-10-21 14:57:29,062] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:57:29,142] {logging_mixin.py:115} INFO - [2022-10-21 14:57:29,142] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:57:28.390034+00:00, run_after=2022-10-22T14:57:28.390034+00:00
[2022-10-21 14:57:29,188] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 27.767 seconds
[2022-10-21 14:57:31,992] {processor.py:153} INFO - Started process (PID=90833) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:57:32,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:57:32,002] {logging_mixin.py:115} INFO - [2022-10-21 14:57:32,002] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:57:32,665] {logging_mixin.py:115} INFO - [2022-10-21 14:57:32,663] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:57:32,668] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:57:32,754] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.773 seconds
[2022-10-21 14:58:18,211] {processor.py:153} INFO - Started process (PID=18930) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:58:18,217] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:58:18,220] {logging_mixin.py:115} INFO - [2022-10-21 14:58:18,219] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:58:28,536] {processor.py:153} INFO - Started process (PID=91371) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:58:28,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:58:28,540] {logging_mixin.py:115} INFO - [2022-10-21 14:58:28,540] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:58:29,132] {logging_mixin.py:115} INFO - [2022-10-21 14:58:29,131] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:58:29,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:58:29,193] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.676 seconds
[2022-10-21 14:58:39,115] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:58:39,146] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:58:39,346] {logging_mixin.py:115} INFO - [2022-10-21 14:58:39,346] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:58:39,385] {logging_mixin.py:115} INFO - [2022-10-21 14:58:39,385] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:58:39.141452+00:00, run_after=2022-10-22T14:58:39.141452+00:00
[2022-10-21 14:58:39,410] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 21.234 seconds
[2022-10-21 14:59:12,528] {processor.py:153} INFO - Started process (PID=91844) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:59:12,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:59:12,534] {logging_mixin.py:115} INFO - [2022-10-21 14:59:12,534] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:59:13,185] {logging_mixin.py:115} INFO - [2022-10-21 14:59:13,184] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 14:59:13,188] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:59:13,236] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.715 seconds
[2022-10-21 14:59:23,179] {processor.py:153} INFO - Started process (PID=19736) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:59:23,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 14:59:23,185] {logging_mixin.py:115} INFO - [2022-10-21 14:59:23,185] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:59:41,748] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 14:59:41,837] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 14:59:42,148] {logging_mixin.py:115} INFO - [2022-10-21 14:59:42,146] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 14:59:42,251] {logging_mixin.py:115} INFO - [2022-10-21 14:59:42,251] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T14:59:41.833647+00:00, run_after=2022-10-22T14:59:41.833647+00:00
[2022-10-21 14:59:42,336] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.174 seconds
[2022-10-21 15:00:30,441] {processor.py:153} INFO - Started process (PID=92260) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:00:30,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:00:30,446] {logging_mixin.py:115} INFO - [2022-10-21 15:00:30,446] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:00:30,705] {logging_mixin.py:115} INFO - [2022-10-21 15:00:30,704] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:00:30,707] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:00:30,751] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.322 seconds
[2022-10-21 15:00:59,302] {processor.py:153} INFO - Started process (PID=20511) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:00:59,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:00:59,306] {logging_mixin.py:115} INFO - [2022-10-21 15:00:59,306] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:04,954] {processor.py:153} INFO - Started process (PID=92723) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:04,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:01:04,964] {logging_mixin.py:115} INFO - [2022-10-21 15:01:04,964] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:05,411] {logging_mixin.py:115} INFO - [2022-10-21 15:01:05,410] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:01:05,413] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:05,496] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.547 seconds
[2022-10-21 15:01:13,127] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:01:13,155] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:13,284] {logging_mixin.py:115} INFO - [2022-10-21 15:01:13,284] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:01:13,316] {logging_mixin.py:115} INFO - [2022-10-21 15:01:13,316] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:01:13.150145+00:00, run_after=2022-10-22T15:01:13.150145+00:00
[2022-10-21 15:01:13,342] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.046 seconds
[2022-10-21 15:01:41,023] {processor.py:153} INFO - Started process (PID=93189) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:41,026] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:01:41,028] {logging_mixin.py:115} INFO - [2022-10-21 15:01:41,028] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:41,292] {logging_mixin.py:115} INFO - [2022-10-21 15:01:41,291] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:01:41,294] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:41,368] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.354 seconds
[2022-10-21 15:01:47,251] {processor.py:153} INFO - Started process (PID=21241) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:01:47,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:01:47,255] {logging_mixin.py:115} INFO - [2022-10-21 15:01:47,254] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:00,646] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:02:00,681] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:00,883] {logging_mixin.py:115} INFO - [2022-10-21 15:02:00,883] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:02:00,957] {logging_mixin.py:115} INFO - [2022-10-21 15:02:00,957] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:02:00.678001+00:00, run_after=2022-10-22T15:02:00.678001+00:00
[2022-10-21 15:02:00,986] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.762 seconds
[2022-10-21 15:02:16,638] {processor.py:153} INFO - Started process (PID=93707) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:16,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:02:16,642] {logging_mixin.py:115} INFO - [2022-10-21 15:02:16,642] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:16,927] {logging_mixin.py:115} INFO - [2022-10-21 15:02:16,925] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:02:16,931] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:16,981] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.350 seconds
[2022-10-21 15:02:35,562] {processor.py:153} INFO - Started process (PID=22011) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:35,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:02:35,565] {logging_mixin.py:115} INFO - [2022-10-21 15:02:35,565] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:49,824] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:02:49,908] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:50,189] {logging_mixin.py:115} INFO - [2022-10-21 15:02:50,189] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:02:50,244] {logging_mixin.py:115} INFO - [2022-10-21 15:02:50,244] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:02:49.892802+00:00, run_after=2022-10-22T15:02:49.892802+00:00
[2022-10-21 15:02:50,285] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.732 seconds
[2022-10-21 15:02:53,017] {processor.py:153} INFO - Started process (PID=94237) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:53,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:02:53,026] {logging_mixin.py:115} INFO - [2022-10-21 15:02:53,026] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:53,380] {logging_mixin.py:115} INFO - [2022-10-21 15:02:53,378] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:02:53,395] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:02:53,494] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.485 seconds
[2022-10-21 15:03:23,739] {processor.py:153} INFO - Started process (PID=22784) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:23,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:03:23,742] {logging_mixin.py:115} INFO - [2022-10-21 15:03:23,742] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:24,001] {processor.py:153} INFO - Started process (PID=94693) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:24,003] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:03:24,005] {logging_mixin.py:115} INFO - [2022-10-21 15:03:24,005] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:24,257] {logging_mixin.py:115} INFO - [2022-10-21 15:03:24,256] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:03:24,260] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:24,310] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.316 seconds
[2022-10-21 15:03:36,259] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:03:36,288] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:36,407] {logging_mixin.py:115} INFO - [2022-10-21 15:03:36,407] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:03:36,444] {logging_mixin.py:115} INFO - [2022-10-21 15:03:36,444] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:03:36.284762+00:00, run_after=2022-10-22T15:03:36.284762+00:00
[2022-10-21 15:03:36,476] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 12.744 seconds
[2022-10-21 15:03:59,479] {processor.py:153} INFO - Started process (PID=95229) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:59,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:03:59,498] {logging_mixin.py:115} INFO - [2022-10-21 15:03:59,498] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:59,836] {logging_mixin.py:115} INFO - [2022-10-21 15:03:59,834] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:03:59,839] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:03:59,886] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.428 seconds
[2022-10-21 15:04:10,424] {processor.py:153} INFO - Started process (PID=23544) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:04:10,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:04:10,440] {logging_mixin.py:115} INFO - [2022-10-21 15:04:10,440] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:04:23,833] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:04:23,851] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:04:24,081] {logging_mixin.py:115} INFO - [2022-10-21 15:04:24,080] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:04:24,117] {logging_mixin.py:115} INFO - [2022-10-21 15:04:24,117] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:04:23.847806+00:00, run_after=2022-10-22T15:04:23.847806+00:00
[2022-10-21 15:04:24,173] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.791 seconds
[2022-10-21 15:04:31,826] {processor.py:153} INFO - Started process (PID=95684) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:04:31,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:04:31,829] {logging_mixin.py:115} INFO - [2022-10-21 15:04:31,829] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:04:32,068] {logging_mixin.py:115} INFO - [2022-10-21 15:04:32,067] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:04:32,069] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:04:32,111] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.292 seconds
[2022-10-21 15:04:59,834] {processor.py:153} INFO - Started process (PID=24317) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:04:59,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:04:59,837] {logging_mixin.py:115} INFO - [2022-10-21 15:04:59,837] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:05:18,660] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:05:18,710] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:05:18,866] {logging_mixin.py:115} INFO - [2022-10-21 15:05:18,865] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:05:18,904] {logging_mixin.py:115} INFO - [2022-10-21 15:05:18,904] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:05:18.691702+00:00, run_after=2022-10-22T15:05:18.691702+00:00
[2022-10-21 15:05:18,927] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.099 seconds
[2022-10-21 15:05:19,436] {processor.py:153} INFO - Started process (PID=95894) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:05:19,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:05:19,442] {logging_mixin.py:115} INFO - [2022-10-21 15:05:19,442] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:05:19,700] {logging_mixin.py:115} INFO - [2022-10-21 15:05:19,699] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:05:19,704] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:05:19,769] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.339 seconds
[2022-10-21 15:05:52,593] {processor.py:153} INFO - Started process (PID=96421) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:05:52,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:05:52,598] {logging_mixin.py:115} INFO - [2022-10-21 15:05:52,597] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:05:52,900] {logging_mixin.py:115} INFO - [2022-10-21 15:05:52,899] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:05:52,903] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:05:52,954] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.367 seconds
[2022-10-21 15:06:09,130] {processor.py:153} INFO - Started process (PID=25102) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:06:09,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:06:09,133] {logging_mixin.py:115} INFO - [2022-10-21 15:06:09,133] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:06:22,072] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:06:22,098] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:06:22,328] {logging_mixin.py:115} INFO - [2022-10-21 15:06:22,328] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:06:22,370] {logging_mixin.py:115} INFO - [2022-10-21 15:06:22,370] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:06:22.094245+00:00, run_after=2022-10-22T15:06:22.094245+00:00
[2022-10-21 15:06:22,424] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.322 seconds
[2022-10-21 15:06:27,761] {processor.py:153} INFO - Started process (PID=96933) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:06:27,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:06:27,765] {logging_mixin.py:115} INFO - [2022-10-21 15:06:27,765] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:06:28,320] {logging_mixin.py:115} INFO - [2022-10-21 15:06:28,319] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:06:28,323] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:06:28,396] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.647 seconds
[2022-10-21 15:06:56,796] {processor.py:153} INFO - Started process (PID=25864) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:06:56,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:06:56,800] {logging_mixin.py:115} INFO - [2022-10-21 15:06:56,800] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:00,288] {processor.py:153} INFO - Started process (PID=97407) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:00,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:07:00,303] {logging_mixin.py:115} INFO - [2022-10-21 15:07:00,303] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:00,647] {logging_mixin.py:115} INFO - [2022-10-21 15:07:00,646] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:07:00,653] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:00,700] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.420 seconds
[2022-10-21 15:07:10,128] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:07:10,181] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:10,407] {logging_mixin.py:115} INFO - [2022-10-21 15:07:10,407] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:07:10,455] {logging_mixin.py:115} INFO - [2022-10-21 15:07:10,455] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:07:10.175775+00:00, run_after=2022-10-22T15:07:10.175775+00:00
[2022-10-21 15:07:10,495] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.710 seconds
[2022-10-21 15:07:36,626] {processor.py:153} INFO - Started process (PID=97937) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:36,628] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:07:36,630] {logging_mixin.py:115} INFO - [2022-10-21 15:07:36,630] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:36,926] {logging_mixin.py:115} INFO - [2022-10-21 15:07:36,925] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:07:36,929] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:36,986] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.369 seconds
[2022-10-21 15:07:45,331] {processor.py:153} INFO - Started process (PID=26673) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:45,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:07:45,339] {logging_mixin.py:115} INFO - [2022-10-21 15:07:45,338] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:59,457] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:07:59,478] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:07:59,600] {logging_mixin.py:115} INFO - [2022-10-21 15:07:59,600] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:07:59,641] {logging_mixin.py:115} INFO - [2022-10-21 15:07:59,640] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:07:59.474408+00:00, run_after=2022-10-22T15:07:59.474408+00:00
[2022-10-21 15:07:59,671] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.368 seconds
[2022-10-21 15:08:11,192] {processor.py:153} INFO - Started process (PID=98426) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:11,194] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:08:11,195] {logging_mixin.py:115} INFO - [2022-10-21 15:08:11,195] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:11,436] {logging_mixin.py:115} INFO - [2022-10-21 15:08:11,435] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:08:11,437] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:11,481] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.301 seconds
[2022-10-21 15:08:32,980] {processor.py:153} INFO - Started process (PID=27401) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:32,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:08:32,984] {logging_mixin.py:115} INFO - [2022-10-21 15:08:32,984] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:46,410] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:08:46,500] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:46,685] {logging_mixin.py:115} INFO - [2022-10-21 15:08:46,685] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:08:46,711] {processor.py:153} INFO - Started process (PID=98934) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:46,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:08:46,717] {logging_mixin.py:115} INFO - [2022-10-21 15:08:46,717] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:46,729] {logging_mixin.py:115} INFO - [2022-10-21 15:08:46,728] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:08:46.497523+00:00, run_after=2022-10-22T15:08:46.497523+00:00
[2022-10-21 15:08:46,762] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.788 seconds
[2022-10-21 15:08:47,093] {logging_mixin.py:115} INFO - [2022-10-21 15:08:47,091] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:08:47,095] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:08:47,145] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.453 seconds
[2022-10-21 15:09:21,809] {processor.py:153} INFO - Started process (PID=28170) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:09:21,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:09:21,814] {logging_mixin.py:115} INFO - [2022-10-21 15:09:21,814] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:09:22,244] {processor.py:153} INFO - Started process (PID=99449) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:09:22,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:09:22,248] {logging_mixin.py:115} INFO - [2022-10-21 15:09:22,248] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:09:22,517] {logging_mixin.py:115} INFO - [2022-10-21 15:09:22,516] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:09:22,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:09:22,564] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.328 seconds
[2022-10-21 15:09:36,179] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:09:36,197] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:09:36,322] {logging_mixin.py:115} INFO - [2022-10-21 15:09:36,322] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:09:36,354] {logging_mixin.py:115} INFO - [2022-10-21 15:09:36,354] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:09:36.194539+00:00, run_after=2022-10-22T15:09:36.194539+00:00
[2022-10-21 15:09:36,379] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.576 seconds
[2022-10-21 15:10:20,452] {processor.py:153} INFO - Started process (PID=99827) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:20,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:10:20,456] {logging_mixin.py:115} INFO - [2022-10-21 15:10:20,455] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:20,752] {logging_mixin.py:115} INFO - [2022-10-21 15:10:20,750] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:10:20,755] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:20,794] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.351 seconds
[2022-10-21 15:10:40,962] {processor.py:153} INFO - Started process (PID=28980) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:40,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:10:40,974] {logging_mixin.py:115} INFO - [2022-10-21 15:10:40,974] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:52,010] {processor.py:153} INFO - Started process (PID=623) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:52,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:10:52,021] {logging_mixin.py:115} INFO - [2022-10-21 15:10:52,021] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:53,836] {logging_mixin.py:115} INFO - [2022-10-21 15:10:53,834] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:10:53,839] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:54,082] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.077 seconds
[2022-10-21 15:10:57,934] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:10:57,967] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:10:58,157] {logging_mixin.py:115} INFO - [2022-10-21 15:10:58,156] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:10:58,204] {logging_mixin.py:115} INFO - [2022-10-21 15:10:58,204] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:10:57.962964+00:00, run_after=2022-10-22T15:10:57.962964+00:00
[2022-10-21 15:10:58,238] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.303 seconds
[2022-10-21 15:11:27,093] {processor.py:153} INFO - Started process (PID=1075) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:11:27,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:11:27,099] {logging_mixin.py:115} INFO - [2022-10-21 15:11:27,099] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:11:27,379] {logging_mixin.py:115} INFO - [2022-10-21 15:11:27,378] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:11:27,382] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:11:27,442] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.355 seconds
[2022-10-21 15:11:31,806] {processor.py:153} INFO - Started process (PID=29724) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:11:31,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:11:31,811] {logging_mixin.py:115} INFO - [2022-10-21 15:11:31,811] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:11:46,289] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:11:46,351] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:11:46,563] {logging_mixin.py:115} INFO - [2022-10-21 15:11:46,563] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:11:46,589] {logging_mixin.py:115} INFO - [2022-10-21 15:11:46,589] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:11:46.349525+00:00, run_after=2022-10-22T15:11:46.349525+00:00
[2022-10-21 15:11:46,608] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.812 seconds
[2022-10-21 15:12:02,206] {processor.py:153} INFO - Started process (PID=1598) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:12:02,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:12:02,210] {logging_mixin.py:115} INFO - [2022-10-21 15:12:02,210] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:12:02,652] {logging_mixin.py:115} INFO - [2022-10-21 15:12:02,651] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:12:02,657] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:12:02,715] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.528 seconds
[2022-10-21 15:12:43,296] {processor.py:153} INFO - Started process (PID=30492) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:12:43,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:12:43,313] {logging_mixin.py:115} INFO - [2022-10-21 15:12:43,312] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:12:52,178] {processor.py:153} INFO - Started process (PID=1917) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:12:52,183] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:12:52,185] {logging_mixin.py:115} INFO - [2022-10-21 15:12:52,185] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:12:52,597] {logging_mixin.py:115} INFO - [2022-10-21 15:12:52,595] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:12:52,599] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:12:52,652] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.482 seconds
[2022-10-21 15:13:04,248] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:13:04,293] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:13:04,541] {logging_mixin.py:115} INFO - [2022-10-21 15:13:04,541] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:13:04,600] {logging_mixin.py:115} INFO - [2022-10-21 15:13:04,600] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:13:04.287187+00:00, run_after=2022-10-22T15:13:04.287187+00:00
[2022-10-21 15:13:04,641] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 21.351 seconds
[2022-10-21 15:13:42,420] {processor.py:153} INFO - Started process (PID=2396) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:13:42,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:13:42,426] {logging_mixin.py:115} INFO - [2022-10-21 15:13:42,426] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:13:42,882] {logging_mixin.py:115} INFO - [2022-10-21 15:13:42,879] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:13:42,885] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:13:43,015] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.607 seconds
[2022-10-21 15:14:02,600] {processor.py:153} INFO - Started process (PID=31288) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:14:02,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:14:02,615] {logging_mixin.py:115} INFO - [2022-10-21 15:14:02,614] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:14:16,443] {processor.py:153} INFO - Started process (PID=2676) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:14:16,445] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:14:16,448] {logging_mixin.py:115} INFO - [2022-10-21 15:14:16,447] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:14:16,829] {logging_mixin.py:115} INFO - [2022-10-21 15:14:16,827] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:14:16,836] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:14:16,995] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.572 seconds
[2022-10-21 15:14:31,723] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:14:31,803] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:14:32,165] {logging_mixin.py:115} INFO - [2022-10-21 15:14:32,165] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:14:32,302] {logging_mixin.py:115} INFO - [2022-10-21 15:14:32,301] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:14:31.794325+00:00, run_after=2022-10-22T15:14:31.794325+00:00
[2022-10-21 15:14:32,412] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 29.842 seconds
[2022-10-21 15:15:58,303] {processor.py:153} INFO - Started process (PID=31863) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:15:58,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:15:58,309] {logging_mixin.py:115} INFO - [2022-10-21 15:15:58,309] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:16:12,196] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:16:12,221] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:16:12,388] {logging_mixin.py:115} INFO - [2022-10-21 15:16:12,388] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:16:12,434] {logging_mixin.py:115} INFO - [2022-10-21 15:16:12,433] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:16:12.215400+00:00, run_after=2022-10-22T15:16:12.215400+00:00
[2022-10-21 15:16:12,512] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.219 seconds
[2022-10-21 15:16:18,083] {processor.py:153} INFO - Started process (PID=2943) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:16:18,086] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:16:18,089] {logging_mixin.py:115} INFO - [2022-10-21 15:16:18,088] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:16:19,541] {logging_mixin.py:115} INFO - [2022-10-21 15:16:19,539] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:16:19,547] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:16:19,624] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.546 seconds
[2022-10-21 15:16:54,461] {processor.py:153} INFO - Started process (PID=32557) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:16:54,463] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:16:54,467] {logging_mixin.py:115} INFO - [2022-10-21 15:16:54,467] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:17:13,316] {processor.py:153} INFO - Started process (PID=3479) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:17:13,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:17:13,322] {logging_mixin.py:115} INFO - [2022-10-21 15:17:13,322] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:17:13,667] {logging_mixin.py:115} INFO - [2022-10-21 15:17:13,666] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:17:13,671] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:17:13,732] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.428 seconds
[2022-10-21 15:17:14,140] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:17:14,173] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:17:14,416] {logging_mixin.py:115} INFO - [2022-10-21 15:17:14,416] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:17:14,508] {logging_mixin.py:115} INFO - [2022-10-21 15:17:14,508] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:17:14.169144+00:00, run_after=2022-10-22T15:17:14.169144+00:00
[2022-10-21 15:17:14,560] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 20.130 seconds
[2022-10-21 15:17:52,471] {processor.py:153} INFO - Started process (PID=3896) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:17:52,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:17:52,476] {logging_mixin.py:115} INFO - [2022-10-21 15:17:52,476] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:17:52,933] {logging_mixin.py:115} INFO - [2022-10-21 15:17:52,931] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:17:52,936] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:17:53,001] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.553 seconds
[2022-10-21 15:18:04,493] {processor.py:153} INFO - Started process (PID=33347) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:18:04,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:18:04,500] {logging_mixin.py:115} INFO - [2022-10-21 15:18:04,500] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:18:20,761] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:18:20,902] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:18:21,262] {logging_mixin.py:115} INFO - [2022-10-21 15:18:21,262] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:18:21,361] {logging_mixin.py:115} INFO - [2022-10-21 15:18:21,361] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:18:20.863654+00:00, run_after=2022-10-22T15:18:20.863654+00:00
[2022-10-21 15:18:21,399] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 16.936 seconds
[2022-10-21 15:18:34,260] {processor.py:153} INFO - Started process (PID=4350) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:18:34,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:18:34,268] {logging_mixin.py:115} INFO - [2022-10-21 15:18:34,268] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:18:34,744] {logging_mixin.py:115} INFO - [2022-10-21 15:18:34,740] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:18:34,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:18:34,819] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.569 seconds
[2022-10-21 15:19:02,465] {processor.py:153} INFO - Started process (PID=34123) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:02,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:19:02,472] {logging_mixin.py:115} INFO - [2022-10-21 15:19:02,472] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:17,668] {processor.py:153} INFO - Started process (PID=4869) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:17,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:19:17,672] {logging_mixin.py:115} INFO - [2022-10-21 15:19:17,672] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:18,135] {logging_mixin.py:115} INFO - [2022-10-21 15:19:18,134] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:19:18,139] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:18,235] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.583 seconds
[2022-10-21 15:19:21,419] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:19:21,469] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:21,767] {logging_mixin.py:115} INFO - [2022-10-21 15:19:21,766] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:19:21,802] {logging_mixin.py:115} INFO - [2022-10-21 15:19:21,802] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:19:21.465608+00:00, run_after=2022-10-22T15:19:21.465608+00:00
[2022-10-21 15:19:21,823] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.393 seconds
[2022-10-21 15:19:50,060] {processor.py:153} INFO - Started process (PID=5229) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:50,073] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:19:50,075] {logging_mixin.py:115} INFO - [2022-10-21 15:19:50,075] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:50,555] {logging_mixin.py:115} INFO - [2022-10-21 15:19:50,554] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:19:50,558] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:19:50,617] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.577 seconds
[2022-10-21 15:20:29,138] {processor.py:153} INFO - Started process (PID=5733) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:20:29,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:20:29,142] {logging_mixin.py:115} INFO - [2022-10-21 15:20:29,142] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:20:29,400] {logging_mixin.py:115} INFO - [2022-10-21 15:20:29,399] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:20:29,405] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:20:29,578] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.445 seconds
[2022-10-21 15:20:42,916] {processor.py:153} INFO - Started process (PID=34956) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:20:42,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:20:42,928] {logging_mixin.py:115} INFO - [2022-10-21 15:20:42,927] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:21:03,816] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:21:03,838] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:21:03,980] {logging_mixin.py:115} INFO - [2022-10-21 15:21:03,979] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:21:04,013] {logging_mixin.py:115} INFO - [2022-10-21 15:21:04,013] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:21:03.834887+00:00, run_after=2022-10-22T15:21:03.834887+00:00
[2022-10-21 15:21:04,045] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 21.175 seconds
[2022-10-21 15:21:26,820] {processor.py:153} INFO - Started process (PID=5926) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:21:26,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:21:26,837] {logging_mixin.py:115} INFO - [2022-10-21 15:21:26,836] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:21:27,464] {logging_mixin.py:115} INFO - [2022-10-21 15:21:27,463] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:21:27,467] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:21:27,602] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.808 seconds
[2022-10-21 15:21:47,516] {processor.py:153} INFO - Started process (PID=35709) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:21:47,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:21:47,526] {logging_mixin.py:115} INFO - [2022-10-21 15:21:47,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:04,690] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:22:04,743] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:04,915] {logging_mixin.py:115} INFO - [2022-10-21 15:22:04,915] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:22:04,976] {logging_mixin.py:115} INFO - [2022-10-21 15:22:04,975] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:22:04.737227+00:00, run_after=2022-10-22T15:22:04.737227+00:00
[2022-10-21 15:22:05,048] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.540 seconds
[2022-10-21 15:22:11,231] {processor.py:153} INFO - Started process (PID=6403) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:11,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:22:11,255] {logging_mixin.py:115} INFO - [2022-10-21 15:22:11,250] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:11,976] {logging_mixin.py:115} INFO - [2022-10-21 15:22:11,969] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:22:11,981] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:12,118] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.896 seconds
[2022-10-21 15:22:43,309] {processor.py:153} INFO - Started process (PID=6791) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:43,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:22:43,316] {logging_mixin.py:115} INFO - [2022-10-21 15:22:43,316] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:43,759] {logging_mixin.py:115} INFO - [2022-10-21 15:22:43,758] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:22:43,762] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:43,885] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.596 seconds
[2022-10-21 15:22:50,266] {processor.py:153} INFO - Started process (PID=36465) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:22:50,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:22:50,278] {logging_mixin.py:115} INFO - [2022-10-21 15:22:50,277] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:12,552] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:23:12,573] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:12,749] {logging_mixin.py:115} INFO - [2022-10-21 15:23:12,748] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:23:12,782] {logging_mixin.py:115} INFO - [2022-10-21 15:23:12,782] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:23:12.569948+00:00, run_after=2022-10-22T15:23:12.569948+00:00
[2022-10-21 15:23:12,824] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 22.594 seconds
[2022-10-21 15:23:15,858] {processor.py:153} INFO - Started process (PID=7104) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:15,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:23:15,896] {logging_mixin.py:115} INFO - [2022-10-21 15:23:15,896] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:16,379] {logging_mixin.py:115} INFO - [2022-10-21 15:23:16,377] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:23:16,383] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:16,510] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.668 seconds
[2022-10-21 15:23:56,703] {processor.py:153} INFO - Started process (PID=7554) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:56,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:23:56,710] {logging_mixin.py:115} INFO - [2022-10-21 15:23:56,709] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:56,901] {processor.py:153} INFO - Started process (PID=37245) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:56,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:23:56,912] {logging_mixin.py:115} INFO - [2022-10-21 15:23:56,912] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:57,081] {logging_mixin.py:115} INFO - [2022-10-21 15:23:57,080] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:23:57,085] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:23:57,168] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.478 seconds
[2022-10-21 15:24:16,166] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:24:16,206] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:24:16,592] {logging_mixin.py:115} INFO - [2022-10-21 15:24:16,591] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:24:16,658] {logging_mixin.py:115} INFO - [2022-10-21 15:24:16,657] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:24:16.202207+00:00, run_after=2022-10-22T15:24:16.202207+00:00
[2022-10-21 15:24:16,734] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.862 seconds
[2022-10-21 15:24:32,183] {processor.py:153} INFO - Started process (PID=7934) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:24:32,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:24:32,189] {logging_mixin.py:115} INFO - [2022-10-21 15:24:32,189] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:24:32,692] {logging_mixin.py:115} INFO - [2022-10-21 15:24:32,690] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:24:32,696] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:24:32,798] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.628 seconds
[2022-10-21 15:25:15,006] {processor.py:153} INFO - Started process (PID=8350) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:25:15,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:25:15,012] {logging_mixin.py:115} INFO - [2022-10-21 15:25:15,012] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:25:15,410] {logging_mixin.py:115} INFO - [2022-10-21 15:25:15,408] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:25:15,412] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:25:15,464] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.475 seconds
[2022-10-21 15:26:25,532] {processor.py:153} INFO - Started process (PID=8639) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:26:25,536] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:26:25,539] {logging_mixin.py:115} INFO - [2022-10-21 15:26:25,539] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:26:25,873] {logging_mixin.py:115} INFO - [2022-10-21 15:26:25,872] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:26:25,875] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:26:25,916] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.399 seconds
[2022-10-21 15:26:34,763] {processor.py:153} INFO - Started process (PID=38088) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:26:34,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:26:34,774] {logging_mixin.py:115} INFO - [2022-10-21 15:26:34,774] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:26:53,550] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:26:53,584] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:26:53,779] {logging_mixin.py:115} INFO - [2022-10-21 15:26:53,779] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:26:53,884] {logging_mixin.py:115} INFO - [2022-10-21 15:26:53,883] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:26:53.580239+00:00, run_after=2022-10-22T15:26:53.580239+00:00
[2022-10-21 15:26:53,962] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.237 seconds
[2022-10-21 15:27:13,885] {processor.py:153} INFO - Started process (PID=9119) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:27:13,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:27:13,891] {logging_mixin.py:115} INFO - [2022-10-21 15:27:13,891] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:27:14,425] {logging_mixin.py:115} INFO - [2022-10-21 15:27:14,423] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:27:14,438] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:27:14,541] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.670 seconds
[2022-10-21 15:27:50,176] {processor.py:153} INFO - Started process (PID=38896) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:27:50,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:27:50,181] {logging_mixin.py:115} INFO - [2022-10-21 15:27:50,181] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:28:10,911] {processor.py:153} INFO - Started process (PID=9645) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:28:10,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:28:10,926] {logging_mixin.py:115} INFO - [2022-10-21 15:28:10,926] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:28:11,871] {logging_mixin.py:115} INFO - [2022-10-21 15:28:11,865] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:28:11,882] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:28:11,961] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.094 seconds
[2022-10-21 15:28:14,513] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:28:14,593] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:28:15,212] {logging_mixin.py:115} INFO - [2022-10-21 15:28:15,210] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:28:15,344] {logging_mixin.py:115} INFO - [2022-10-21 15:28:15,343] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:28:14.576927+00:00, run_after=2022-10-22T15:28:14.576927+00:00
[2022-10-21 15:28:15,427] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 25.282 seconds
[2022-10-21 15:29:06,777] {processor.py:153} INFO - Started process (PID=10156) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:06,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:29:06,787] {logging_mixin.py:115} INFO - [2022-10-21 15:29:06,787] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:07,287] {logging_mixin.py:115} INFO - [2022-10-21 15:29:07,286] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:29:07,290] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:07,354] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.595 seconds
[2022-10-21 15:29:08,431] {processor.py:153} INFO - Started process (PID=39661) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:08,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:29:08,445] {logging_mixin.py:115} INFO - [2022-10-21 15:29:08,445] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:28,623] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:29:28,666] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:29,174] {logging_mixin.py:115} INFO - [2022-10-21 15:29:29,173] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:29:29,242] {logging_mixin.py:115} INFO - [2022-10-21 15:29:29,241] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:29:28.655654+00:00, run_after=2022-10-22T15:29:28.655654+00:00
[2022-10-21 15:29:29,295] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 20.893 seconds
[2022-10-21 15:29:55,713] {processor.py:153} INFO - Started process (PID=10625) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:55,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:29:55,718] {logging_mixin.py:115} INFO - [2022-10-21 15:29:55,718] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:56,139] {logging_mixin.py:115} INFO - [2022-10-21 15:29:56,138] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:29:56,141] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:29:56,229] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.526 seconds
[2022-10-21 15:30:19,405] {processor.py:153} INFO - Started process (PID=40448) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:30:19,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:30:19,412] {logging_mixin.py:115} INFO - [2022-10-21 15:30:19,412] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:30:48,264] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:30:48,403] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:30:48,827] {logging_mixin.py:115} INFO - [2022-10-21 15:30:48,825] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:30:49,005] {logging_mixin.py:115} INFO - [2022-10-21 15:30:49,005] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:30:48.356319+00:00, run_after=2022-10-22T15:30:48.356319+00:00
[2022-10-21 15:30:49,204] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 29.839 seconds
[2022-10-21 15:31:26,367] {processor.py:153} INFO - Started process (PID=11145) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:31:26,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:31:26,373] {logging_mixin.py:115} INFO - [2022-10-21 15:31:26,372] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:31:26,680] {logging_mixin.py:115} INFO - [2022-10-21 15:31:26,679] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:31:26,682] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:31:26,759] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.404 seconds
[2022-10-21 15:31:43,715] {processor.py:153} INFO - Started process (PID=40934) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:31:43,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:31:43,727] {logging_mixin.py:115} INFO - [2022-10-21 15:31:43,727] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:02,279] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:32:02,381] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:02,709] {logging_mixin.py:115} INFO - [2022-10-21 15:32:02,709] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:32:02,814] {logging_mixin.py:115} INFO - [2022-10-21 15:32:02,814] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:32:02.365348+00:00, run_after=2022-10-22T15:32:02.365348+00:00
[2022-10-21 15:32:02,886] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.200 seconds
[2022-10-21 15:32:06,577] {processor.py:153} INFO - Started process (PID=11578) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:06,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:32:06,582] {logging_mixin.py:115} INFO - [2022-10-21 15:32:06,582] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:06,937] {logging_mixin.py:115} INFO - [2022-10-21 15:32:06,936] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:32:06,942] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:07,027] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.460 seconds
[2022-10-21 15:32:36,260] {processor.py:153} INFO - Started process (PID=41580) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:36,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:32:36,282] {logging_mixin.py:115} INFO - [2022-10-21 15:32:36,282] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:41,668] {processor.py:153} INFO - Started process (PID=11971) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:41,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:32:41,673] {logging_mixin.py:115} INFO - [2022-10-21 15:32:41,672] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:41,967] {logging_mixin.py:115} INFO - [2022-10-21 15:32:41,965] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:32:41,971] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:42,021] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.368 seconds
[2022-10-21 15:32:53,715] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:32:53,734] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:32:53,892] {logging_mixin.py:115} INFO - [2022-10-21 15:32:53,892] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:32:53,934] {logging_mixin.py:115} INFO - [2022-10-21 15:32:53,934] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:32:53.730306+00:00, run_after=2022-10-22T15:32:53.730306+00:00
[2022-10-21 15:32:53,962] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.743 seconds
[2022-10-21 15:33:21,066] {processor.py:153} INFO - Started process (PID=12462) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:33:21,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:33:21,073] {logging_mixin.py:115} INFO - [2022-10-21 15:33:21,073] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:33:21,420] {logging_mixin.py:115} INFO - [2022-10-21 15:33:21,418] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:33:21,423] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:33:21,469] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.410 seconds
[2022-10-21 15:33:32,096] {processor.py:153} INFO - Started process (PID=42324) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:33:32,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:33:32,100] {logging_mixin.py:115} INFO - [2022-10-21 15:33:32,100] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:33:53,545] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:33:53,637] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:33:54,075] {logging_mixin.py:115} INFO - [2022-10-21 15:33:54,075] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:33:54,163] {logging_mixin.py:115} INFO - [2022-10-21 15:33:54,163] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:33:53.632589+00:00, run_after=2022-10-22T15:33:53.632589+00:00
[2022-10-21 15:33:54,217] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 22.165 seconds
[2022-10-21 15:34:09,651] {processor.py:153} INFO - Started process (PID=12931) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:34:09,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:34:09,656] {logging_mixin.py:115} INFO - [2022-10-21 15:34:09,656] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:34:09,938] {logging_mixin.py:115} INFO - [2022-10-21 15:34:09,937] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:34:09,940] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:34:10,012] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.370 seconds
[2022-10-21 15:34:41,519] {processor.py:153} INFO - Started process (PID=13220) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:34:41,522] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:34:41,527] {logging_mixin.py:115} INFO - [2022-10-21 15:34:41,526] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:34:41,905] {logging_mixin.py:115} INFO - [2022-10-21 15:34:41,903] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:34:41,908] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:34:41,954] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.446 seconds
[2022-10-21 15:34:54,490] {processor.py:153} INFO - Started process (PID=43148) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:34:54,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:34:54,495] {logging_mixin.py:115} INFO - [2022-10-21 15:34:54,495] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:35:18,468] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:35:18,506] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:35:18,898] {logging_mixin.py:115} INFO - [2022-10-21 15:35:18,898] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:35:18,963] {logging_mixin.py:115} INFO - [2022-10-21 15:35:18,963] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:35:18.500738+00:00, run_after=2022-10-22T15:35:18.500738+00:00
[2022-10-21 15:35:19,012] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 24.560 seconds
[2022-10-21 15:36:27,806] {processor.py:153} INFO - Started process (PID=13759) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:36:27,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:36:27,813] {logging_mixin.py:115} INFO - [2022-10-21 15:36:27,813] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:36:28,243] {logging_mixin.py:115} INFO - [2022-10-21 15:36:28,241] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:36:28,249] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:36:28,363] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.575 seconds
[2022-10-21 15:36:58,680] {processor.py:153} INFO - Started process (PID=43942) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:36:58,683] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:36:58,687] {logging_mixin.py:115} INFO - [2022-10-21 15:36:58,687] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:37:20,696] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:37:20,757] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:37:20,950] {logging_mixin.py:115} INFO - [2022-10-21 15:37:20,950] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:37:21,032] {logging_mixin.py:115} INFO - [2022-10-21 15:37:21,031] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:37:20.753701+00:00, run_after=2022-10-22T15:37:20.753701+00:00
[2022-10-21 15:37:21,099] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 22.441 seconds
[2022-10-21 15:37:24,504] {processor.py:153} INFO - Started process (PID=14278) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:37:24,510] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:37:24,516] {logging_mixin.py:115} INFO - [2022-10-21 15:37:24,515] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:37:24,887] {logging_mixin.py:115} INFO - [2022-10-21 15:37:24,882] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:37:24,889] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:37:24,975] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.492 seconds
[2022-10-21 15:37:56,930] {processor.py:153} INFO - Started process (PID=44583) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:37:56,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:37:56,945] {logging_mixin.py:115} INFO - [2022-10-21 15:37:56,945] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:38:26,974] {logging_mixin.py:115} INFO - [2022-10-21 15:38:26,939] {timeout.py:67} ERROR - Process timed out, PID: 44583
[2022-10-21 15:38:27,207] {logging_mixin.py:115} INFO - [2022-10-21 15:38:27,019] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 44583
[2022-10-21 15:38:27,217] {logging_mixin.py:115} INFO - [2022-10-21 15:38:27,216] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 15:38:27,306] {logging_mixin.py:115} INFO - [2022-10-21 15:38:27,233] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 44583

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 15:38:27,342] {logging_mixin.py:115} INFO - [2022-10-21 15:38:27,341] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 15:38:27,388] {logging_mixin.py:115} INFO - [2022-10-21 15:38:27,363] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 15:38:27,453] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:38:28,109] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.255 seconds
[2022-10-21 15:38:34,596] {processor.py:153} INFO - Started process (PID=14783) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:38:34,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:38:34,607] {logging_mixin.py:115} INFO - [2022-10-21 15:38:34,607] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:38:35,043] {logging_mixin.py:115} INFO - [2022-10-21 15:38:35,041] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:38:35,048] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:38:35,128] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.549 seconds
[2022-10-21 15:39:11,304] {processor.py:153} INFO - Started process (PID=15151) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:39:11,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:39:11,310] {logging_mixin.py:115} INFO - [2022-10-21 15:39:11,310] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:39:11,765] {logging_mixin.py:115} INFO - [2022-10-21 15:39:11,764] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:39:11,767] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:39:11,810] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.521 seconds
[2022-10-21 15:39:20,208] {processor.py:153} INFO - Started process (PID=45261) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:39:20,213] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:39:20,216] {logging_mixin.py:115} INFO - [2022-10-21 15:39:20,216] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:39:41,460] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:39:41,496] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:39:42,103] {logging_mixin.py:115} INFO - [2022-10-21 15:39:42,103] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:39:42,208] {logging_mixin.py:115} INFO - [2022-10-21 15:39:42,208] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:39:41.490996+00:00, run_after=2022-10-22T15:39:41.490996+00:00
[2022-10-21 15:39:42,260] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 22.132 seconds
[2022-10-21 15:40:04,619] {processor.py:153} INFO - Started process (PID=15642) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:40:04,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:40:04,629] {logging_mixin.py:115} INFO - [2022-10-21 15:40:04,629] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:40:05,352] {logging_mixin.py:115} INFO - [2022-10-21 15:40:05,350] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:40:05,362] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:40:05,523] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.916 seconds
[2022-10-21 15:40:33,072] {processor.py:153} INFO - Started process (PID=46074) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:40:33,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:40:33,092] {logging_mixin.py:115} INFO - [2022-10-21 15:40:33,092] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:41:03,087] {logging_mixin.py:115} INFO - [2022-10-21 15:41:03,085] {timeout.py:67} ERROR - Process timed out, PID: 46074
[2022-10-21 15:41:03,097] {logging_mixin.py:115} INFO - [2022-10-21 15:41:03,090] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 46074
[2022-10-21 15:41:03,099] {logging_mixin.py:115} INFO - [2022-10-21 15:41:03,099] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 15:41:03,105] {logging_mixin.py:115} INFO - [2022-10-21 15:41:03,100] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 46074

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 15:41:03,108] {logging_mixin.py:115} INFO - [2022-10-21 15:41:03,108] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 15:41:03,116] {logging_mixin.py:115} INFO - [2022-10-21 15:41:03,112] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 15:41:03,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:41:03,382] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.345 seconds
[2022-10-21 15:41:38,463] {processor.py:153} INFO - Started process (PID=16157) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:41:38,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:41:38,468] {logging_mixin.py:115} INFO - [2022-10-21 15:41:38,468] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:41:38,792] {logging_mixin.py:115} INFO - [2022-10-21 15:41:38,790] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:41:38,796] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:41:38,897] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.443 seconds
[2022-10-21 15:42:01,849] {processor.py:153} INFO - Started process (PID=46501) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:01,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:42:01,856] {logging_mixin.py:115} INFO - [2022-10-21 15:42:01,856] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:21,156] {processor.py:153} INFO - Started process (PID=16520) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:21,158] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:42:21,161] {logging_mixin.py:115} INFO - [2022-10-21 15:42:21,161] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:21,507] {logging_mixin.py:115} INFO - [2022-10-21 15:42:21,506] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:42:21,509] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:21,550] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.403 seconds
[2022-10-21 15:42:24,627] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:42:24,662] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:24,897] {logging_mixin.py:115} INFO - [2022-10-21 15:42:24,897] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:42:24,942] {logging_mixin.py:115} INFO - [2022-10-21 15:42:24,942] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:42:24.659249+00:00, run_after=2022-10-22T15:42:24.659249+00:00
[2022-10-21 15:42:25,006] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 23.197 seconds
[2022-10-21 15:42:58,516] {processor.py:153} INFO - Started process (PID=16947) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:58,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:42:58,520] {logging_mixin.py:115} INFO - [2022-10-21 15:42:58,520] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:58,841] {logging_mixin.py:115} INFO - [2022-10-21 15:42:58,840] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:42:58,845] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:42:58,880] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.374 seconds
[2022-10-21 15:43:07,619] {processor.py:153} INFO - Started process (PID=47284) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:43:07,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:43:07,623] {logging_mixin.py:115} INFO - [2022-10-21 15:43:07,622] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:43:26,177] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:43:26,200] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:43:26,367] {logging_mixin.py:115} INFO - [2022-10-21 15:43:26,367] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:43:26,399] {logging_mixin.py:115} INFO - [2022-10-21 15:43:26,399] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:43:26.196878+00:00, run_after=2022-10-22T15:43:26.196878+00:00
[2022-10-21 15:43:26,426] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 18.851 seconds
[2022-10-21 15:43:33,026] {processor.py:153} INFO - Started process (PID=17339) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:43:33,028] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:43:33,030] {logging_mixin.py:115} INFO - [2022-10-21 15:43:33,029] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:43:33,308] {logging_mixin.py:115} INFO - [2022-10-21 15:43:33,306] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:43:33,310] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:43:33,376] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.355 seconds
[2022-10-21 15:44:15,488] {processor.py:153} INFO - Started process (PID=48069) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:44:15,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:44:15,501] {logging_mixin.py:115} INFO - [2022-10-21 15:44:15,500] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:44:22,818] {processor.py:153} INFO - Started process (PID=17806) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:44:22,822] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:44:22,828] {logging_mixin.py:115} INFO - [2022-10-21 15:44:22,826] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:44:24,452] {logging_mixin.py:115} INFO - [2022-10-21 15:44:24,450] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:44:24,463] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:44:24,647] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.862 seconds
[2022-10-21 15:44:38,468] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:44:38,489] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:44:38,771] {logging_mixin.py:115} INFO - [2022-10-21 15:44:38,771] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:44:38,859] {logging_mixin.py:115} INFO - [2022-10-21 15:44:38,859] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:44:38.485031+00:00, run_after=2022-10-22T15:44:38.485031+00:00
[2022-10-21 15:44:38,895] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 23.414 seconds
[2022-10-21 15:45:02,695] {processor.py:153} INFO - Started process (PID=18237) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:45:02,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:45:02,703] {logging_mixin.py:115} INFO - [2022-10-21 15:45:02,703] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:45:03,225] {logging_mixin.py:115} INFO - [2022-10-21 15:45:03,224] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:45:03,227] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:45:03,298] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.620 seconds
[2022-10-21 15:45:29,989] {processor.py:153} INFO - Started process (PID=48854) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:45:29,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:45:29,997] {logging_mixin.py:115} INFO - [2022-10-21 15:45:29,996] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:45:52,775] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:45:52,821] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:45:53,212] {logging_mixin.py:115} INFO - [2022-10-21 15:45:53,212] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:45:53,281] {logging_mixin.py:115} INFO - [2022-10-21 15:45:53,281] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:45:52.811977+00:00, run_after=2022-10-22T15:45:52.811977+00:00
[2022-10-21 15:45:53,318] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 23.378 seconds
[2022-10-21 15:46:31,493] {processor.py:153} INFO - Started process (PID=18706) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:46:31,495] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:46:31,499] {logging_mixin.py:115} INFO - [2022-10-21 15:46:31,499] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:46:31,793] {logging_mixin.py:115} INFO - [2022-10-21 15:46:31,791] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:46:31,796] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:46:31,883] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.410 seconds
[2022-10-21 15:46:51,365] {processor.py:153} INFO - Started process (PID=49385) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:46:51,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:46:51,374] {logging_mixin.py:115} INFO - [2022-10-21 15:46:51,372] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:03,996] {processor.py:153} INFO - Started process (PID=19082) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:04,002] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:47:04,004] {logging_mixin.py:115} INFO - [2022-10-21 15:47:04,003] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:04,311] {logging_mixin.py:115} INFO - [2022-10-21 15:47:04,310] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:47:04,313] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:04,371] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.381 seconds
[2022-10-21 15:47:08,592] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:47:08,624] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:08,870] {logging_mixin.py:115} INFO - [2022-10-21 15:47:08,870] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:47:09,000] {logging_mixin.py:115} INFO - [2022-10-21 15:47:09,000] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:47:08.621434+00:00, run_after=2022-10-22T15:47:08.621434+00:00
[2022-10-21 15:47:09,065] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.721 seconds
[2022-10-21 15:47:37,929] {processor.py:153} INFO - Started process (PID=19527) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:37,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:47:37,933] {logging_mixin.py:115} INFO - [2022-10-21 15:47:37,933] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:38,381] {logging_mixin.py:115} INFO - [2022-10-21 15:47:38,377] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:47:38,398] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:38,647] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.732 seconds
[2022-10-21 15:47:49,509] {processor.py:153} INFO - Started process (PID=50201) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:47:49,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:47:49,514] {logging_mixin.py:115} INFO - [2022-10-21 15:47:49,513] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:05,936] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:48:05,966] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:06,174] {logging_mixin.py:115} INFO - [2022-10-21 15:48:06,173] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:48:06,227] {logging_mixin.py:115} INFO - [2022-10-21 15:48:06,227] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:48:05.963225+00:00, run_after=2022-10-22T15:48:05.963225+00:00
[2022-10-21 15:48:06,293] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 16.800 seconds
[2022-10-21 15:48:11,229] {processor.py:153} INFO - Started process (PID=19941) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:11,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:48:11,233] {logging_mixin.py:115} INFO - [2022-10-21 15:48:11,233] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:11,512] {logging_mixin.py:115} INFO - [2022-10-21 15:48:11,511] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:48:11,516] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:11,581] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.371 seconds
[2022-10-21 15:48:43,590] {processor.py:153} INFO - Started process (PID=50952) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:43,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:48:43,600] {logging_mixin.py:115} INFO - [2022-10-21 15:48:43,600] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:46,290] {processor.py:153} INFO - Started process (PID=20394) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:46,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:48:46,298] {logging_mixin.py:115} INFO - [2022-10-21 15:48:46,297] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:46,613] {logging_mixin.py:115} INFO - [2022-10-21 15:48:46,609] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:48:46,619] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:48:46,686] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.407 seconds
[2022-10-21 15:49:02,177] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:49:02,242] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:49:02,858] {logging_mixin.py:115} INFO - [2022-10-21 15:49:02,858] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:49:02,902] {logging_mixin.py:115} INFO - [2022-10-21 15:49:02,901] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:49:02.233352+00:00, run_after=2022-10-22T15:49:02.233352+00:00
[2022-10-21 15:49:02,935] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.364 seconds
[2022-10-21 15:49:30,498] {processor.py:153} INFO - Started process (PID=20903) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:49:30,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:49:30,502] {logging_mixin.py:115} INFO - [2022-10-21 15:49:30,502] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:49:30,986] {logging_mixin.py:115} INFO - [2022-10-21 15:49:30,985] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:49:30,989] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:49:31,081] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.601 seconds
[2022-10-21 15:49:45,508] {processor.py:153} INFO - Started process (PID=51740) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:49:45,510] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:49:45,513] {logging_mixin.py:115} INFO - [2022-10-21 15:49:45,513] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:50:03,984] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:50:04,087] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:50:04,359] {logging_mixin.py:115} INFO - [2022-10-21 15:50:04,358] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:50:04,398] {logging_mixin.py:115} INFO - [2022-10-21 15:50:04,398] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:50:04.066235+00:00, run_after=2022-10-22T15:50:04.066235+00:00
[2022-10-21 15:50:04,446] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 18.947 seconds
[2022-10-21 15:50:16,463] {processor.py:153} INFO - Started process (PID=21414) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:50:16,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:50:16,467] {logging_mixin.py:115} INFO - [2022-10-21 15:50:16,467] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:50:16,889] {logging_mixin.py:115} INFO - [2022-10-21 15:50:16,888] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:50:16,891] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:50:16,955] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.511 seconds
[2022-10-21 15:50:51,423] {processor.py:153} INFO - Started process (PID=52555) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:50:51,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:50:51,440] {logging_mixin.py:115} INFO - [2022-10-21 15:50:51,439] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:51:18,485] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:51:18,535] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:51:18,827] {logging_mixin.py:115} INFO - [2022-10-21 15:51:18,827] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:51:18,893] {logging_mixin.py:115} INFO - [2022-10-21 15:51:18,893] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:51:18.528241+00:00, run_after=2022-10-22T15:51:18.528241+00:00
[2022-10-21 15:51:18,963] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 27.604 seconds
[2022-10-21 15:51:55,306] {processor.py:153} INFO - Started process (PID=52979) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:51:55,308] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:51:55,310] {logging_mixin.py:115} INFO - [2022-10-21 15:51:55,310] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:04,442] {processor.py:153} INFO - Started process (PID=21713) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:04,446] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:52:04,449] {logging_mixin.py:115} INFO - [2022-10-21 15:52:04,449] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:04,870] {logging_mixin.py:115} INFO - [2022-10-21 15:52:04,868] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:52:04,873] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:04,940] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.513 seconds
[2022-10-21 15:52:07,972] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:52:08,001] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:08,265] {logging_mixin.py:115} INFO - [2022-10-21 15:52:08,265] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:52:08,316] {logging_mixin.py:115} INFO - [2022-10-21 15:52:08,316] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:52:07.997085+00:00, run_after=2022-10-22T15:52:07.997085+00:00
[2022-10-21 15:52:08,342] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.052 seconds
[2022-10-21 15:52:44,980] {processor.py:153} INFO - Started process (PID=22242) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:44,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:52:44,989] {logging_mixin.py:115} INFO - [2022-10-21 15:52:44,988] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:45,323] {logging_mixin.py:115} INFO - [2022-10-21 15:52:45,321] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:52:45,327] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:45,423] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.450 seconds
[2022-10-21 15:52:47,417] {processor.py:153} INFO - Started process (PID=53755) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:52:47,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:52:47,421] {logging_mixin.py:115} INFO - [2022-10-21 15:52:47,421] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:53:04,579] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:53:04,643] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:53:04,820] {logging_mixin.py:115} INFO - [2022-10-21 15:53:04,820] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:53:04,858] {logging_mixin.py:115} INFO - [2022-10-21 15:53:04,858] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:53:04.634721+00:00, run_after=2022-10-22T15:53:04.634721+00:00
[2022-10-21 15:53:04,882] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.478 seconds
[2022-10-21 15:53:17,705] {processor.py:153} INFO - Started process (PID=22660) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:53:17,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:53:17,708] {logging_mixin.py:115} INFO - [2022-10-21 15:53:17,708] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:53:18,052] {logging_mixin.py:115} INFO - [2022-10-21 15:53:18,051] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:53:18,055] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:53:18,116] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.428 seconds
[2022-10-21 15:53:42,003] {processor.py:153} INFO - Started process (PID=54479) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:53:42,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:53:42,007] {logging_mixin.py:115} INFO - [2022-10-21 15:53:42,007] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:53:59,983] {processor.py:153} INFO - Started process (PID=23120) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:53:59,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:53:59,989] {logging_mixin.py:115} INFO - [2022-10-21 15:53:59,988] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:54:00,430] {logging_mixin.py:115} INFO - [2022-10-21 15:54:00,429] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:54:00,433] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:54:00,564] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.603 seconds
[2022-10-21 15:54:03,033] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:54:03,092] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:54:03,353] {logging_mixin.py:115} INFO - [2022-10-21 15:54:03,353] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:54:03,440] {logging_mixin.py:115} INFO - [2022-10-21 15:54:03,439] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:54:03.089471+00:00, run_after=2022-10-22T15:54:03.089471+00:00
[2022-10-21 15:54:03,481] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 21.484 seconds
[2022-10-21 15:54:40,445] {processor.py:153} INFO - Started process (PID=23560) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:54:40,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:54:40,449] {logging_mixin.py:115} INFO - [2022-10-21 15:54:40,448] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:54:40,774] {logging_mixin.py:115} INFO - [2022-10-21 15:54:40,772] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:54:40,779] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:54:40,834] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.399 seconds
[2022-10-21 15:54:48,712] {processor.py:153} INFO - Started process (PID=55266) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:54:48,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:54:48,721] {logging_mixin.py:115} INFO - [2022-10-21 15:54:48,720] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:55:05,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:55:05,180] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:55:05,509] {logging_mixin.py:115} INFO - [2022-10-21 15:55:05,509] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:55:06,060] {logging_mixin.py:115} INFO - [2022-10-21 15:55:06,059] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:55:05.174591+00:00, run_after=2022-10-22T15:55:05.174591+00:00
[2022-10-21 15:55:06,131] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.435 seconds
[2022-10-21 15:55:22,566] {processor.py:153} INFO - Started process (PID=24083) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:55:22,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:55:22,581] {logging_mixin.py:115} INFO - [2022-10-21 15:55:22,580] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:55:23,081] {logging_mixin.py:115} INFO - [2022-10-21 15:55:23,080] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:55:23,098] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:55:23,213] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.655 seconds
[2022-10-21 15:55:50,952] {processor.py:153} INFO - Started process (PID=56068) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:55:50,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:55:50,957] {logging_mixin.py:115} INFO - [2022-10-21 15:55:50,956] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:56:07,410] {processor.py:153} INFO - Started process (PID=24609) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:56:07,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:56:07,417] {logging_mixin.py:115} INFO - [2022-10-21 15:56:07,416] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:56:07,900] {logging_mixin.py:115} INFO - [2022-10-21 15:56:07,898] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:56:07,905] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:56:07,966] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.573 seconds
[2022-10-21 15:56:13,544] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:56:13,583] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:56:13,899] {logging_mixin.py:115} INFO - [2022-10-21 15:56:13,898] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:56:13,969] {logging_mixin.py:115} INFO - [2022-10-21 15:56:13,969] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:56:13.573023+00:00, run_after=2022-10-22T15:56:13.573023+00:00
[2022-10-21 15:56:14,003] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 23.083 seconds
[2022-10-21 15:57:07,667] {processor.py:153} INFO - Started process (PID=24986) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:07,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:57:07,676] {logging_mixin.py:115} INFO - [2022-10-21 15:57:07,676] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:07,960] {logging_mixin.py:115} INFO - [2022-10-21 15:57:07,958] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:57:07,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:08,025] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.364 seconds
[2022-10-21 15:57:10,349] {processor.py:153} INFO - Started process (PID=56834) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:10,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:57:10,355] {logging_mixin.py:115} INFO - [2022-10-21 15:57:10,355] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:26,646] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:57:26,704] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:27,020] {logging_mixin.py:115} INFO - [2022-10-21 15:57:27,019] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:57:27,085] {logging_mixin.py:115} INFO - [2022-10-21 15:57:27,085] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:57:26.696655+00:00, run_after=2022-10-22T15:57:26.696655+00:00
[2022-10-21 15:57:27,154] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 16.841 seconds
[2022-10-21 15:57:42,506] {processor.py:153} INFO - Started process (PID=25438) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:42,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:57:42,509] {logging_mixin.py:115} INFO - [2022-10-21 15:57:42,509] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:42,787] {logging_mixin.py:115} INFO - [2022-10-21 15:57:42,786] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:57:42,790] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:57:42,867] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.368 seconds
[2022-10-21 15:58:03,487] {processor.py:153} INFO - Started process (PID=57605) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:58:03,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:58:03,491] {logging_mixin.py:115} INFO - [2022-10-21 15:58:03,491] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:58:19,180] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:58:19,235] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:58:19,427] {logging_mixin.py:115} INFO - [2022-10-21 15:58:19,427] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:58:19,491] {logging_mixin.py:115} INFO - [2022-10-21 15:58:19,491] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:58:19.224015+00:00, run_after=2022-10-22T15:58:19.224015+00:00
[2022-10-21 15:58:19,531] {processor.py:153} INFO - Started process (PID=25945) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:58:19,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:58:19,540] {logging_mixin.py:115} INFO - [2022-10-21 15:58:19,540] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:58:19,541] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 16.084 seconds
[2022-10-21 15:58:19,992] {logging_mixin.py:115} INFO - [2022-10-21 15:58:19,990] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:58:19,995] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:58:20,082] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.567 seconds
[2022-10-21 15:59:01,393] {processor.py:153} INFO - Started process (PID=26470) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:01,395] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:59:01,397] {logging_mixin.py:115} INFO - [2022-10-21 15:59:01,397] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:01,699] {logging_mixin.py:115} INFO - [2022-10-21 15:59:01,698] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:59:01,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:01,798] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.412 seconds
[2022-10-21 15:59:06,718] {processor.py:153} INFO - Started process (PID=58506) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:06,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:59:06,722] {logging_mixin.py:115} INFO - [2022-10-21 15:59:06,722] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:19,471] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 15:59:19,497] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:19,618] {logging_mixin.py:115} INFO - [2022-10-21 15:59:19,618] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 15:59:19,651] {logging_mixin.py:115} INFO - [2022-10-21 15:59:19,650] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T15:59:19.492963+00:00, run_after=2022-10-22T15:59:19.492963+00:00
[2022-10-21 15:59:19,680] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 12.991 seconds
[2022-10-21 15:59:34,295] {processor.py:153} INFO - Started process (PID=26914) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:34,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 15:59:34,299] {logging_mixin.py:115} INFO - [2022-10-21 15:59:34,299] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:34,649] {logging_mixin.py:115} INFO - [2022-10-21 15:59:34,648] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 15:59:34,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 15:59:34,706] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.416 seconds
[2022-10-21 16:00:02,499] {processor.py:153} INFO - Started process (PID=59307) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:02,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:00:02,508] {logging_mixin.py:115} INFO - [2022-10-21 16:00:02,508] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:12,643] {processor.py:153} INFO - Started process (PID=27404) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:12,644] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:00:12,646] {logging_mixin.py:115} INFO - [2022-10-21 16:00:12,646] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:13,035] {logging_mixin.py:115} INFO - [2022-10-21 16:00:13,033] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:00:13,037] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:13,116] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.494 seconds
[2022-10-21 16:00:15,718] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:00:15,744] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:15,928] {logging_mixin.py:115} INFO - [2022-10-21 16:00:15,928] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:00:15,963] {logging_mixin.py:115} INFO - [2022-10-21 16:00:15,963] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:00:15.741371+00:00, run_after=2022-10-22T16:00:15.741371+00:00
[2022-10-21 16:00:16,005] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.551 seconds
[2022-10-21 16:00:45,598] {processor.py:153} INFO - Started process (PID=27842) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:45,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:00:45,606] {logging_mixin.py:115} INFO - [2022-10-21 16:00:45,605] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:45,996] {logging_mixin.py:115} INFO - [2022-10-21 16:00:45,995] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:00:45,999] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:00:46,073] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.481 seconds
[2022-10-21 16:01:23,813] {processor.py:153} INFO - Started process (PID=28319) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:01:23,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:01:23,819] {logging_mixin.py:115} INFO - [2022-10-21 16:01:23,819] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:01:24,297] {logging_mixin.py:115} INFO - [2022-10-21 16:01:24,296] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:01:24,299] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:01:24,367] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.560 seconds
[2022-10-21 16:01:35,799] {processor.py:153} INFO - Started process (PID=60162) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:01:35,802] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:01:35,805] {logging_mixin.py:115} INFO - [2022-10-21 16:01:35,805] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:01:51,864] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:01:51,907] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:01:52,154] {logging_mixin.py:115} INFO - [2022-10-21 16:01:52,154] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:01:52,216] {logging_mixin.py:115} INFO - [2022-10-21 16:01:52,216] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:01:51.903135+00:00, run_after=2022-10-22T16:01:51.903135+00:00
[2022-10-21 16:01:52,241] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 16.472 seconds
[2022-10-21 16:02:10,032] {processor.py:153} INFO - Started process (PID=28487) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:02:10,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:02:10,036] {logging_mixin.py:115} INFO - [2022-10-21 16:02:10,035] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:02:10,326] {logging_mixin.py:115} INFO - [2022-10-21 16:02:10,325] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:02:10,328] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:02:10,416] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.391 seconds
[2022-10-21 16:02:25,149] {processor.py:153} INFO - Started process (PID=60866) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:02:25,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:02:25,155] {logging_mixin.py:115} INFO - [2022-10-21 16:02:25,154] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:02:55,169] {logging_mixin.py:115} INFO - [2022-10-21 16:02:55,166] {timeout.py:67} ERROR - Process timed out, PID: 60866
[2022-10-21 16:02:55,175] {logging_mixin.py:115} INFO - [2022-10-21 16:02:55,171] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 60866
[2022-10-21 16:02:55,176] {logging_mixin.py:115} INFO - [2022-10-21 16:02:55,176] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 16:02:55,181] {logging_mixin.py:115} INFO - [2022-10-21 16:02:55,178] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 60866

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 16:02:55,182] {logging_mixin.py:115} INFO - [2022-10-21 16:02:55,182] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 16:02:55,186] {logging_mixin.py:115} INFO - [2022-10-21 16:02:55,184] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 16:02:55,194] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:02:55,363] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.266 seconds
[2022-10-21 16:02:59,775] {processor.py:153} INFO - Started process (PID=28954) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:02:59,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:02:59,842] {logging_mixin.py:115} INFO - [2022-10-21 16:02:59,842] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:03:00,336] {logging_mixin.py:115} INFO - [2022-10-21 16:03:00,334] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:03:00,357] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:03:00,441] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.704 seconds
[2022-10-21 16:03:36,666] {processor.py:153} INFO - Started process (PID=29256) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:03:36,668] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:03:36,671] {logging_mixin.py:115} INFO - [2022-10-21 16:03:36,670] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:03:37,008] {logging_mixin.py:115} INFO - [2022-10-21 16:03:37,006] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:03:37,012] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:03:37,085] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.440 seconds
[2022-10-21 16:04:05,233] {processor.py:153} INFO - Started process (PID=61786) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:04:05,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:04:05,238] {logging_mixin.py:115} INFO - [2022-10-21 16:04:05,238] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:04:21,911] {processor.py:153} INFO - Started process (PID=29743) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:04:21,914] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:04:21,916] {logging_mixin.py:115} INFO - [2022-10-21 16:04:21,916] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:04:22,209] {logging_mixin.py:115} INFO - [2022-10-21 16:04:22,207] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:04:22,221] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:04:22,283] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.384 seconds
[2022-10-21 16:04:23,570] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:04:23,619] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:04:23,978] {logging_mixin.py:115} INFO - [2022-10-21 16:04:23,977] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:04:24,043] {logging_mixin.py:115} INFO - [2022-10-21 16:04:24,043] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:04:23.609877+00:00, run_after=2022-10-22T16:04:23.609877+00:00
[2022-10-21 16:04:24,072] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 18.870 seconds
[2022-10-21 16:05:01,478] {processor.py:153} INFO - Started process (PID=62442) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:01,519] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:05:01,533] {logging_mixin.py:115} INFO - [2022-10-21 16:05:01,533] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:07,111] {processor.py:153} INFO - Started process (PID=30171) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:07,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:05:07,117] {logging_mixin.py:115} INFO - [2022-10-21 16:05:07,117] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:07,625] {logging_mixin.py:115} INFO - [2022-10-21 16:05:07,624] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:05:07,628] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:07,690] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.617 seconds
[2022-10-21 16:05:29,811] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:05:29,880] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:30,158] {logging_mixin.py:115} INFO - [2022-10-21 16:05:30,157] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:05:30,230] {logging_mixin.py:115} INFO - [2022-10-21 16:05:30,230] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:05:29.876732+00:00, run_after=2022-10-22T16:05:29.876732+00:00
[2022-10-21 16:05:30,260] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 28.843 seconds
[2022-10-21 16:05:45,416] {processor.py:153} INFO - Started process (PID=30606) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:45,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:05:45,420] {logging_mixin.py:115} INFO - [2022-10-21 16:05:45,420] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:45,680] {logging_mixin.py:115} INFO - [2022-10-21 16:05:45,679] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:05:45,682] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:05:45,738] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.330 seconds
[2022-10-21 16:06:20,701] {processor.py:153} INFO - Started process (PID=30966) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:06:20,704] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:06:20,706] {logging_mixin.py:115} INFO - [2022-10-21 16:06:20,706] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:06:20,979] {logging_mixin.py:115} INFO - [2022-10-21 16:06:20,978] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:06:20,982] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:06:21,018] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.327 seconds
[2022-10-21 16:06:55,720] {processor.py:153} INFO - Started process (PID=63314) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:06:55,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:06:55,724] {logging_mixin.py:115} INFO - [2022-10-21 16:06:55,724] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:13,134] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:07:13,268] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:13,605] {logging_mixin.py:115} INFO - [2022-10-21 16:07:13,605] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:07:13,688] {logging_mixin.py:115} INFO - [2022-10-21 16:07:13,687] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:07:13.263474+00:00, run_after=2022-10-22T16:07:13.263474+00:00
[2022-10-21 16:07:13,754] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 18.066 seconds
[2022-10-21 16:07:21,321] {processor.py:153} INFO - Started process (PID=31224) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:21,323] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:07:21,326] {logging_mixin.py:115} INFO - [2022-10-21 16:07:21,325] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:21,714] {logging_mixin.py:115} INFO - [2022-10-21 16:07:21,713] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:07:21,718] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:21,830] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.523 seconds
[2022-10-21 16:07:58,305] {processor.py:153} INFO - Started process (PID=31625) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:58,311] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:07:58,315] {logging_mixin.py:115} INFO - [2022-10-21 16:07:58,315] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:58,701] {logging_mixin.py:115} INFO - [2022-10-21 16:07:58,700] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:07:58,703] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:58,763] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.472 seconds
[2022-10-21 16:07:58,795] {processor.py:153} INFO - Started process (PID=64102) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:07:58,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:07:58,800] {logging_mixin.py:115} INFO - [2022-10-21 16:07:58,799] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:08:21,397] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:08:21,496] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:08:22,541] {logging_mixin.py:115} INFO - [2022-10-21 16:08:22,540] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:08:22,659] {logging_mixin.py:115} INFO - [2022-10-21 16:08:22,658] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:08:21.480063+00:00, run_after=2022-10-22T16:08:21.480063+00:00
[2022-10-21 16:08:22,733] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 23.967 seconds
[2022-10-21 16:08:59,084] {processor.py:153} INFO - Started process (PID=32040) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:08:59,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:08:59,097] {logging_mixin.py:115} INFO - [2022-10-21 16:08:59,097] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:08:59,573] {logging_mixin.py:115} INFO - [2022-10-21 16:08:59,572] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:08:59,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:08:59,678] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.618 seconds
[2022-10-21 16:09:05,200] {processor.py:153} INFO - Started process (PID=64610) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:09:05,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:09:05,215] {logging_mixin.py:115} INFO - [2022-10-21 16:09:05,214] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:09:35,209] {logging_mixin.py:115} INFO - [2022-10-21 16:09:35,208] {timeout.py:67} ERROR - Process timed out, PID: 64610
[2022-10-21 16:09:35,222] {logging_mixin.py:115} INFO - [2022-10-21 16:09:35,212] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 64610
[2022-10-21 16:09:35,225] {logging_mixin.py:115} INFO - [2022-10-21 16:09:35,224] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 16:09:35,228] {logging_mixin.py:115} INFO - [2022-10-21 16:09:35,227] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 64610

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 16:09:35,233] {logging_mixin.py:115} INFO - [2022-10-21 16:09:35,232] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 16:09:35,244] {logging_mixin.py:115} INFO - [2022-10-21 16:09:35,239] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 16:09:35,248] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:09:35,401] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.230 seconds
[2022-10-21 16:09:52,074] {processor.py:153} INFO - Started process (PID=32439) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:09:52,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:09:52,081] {logging_mixin.py:115} INFO - [2022-10-21 16:09:52,081] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:09:52,465] {logging_mixin.py:115} INFO - [2022-10-21 16:09:52,461] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:09:52,473] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:09:52,538] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.500 seconds
[2022-10-21 16:10:23,906] {processor.py:153} INFO - Started process (PID=65271) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:10:23,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:10:23,913] {logging_mixin.py:115} INFO - [2022-10-21 16:10:23,912] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:10:27,636] {processor.py:153} INFO - Started process (PID=32755) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:10:27,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:10:27,650] {logging_mixin.py:115} INFO - [2022-10-21 16:10:27,650] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:10:28,495] {logging_mixin.py:115} INFO - [2022-10-21 16:10:28,489] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:10:28,505] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:10:28,804] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.184 seconds
[2022-10-21 16:10:53,911] {logging_mixin.py:115} INFO - [2022-10-21 16:10:53,911] {timeout.py:67} ERROR - Process timed out, PID: 65271
[2022-10-21 16:10:53,914] {logging_mixin.py:115} INFO - [2022-10-21 16:10:53,913] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 65271
[2022-10-21 16:10:53,946] {logging_mixin.py:115} INFO - [2022-10-21 16:10:53,928] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 16:10:53,962] {logging_mixin.py:115} INFO - [2022-10-21 16:10:53,948] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 65271

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 16:10:53,980] {logging_mixin.py:115} INFO - [2022-10-21 16:10:53,967] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 16:10:53,983] {logging_mixin.py:115} INFO - [2022-10-21 16:10:53,982] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 16:10:53,994] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:10:54,331] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.455 seconds
[2022-10-21 16:11:03,580] {processor.py:153} INFO - Started process (PID=33012) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:11:03,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:11:03,587] {logging_mixin.py:115} INFO - [2022-10-21 16:11:03,587] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:11:04,105] {logging_mixin.py:115} INFO - [2022-10-21 16:11:04,103] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:11:04,108] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:11:04,202] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.632 seconds
[2022-10-21 16:12:17,734] {processor.py:153} INFO - Started process (PID=65953) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:12:17,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:12:17,749] {logging_mixin.py:115} INFO - [2022-10-21 16:12:17,748] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:12:47,731] {logging_mixin.py:115} INFO - [2022-10-21 16:12:47,731] {timeout.py:67} ERROR - Process timed out, PID: 65953
[2022-10-21 16:12:47,738] {logging_mixin.py:115} INFO - [2022-10-21 16:12:47,736] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 65953
[2022-10-21 16:12:47,740] {logging_mixin.py:115} INFO - [2022-10-21 16:12:47,739] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 16:12:47,745] {logging_mixin.py:115} INFO - [2022-10-21 16:12:47,743] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 65953

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 16:12:47,746] {logging_mixin.py:115} INFO - [2022-10-21 16:12:47,746] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 16:12:47,749] {logging_mixin.py:115} INFO - [2022-10-21 16:12:47,748] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 16:12:47,761] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:12:47,881] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.179 seconds
[2022-10-21 16:13:49,113] {processor.py:153} INFO - Started process (PID=66904) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:13:49,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:13:49,118] {logging_mixin.py:115} INFO - [2022-10-21 16:13:49,118] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:00,608] {processor.py:153} INFO - Started process (PID=33375) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:00,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:14:00,614] {logging_mixin.py:115} INFO - [2022-10-21 16:14:00,614] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:01,014] {logging_mixin.py:115} INFO - [2022-10-21 16:14:01,013] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:14:01,016] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:01,065] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.467 seconds
[2022-10-21 16:14:04,245] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:14:04,368] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:04,609] {logging_mixin.py:115} INFO - [2022-10-21 16:14:04,609] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:14:04,765] {logging_mixin.py:115} INFO - [2022-10-21 16:14:04,764] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:14:04.354301+00:00, run_after=2022-10-22T16:14:04.354301+00:00
[2022-10-21 16:14:04,831] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 15.727 seconds
[2022-10-21 16:14:47,176] {processor.py:153} INFO - Started process (PID=33903) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:47,179] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:14:47,181] {logging_mixin.py:115} INFO - [2022-10-21 16:14:47,181] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:47,521] {logging_mixin.py:115} INFO - [2022-10-21 16:14:47,520] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:14:47,523] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:47,591] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.432 seconds
[2022-10-21 16:14:54,721] {processor.py:153} INFO - Started process (PID=67693) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:14:54,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:14:54,726] {logging_mixin.py:115} INFO - [2022-10-21 16:14:54,725] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:15:08,779] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:15:08,856] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:15:09,265] {logging_mixin.py:115} INFO - [2022-10-21 16:15:09,265] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:15:09,331] {logging_mixin.py:115} INFO - [2022-10-21 16:15:09,331] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:15:08.852099+00:00, run_after=2022-10-22T16:15:08.852099+00:00
[2022-10-21 16:15:09,407] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.696 seconds
[2022-10-21 16:15:19,386] {processor.py:153} INFO - Started process (PID=34263) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:15:19,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:15:19,392] {logging_mixin.py:115} INFO - [2022-10-21 16:15:19,392] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:15:19,735] {logging_mixin.py:115} INFO - [2022-10-21 16:15:19,733] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:15:19,738] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:15:19,808] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.430 seconds
[2022-10-21 16:15:36,699] {processor.py:153} INFO - Started process (PID=34454) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:15:36,701] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:15:36,703] {logging_mixin.py:115} INFO - [2022-10-21 16:15:36,703] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:15:37,095] {logging_mixin.py:115} INFO - [2022-10-21 16:15:37,093] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:15:37,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:15:37,233] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.543 seconds
[2022-10-21 16:16:34,155] {processor.py:153} INFO - Started process (PID=34942) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:16:34,158] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:16:34,163] {logging_mixin.py:115} INFO - [2022-10-21 16:16:34,163] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:16:34,584] {logging_mixin.py:115} INFO - [2022-10-21 16:16:34,583] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:16:34,587] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:16:34,646] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.507 seconds
[2022-10-21 16:17:21,919] {processor.py:153} INFO - Started process (PID=35458) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:17:21,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:17:21,923] {logging_mixin.py:115} INFO - [2022-10-21 16:17:21,923] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:17:22,179] {logging_mixin.py:115} INFO - [2022-10-21 16:17:22,176] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:17:22,184] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:17:22,232] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.328 seconds
[2022-10-21 16:17:30,311] {processor.py:153} INFO - Started process (PID=68581) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:17:30,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:17:30,327] {logging_mixin.py:115} INFO - [2022-10-21 16:17:30,326] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:17:49,170] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:17:49,215] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:17:49,352] {logging_mixin.py:115} INFO - [2022-10-21 16:17:49,351] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:17:49,394] {logging_mixin.py:115} INFO - [2022-10-21 16:17:49,394] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:17:49.211978+00:00, run_after=2022-10-22T16:17:49.211978+00:00
[2022-10-21 16:17:49,429] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 19.169 seconds
[2022-10-21 16:18:00,871] {processor.py:153} INFO - Started process (PID=35904) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:18:00,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:18:00,877] {logging_mixin.py:115} INFO - [2022-10-21 16:18:00,877] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:18:01,223] {logging_mixin.py:115} INFO - [2022-10-21 16:18:01,221] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:18:01,228] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:18:01,331] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.477 seconds
[2022-10-21 16:18:59,864] {processor.py:153} INFO - Started process (PID=69586) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:18:59,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:18:59,882] {logging_mixin.py:115} INFO - [2022-10-21 16:18:59,882] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:19:29,644] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:19:29,666] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:19:29,825] {logging_mixin.py:115} INFO - [2022-10-21 16:19:29,824] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:19:29,875] {logging_mixin.py:115} INFO - [2022-10-21 16:19:29,875] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:19:29.661406+00:00, run_after=2022-10-22T16:19:29.661406+00:00
[2022-10-21 16:19:29,924] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.105 seconds
[2022-10-21 16:19:46,129] {processor.py:153} INFO - Started process (PID=36076) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:19:46,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:19:46,144] {logging_mixin.py:115} INFO - [2022-10-21 16:19:46,144] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:19:46,639] {logging_mixin.py:115} INFO - [2022-10-21 16:19:46,638] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:19:46,644] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:19:46,707] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.610 seconds
[2022-10-21 16:20:09,135] {processor.py:153} INFO - Started process (PID=70453) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:20:09,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:20:09,142] {logging_mixin.py:115} INFO - [2022-10-21 16:20:09,141] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:20:25,987] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:20:26,030] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:20:26,169] {logging_mixin.py:115} INFO - [2022-10-21 16:20:26,169] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:20:26,206] {logging_mixin.py:115} INFO - [2022-10-21 16:20:26,206] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:20:26.022906+00:00, run_after=2022-10-22T16:20:26.022906+00:00
[2022-10-21 16:20:26,255] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 17.154 seconds
[2022-10-21 16:20:29,512] {processor.py:153} INFO - Started process (PID=36599) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:20:29,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:20:29,527] {logging_mixin.py:115} INFO - [2022-10-21 16:20:29,527] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:20:29,870] {logging_mixin.py:115} INFO - [2022-10-21 16:20:29,867] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:20:29,882] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:20:30,033] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.539 seconds
[2022-10-21 16:21:05,056] {processor.py:153} INFO - Started process (PID=71171) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:05,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:21:05,060] {logging_mixin.py:115} INFO - [2022-10-21 16:21:05,060] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:10,076] {processor.py:153} INFO - Started process (PID=37072) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:10,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:21:10,081] {logging_mixin.py:115} INFO - [2022-10-21 16:21:10,081] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:10,350] {logging_mixin.py:115} INFO - [2022-10-21 16:21:10,349] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:21:10,352] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:10,396] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.341 seconds
[2022-10-21 16:21:21,320] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:21:21,362] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:21,530] {logging_mixin.py:115} INFO - [2022-10-21 16:21:21,530] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:21:21,577] {logging_mixin.py:115} INFO - [2022-10-21 16:21:21,577] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:21:21.355922+00:00, run_after=2022-10-22T16:21:21.355922+00:00
[2022-10-21 16:21:21,653] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 16.627 seconds
[2022-10-21 16:21:44,875] {processor.py:153} INFO - Started process (PID=37444) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:44,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:21:44,880] {logging_mixin.py:115} INFO - [2022-10-21 16:21:44,880] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:45,429] {logging_mixin.py:115} INFO - [2022-10-21 16:21:45,428] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:21:45,435] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:21:45,507] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.639 seconds
[2022-10-21 16:22:49,823] {processor.py:153} INFO - Started process (PID=37963) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:22:49,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:22:49,831] {logging_mixin.py:115} INFO - [2022-10-21 16:22:49,831] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:22:50,439] {logging_mixin.py:115} INFO - [2022-10-21 16:22:50,437] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:22:50,443] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:22:50,540] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.746 seconds
[2022-10-21 16:23:26,007] {processor.py:153} INFO - Started process (PID=38255) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:23:26,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:23:26,019] {logging_mixin.py:115} INFO - [2022-10-21 16:23:26,019] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:23:26,503] {logging_mixin.py:115} INFO - [2022-10-21 16:23:26,501] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:23:26,505] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:23:26,551] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.573 seconds
[2022-10-21 16:24:14,080] {processor.py:153} INFO - Started process (PID=72181) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:24:14,087] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:24:14,089] {logging_mixin.py:115} INFO - [2022-10-21 16:24:14,089] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:24:29,205] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:24:29,245] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:24:29,426] {logging_mixin.py:115} INFO - [2022-10-21 16:24:29,426] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:24:29,472] {logging_mixin.py:115} INFO - [2022-10-21 16:24:29,471] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:24:29.240008+00:00, run_after=2022-10-22T16:24:29.240008+00:00
[2022-10-21 16:24:29,522] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 15.451 seconds
[2022-10-21 16:24:49,562] {processor.py:153} INFO - Started process (PID=38798) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:24:49,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:24:49,570] {logging_mixin.py:115} INFO - [2022-10-21 16:24:49,570] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:24:49,847] {logging_mixin.py:115} INFO - [2022-10-21 16:24:49,845] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:24:49,852] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:24:49,909] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.358 seconds
[2022-10-21 16:25:12,031] {processor.py:153} INFO - Started process (PID=72954) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:25:12,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:25:12,041] {logging_mixin.py:115} INFO - [2022-10-21 16:25:12,041] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:25:30,282] {processor.py:153} INFO - Started process (PID=39213) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:25:30,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:25:30,287] {logging_mixin.py:115} INFO - [2022-10-21 16:25:30,286] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:25:30,584] {logging_mixin.py:115} INFO - [2022-10-21 16:25:30,583] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:25:30,586] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:25:30,644] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.373 seconds
[2022-10-21 16:25:35,512] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:25:35,588] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:25:35,899] {logging_mixin.py:115} INFO - [2022-10-21 16:25:35,895] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:25:35,973] {logging_mixin.py:115} INFO - [2022-10-21 16:25:35,972] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:25:35.576277+00:00, run_after=2022-10-22T16:25:35.576277+00:00
[2022-10-21 16:25:36,061] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 24.039 seconds
[2022-10-21 16:26:12,485] {processor.py:153} INFO - Started process (PID=39686) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:12,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:26:12,492] {logging_mixin.py:115} INFO - [2022-10-21 16:26:12,491] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:12,832] {logging_mixin.py:115} INFO - [2022-10-21 16:26:12,830] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate()#.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:26:12,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:12,966] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.499 seconds
[2022-10-21 16:26:20,030] {processor.py:153} INFO - Started process (PID=73736) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:20,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:26:20,035] {logging_mixin.py:115} INFO - [2022-10-21 16:26:20,035] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:47,040] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 16:26:47,071] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:47,849] {logging_mixin.py:115} INFO - [2022-10-21 16:26:47,849] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:26:47,967] {logging_mixin.py:115} INFO - [2022-10-21 16:26:47,967] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:26:47.064086+00:00, run_after=2022-10-22T16:26:47.064086+00:00
[2022-10-21 16:26:48,123] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 28.125 seconds
[2022-10-21 16:26:51,737] {processor.py:153} INFO - Started process (PID=40019) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:51,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:26:51,756] {logging_mixin.py:115} INFO - [2022-10-21 16:26:51,756] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:52,158] {logging_mixin.py:115} INFO - [2022-10-21 16:26:52,156] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 15, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 16:26:52,163] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:26:52,217] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.495 seconds
[2022-10-21 16:27:26,108] {processor.py:153} INFO - Started process (PID=40322) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:27:26,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:27:26,133] {logging_mixin.py:115} INFO - [2022-10-21 16:27:26,133] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:27:26,581] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:27:26,831] {logging_mixin.py:115} INFO - [2022-10-21 16:27:26,831] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:27:26,895] {logging_mixin.py:115} INFO - [2022-10-21 16:27:26,895] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:27:26.575494+00:00, run_after=2022-10-22T16:27:26.575494+00:00
[2022-10-21 16:27:26,929] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.832 seconds
[2022-10-21 16:27:47,732] {processor.py:153} INFO - Started process (PID=74538) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:27:47,737] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:27:47,740] {logging_mixin.py:115} INFO - [2022-10-21 16:27:47,740] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:27:47,954] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:27:48,008] {logging_mixin.py:115} INFO - [2022-10-21 16:27:48,008] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:27:48,055] {logging_mixin.py:115} INFO - [2022-10-21 16:27:48,055] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:27:47.948833+00:00, run_after=2022-10-22T16:27:47.948833+00:00
[2022-10-21 16:27:48,087] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.372 seconds
[2022-10-21 16:28:30,275] {processor.py:153} INFO - Started process (PID=40849) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:28:30,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:28:30,285] {logging_mixin.py:115} INFO - [2022-10-21 16:28:30,285] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:28:30,541] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:28:30,857] {logging_mixin.py:115} INFO - [2022-10-21 16:28:30,857] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:28:30,920] {logging_mixin.py:115} INFO - [2022-10-21 16:28:30,919] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:28:30.534033+00:00, run_after=2022-10-22T16:28:30.534033+00:00
[2022-10-21 16:28:30,978] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.718 seconds
[2022-10-21 16:29:03,780] {processor.py:153} INFO - Started process (PID=41112) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:29:03,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:29:03,787] {logging_mixin.py:115} INFO - [2022-10-21 16:29:03,786] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:29:04,104] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:29:04,454] {logging_mixin.py:115} INFO - [2022-10-21 16:29:04,454] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:29:04,542] {logging_mixin.py:115} INFO - [2022-10-21 16:29:04,542] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:29:04.092039+00:00, run_after=2022-10-22T16:29:04.092039+00:00
[2022-10-21 16:29:04,588] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.822 seconds
[2022-10-21 16:30:07,831] {processor.py:153} INFO - Started process (PID=74982) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:07,846] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:30:07,859] {logging_mixin.py:115} INFO - [2022-10-21 16:30:07,858] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:08,230] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:08,364] {logging_mixin.py:115} INFO - [2022-10-21 16:30:08,364] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:30:08,402] {logging_mixin.py:115} INFO - [2022-10-21 16:30:08,401] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:30:08.224755+00:00, run_after=2022-10-22T16:30:08.224755+00:00
[2022-10-21 16:30:08,426] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.608 seconds
[2022-10-21 16:30:16,836] {processor.py:153} INFO - Started process (PID=41401) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:16,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:30:16,845] {logging_mixin.py:115} INFO - [2022-10-21 16:30:16,845] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:17,127] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:17,195] {logging_mixin.py:115} INFO - [2022-10-21 16:30:17,195] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:30:17,295] {logging_mixin.py:115} INFO - [2022-10-21 16:30:17,294] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:30:17.111208+00:00, run_after=2022-10-22T16:30:17.111208+00:00
[2022-10-21 16:30:17,330] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.502 seconds
[2022-10-21 16:30:54,800] {processor.py:153} INFO - Started process (PID=75503) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:54,802] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:30:54,807] {logging_mixin.py:115} INFO - [2022-10-21 16:30:54,807] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:54,821] {logging_mixin.py:115} INFO - [2022-10-21 16:30:54,819] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24
    python_callable=pyspark.start_spark_session
                  ^
SyntaxError: invalid syntax
[2022-10-21 16:30:54,822] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:30:54,874] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.081 seconds
[2022-10-21 16:31:00,710] {processor.py:153} INFO - Started process (PID=41865) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:00,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:31:00,717] {logging_mixin.py:115} INFO - [2022-10-21 16:31:00,717] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:01,044] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:01,427] {logging_mixin.py:115} INFO - [2022-10-21 16:31:01,427] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:31:01,565] {logging_mixin.py:115} INFO - [2022-10-21 16:31:01,565] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:31:01.034230+00:00, run_after=2022-10-22T16:31:01.034230+00:00
[2022-10-21 16:31:01,616] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.923 seconds
[2022-10-21 16:31:13,054] {processor.py:153} INFO - Started process (PID=75676) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:13,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:31:13,060] {logging_mixin.py:115} INFO - [2022-10-21 16:31:13,060] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:13,301] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:13,338] {logging_mixin.py:115} INFO - [2022-10-21 16:31:13,337] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:31:13,389] {logging_mixin.py:115} INFO - [2022-10-21 16:31:13,389] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:31:13.296445+00:00, run_after=2022-10-22T16:31:13.296445+00:00
[2022-10-21 16:31:13,442] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.406 seconds
[2022-10-21 16:31:20,015] {processor.py:153} INFO - Started process (PID=42053) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:20,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:31:20,022] {logging_mixin.py:115} INFO - [2022-10-21 16:31:20,021] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:20,283] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:20,316] {logging_mixin.py:115} INFO - [2022-10-21 16:31:20,316] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:31:20,397] {logging_mixin.py:115} INFO - [2022-10-21 16:31:20,396] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:31:20.278133+00:00, run_after=2022-10-22T16:31:20.278133+00:00
[2022-10-21 16:31:20,425] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.429 seconds
[2022-10-21 16:31:57,400] {processor.py:153} INFO - Started process (PID=76097) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:57,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:31:57,404] {logging_mixin.py:115} INFO - [2022-10-21 16:31:57,404] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:57,590] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:31:57,755] {logging_mixin.py:115} INFO - [2022-10-21 16:31:57,755] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:31:57,796] {logging_mixin.py:115} INFO - [2022-10-21 16:31:57,796] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:31:57.586385+00:00, run_after=2022-10-22T16:31:57.586385+00:00
[2022-10-21 16:31:57,828] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.435 seconds
[2022-10-21 16:32:07,246] {processor.py:153} INFO - Started process (PID=42489) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:32:07,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:32:07,250] {logging_mixin.py:115} INFO - [2022-10-21 16:32:07,250] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:32:07,422] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:32:07,461] {logging_mixin.py:115} INFO - [2022-10-21 16:32:07,461] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:32:07,509] {logging_mixin.py:115} INFO - [2022-10-21 16:32:07,509] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:32:07.412559+00:00, run_after=2022-10-22T16:32:07.412559+00:00
[2022-10-21 16:32:07,526] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.289 seconds
[2022-10-21 16:32:33,766] {processor.py:153} INFO - Started process (PID=76482) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:32:33,770] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:32:33,773] {logging_mixin.py:115} INFO - [2022-10-21 16:32:33,772] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:32:34,241] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:32:34,604] {logging_mixin.py:115} INFO - [2022-10-21 16:32:34,604] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:32:34,666] {logging_mixin.py:115} INFO - [2022-10-21 16:32:34,665] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:32:34.225350+00:00, run_after=2022-10-22T16:32:34.225350+00:00
[2022-10-21 16:32:34,749] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.003 seconds
[2022-10-21 16:33:02,856] {processor.py:153} INFO - Started process (PID=42984) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:33:02,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:33:02,866] {logging_mixin.py:115} INFO - [2022-10-21 16:33:02,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:33:03,052] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:33:03,097] {logging_mixin.py:115} INFO - [2022-10-21 16:33:03,097] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:33:03,160] {logging_mixin.py:115} INFO - [2022-10-21 16:33:03,160] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:33:03.046297+00:00, run_after=2022-10-22T16:33:03.046297+00:00
[2022-10-21 16:33:03,198] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.351 seconds
[2022-10-21 16:33:08,698] {processor.py:153} INFO - Started process (PID=76822) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:33:08,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:33:08,704] {logging_mixin.py:115} INFO - [2022-10-21 16:33:08,703] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:33:08,896] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:33:09,085] {logging_mixin.py:115} INFO - [2022-10-21 16:33:09,085] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:33:09,123] {logging_mixin.py:115} INFO - [2022-10-21 16:33:09,123] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:33:08.890314+00:00, run_after=2022-10-22T16:33:08.890314+00:00
[2022-10-21 16:33:09,161] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.473 seconds
[2022-10-21 16:34:02,754] {processor.py:153} INFO - Started process (PID=77279) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:34:02,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:34:02,761] {logging_mixin.py:115} INFO - [2022-10-21 16:34:02,761] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:34:02,788] {logging_mixin.py:115} INFO - [2022-10-21 16:34:02,783] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13
    globals spark, conf, sc , sqlContext
                ^
SyntaxError: invalid syntax
[2022-10-21 16:34:02,790] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:34:02,855] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.120 seconds
[2022-10-21 16:34:51,902] {processor.py:153} INFO - Started process (PID=43513) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:34:51,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:34:51,906] {logging_mixin.py:115} INFO - [2022-10-21 16:34:51,906] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:34:52,347] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:34:52,591] {logging_mixin.py:115} INFO - [2022-10-21 16:34:52,590] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:34:52,641] {logging_mixin.py:115} INFO - [2022-10-21 16:34:52,641] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:34:52.340309+00:00, run_after=2022-10-22T16:34:52.340309+00:00
[2022-10-21 16:34:52,684] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.787 seconds
[2022-10-21 16:35:34,559] {processor.py:153} INFO - Started process (PID=43791) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:35:34,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:35:34,566] {logging_mixin.py:115} INFO - [2022-10-21 16:35:34,565] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:35:34,941] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:35:35,363] {logging_mixin.py:115} INFO - [2022-10-21 16:35:35,363] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:35:35,494] {logging_mixin.py:115} INFO - [2022-10-21 16:35:35,494] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:35:34.925714+00:00, run_after=2022-10-22T16:35:34.925714+00:00
[2022-10-21 16:35:35,600] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.054 seconds
[2022-10-21 16:36:12,416] {processor.py:153} INFO - Started process (PID=44131) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:36:12,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:36:12,422] {logging_mixin.py:115} INFO - [2022-10-21 16:36:12,422] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:36:12,747] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:36:12,934] {logging_mixin.py:115} INFO - [2022-10-21 16:36:12,934] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:36:13,032] {logging_mixin.py:115} INFO - [2022-10-21 16:36:13,032] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:36:12.737196+00:00, run_after=2022-10-22T16:36:12.737196+00:00
[2022-10-21 16:36:13,072] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.670 seconds
[2022-10-21 16:37:12,326] {processor.py:153} INFO - Started process (PID=44631) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:12,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:37:12,334] {logging_mixin.py:115} INFO - [2022-10-21 16:37:12,333] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:12,552] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:12,747] {logging_mixin.py:115} INFO - [2022-10-21 16:37:12,747] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:37:12,796] {logging_mixin.py:115} INFO - [2022-10-21 16:37:12,796] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:37:12.544246+00:00, run_after=2022-10-22T16:37:12.544246+00:00
[2022-10-21 16:37:12,832] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.518 seconds
[2022-10-21 16:37:39,188] {processor.py:153} INFO - Started process (PID=77753) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:39,190] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:37:39,192] {logging_mixin.py:115} INFO - [2022-10-21 16:37:39,192] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:39,339] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:39,399] {logging_mixin.py:115} INFO - [2022-10-21 16:37:39,398] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:37:39,487] {logging_mixin.py:115} INFO - [2022-10-21 16:37:39,487] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:37:39.333171+00:00, run_after=2022-10-22T16:37:39.333171+00:00
[2022-10-21 16:37:39,514] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.331 seconds
[2022-10-21 16:37:45,489] {processor.py:153} INFO - Started process (PID=45053) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:45,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:37:45,510] {logging_mixin.py:115} INFO - [2022-10-21 16:37:45,508] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:45,742] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:37:46,071] {logging_mixin.py:115} INFO - [2022-10-21 16:37:46,071] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:37:46,169] {logging_mixin.py:115} INFO - [2022-10-21 16:37:46,169] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:37:45.734962+00:00, run_after=2022-10-22T16:37:45.734962+00:00
[2022-10-21 16:37:46,201] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.735 seconds
[2022-10-21 16:38:20,734] {processor.py:153} INFO - Started process (PID=45386) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:20,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:38:20,738] {logging_mixin.py:115} INFO - [2022-10-21 16:38:20,738] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:20,986] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:21,279] {logging_mixin.py:115} INFO - [2022-10-21 16:38:21,279] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:38:21,378] {logging_mixin.py:115} INFO - [2022-10-21 16:38:21,378] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:38:20.980163+00:00, run_after=2022-10-22T16:38:20.980163+00:00
[2022-10-21 16:38:21,447] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.721 seconds
[2022-10-21 16:38:27,038] {processor.py:153} INFO - Started process (PID=78280) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:27,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:38:27,061] {logging_mixin.py:115} INFO - [2022-10-21 16:38:27,061] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:27,251] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:27,301] {logging_mixin.py:115} INFO - [2022-10-21 16:38:27,300] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:38:27,342] {logging_mixin.py:115} INFO - [2022-10-21 16:38:27,342] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:38:27.245135+00:00, run_after=2022-10-22T16:38:27.245135+00:00
[2022-10-21 16:38:27,370] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.338 seconds
[2022-10-21 16:38:52,513] {processor.py:153} INFO - Started process (PID=45768) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:52,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:38:52,519] {logging_mixin.py:115} INFO - [2022-10-21 16:38:52,519] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:52,798] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:38:53,014] {logging_mixin.py:115} INFO - [2022-10-21 16:38:53,014] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:38:53,046] {logging_mixin.py:115} INFO - [2022-10-21 16:38:53,046] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:38:52.785749+00:00, run_after=2022-10-22T16:38:52.785749+00:00
[2022-10-21 16:38:53,071] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.571 seconds
[2022-10-21 16:39:01,779] {processor.py:153} INFO - Started process (PID=78724) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:01,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:39:01,784] {logging_mixin.py:115} INFO - [2022-10-21 16:39:01,784] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:02,020] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:02,062] {logging_mixin.py:115} INFO - [2022-10-21 16:39:02,062] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:39:02,134] {logging_mixin.py:115} INFO - [2022-10-21 16:39:02,134] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:39:02.002075+00:00, run_after=2022-10-22T16:39:02.002075+00:00
[2022-10-21 16:39:02,157] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.385 seconds
[2022-10-21 16:39:33,608] {processor.py:153} INFO - Started process (PID=79139) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:33,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:39:33,613] {logging_mixin.py:115} INFO - [2022-10-21 16:39:33,613] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:33,773] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:33,903] {logging_mixin.py:115} INFO - [2022-10-21 16:39:33,903] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:39:33,935] {logging_mixin.py:115} INFO - [2022-10-21 16:39:33,934] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:39:33.767808+00:00, run_after=2022-10-22T16:39:33.767808+00:00
[2022-10-21 16:39:33,958] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.359 seconds
[2022-10-21 16:39:50,594] {processor.py:153} INFO - Started process (PID=46078) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:50,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:39:50,598] {logging_mixin.py:115} INFO - [2022-10-21 16:39:50,597] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:50,785] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:39:50,818] {logging_mixin.py:115} INFO - [2022-10-21 16:39:50,818] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:39:50,869] {logging_mixin.py:115} INFO - [2022-10-21 16:39:50,869] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:39:50.779275+00:00, run_after=2022-10-22T16:39:50.779275+00:00
[2022-10-21 16:39:50,896] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.319 seconds
[2022-10-21 16:40:08,793] {processor.py:153} INFO - Started process (PID=79635) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:08,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:40:08,806] {logging_mixin.py:115} INFO - [2022-10-21 16:40:08,806] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:09,064] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:09,290] {logging_mixin.py:115} INFO - [2022-10-21 16:40:09,289] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:40:09,355] {logging_mixin.py:115} INFO - [2022-10-21 16:40:09,355] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:40:09.059046+00:00, run_after=2022-10-22T16:40:09.059046+00:00
[2022-10-21 16:40:09,381] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.598 seconds
[2022-10-21 16:40:28,972] {processor.py:153} INFO - Started process (PID=46572) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:28,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:40:28,977] {logging_mixin.py:115} INFO - [2022-10-21 16:40:28,976] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:29,245] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:29,285] {logging_mixin.py:115} INFO - [2022-10-21 16:40:29,285] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:40:29,340] {logging_mixin.py:115} INFO - [2022-10-21 16:40:29,339] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:40:29.235575+00:00, run_after=2022-10-22T16:40:29.235575+00:00
[2022-10-21 16:40:29,400] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.436 seconds
[2022-10-21 16:40:40,521] {processor.py:153} INFO - Started process (PID=80060) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:40,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:40:40,525] {logging_mixin.py:115} INFO - [2022-10-21 16:40:40,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:40,652] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:40:40,876] {logging_mixin.py:115} INFO - [2022-10-21 16:40:40,876] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:40:40,938] {logging_mixin.py:115} INFO - [2022-10-21 16:40:40,938] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:40:40.647760+00:00, run_after=2022-10-22T16:40:40.647760+00:00
[2022-10-21 16:40:40,967] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.453 seconds
[2022-10-21 16:41:08,709] {processor.py:153} INFO - Started process (PID=47083) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:08,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:41:08,721] {logging_mixin.py:115} INFO - [2022-10-21 16:41:08,721] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:08,991] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:09,026] {logging_mixin.py:115} INFO - [2022-10-21 16:41:09,025] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:41:09,073] {logging_mixin.py:115} INFO - [2022-10-21 16:41:09,073] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:41:08.987067+00:00, run_after=2022-10-22T16:41:08.987067+00:00
[2022-10-21 16:41:09,097] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.396 seconds
[2022-10-21 16:41:15,342] {processor.py:153} INFO - Started process (PID=80508) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:15,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:41:15,345] {logging_mixin.py:115} INFO - [2022-10-21 16:41:15,345] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:15,525] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:15,732] {logging_mixin.py:115} INFO - [2022-10-21 16:41:15,732] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:41:15,785] {logging_mixin.py:115} INFO - [2022-10-21 16:41:15,785] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:41:15.517069+00:00, run_after=2022-10-22T16:41:15.517069+00:00
[2022-10-21 16:41:15,841] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.505 seconds
[2022-10-21 16:41:41,593] {processor.py:153} INFO - Started process (PID=47489) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:41,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:41:41,597] {logging_mixin.py:115} INFO - [2022-10-21 16:41:41,597] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:41,781] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:41,822] {logging_mixin.py:115} INFO - [2022-10-21 16:41:41,822] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:41:41,871] {logging_mixin.py:115} INFO - [2022-10-21 16:41:41,871] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:41:41.772718+00:00, run_after=2022-10-22T16:41:41.772718+00:00
[2022-10-21 16:41:41,895] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.309 seconds
[2022-10-21 16:41:50,552] {processor.py:153} INFO - Started process (PID=80974) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:50,553] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:41:50,555] {logging_mixin.py:115} INFO - [2022-10-21 16:41:50,555] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:50,811] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:41:51,002] {logging_mixin.py:115} INFO - [2022-10-21 16:41:51,002] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:41:51,035] {logging_mixin.py:115} INFO - [2022-10-21 16:41:51,035] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:41:50.801112+00:00, run_after=2022-10-22T16:41:50.801112+00:00
[2022-10-21 16:41:51,061] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.517 seconds
[2022-10-21 16:42:13,966] {processor.py:153} INFO - Started process (PID=47880) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:13,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:42:13,970] {logging_mixin.py:115} INFO - [2022-10-21 16:42:13,970] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:14,088] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:14,128] {logging_mixin.py:115} INFO - [2022-10-21 16:42:14,128] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:42:14,169] {logging_mixin.py:115} INFO - [2022-10-21 16:42:14,169] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:42:14.084022+00:00, run_after=2022-10-22T16:42:14.084022+00:00
[2022-10-21 16:42:14,194] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.234 seconds
[2022-10-21 16:42:43,045] {processor.py:153} INFO - Started process (PID=81211) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:43,047] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:42:43,049] {logging_mixin.py:115} INFO - [2022-10-21 16:42:43,049] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:43,219] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:43,456] {logging_mixin.py:115} INFO - [2022-10-21 16:42:43,456] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:42:43,500] {logging_mixin.py:115} INFO - [2022-10-21 16:42:43,500] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:42:43.214386+00:00, run_after=2022-10-22T16:42:43.214386+00:00
[2022-10-21 16:42:43,524] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.487 seconds
[2022-10-21 16:42:45,961] {processor.py:153} INFO - Started process (PID=48287) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:45,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:42:45,984] {logging_mixin.py:115} INFO - [2022-10-21 16:42:45,983] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:46,197] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:42:46,239] {logging_mixin.py:115} INFO - [2022-10-21 16:42:46,239] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:42:46,303] {logging_mixin.py:115} INFO - [2022-10-21 16:42:46,302] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:42:46.191153+00:00, run_after=2022-10-22T16:42:46.191153+00:00
[2022-10-21 16:42:46,360] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.423 seconds
[2022-10-21 16:43:18,213] {processor.py:153} INFO - Started process (PID=81630) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:18,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:43:18,218] {logging_mixin.py:115} INFO - [2022-10-21 16:43:18,218] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:18,454] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:18,657] {logging_mixin.py:115} INFO - [2022-10-21 16:43:18,656] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:43:18,697] {logging_mixin.py:115} INFO - [2022-10-21 16:43:18,696] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:43:18.446327+00:00, run_after=2022-10-22T16:43:18.446327+00:00
[2022-10-21 16:43:18,727] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.524 seconds
[2022-10-21 16:43:22,965] {processor.py:153} INFO - Started process (PID=48723) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:22,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:43:22,969] {logging_mixin.py:115} INFO - [2022-10-21 16:43:22,969] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:23,240] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:23,285] {logging_mixin.py:115} INFO - [2022-10-21 16:43:23,285] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:43:23,342] {logging_mixin.py:115} INFO - [2022-10-21 16:43:23,342] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:43:23.235581+00:00, run_after=2022-10-22T16:43:23.235581+00:00
[2022-10-21 16:43:23,390] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.438 seconds
[2022-10-21 16:43:53,920] {processor.py:153} INFO - Started process (PID=82072) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:53,924] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:43:53,927] {logging_mixin.py:115} INFO - [2022-10-21 16:43:53,927] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:54,082] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:54,225] {logging_mixin.py:115} INFO - [2022-10-21 16:43:54,225] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:43:54,267] {logging_mixin.py:115} INFO - [2022-10-21 16:43:54,266] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:43:54.077349+00:00, run_after=2022-10-22T16:43:54.077349+00:00
[2022-10-21 16:43:54,305] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.398 seconds
[2022-10-21 16:43:59,185] {processor.py:153} INFO - Started process (PID=49169) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:59,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:43:59,190] {logging_mixin.py:115} INFO - [2022-10-21 16:43:59,189] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:59,339] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:43:59,389] {logging_mixin.py:115} INFO - [2022-10-21 16:43:59,389] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:43:59,437] {logging_mixin.py:115} INFO - [2022-10-21 16:43:59,437] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:43:59.335158+00:00, run_after=2022-10-22T16:43:59.335158+00:00
[2022-10-21 16:43:59,469] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.295 seconds
[2022-10-21 16:44:31,300] {processor.py:153} INFO - Started process (PID=82537) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:44:31,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:44:31,307] {logging_mixin.py:115} INFO - [2022-10-21 16:44:31,307] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:44:31,447] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:44:31,610] {logging_mixin.py:115} INFO - [2022-10-21 16:44:31,609] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:44:31,647] {logging_mixin.py:115} INFO - [2022-10-21 16:44:31,647] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:44:31.443432+00:00, run_after=2022-10-22T16:44:31.443432+00:00
[2022-10-21 16:44:31,678] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.401 seconds
[2022-10-21 16:44:49,528] {processor.py:153} INFO - Started process (PID=49332) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:44:49,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:44:49,532] {logging_mixin.py:115} INFO - [2022-10-21 16:44:49,532] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:44:49,783] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:44:49,831] {logging_mixin.py:115} INFO - [2022-10-21 16:44:49,831] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:44:49,872] {logging_mixin.py:115} INFO - [2022-10-21 16:44:49,871] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:44:49.772407+00:00, run_after=2022-10-22T16:44:49.772407+00:00
[2022-10-21 16:44:49,914] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.393 seconds
[2022-10-21 16:45:05,738] {processor.py:153} INFO - Started process (PID=82976) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:05,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:45:05,744] {logging_mixin.py:115} INFO - [2022-10-21 16:45:05,744] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:05,964] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:06,142] {logging_mixin.py:115} INFO - [2022-10-21 16:45:06,142] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:45:06,192] {logging_mixin.py:115} INFO - [2022-10-21 16:45:06,192] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:45:05.957705+00:00, run_after=2022-10-22T16:45:05.957705+00:00
[2022-10-21 16:45:06,219] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.497 seconds
[2022-10-21 16:45:28,236] {processor.py:153} INFO - Started process (PID=49761) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:28,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:45:28,259] {logging_mixin.py:115} INFO - [2022-10-21 16:45:28,259] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:28,491] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:28,533] {logging_mixin.py:115} INFO - [2022-10-21 16:45:28,533] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:45:28,584] {logging_mixin.py:115} INFO - [2022-10-21 16:45:28,584] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:45:28.485135+00:00, run_after=2022-10-22T16:45:28.485135+00:00
[2022-10-21 16:45:28,608] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.387 seconds
[2022-10-21 16:45:48,616] {processor.py:153} INFO - Started process (PID=83465) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:48,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:45:48,625] {logging_mixin.py:115} INFO - [2022-10-21 16:45:48,624] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:48,840] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:45:49,038] {logging_mixin.py:115} INFO - [2022-10-21 16:45:49,037] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:45:49,094] {logging_mixin.py:115} INFO - [2022-10-21 16:45:49,094] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:45:48.832368+00:00, run_after=2022-10-22T16:45:48.832368+00:00
[2022-10-21 16:45:49,124] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.522 seconds
[2022-10-21 16:46:10,565] {processor.py:153} INFO - Started process (PID=50272) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:10,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:46:10,569] {logging_mixin.py:115} INFO - [2022-10-21 16:46:10,568] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:10,762] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:10,826] {logging_mixin.py:115} INFO - [2022-10-21 16:46:10,826] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:46:10,884] {logging_mixin.py:115} INFO - [2022-10-21 16:46:10,882] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:46:10.757435+00:00, run_after=2022-10-22T16:46:10.757435+00:00
[2022-10-21 16:46:10,934] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.380 seconds
[2022-10-21 16:46:24,806] {processor.py:153} INFO - Started process (PID=83924) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:24,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:46:24,815] {logging_mixin.py:115} INFO - [2022-10-21 16:46:24,815] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:25,005] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:25,168] {logging_mixin.py:115} INFO - [2022-10-21 16:46:25,168] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:46:25,225] {logging_mixin.py:115} INFO - [2022-10-21 16:46:25,225] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:46:24.988544+00:00, run_after=2022-10-22T16:46:24.988544+00:00
[2022-10-21 16:46:25,275] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.475 seconds
[2022-10-21 16:46:44,913] {processor.py:153} INFO - Started process (PID=50696) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:44,915] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:46:44,917] {logging_mixin.py:115} INFO - [2022-10-21 16:46:44,916] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:45,100] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:45,125] {logging_mixin.py:115} INFO - [2022-10-21 16:46:45,125] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:46:45,197] {logging_mixin.py:115} INFO - [2022-10-21 16:46:45,197] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:46:45.093517+00:00, run_after=2022-10-22T16:46:45.093517+00:00
[2022-10-21 16:46:45,217] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.310 seconds
[2022-10-21 16:46:55,783] {processor.py:153} INFO - Started process (PID=84301) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:55,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:46:55,789] {logging_mixin.py:115} INFO - [2022-10-21 16:46:55,789] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:56,059] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:46:56,238] {logging_mixin.py:115} INFO - [2022-10-21 16:46:56,237] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:46:56,285] {logging_mixin.py:115} INFO - [2022-10-21 16:46:56,284] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:46:56.042802+00:00, run_after=2022-10-22T16:46:56.042802+00:00
[2022-10-21 16:46:56,317] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.543 seconds
[2022-10-21 16:47:26,726] {processor.py:153} INFO - Started process (PID=51198) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:47:26,728] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:47:26,732] {logging_mixin.py:115} INFO - [2022-10-21 16:47:26,731] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:47:26,990] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:47:27,141] {logging_mixin.py:115} INFO - [2022-10-21 16:47:27,141] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:47:27,184] {logging_mixin.py:115} INFO - [2022-10-21 16:47:27,183] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:47:26.978074+00:00, run_after=2022-10-22T16:47:26.978074+00:00
[2022-10-21 16:47:27,223] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.506 seconds
[2022-10-21 16:47:42,989] {processor.py:153} INFO - Started process (PID=84466) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:47:42,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:47:42,993] {logging_mixin.py:115} INFO - [2022-10-21 16:47:42,993] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:47:43,141] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:47:43,183] {logging_mixin.py:115} INFO - [2022-10-21 16:47:43,183] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:47:43,220] {logging_mixin.py:115} INFO - [2022-10-21 16:47:43,220] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:47:43.134252+00:00, run_after=2022-10-22T16:47:43.134252+00:00
[2022-10-21 16:47:43,241] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.259 seconds
[2022-10-21 16:48:08,265] {processor.py:153} INFO - Started process (PID=51708) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:08,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:48:08,274] {logging_mixin.py:115} INFO - [2022-10-21 16:48:08,274] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:08,610] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:08,871] {logging_mixin.py:115} INFO - [2022-10-21 16:48:08,871] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:48:08,922] {logging_mixin.py:115} INFO - [2022-10-21 16:48:08,921] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:48:08.601223+00:00, run_after=2022-10-22T16:48:08.601223+00:00
[2022-10-21 16:48:08,953] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.721 seconds
[2022-10-21 16:48:17,154] {processor.py:153} INFO - Started process (PID=84892) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:17,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:48:17,161] {logging_mixin.py:115} INFO - [2022-10-21 16:48:17,161] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:17,331] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:17,361] {logging_mixin.py:115} INFO - [2022-10-21 16:48:17,361] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:48:17,397] {logging_mixin.py:115} INFO - [2022-10-21 16:48:17,397] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:48:17.326137+00:00, run_after=2022-10-22T16:48:17.326137+00:00
[2022-10-21 16:48:17,447] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.306 seconds
[2022-10-21 16:48:52,102] {processor.py:153} INFO - Started process (PID=52215) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:52,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:48:52,108] {logging_mixin.py:115} INFO - [2022-10-21 16:48:52,108] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:52,321] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:52,562] {logging_mixin.py:115} INFO - [2022-10-21 16:48:52,562] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:48:52,613] {logging_mixin.py:115} INFO - [2022-10-21 16:48:52,613] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:48:52.309701+00:00, run_after=2022-10-22T16:48:52.309701+00:00
[2022-10-21 16:48:52,671] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.590 seconds
[2022-10-21 16:48:56,017] {processor.py:153} INFO - Started process (PID=85351) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:56,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:48:56,022] {logging_mixin.py:115} INFO - [2022-10-21 16:48:56,022] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:56,276] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:48:56,320] {logging_mixin.py:115} INFO - [2022-10-21 16:48:56,320] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:48:56,366] {logging_mixin.py:115} INFO - [2022-10-21 16:48:56,366] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:48:56.272284+00:00, run_after=2022-10-22T16:48:56.272284+00:00
[2022-10-21 16:48:56,798] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.792 seconds
[2022-10-21 16:49:36,677] {processor.py:153} INFO - Started process (PID=85839) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:49:36,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:49:36,682] {logging_mixin.py:115} INFO - [2022-10-21 16:49:36,682] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:49:36,807] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:49:37,137] {logging_mixin.py:115} INFO - [2022-10-21 16:49:37,137] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:49:37,169] {logging_mixin.py:115} INFO - [2022-10-21 16:49:37,169] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:49:36.803126+00:00, run_after=2022-10-22T16:49:36.803126+00:00
[2022-10-21 16:49:37,199] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.531 seconds
[2022-10-21 16:49:43,921] {processor.py:153} INFO - Started process (PID=52385) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:49:43,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:49:43,939] {logging_mixin.py:115} INFO - [2022-10-21 16:49:43,938] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:49:44,099] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:49:44,153] {logging_mixin.py:115} INFO - [2022-10-21 16:49:44,153] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:49:44,208] {logging_mixin.py:115} INFO - [2022-10-21 16:49:44,208] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:49:44.088359+00:00, run_after=2022-10-22T16:49:44.088359+00:00
[2022-10-21 16:49:44,239] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.329 seconds
[2022-10-21 16:50:08,212] {processor.py:153} INFO - Started process (PID=86229) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:08,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:50:08,228] {logging_mixin.py:115} INFO - [2022-10-21 16:50:08,228] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:09,067] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:09,391] {logging_mixin.py:115} INFO - [2022-10-21 16:50:09,390] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:50:09,476] {logging_mixin.py:115} INFO - [2022-10-21 16:50:09,476] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:50:09.064398+00:00, run_after=2022-10-22T16:50:09.064398+00:00
[2022-10-21 16:50:09,516] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.339 seconds
[2022-10-21 16:50:24,695] {processor.py:153} INFO - Started process (PID=52883) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:24,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:50:24,700] {logging_mixin.py:115} INFO - [2022-10-21 16:50:24,700] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:24,827] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:24,859] {logging_mixin.py:115} INFO - [2022-10-21 16:50:24,858] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:50:24,931] {logging_mixin.py:115} INFO - [2022-10-21 16:50:24,923] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:50:24.821075+00:00, run_after=2022-10-22T16:50:24.821075+00:00
[2022-10-21 16:50:24,951] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.276 seconds
[2022-10-21 16:50:40,782] {processor.py:153} INFO - Started process (PID=86641) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:40,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:50:40,788] {logging_mixin.py:115} INFO - [2022-10-21 16:50:40,788] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:41,316] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:50:41,498] {logging_mixin.py:115} INFO - [2022-10-21 16:50:41,497] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:50:41,575] {logging_mixin.py:115} INFO - [2022-10-21 16:50:41,575] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:50:41.310217+00:00, run_after=2022-10-22T16:50:41.310217+00:00
[2022-10-21 16:50:41,599] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.827 seconds
[2022-10-21 16:51:02,069] {processor.py:153} INFO - Started process (PID=53382) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:02,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:51:02,075] {logging_mixin.py:115} INFO - [2022-10-21 16:51:02,074] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:02,359] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:02,410] {logging_mixin.py:115} INFO - [2022-10-21 16:51:02,409] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:51:02,489] {logging_mixin.py:115} INFO - [2022-10-21 16:51:02,488] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:51:02.349738+00:00, run_after=2022-10-22T16:51:02.349738+00:00
[2022-10-21 16:51:02,527] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.474 seconds
[2022-10-21 16:51:21,512] {processor.py:153} INFO - Started process (PID=87156) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:21,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:51:21,522] {logging_mixin.py:115} INFO - [2022-10-21 16:51:21,521] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:22,091] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:22,262] {logging_mixin.py:115} INFO - [2022-10-21 16:51:22,262] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:51:22,304] {logging_mixin.py:115} INFO - [2022-10-21 16:51:22,303] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:51:22.088439+00:00, run_after=2022-10-22T16:51:22.088439+00:00
[2022-10-21 16:51:22,340] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.840 seconds
[2022-10-21 16:51:41,146] {processor.py:153} INFO - Started process (PID=53885) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:41,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:51:41,155] {logging_mixin.py:115} INFO - [2022-10-21 16:51:41,155] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:41,409] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:51:41,454] {logging_mixin.py:115} INFO - [2022-10-21 16:51:41,454] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:51:41,502] {logging_mixin.py:115} INFO - [2022-10-21 16:51:41,502] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:51:41.386679+00:00, run_after=2022-10-22T16:51:41.386679+00:00
[2022-10-21 16:51:41,525] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.410 seconds
[2022-10-21 16:52:23,968] {processor.py:153} INFO - Started process (PID=54401) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:52:23,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:52:23,971] {logging_mixin.py:115} INFO - [2022-10-21 16:52:23,971] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:52:24,106] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:52:24,222] {logging_mixin.py:115} INFO - [2022-10-21 16:52:24,222] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:52:24,259] {logging_mixin.py:115} INFO - [2022-10-21 16:52:24,259] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:52:24.100110+00:00, run_after=2022-10-22T16:52:24.100110+00:00
[2022-10-21 16:52:24,291] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.329 seconds
[2022-10-21 16:52:40,871] {processor.py:153} INFO - Started process (PID=87684) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:52:40,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:52:40,875] {logging_mixin.py:115} INFO - [2022-10-21 16:52:40,875] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:52:41,022] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:52:41,049] {logging_mixin.py:115} INFO - [2022-10-21 16:52:41,049] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:52:41,137] {logging_mixin.py:115} INFO - [2022-10-21 16:52:41,137] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:52:41.017987+00:00, run_after=2022-10-22T16:52:41.017987+00:00
[2022-10-21 16:52:41,168] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.308 seconds
[2022-10-21 16:53:02,987] {processor.py:153} INFO - Started process (PID=54900) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:02,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:53:02,999] {logging_mixin.py:115} INFO - [2022-10-21 16:53:02,999] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:03,155] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:03,436] {logging_mixin.py:115} INFO - [2022-10-21 16:53:03,435] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:53:03,486] {logging_mixin.py:115} INFO - [2022-10-21 16:53:03,485] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:53:03.148859+00:00, run_after=2022-10-22T16:53:03.148859+00:00
[2022-10-21 16:53:03,529] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.550 seconds
[2022-10-21 16:53:30,679] {processor.py:153} INFO - Started process (PID=88202) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:30,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:53:30,683] {logging_mixin.py:115} INFO - [2022-10-21 16:53:30,683] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:30,859] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:30,898] {logging_mixin.py:115} INFO - [2022-10-21 16:53:30,897] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:53:30,949] {logging_mixin.py:115} INFO - [2022-10-21 16:53:30,949] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:53:30.854305+00:00, run_after=2022-10-22T16:53:30.854305+00:00
[2022-10-21 16:53:30,979] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.311 seconds
[2022-10-21 16:53:44,020] {processor.py:153} INFO - Started process (PID=55295) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:44,024] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:53:44,045] {logging_mixin.py:115} INFO - [2022-10-21 16:53:44,044] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:44,375] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:53:44,685] {logging_mixin.py:115} INFO - [2022-10-21 16:53:44,685] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:53:44,781] {logging_mixin.py:115} INFO - [2022-10-21 16:53:44,780] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:53:44.366543+00:00, run_after=2022-10-22T16:53:44.366543+00:00
[2022-10-21 16:53:44,809] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.812 seconds
[2022-10-21 16:54:02,027] {processor.py:153} INFO - Started process (PID=88596) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:02,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:54:02,031] {logging_mixin.py:115} INFO - [2022-10-21 16:54:02,030] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:02,179] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:02,211] {logging_mixin.py:115} INFO - [2022-10-21 16:54:02,211] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:54:02,285] {logging_mixin.py:115} INFO - [2022-10-21 16:54:02,285] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:54:02.172233+00:00, run_after=2022-10-22T16:54:02.172233+00:00
[2022-10-21 16:54:02,342] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.322 seconds
[2022-10-21 16:54:37,578] {processor.py:153} INFO - Started process (PID=89033) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:37,583] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:54:37,586] {logging_mixin.py:115} INFO - [2022-10-21 16:54:37,586] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:37,777] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:38,003] {logging_mixin.py:115} INFO - [2022-10-21 16:54:38,003] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:54:38,047] {logging_mixin.py:115} INFO - [2022-10-21 16:54:38,047] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:54:37.764394+00:00, run_after=2022-10-22T16:54:37.764394+00:00
[2022-10-21 16:54:38,082] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.523 seconds
[2022-10-21 16:54:59,652] {processor.py:153} INFO - Started process (PID=55701) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:59,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:54:59,656] {logging_mixin.py:115} INFO - [2022-10-21 16:54:59,656] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:59,782] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:54:59,818] {logging_mixin.py:115} INFO - [2022-10-21 16:54:59,818] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:54:59,871] {logging_mixin.py:115} INFO - [2022-10-21 16:54:59,871] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:54:59.775553+00:00, run_after=2022-10-22T16:54:59.775553+00:00
[2022-10-21 16:54:59,922] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.276 seconds
[2022-10-21 16:55:08,718] {processor.py:153} INFO - Started process (PID=89332) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:08,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:55:08,726] {logging_mixin.py:115} INFO - [2022-10-21 16:55:08,725] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:08,966] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:09,257] {logging_mixin.py:115} INFO - [2022-10-21 16:55:09,256] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:55:09,415] {logging_mixin.py:115} INFO - [2022-10-21 16:55:09,415] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:55:08.959863+00:00, run_after=2022-10-22T16:55:08.959863+00:00
[2022-10-21 16:55:09,398] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.773 seconds
[2022-10-21 16:55:43,925] {processor.py:153} INFO - Started process (PID=56087) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:43,928] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:55:43,931] {logging_mixin.py:115} INFO - [2022-10-21 16:55:43,931] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:44,148] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:44,407] {logging_mixin.py:115} INFO - [2022-10-21 16:55:44,406] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:55:44,450] {logging_mixin.py:115} INFO - [2022-10-21 16:55:44,449] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:55:44.138924+00:00, run_after=2022-10-22T16:55:44.138924+00:00
[2022-10-21 16:55:44,476] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.561 seconds
[2022-10-21 16:55:54,649] {processor.py:153} INFO - Started process (PID=89772) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:54,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:55:54,653] {logging_mixin.py:115} INFO - [2022-10-21 16:55:54,653] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:54,916] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:55:54,951] {logging_mixin.py:115} INFO - [2022-10-21 16:55:54,951] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:55:55,008] {logging_mixin.py:115} INFO - [2022-10-21 16:55:55,007] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:55:54.907574+00:00, run_after=2022-10-22T16:55:54.907574+00:00
[2022-10-21 16:55:55,040] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.408 seconds
[2022-10-21 16:56:31,553] {processor.py:153} INFO - Started process (PID=56560) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:56:31,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:56:31,561] {logging_mixin.py:115} INFO - [2022-10-21 16:56:31,560] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:56:31,784] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:56:31,990] {logging_mixin.py:115} INFO - [2022-10-21 16:56:31,989] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:56:32,068] {logging_mixin.py:115} INFO - [2022-10-21 16:56:32,068] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:56:31.770117+00:00, run_after=2022-10-22T16:56:31.770117+00:00
[2022-10-21 16:56:32,115] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.568 seconds
[2022-10-21 16:56:37,549] {processor.py:153} INFO - Started process (PID=90241) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:56:37,552] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:56:37,556] {logging_mixin.py:115} INFO - [2022-10-21 16:56:37,555] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:56:37,776] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:56:37,801] {logging_mixin.py:115} INFO - [2022-10-21 16:56:37,801] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:56:37,841] {logging_mixin.py:115} INFO - [2022-10-21 16:56:37,841] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:56:37.769745+00:00, run_after=2022-10-22T16:56:37.769745+00:00
[2022-10-21 16:56:37,861] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.333 seconds
[2022-10-21 16:57:13,779] {processor.py:153} INFO - Started process (PID=57070) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:13,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:57:13,786] {logging_mixin.py:115} INFO - [2022-10-21 16:57:13,786] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:13,945] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:14,073] {logging_mixin.py:115} INFO - [2022-10-21 16:57:14,073] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:57:14,101] {logging_mixin.py:115} INFO - [2022-10-21 16:57:14,101] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:57:13.940661+00:00, run_after=2022-10-22T16:57:13.940661+00:00
[2022-10-21 16:57:14,128] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.371 seconds
[2022-10-21 16:57:33,343] {processor.py:153} INFO - Started process (PID=90570) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:33,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:57:33,347] {logging_mixin.py:115} INFO - [2022-10-21 16:57:33,347] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:33,492] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:33,552] {logging_mixin.py:115} INFO - [2022-10-21 16:57:33,551] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:57:33,607] {logging_mixin.py:115} INFO - [2022-10-21 16:57:33,607] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:57:33.488129+00:00, run_after=2022-10-22T16:57:33.488129+00:00
[2022-10-21 16:57:33,625] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.292 seconds
[2022-10-21 16:57:45,874] {processor.py:153} INFO - Started process (PID=57527) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:45,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:57:45,879] {logging_mixin.py:115} INFO - [2022-10-21 16:57:45,878] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:46,015] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:57:46,216] {logging_mixin.py:115} INFO - [2022-10-21 16:57:46,216] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:57:46,260] {logging_mixin.py:115} INFO - [2022-10-21 16:57:46,259] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:57:46.010059+00:00, run_after=2022-10-22T16:57:46.010059+00:00
[2022-10-21 16:57:46,287] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.420 seconds
[2022-10-21 16:58:12,252] {processor.py:153} INFO - Started process (PID=91086) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:12,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:58:12,256] {logging_mixin.py:115} INFO - [2022-10-21 16:58:12,256] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:12,430] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:12,466] {logging_mixin.py:115} INFO - [2022-10-21 16:58:12,465] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:58:12,502] {logging_mixin.py:115} INFO - [2022-10-21 16:58:12,502] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:58:12.423755+00:00, run_after=2022-10-22T16:58:12.423755+00:00
[2022-10-21 16:58:12,527] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.286 seconds
[2022-10-21 16:58:19,335] {processor.py:153} INFO - Started process (PID=57952) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:19,338] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:58:19,342] {logging_mixin.py:115} INFO - [2022-10-21 16:58:19,341] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:19,570] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:19,686] {logging_mixin.py:115} INFO - [2022-10-21 16:58:19,685] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:58:19,934] {logging_mixin.py:115} INFO - [2022-10-21 16:58:19,934] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:58:19.565573+00:00, run_after=2022-10-22T16:58:19.565573+00:00
[2022-10-21 16:58:19,965] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.644 seconds
[2022-10-21 16:58:45,238] {processor.py:153} INFO - Started process (PID=91523) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:45,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:58:45,253] {logging_mixin.py:115} INFO - [2022-10-21 16:58:45,252] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:45,413] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:45,441] {logging_mixin.py:115} INFO - [2022-10-21 16:58:45,441] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:58:45,478] {logging_mixin.py:115} INFO - [2022-10-21 16:58:45,478] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:58:45.406893+00:00, run_after=2022-10-22T16:58:45.406893+00:00
[2022-10-21 16:58:45,497] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.265 seconds
[2022-10-21 16:58:55,943] {processor.py:153} INFO - Started process (PID=58430) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:55,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:58:55,947] {logging_mixin.py:115} INFO - [2022-10-21 16:58:55,947] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:56,204] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:58:56,727] {logging_mixin.py:115} INFO - [2022-10-21 16:58:56,727] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:58:56,805] {logging_mixin.py:115} INFO - [2022-10-21 16:58:56,805] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:58:56.199321+00:00, run_after=2022-10-22T16:58:56.199321+00:00
[2022-10-21 16:58:56,827] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.892 seconds
[2022-10-21 16:59:19,707] {processor.py:153} INFO - Started process (PID=91951) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:19,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:59:19,711] {logging_mixin.py:115} INFO - [2022-10-21 16:59:19,711] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:19,872] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:19,906] {logging_mixin.py:115} INFO - [2022-10-21 16:59:19,906] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:59:19,953] {logging_mixin.py:115} INFO - [2022-10-21 16:59:19,953] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:59:19.866167+00:00, run_after=2022-10-22T16:59:19.866167+00:00
[2022-10-21 16:59:19,977] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.278 seconds
[2022-10-21 16:59:49,159] {processor.py:153} INFO - Started process (PID=58688) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:49,161] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:59:49,163] {logging_mixin.py:115} INFO - [2022-10-21 16:59:49,163] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:49,342] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:49,539] {logging_mixin.py:115} INFO - [2022-10-21 16:59:49,539] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:59:49,602] {logging_mixin.py:115} INFO - [2022-10-21 16:59:49,602] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:59:49.336524+00:00, run_after=2022-10-22T16:59:49.336524+00:00
[2022-10-21 16:59:49,633] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.481 seconds
[2022-10-21 16:59:53,148] {processor.py:153} INFO - Started process (PID=92453) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:53,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 16:59:53,159] {logging_mixin.py:115} INFO - [2022-10-21 16:59:53,158] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:53,382] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 16:59:53,432] {logging_mixin.py:115} INFO - [2022-10-21 16:59:53,431] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 16:59:53,469] {logging_mixin.py:115} INFO - [2022-10-21 16:59:53,469] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T16:59:53.366197+00:00, run_after=2022-10-22T16:59:53.366197+00:00
[2022-10-21 16:59:53,494] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.360 seconds
[2022-10-21 17:00:27,283] {processor.py:153} INFO - Started process (PID=59198) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:00:27,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:00:27,292] {logging_mixin.py:115} INFO - [2022-10-21 17:00:27,292] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:00:27,584] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:00:27,808] {logging_mixin.py:115} INFO - [2022-10-21 17:00:27,808] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:00:27,872] {logging_mixin.py:115} INFO - [2022-10-21 17:00:27,871] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:00:27.574704+00:00, run_after=2022-10-22T17:00:27.574704+00:00
[2022-10-21 17:00:27,902] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.631 seconds
[2022-10-21 17:00:29,644] {processor.py:153} INFO - Started process (PID=92938) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:00:29,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:00:29,652] {logging_mixin.py:115} INFO - [2022-10-21 17:00:29,652] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:00:29,821] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:00:29,856] {logging_mixin.py:115} INFO - [2022-10-21 17:00:29,855] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:00:29,899] {logging_mixin.py:115} INFO - [2022-10-21 17:00:29,899] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:00:29.816223+00:00, run_after=2022-10-22T17:00:29.816223+00:00
[2022-10-21 17:00:29,921] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.283 seconds
[2022-10-21 17:01:00,931] {processor.py:153} INFO - Started process (PID=59584) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:00,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:01:00,939] {logging_mixin.py:115} INFO - [2022-10-21 17:01:00,939] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:01,127] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:01,222] {processor.py:153} INFO - Started process (PID=93302) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:01,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:01:01,226] {logging_mixin.py:115} INFO - [2022-10-21 17:01:01,225] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:01,268] {logging_mixin.py:115} INFO - [2022-10-21 17:01:01,268] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:01:01,304] {logging_mixin.py:115} INFO - [2022-10-21 17:01:01,304] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:01:01.117796+00:00, run_after=2022-10-22T17:01:01.117796+00:00
[2022-10-21 17:01:01,333] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.414 seconds
[2022-10-21 17:01:01,352] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:01,404] {logging_mixin.py:115} INFO - [2022-10-21 17:01:01,404] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:01:01,461] {logging_mixin.py:115} INFO - [2022-10-21 17:01:01,460] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:01:01.347511+00:00, run_after=2022-10-22T17:01:01.347511+00:00
[2022-10-21 17:01:01,490] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.275 seconds
[2022-10-21 17:01:32,816] {processor.py:153} INFO - Started process (PID=93719) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:32,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:01:32,832] {logging_mixin.py:115} INFO - [2022-10-21 17:01:32,829] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:33,068] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:33,309] {logging_mixin.py:115} INFO - [2022-10-21 17:01:33,308] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:01:33,361] {logging_mixin.py:115} INFO - [2022-10-21 17:01:33,361] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:01:33.064032+00:00, run_after=2022-10-22T17:01:33.064032+00:00
[2022-10-21 17:01:33,414] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.618 seconds
[2022-10-21 17:01:35,505] {processor.py:153} INFO - Started process (PID=60017) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:35,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:01:35,519] {logging_mixin.py:115} INFO - [2022-10-21 17:01:35,519] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:35,929] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:01:35,968] {logging_mixin.py:115} INFO - [2022-10-21 17:01:35,968] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:01:36,027] {logging_mixin.py:115} INFO - [2022-10-21 17:01:36,027] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:01:35.925099+00:00, run_after=2022-10-22T17:01:35.925099+00:00
[2022-10-21 17:01:36,071] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.588 seconds
[2022-10-21 17:02:20,092] {processor.py:153} INFO - Started process (PID=60472) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:20,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:02:20,097] {logging_mixin.py:115} INFO - [2022-10-21 17:02:20,097] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:20,306] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:20,502] {logging_mixin.py:115} INFO - [2022-10-21 17:02:20,502] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:02:20,546] {logging_mixin.py:115} INFO - [2022-10-21 17:02:20,546] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:02:20.299000+00:00, run_after=2022-10-22T17:02:20.299000+00:00
[2022-10-21 17:02:20,573] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.502 seconds
[2022-10-21 17:02:48,509] {processor.py:153} INFO - Started process (PID=94135) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:48,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:02:48,513] {logging_mixin.py:115} INFO - [2022-10-21 17:02:48,513] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:48,904] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:48,934] {logging_mixin.py:115} INFO - [2022-10-21 17:02:48,934] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:02:48,981] {logging_mixin.py:115} INFO - [2022-10-21 17:02:48,981] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:02:48.900835+00:00, run_after=2022-10-22T17:02:48.900835+00:00
[2022-10-21 17:02:49,015] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.513 seconds
[2022-10-21 17:02:52,047] {processor.py:153} INFO - Started process (PID=60861) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:52,049] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:02:52,054] {logging_mixin.py:115} INFO - [2022-10-21 17:02:52,053] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:52,286] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:02:52,468] {logging_mixin.py:115} INFO - [2022-10-21 17:02:52,468] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:02:52,562] {logging_mixin.py:115} INFO - [2022-10-21 17:02:52,561] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:02:52.279210+00:00, run_after=2022-10-22T17:02:52.279210+00:00
[2022-10-21 17:02:52,620] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.588 seconds
[2022-10-21 17:03:21,596] {processor.py:153} INFO - Started process (PID=94578) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:21,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:03:21,600] {logging_mixin.py:115} INFO - [2022-10-21 17:03:21,600] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:21,996] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:22,030] {logging_mixin.py:115} INFO - [2022-10-21 17:03:22,030] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:03:22,063] {logging_mixin.py:115} INFO - [2022-10-21 17:03:22,062] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:03:21.993661+00:00, run_after=2022-10-22T17:03:21.993661+00:00
[2022-10-21 17:03:22,078] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.490 seconds
[2022-10-21 17:03:24,429] {processor.py:153} INFO - Started process (PID=61286) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:24,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:03:24,436] {logging_mixin.py:115} INFO - [2022-10-21 17:03:24,436] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:24,616] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:24,881] {logging_mixin.py:115} INFO - [2022-10-21 17:03:24,881] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:03:24,954] {logging_mixin.py:115} INFO - [2022-10-21 17:03:24,954] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:03:24.611899+00:00, run_after=2022-10-22T17:03:24.611899+00:00
[2022-10-21 17:03:24,994] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.597 seconds
[2022-10-21 17:03:56,414] {processor.py:153} INFO - Started process (PID=61714) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:56,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:03:56,428] {logging_mixin.py:115} INFO - [2022-10-21 17:03:56,428] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:56,626] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:56,860] {logging_mixin.py:115} INFO - [2022-10-21 17:03:56,859] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:03:56,950] {logging_mixin.py:115} INFO - [2022-10-21 17:03:56,950] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:03:56.619205+00:00, run_after=2022-10-22T17:03:56.619205+00:00
[2022-10-21 17:03:56,990] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.587 seconds
[2022-10-21 17:03:57,401] {processor.py:153} INFO - Started process (PID=95041) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:57,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:03:57,404] {logging_mixin.py:115} INFO - [2022-10-21 17:03:57,404] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:57,843] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:03:57,868] {logging_mixin.py:115} INFO - [2022-10-21 17:03:57,868] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:03:57,926] {logging_mixin.py:115} INFO - [2022-10-21 17:03:57,925] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:03:57.840293+00:00, run_after=2022-10-22T17:03:57.840293+00:00
[2022-10-21 17:03:57,963] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.568 seconds
[2022-10-21 17:04:35,530] {processor.py:153} INFO - Started process (PID=95553) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:04:35,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:04:35,534] {logging_mixin.py:115} INFO - [2022-10-21 17:04:35,534] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:04:35,904] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:04:36,099] {logging_mixin.py:115} INFO - [2022-10-21 17:04:36,098] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:04:36,144] {logging_mixin.py:115} INFO - [2022-10-21 17:04:36,143] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:04:35.902044+00:00, run_after=2022-10-22T17:04:35.902044+00:00
[2022-10-21 17:04:36,173] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.652 seconds
[2022-10-21 17:04:48,273] {processor.py:153} INFO - Started process (PID=61953) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:04:48,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:04:48,277] {logging_mixin.py:115} INFO - [2022-10-21 17:04:48,277] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:04:48,436] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:04:48,474] {logging_mixin.py:115} INFO - [2022-10-21 17:04:48,474] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:04:48,541] {logging_mixin.py:115} INFO - [2022-10-21 17:04:48,541] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:04:48.431061+00:00, run_after=2022-10-22T17:04:48.431061+00:00
[2022-10-21 17:04:48,563] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.297 seconds
[2022-10-21 17:05:13,611] {processor.py:153} INFO - Started process (PID=96071) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:13,613] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:05:13,614] {logging_mixin.py:115} INFO - [2022-10-21 17:05:13,614] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:14,136] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:14,267] {logging_mixin.py:115} INFO - [2022-10-21 17:05:14,267] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:05:14,299] {logging_mixin.py:115} INFO - [2022-10-21 17:05:14,299] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:05:14.129947+00:00, run_after=2022-10-22T17:05:14.129947+00:00
[2022-10-21 17:05:14,320] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.715 seconds
[2022-10-21 17:05:21,122] {processor.py:153} INFO - Started process (PID=62363) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:21,124] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:05:21,126] {logging_mixin.py:115} INFO - [2022-10-21 17:05:21,126] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:21,335] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:21,384] {logging_mixin.py:115} INFO - [2022-10-21 17:05:21,384] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:05:21,450] {logging_mixin.py:115} INFO - [2022-10-21 17:05:21,450] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:05:21.326914+00:00, run_after=2022-10-22T17:05:21.326914+00:00
[2022-10-21 17:05:21,482] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.367 seconds
[2022-10-21 17:05:47,882] {processor.py:153} INFO - Started process (PID=96519) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:47,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:05:47,894] {logging_mixin.py:115} INFO - [2022-10-21 17:05:47,893] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:48,443] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:05:48,601] {logging_mixin.py:115} INFO - [2022-10-21 17:05:48,601] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:05:48,644] {logging_mixin.py:115} INFO - [2022-10-21 17:05:48,644] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:05:48.440660+00:00, run_after=2022-10-22T17:05:48.440660+00:00
[2022-10-21 17:05:48,673] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.802 seconds
[2022-10-21 17:06:01,291] {processor.py:153} INFO - Started process (PID=62878) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:01,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:06:01,302] {logging_mixin.py:115} INFO - [2022-10-21 17:06:01,302] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:01,584] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:01,637] {logging_mixin.py:115} INFO - [2022-10-21 17:06:01,637] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:06:01,739] {logging_mixin.py:115} INFO - [2022-10-21 17:06:01,739] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:06:01.557201+00:00, run_after=2022-10-22T17:06:01.557201+00:00
[2022-10-21 17:06:01,785] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.504 seconds
[2022-10-21 17:06:19,133] {processor.py:153} INFO - Started process (PID=96951) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:19,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:06:19,139] {logging_mixin.py:115} INFO - [2022-10-21 17:06:19,139] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:19,606] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:19,737] {logging_mixin.py:115} INFO - [2022-10-21 17:06:19,736] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:06:19,763] {logging_mixin.py:115} INFO - [2022-10-21 17:06:19,762] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:06:19.603491+00:00, run_after=2022-10-22T17:06:19.603491+00:00
[2022-10-21 17:06:19,788] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.672 seconds
[2022-10-21 17:06:42,170] {processor.py:153} INFO - Started process (PID=63393) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:42,173] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:06:42,175] {logging_mixin.py:115} INFO - [2022-10-21 17:06:42,175] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:42,413] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:42,464] {logging_mixin.py:115} INFO - [2022-10-21 17:06:42,463] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:06:42,520] {logging_mixin.py:115} INFO - [2022-10-21 17:06:42,520] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:06:42.399525+00:00, run_after=2022-10-22T17:06:42.399525+00:00
[2022-10-21 17:06:42,565] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.406 seconds
[2022-10-21 17:06:51,314] {processor.py:153} INFO - Started process (PID=97363) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:51,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:06:51,318] {logging_mixin.py:115} INFO - [2022-10-21 17:06:51,318] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:51,673] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:06:51,824] {logging_mixin.py:115} INFO - [2022-10-21 17:06:51,823] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:06:51,852] {logging_mixin.py:115} INFO - [2022-10-21 17:06:51,852] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:06:51.670920+00:00, run_after=2022-10-22T17:06:51.670920+00:00
[2022-10-21 17:06:51,871] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.565 seconds
[2022-10-21 17:07:14,519] {processor.py:153} INFO - Started process (PID=63788) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:14,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:07:14,523] {logging_mixin.py:115} INFO - [2022-10-21 17:07:14,523] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:14,630] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:14,655] {logging_mixin.py:115} INFO - [2022-10-21 17:07:14,655] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:07:14,686] {logging_mixin.py:115} INFO - [2022-10-21 17:07:14,686] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:07:14.626121+00:00, run_after=2022-10-22T17:07:14.626121+00:00
[2022-10-21 17:07:14,706] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.192 seconds
[2022-10-21 17:07:34,054] {processor.py:153} INFO - Started process (PID=97514) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:34,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:07:34,059] {logging_mixin.py:115} INFO - [2022-10-21 17:07:34,059] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:34,241] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:34,426] {logging_mixin.py:115} INFO - [2022-10-21 17:07:34,426] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:07:34,470] {logging_mixin.py:115} INFO - [2022-10-21 17:07:34,470] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:07:34.236543+00:00, run_after=2022-10-22T17:07:34.236543+00:00
[2022-10-21 17:07:34,508] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.470 seconds
[2022-10-21 17:07:46,593] {processor.py:153} INFO - Started process (PID=64228) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:46,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:07:46,597] {logging_mixin.py:115} INFO - [2022-10-21 17:07:46,597] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:46,797] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:07:46,865] {logging_mixin.py:115} INFO - [2022-10-21 17:07:46,864] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:07:46,910] {logging_mixin.py:115} INFO - [2022-10-21 17:07:46,910] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:07:46.788604+00:00, run_after=2022-10-22T17:07:46.788604+00:00
[2022-10-21 17:07:46,991] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.417 seconds
[2022-10-21 17:08:14,612] {processor.py:153} INFO - Started process (PID=98026) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:14,614] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:08:14,616] {logging_mixin.py:115} INFO - [2022-10-21 17:08:14,616] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:14,763] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:14,936] {logging_mixin.py:115} INFO - [2022-10-21 17:08:14,936] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:08:14,970] {logging_mixin.py:115} INFO - [2022-10-21 17:08:14,970] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:08:14.758166+00:00, run_after=2022-10-22T17:08:14.758166+00:00
[2022-10-21 17:08:15,018] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.416 seconds
[2022-10-21 17:08:18,774] {processor.py:153} INFO - Started process (PID=64627) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:18,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:08:18,779] {logging_mixin.py:115} INFO - [2022-10-21 17:08:18,779] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:18,952] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:19,004] {logging_mixin.py:115} INFO - [2022-10-21 17:08:19,004] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:08:19,051] {logging_mixin.py:115} INFO - [2022-10-21 17:08:19,051] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:08:18.947314+00:00, run_after=2022-10-22T17:08:18.947314+00:00
[2022-10-21 17:08:19,075] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.309 seconds
[2022-10-21 17:08:51,426] {processor.py:153} INFO - Started process (PID=98511) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:51,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:08:51,436] {logging_mixin.py:115} INFO - [2022-10-21 17:08:51,435] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:51,633] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:51,828] {logging_mixin.py:115} INFO - [2022-10-21 17:08:51,828] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:08:51,864] {logging_mixin.py:115} INFO - [2022-10-21 17:08:51,864] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:08:51.626598+00:00, run_after=2022-10-22T17:08:51.626598+00:00
[2022-10-21 17:08:51,900] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.483 seconds
[2022-10-21 17:08:58,486] {processor.py:153} INFO - Started process (PID=65135) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:58,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:08:58,493] {logging_mixin.py:115} INFO - [2022-10-21 17:08:58,493] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:58,674] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:08:58,718] {logging_mixin.py:115} INFO - [2022-10-21 17:08:58,718] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:08:58,782] {logging_mixin.py:115} INFO - [2022-10-21 17:08:58,781] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:08:58.670071+00:00, run_after=2022-10-22T17:08:58.670071+00:00
[2022-10-21 17:08:58,799] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.331 seconds
[2022-10-21 17:09:29,623] {processor.py:153} INFO - Started process (PID=99022) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:09:29,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:09:29,627] {logging_mixin.py:115} INFO - [2022-10-21 17:09:29,626] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:09:29,737] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:09:29,874] {logging_mixin.py:115} INFO - [2022-10-21 17:09:29,874] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:09:29,902] {logging_mixin.py:115} INFO - [2022-10-21 17:09:29,902] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:09:29.732443+00:00, run_after=2022-10-22T17:09:29.732443+00:00
[2022-10-21 17:09:29,925] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.309 seconds
[2022-10-21 17:09:42,718] {processor.py:153} INFO - Started process (PID=65288) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:09:42,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:09:42,725] {logging_mixin.py:115} INFO - [2022-10-21 17:09:42,725] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:09:42,871] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:09:42,904] {logging_mixin.py:115} INFO - [2022-10-21 17:09:42,904] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:09:42,986] {logging_mixin.py:115} INFO - [2022-10-21 17:09:42,985] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:09:42.867206+00:00, run_after=2022-10-22T17:09:42.867206+00:00
[2022-10-21 17:09:43,384] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.672 seconds
[2022-10-21 17:10:02,252] {processor.py:153} INFO - Started process (PID=99475) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:02,255] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:10:02,257] {logging_mixin.py:115} INFO - [2022-10-21 17:10:02,257] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:02,472] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:02,712] {logging_mixin.py:115} INFO - [2022-10-21 17:10:02,712] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:10:02,774] {logging_mixin.py:115} INFO - [2022-10-21 17:10:02,774] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:10:02.465250+00:00, run_after=2022-10-22T17:10:02.465250+00:00
[2022-10-21 17:10:02,805] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.561 seconds
[2022-10-21 17:10:20,455] {processor.py:153} INFO - Started process (PID=65769) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:20,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:10:20,463] {logging_mixin.py:115} INFO - [2022-10-21 17:10:20,461] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:20,834] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:20,856] {logging_mixin.py:115} INFO - [2022-10-21 17:10:20,855] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:10:20,908] {logging_mixin.py:115} INFO - [2022-10-21 17:10:20,908] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:10:20.832056+00:00, run_after=2022-10-22T17:10:20.832056+00:00
[2022-10-21 17:10:20,936] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.492 seconds
[2022-10-21 17:10:34,910] {processor.py:153} INFO - Started process (PID=99922) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:34,914] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:10:34,918] {logging_mixin.py:115} INFO - [2022-10-21 17:10:34,918] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:35,158] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:35,453] {logging_mixin.py:115} INFO - [2022-10-21 17:10:35,452] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:10:35,506] {logging_mixin.py:115} INFO - [2022-10-21 17:10:35,505] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:10:35.147294+00:00, run_after=2022-10-22T17:10:35.147294+00:00
[2022-10-21 17:10:35,556] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.672 seconds
[2022-10-21 17:10:54,376] {processor.py:153} INFO - Started process (PID=66163) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:54,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:10:54,380] {logging_mixin.py:115} INFO - [2022-10-21 17:10:54,380] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:54,516] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:10:54,547] {logging_mixin.py:115} INFO - [2022-10-21 17:10:54,547] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:10:54,810] {logging_mixin.py:115} INFO - [2022-10-21 17:10:54,810] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:10:54.511151+00:00, run_after=2022-10-22T17:10:54.511151+00:00
[2022-10-21 17:10:54,841] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.474 seconds
[2022-10-21 17:11:14,725] {processor.py:153} INFO - Started process (PID=723) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:14,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:11:14,736] {logging_mixin.py:115} INFO - [2022-10-21 17:11:14,735] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:15,068] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:15,310] {logging_mixin.py:115} INFO - [2022-10-21 17:11:15,309] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:11:15,352] {logging_mixin.py:115} INFO - [2022-10-21 17:11:15,352] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:11:15.027814+00:00, run_after=2022-10-22T17:11:15.027814+00:00
[2022-10-21 17:11:15,380] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.673 seconds
[2022-10-21 17:11:29,389] {processor.py:153} INFO - Started process (PID=66613) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:29,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:11:29,398] {logging_mixin.py:115} INFO - [2022-10-21 17:11:29,398] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:30,185] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:30,258] {logging_mixin.py:115} INFO - [2022-10-21 17:11:30,258] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:11:30,305] {logging_mixin.py:115} INFO - [2022-10-21 17:11:30,305] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:11:30.181251+00:00, run_after=2022-10-22T17:11:30.181251+00:00
[2022-10-21 17:11:30,343] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.965 seconds
[2022-10-21 17:11:49,634] {processor.py:153} INFO - Started process (PID=1207) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:49,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:11:49,644] {logging_mixin.py:115} INFO - [2022-10-21 17:11:49,644] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:49,871] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:11:50,082] {logging_mixin.py:115} INFO - [2022-10-21 17:11:50,081] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:11:50,141] {logging_mixin.py:115} INFO - [2022-10-21 17:11:50,141] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:11:49.867483+00:00, run_after=2022-10-22T17:11:49.867483+00:00
[2022-10-21 17:11:50,168] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.553 seconds
[2022-10-21 17:12:02,174] {processor.py:153} INFO - Started process (PID=67005) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:02,176] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:12:02,178] {logging_mixin.py:115} INFO - [2022-10-21 17:12:02,178] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:02,647] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:02,674] {logging_mixin.py:115} INFO - [2022-10-21 17:12:02,674] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:12:02,732] {logging_mixin.py:115} INFO - [2022-10-21 17:12:02,731] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:12:02.643005+00:00, run_after=2022-10-22T17:12:02.643005+00:00
[2022-10-21 17:12:02,771] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.603 seconds
[2022-10-21 17:12:33,729] {processor.py:153} INFO - Started process (PID=67429) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:33,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:12:33,735] {logging_mixin.py:115} INFO - [2022-10-21 17:12:33,735] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:34,131] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:34,285] {logging_mixin.py:115} INFO - [2022-10-21 17:12:34,285] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:12:34,330] {logging_mixin.py:115} INFO - [2022-10-21 17:12:34,330] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:12:34.127159+00:00, run_after=2022-10-22T17:12:34.127159+00:00
[2022-10-21 17:12:34,385] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.664 seconds
[2022-10-21 17:12:38,983] {processor.py:153} INFO - Started process (PID=1428) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:38,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:12:38,988] {logging_mixin.py:115} INFO - [2022-10-21 17:12:38,987] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:39,133] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:12:39,158] {logging_mixin.py:115} INFO - [2022-10-21 17:12:39,158] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:12:39,208] {logging_mixin.py:115} INFO - [2022-10-21 17:12:39,207] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:12:39.127237+00:00, run_after=2022-10-22T17:12:39.127237+00:00
[2022-10-21 17:12:39,243] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.267 seconds
[2022-10-21 17:13:09,530] {processor.py:153} INFO - Started process (PID=67895) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:09,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:13:09,536] {logging_mixin.py:115} INFO - [2022-10-21 17:13:09,536] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:09,950] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:10,091] {logging_mixin.py:115} INFO - [2022-10-21 17:13:10,091] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:13:10,122] {logging_mixin.py:115} INFO - [2022-10-21 17:13:10,122] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:13:09.943314+00:00, run_after=2022-10-22T17:13:09.943314+00:00
[2022-10-21 17:13:10,142] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.619 seconds
[2022-10-21 17:13:11,079] {processor.py:153} INFO - Started process (PID=1863) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:11,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:13:11,084] {logging_mixin.py:115} INFO - [2022-10-21 17:13:11,083] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:11,238] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:11,267] {logging_mixin.py:115} INFO - [2022-10-21 17:13:11,267] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:13:11,321] {logging_mixin.py:115} INFO - [2022-10-21 17:13:11,321] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:13:11.232971+00:00, run_after=2022-10-22T17:13:11.232971+00:00
[2022-10-21 17:13:11,354] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.286 seconds
[2022-10-21 17:13:48,572] {processor.py:153} INFO - Started process (PID=2373) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:48,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:13:48,575] {logging_mixin.py:115} INFO - [2022-10-21 17:13:48,575] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:48,701] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:48,817] {logging_mixin.py:115} INFO - [2022-10-21 17:13:48,817] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:13:48,859] {logging_mixin.py:115} INFO - [2022-10-21 17:13:48,858] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:13:48.697196+00:00, run_after=2022-10-22T17:13:48.697196+00:00
[2022-10-21 17:13:48,886] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.323 seconds
[2022-10-21 17:13:49,123] {processor.py:153} INFO - Started process (PID=68391) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:49,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:13:49,127] {logging_mixin.py:115} INFO - [2022-10-21 17:13:49,127] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:49,635] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:13:49,654] {logging_mixin.py:115} INFO - [2022-10-21 17:13:49,654] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:13:49,685] {logging_mixin.py:115} INFO - [2022-10-21 17:13:49,685] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:13:49.628819+00:00, run_after=2022-10-22T17:13:49.628819+00:00
[2022-10-21 17:13:49,704] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.589 seconds
[2022-10-21 17:14:24,272] {processor.py:153} INFO - Started process (PID=2842) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:24,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:14:24,279] {logging_mixin.py:115} INFO - [2022-10-21 17:14:24,278] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:24,417] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:24,563] {logging_mixin.py:115} INFO - [2022-10-21 17:14:24,563] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:14:24,596] {logging_mixin.py:115} INFO - [2022-10-21 17:14:24,596] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:14:24.413258+00:00, run_after=2022-10-22T17:14:24.413258+00:00
[2022-10-21 17:14:24,616] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.357 seconds
[2022-10-21 17:14:41,526] {processor.py:153} INFO - Started process (PID=68671) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:41,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:14:41,530] {logging_mixin.py:115} INFO - [2022-10-21 17:14:41,530] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:41,655] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:41,689] {logging_mixin.py:115} INFO - [2022-10-21 17:14:41,689] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:14:41,733] {logging_mixin.py:115} INFO - [2022-10-21 17:14:41,733] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:14:41.645272+00:00, run_after=2022-10-22T17:14:41.645272+00:00
[2022-10-21 17:14:41,753] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.234 seconds
[2022-10-21 17:14:57,948] {processor.py:153} INFO - Started process (PID=3352) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:57,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:14:57,956] {logging_mixin.py:115} INFO - [2022-10-21 17:14:57,955] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:58,150] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:14:58,463] {logging_mixin.py:115} INFO - [2022-10-21 17:14:58,462] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:14:58,490] {logging_mixin.py:115} INFO - [2022-10-21 17:14:58,490] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:14:58.146663+00:00, run_after=2022-10-22T17:14:58.146663+00:00
[2022-10-21 17:14:58,510] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.568 seconds
[2022-10-21 17:15:15,112] {processor.py:153} INFO - Started process (PID=69131) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:15,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:15:15,117] {logging_mixin.py:115} INFO - [2022-10-21 17:15:15,117] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:15,302] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:15,342] {logging_mixin.py:115} INFO - [2022-10-21 17:15:15,342] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:15:15,387] {logging_mixin.py:115} INFO - [2022-10-21 17:15:15,387] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:15:15.294114+00:00, run_after=2022-10-22T17:15:15.294114+00:00
[2022-10-21 17:15:15,419] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.319 seconds
[2022-10-21 17:15:33,982] {processor.py:153} INFO - Started process (PID=3863) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:33,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:15:33,987] {logging_mixin.py:115} INFO - [2022-10-21 17:15:33,987] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:34,110] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:34,237] {logging_mixin.py:115} INFO - [2022-10-21 17:15:34,237] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:15:34,268] {logging_mixin.py:115} INFO - [2022-10-21 17:15:34,268] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:15:34.106343+00:00, run_after=2022-10-22T17:15:34.106343+00:00
[2022-10-21 17:15:34,303] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.332 seconds
[2022-10-21 17:15:48,691] {processor.py:153} INFO - Started process (PID=69601) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:48,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:15:48,694] {logging_mixin.py:115} INFO - [2022-10-21 17:15:48,694] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:48,853] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:15:48,894] {logging_mixin.py:115} INFO - [2022-10-21 17:15:48,894] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:15:48,936] {logging_mixin.py:115} INFO - [2022-10-21 17:15:48,936] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:15:48.845960+00:00, run_after=2022-10-22T17:15:48.845960+00:00
[2022-10-21 17:15:48,958] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.272 seconds
[2022-10-21 17:16:07,984] {processor.py:153} INFO - Started process (PID=4338) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:07,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:16:07,992] {logging_mixin.py:115} INFO - [2022-10-21 17:16:07,992] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:08,149] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:08,295] {logging_mixin.py:115} INFO - [2022-10-21 17:16:08,294] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:16:08,327] {logging_mixin.py:115} INFO - [2022-10-21 17:16:08,327] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:16:08.144643+00:00, run_after=2022-10-22T17:16:08.144643+00:00
[2022-10-21 17:16:08,358] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.381 seconds
[2022-10-21 17:16:25,578] {processor.py:153} INFO - Started process (PID=70105) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:25,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:16:25,582] {logging_mixin.py:115} INFO - [2022-10-21 17:16:25,582] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:25,712] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:25,758] {logging_mixin.py:115} INFO - [2022-10-21 17:16:25,758] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:16:25,805] {logging_mixin.py:115} INFO - [2022-10-21 17:16:25,805] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:16:25.707179+00:00, run_after=2022-10-22T17:16:25.707179+00:00
[2022-10-21 17:16:25,831] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.260 seconds
[2022-10-21 17:16:41,993] {processor.py:153} INFO - Started process (PID=4840) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:41,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:16:41,997] {logging_mixin.py:115} INFO - [2022-10-21 17:16:41,997] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:42,149] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:42,305] {logging_mixin.py:115} INFO - [2022-10-21 17:16:42,305] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:16:42,342] {logging_mixin.py:115} INFO - [2022-10-21 17:16:42,342] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:16:42.132733+00:00, run_after=2022-10-22T17:16:42.132733+00:00
[2022-10-21 17:16:42,366] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.382 seconds
[2022-10-21 17:16:58,575] {processor.py:153} INFO - Started process (PID=70566) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:58,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:16:58,580] {logging_mixin.py:115} INFO - [2022-10-21 17:16:58,580] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:58,798] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:16:58,836] {logging_mixin.py:115} INFO - [2022-10-21 17:16:58,835] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:16:58,886] {logging_mixin.py:115} INFO - [2022-10-21 17:16:58,886] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:16:58.776066+00:00, run_after=2022-10-22T17:16:58.776066+00:00
[2022-10-21 17:16:58,909] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.354 seconds
[2022-10-21 17:17:31,834] {processor.py:153} INFO - Started process (PID=71056) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:17:31,836] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:17:31,838] {logging_mixin.py:115} INFO - [2022-10-21 17:17:31,838] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:17:32,021] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:17:32,276] {logging_mixin.py:115} INFO - [2022-10-21 17:17:32,275] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:17:32,337] {logging_mixin.py:115} INFO - [2022-10-21 17:17:32,337] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:17:32.016498+00:00, run_after=2022-10-22T17:17:32.016498+00:00
[2022-10-21 17:17:32,372] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.552 seconds
[2022-10-21 17:17:34,930] {processor.py:153} INFO - Started process (PID=5163) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:17:34,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:17:34,944] {logging_mixin.py:115} INFO - [2022-10-21 17:17:34,944] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:17:35,067] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:17:35,092] {logging_mixin.py:115} INFO - [2022-10-21 17:17:35,092] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:17:35,122] {logging_mixin.py:115} INFO - [2022-10-21 17:17:35,122] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:17:35.062270+00:00, run_after=2022-10-22T17:17:35.062270+00:00
[2022-10-21 17:17:35,139] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.220 seconds
[2022-10-21 17:18:05,805] {processor.py:153} INFO - Started process (PID=71535) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:05,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:18:05,809] {logging_mixin.py:115} INFO - [2022-10-21 17:18:05,809] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:06,023] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:06,050] {processor.py:153} INFO - Started process (PID=5640) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:06,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:18:06,056] {logging_mixin.py:115} INFO - [2022-10-21 17:18:06,056] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:06,218] {logging_mixin.py:115} INFO - [2022-10-21 17:18:06,218] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:18:06,263] {logging_mixin.py:115} INFO - [2022-10-21 17:18:06,263] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:18:06.011280+00:00, run_after=2022-10-22T17:18:06.011280+00:00
[2022-10-21 17:18:06,299] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.500 seconds
[2022-10-21 17:18:06,301] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:06,341] {logging_mixin.py:115} INFO - [2022-10-21 17:18:06,341] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:18:06,429] {logging_mixin.py:115} INFO - [2022-10-21 17:18:06,429] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:18:06.289772+00:00, run_after=2022-10-22T17:18:06.289772+00:00
[2022-10-21 17:18:06,458] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.420 seconds
[2022-10-21 17:18:36,868] {processor.py:153} INFO - Started process (PID=71978) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:36,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:18:36,873] {logging_mixin.py:115} INFO - [2022-10-21 17:18:36,873] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:37,126] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:37,170] {processor.py:153} INFO - Started process (PID=6100) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:37,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:18:37,179] {logging_mixin.py:115} INFO - [2022-10-21 17:18:37,179] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:37,327] {logging_mixin.py:115} INFO - [2022-10-21 17:18:37,327] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:18:37,382] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:18:37,426] {logging_mixin.py:115} INFO - [2022-10-21 17:18:37,425] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:18:37.119242+00:00, run_after=2022-10-22T17:18:37.119242+00:00
[2022-10-21 17:18:37,468] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.611 seconds
[2022-10-21 17:18:37,570] {logging_mixin.py:115} INFO - [2022-10-21 17:18:37,570] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:18:37,633] {logging_mixin.py:115} INFO - [2022-10-21 17:18:37,632] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:18:37.370842+00:00, run_after=2022-10-22T17:18:37.370842+00:00
[2022-10-21 17:18:37,665] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.501 seconds
[2022-10-21 17:19:12,749] {processor.py:153} INFO - Started process (PID=6606) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:12,757] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:19:12,761] {logging_mixin.py:115} INFO - [2022-10-21 17:19:12,761] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:13,006] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:13,231] {logging_mixin.py:115} INFO - [2022-10-21 17:19:13,230] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:19:13,272] {logging_mixin.py:115} INFO - [2022-10-21 17:19:13,272] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:19:12.997379+00:00, run_after=2022-10-22T17:19:12.997379+00:00
[2022-10-21 17:19:13,299] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.577 seconds
[2022-10-21 17:19:37,073] {processor.py:153} INFO - Started process (PID=72396) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:37,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:19:37,077] {logging_mixin.py:115} INFO - [2022-10-21 17:19:37,077] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:37,294] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:37,339] {logging_mixin.py:115} INFO - [2022-10-21 17:19:37,339] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:19:37,399] {logging_mixin.py:115} INFO - [2022-10-21 17:19:37,399] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:19:37.289230+00:00, run_after=2022-10-22T17:19:37.289230+00:00
[2022-10-21 17:19:37,446] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.387 seconds
[2022-10-21 17:19:44,294] {processor.py:153} INFO - Started process (PID=7095) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:44,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:19:44,299] {logging_mixin.py:115} INFO - [2022-10-21 17:19:44,298] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:44,480] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:19:44,744] {logging_mixin.py:115} INFO - [2022-10-21 17:19:44,743] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:19:44,903] {logging_mixin.py:115} INFO - [2022-10-21 17:19:44,903] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:19:44.475771+00:00, run_after=2022-10-22T17:19:44.475771+00:00
[2022-10-21 17:19:44,947] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.659 seconds
[2022-10-21 17:20:13,558] {processor.py:153} INFO - Started process (PID=72906) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:13,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:20:13,562] {logging_mixin.py:115} INFO - [2022-10-21 17:20:13,562] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:13,687] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:13,725] {logging_mixin.py:115} INFO - [2022-10-21 17:20:13,725] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:20:13,759] {logging_mixin.py:115} INFO - [2022-10-21 17:20:13,759] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:20:13.682601+00:00, run_after=2022-10-22T17:20:13.682601+00:00
[2022-10-21 17:20:13,792] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.242 seconds
[2022-10-21 17:20:15,774] {processor.py:153} INFO - Started process (PID=7564) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:15,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:20:15,781] {logging_mixin.py:115} INFO - [2022-10-21 17:20:15,781] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:15,985] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:16,166] {logging_mixin.py:115} INFO - [2022-10-21 17:20:16,166] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:20:16,225] {logging_mixin.py:115} INFO - [2022-10-21 17:20:16,225] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:20:15.981112+00:00, run_after=2022-10-22T17:20:15.981112+00:00
[2022-10-21 17:20:16,269] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.501 seconds
[2022-10-21 17:20:46,888] {processor.py:153} INFO - Started process (PID=7988) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:46,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:20:46,891] {logging_mixin.py:115} INFO - [2022-10-21 17:20:46,891] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:47,044] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:47,202] {logging_mixin.py:115} INFO - [2022-10-21 17:20:47,202] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:20:47,231] {logging_mixin.py:115} INFO - [2022-10-21 17:20:47,231] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:20:47.038819+00:00, run_after=2022-10-22T17:20:47.038819+00:00
[2022-10-21 17:20:47,251] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.375 seconds
[2022-10-21 17:20:49,818] {processor.py:153} INFO - Started process (PID=73400) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:49,819] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:20:49,821] {logging_mixin.py:115} INFO - [2022-10-21 17:20:49,821] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:49,982] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:20:50,033] {logging_mixin.py:115} INFO - [2022-10-21 17:20:50,033] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:20:50,093] {logging_mixin.py:115} INFO - [2022-10-21 17:20:50,093] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:20:49.970723+00:00, run_after=2022-10-22T17:20:49.970723+00:00
[2022-10-21 17:20:50,113] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.301 seconds
[2022-10-21 17:21:19,683] {processor.py:153} INFO - Started process (PID=8470) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:19,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:21:19,687] {logging_mixin.py:115} INFO - [2022-10-21 17:21:19,687] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:19,835] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:20,045] {logging_mixin.py:115} INFO - [2022-10-21 17:21:20,045] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:21:20,082] {logging_mixin.py:115} INFO - [2022-10-21 17:21:20,082] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:21:19.826699+00:00, run_after=2022-10-22T17:21:19.826699+00:00
[2022-10-21 17:21:20,117] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.443 seconds
[2022-10-21 17:21:25,216] {processor.py:153} INFO - Started process (PID=73905) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:25,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:21:25,224] {logging_mixin.py:115} INFO - [2022-10-21 17:21:25,223] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:25,391] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:25,428] {logging_mixin.py:115} INFO - [2022-10-21 17:21:25,428] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:21:25,474] {logging_mixin.py:115} INFO - [2022-10-21 17:21:25,473] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:21:25.383388+00:00, run_after=2022-10-22T17:21:25.383388+00:00
[2022-10-21 17:21:25,492] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.282 seconds
[2022-10-21 17:21:52,286] {processor.py:153} INFO - Started process (PID=8939) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:52,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:21:52,289] {logging_mixin.py:115} INFO - [2022-10-21 17:21:52,289] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:52,496] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:52,682] {logging_mixin.py:115} INFO - [2022-10-21 17:21:52,682] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:21:52,743] {logging_mixin.py:115} INFO - [2022-10-21 17:21:52,743] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:21:52.482102+00:00, run_after=2022-10-22T17:21:52.482102+00:00
[2022-10-21 17:21:52,774] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.495 seconds
[2022-10-21 17:21:57,596] {processor.py:153} INFO - Started process (PID=74357) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:57,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:21:57,602] {logging_mixin.py:115} INFO - [2022-10-21 17:21:57,602] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:57,797] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:21:57,839] {logging_mixin.py:115} INFO - [2022-10-21 17:21:57,839] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:21:57,890] {logging_mixin.py:115} INFO - [2022-10-21 17:21:57,890] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:21:57.792997+00:00, run_after=2022-10-22T17:21:57.792997+00:00
[2022-10-21 17:21:57,909] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.327 seconds
[2022-10-21 17:22:30,471] {processor.py:153} INFO - Started process (PID=74839) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:22:30,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:22:30,474] {logging_mixin.py:115} INFO - [2022-10-21 17:22:30,474] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:22:30,586] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:22:30,709] {logging_mixin.py:115} INFO - [2022-10-21 17:22:30,709] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:22:30,742] {logging_mixin.py:115} INFO - [2022-10-21 17:22:30,741] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:22:30.581334+00:00, run_after=2022-10-22T17:22:30.581334+00:00
[2022-10-21 17:22:30,761] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.297 seconds
[2022-10-21 17:22:34,251] {processor.py:153} INFO - Started process (PID=9130) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:22:34,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:22:34,257] {logging_mixin.py:115} INFO - [2022-10-21 17:22:34,256] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:22:34,490] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:22:34,524] {logging_mixin.py:115} INFO - [2022-10-21 17:22:34,523] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:22:34,577] {logging_mixin.py:115} INFO - [2022-10-21 17:22:34,577] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:22:34.481020+00:00, run_after=2022-10-22T17:22:34.481020+00:00
[2022-10-21 17:22:34,615] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.376 seconds
[2022-10-21 17:23:06,947] {processor.py:153} INFO - Started process (PID=75316) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:06,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:23:06,951] {logging_mixin.py:115} INFO - [2022-10-21 17:23:06,951] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:07,170] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:07,291] {logging_mixin.py:115} INFO - [2022-10-21 17:23:07,290] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:23:07,321] {logging_mixin.py:115} INFO - [2022-10-21 17:23:07,320] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:23:07.166511+00:00, run_after=2022-10-22T17:23:07.166511+00:00
[2022-10-21 17:23:07,340] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.410 seconds
[2022-10-21 17:23:08,633] {processor.py:153} INFO - Started process (PID=9604) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:08,635] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:23:08,641] {logging_mixin.py:115} INFO - [2022-10-21 17:23:08,641] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:08,795] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:08,839] {logging_mixin.py:115} INFO - [2022-10-21 17:23:08,839] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:23:08,897] {logging_mixin.py:115} INFO - [2022-10-21 17:23:08,897] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:23:08.791560+00:00, run_after=2022-10-22T17:23:08.791560+00:00
[2022-10-21 17:23:08,921] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.307 seconds
[2022-10-21 17:23:37,655] {processor.py:153} INFO - Started process (PID=75749) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:37,663] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:23:37,667] {logging_mixin.py:115} INFO - [2022-10-21 17:23:37,667] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:37,881] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:38,034] {logging_mixin.py:115} INFO - [2022-10-21 17:23:38,033] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:23:38,078] {logging_mixin.py:115} INFO - [2022-10-21 17:23:38,078] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:23:37.877253+00:00, run_after=2022-10-22T17:23:37.877253+00:00
[2022-10-21 17:23:38,107] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.457 seconds
[2022-10-21 17:23:42,053] {processor.py:153} INFO - Started process (PID=10087) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:42,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:23:42,056] {logging_mixin.py:115} INFO - [2022-10-21 17:23:42,056] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:42,197] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:23:42,225] {logging_mixin.py:115} INFO - [2022-10-21 17:23:42,225] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:23:42,285] {logging_mixin.py:115} INFO - [2022-10-21 17:23:42,285] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:23:42.190971+00:00, run_after=2022-10-22T17:23:42.190971+00:00
[2022-10-21 17:23:42,326] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.280 seconds
[2022-10-21 17:24:13,713] {processor.py:153} INFO - Started process (PID=10517) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:13,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:24:13,721] {logging_mixin.py:115} INFO - [2022-10-21 17:24:13,720] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:13,919] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:14,178] {logging_mixin.py:115} INFO - [2022-10-21 17:24:14,178] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:24:14,231] {logging_mixin.py:115} INFO - [2022-10-21 17:24:14,231] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:24:13.912185+00:00, run_after=2022-10-22T17:24:13.912185+00:00
[2022-10-21 17:24:14,269] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.596 seconds
[2022-10-21 17:24:41,587] {processor.py:153} INFO - Started process (PID=76193) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:41,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:24:41,591] {logging_mixin.py:115} INFO - [2022-10-21 17:24:41,590] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:41,739] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:41,777] {logging_mixin.py:115} INFO - [2022-10-21 17:24:41,776] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:24:41,824] {logging_mixin.py:115} INFO - [2022-10-21 17:24:41,823] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:24:41.734513+00:00, run_after=2022-10-22T17:24:41.734513+00:00
[2022-10-21 17:24:41,843] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.265 seconds
[2022-10-21 17:24:46,151] {processor.py:153} INFO - Started process (PID=11002) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:46,154] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:24:46,155] {logging_mixin.py:115} INFO - [2022-10-21 17:24:46,155] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:46,347] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:24:46,517] {logging_mixin.py:115} INFO - [2022-10-21 17:24:46,517] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:24:46,561] {logging_mixin.py:115} INFO - [2022-10-21 17:24:46,561] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:24:46.343279+00:00, run_after=2022-10-22T17:24:46.343279+00:00
[2022-10-21 17:24:46,593] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.454 seconds
[2022-10-21 17:25:17,089] {processor.py:153} INFO - Started process (PID=76680) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:17,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:25:17,096] {logging_mixin.py:115} INFO - [2022-10-21 17:25:17,096] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:17,329] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:17,526] {logging_mixin.py:115} INFO - [2022-10-21 17:25:17,526] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:25:17,573] {logging_mixin.py:115} INFO - [2022-10-21 17:25:17,572] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:25:17.317736+00:00, run_after=2022-10-22T17:25:17.317736+00:00
[2022-10-21 17:25:17,607] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.538 seconds
[2022-10-21 17:25:19,427] {processor.py:153} INFO - Started process (PID=11447) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:19,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:25:19,431] {logging_mixin.py:115} INFO - [2022-10-21 17:25:19,431] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:19,669] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:19,696] {logging_mixin.py:115} INFO - [2022-10-21 17:25:19,696] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:25:19,758] {logging_mixin.py:115} INFO - [2022-10-21 17:25:19,757] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:25:19.659514+00:00, run_after=2022-10-22T17:25:19.659514+00:00
[2022-10-21 17:25:19,802] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.385 seconds
[2022-10-21 17:25:50,981] {processor.py:153} INFO - Started process (PID=11875) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:50,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:25:50,985] {logging_mixin.py:115} INFO - [2022-10-21 17:25:50,985] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:51,189] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:51,399] {logging_mixin.py:115} INFO - [2022-10-21 17:25:51,398] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:25:51,450] {logging_mixin.py:115} INFO - [2022-10-21 17:25:51,449] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:25:51.171147+00:00, run_after=2022-10-22T17:25:51.171147+00:00
[2022-10-21 17:25:51,502] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.528 seconds
[2022-10-21 17:25:52,040] {processor.py:153} INFO - Started process (PID=77133) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:52,041] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:25:52,044] {logging_mixin.py:115} INFO - [2022-10-21 17:25:52,044] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:52,212] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:25:52,256] {logging_mixin.py:115} INFO - [2022-10-21 17:25:52,256] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:25:52,291] {logging_mixin.py:115} INFO - [2022-10-21 17:25:52,291] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:25:52.207453+00:00, run_after=2022-10-22T17:25:52.207453+00:00
[2022-10-21 17:25:52,334] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.301 seconds
[2022-10-21 17:26:23,177] {processor.py:153} INFO - Started process (PID=12327) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:23,179] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:26:23,181] {logging_mixin.py:115} INFO - [2022-10-21 17:26:23,181] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:23,382] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:23,599] {logging_mixin.py:115} INFO - [2022-10-21 17:26:23,599] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:26:23,650] {logging_mixin.py:115} INFO - [2022-10-21 17:26:23,649] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:26:23.373884+00:00, run_after=2022-10-22T17:26:23.373884+00:00
[2022-10-21 17:26:23,670] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.499 seconds
[2022-10-21 17:26:27,860] {processor.py:153} INFO - Started process (PID=77633) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:27,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:26:27,866] {logging_mixin.py:115} INFO - [2022-10-21 17:26:27,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:28,027] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:28,050] {logging_mixin.py:115} INFO - [2022-10-21 17:26:28,049] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:26:28,097] {logging_mixin.py:115} INFO - [2022-10-21 17:26:28,096] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:26:28.023086+00:00, run_after=2022-10-22T17:26:28.023086+00:00
[2022-10-21 17:26:28,169] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.320 seconds
[2022-10-21 17:26:58,076] {processor.py:153} INFO - Started process (PID=12807) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:58,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:26:58,081] {logging_mixin.py:115} INFO - [2022-10-21 17:26:58,081] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:58,252] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:26:58,435] {logging_mixin.py:115} INFO - [2022-10-21 17:26:58,435] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:26:58,486] {logging_mixin.py:115} INFO - [2022-10-21 17:26:58,486] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:26:58.248186+00:00, run_after=2022-10-22T17:26:58.248186+00:00
[2022-10-21 17:26:58,532] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.473 seconds
[2022-10-21 17:27:01,984] {processor.py:153} INFO - Started process (PID=78088) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:01,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:27:01,988] {logging_mixin.py:115} INFO - [2022-10-21 17:27:01,988] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:02,144] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:02,194] {logging_mixin.py:115} INFO - [2022-10-21 17:27:02,194] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:27:02,294] {logging_mixin.py:115} INFO - [2022-10-21 17:27:02,294] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:27:02.139147+00:00, run_after=2022-10-22T17:27:02.139147+00:00
[2022-10-21 17:27:02,340] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.368 seconds
[2022-10-21 17:27:32,853] {processor.py:153} INFO - Started process (PID=78544) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:32,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:27:32,858] {logging_mixin.py:115} INFO - [2022-10-21 17:27:32,858] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:33,045] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:33,254] {logging_mixin.py:115} INFO - [2022-10-21 17:27:33,254] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:27:33,316] {logging_mixin.py:115} INFO - [2022-10-21 17:27:33,314] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:27:33.030052+00:00, run_after=2022-10-22T17:27:33.030052+00:00
[2022-10-21 17:27:33,354] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.509 seconds
[2022-10-21 17:27:36,736] {processor.py:153} INFO - Started process (PID=12927) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:36,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:27:36,742] {logging_mixin.py:115} INFO - [2022-10-21 17:27:36,742] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:36,879] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:27:36,905] {logging_mixin.py:115} INFO - [2022-10-21 17:27:36,904] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:27:36,946] {logging_mixin.py:115} INFO - [2022-10-21 17:27:36,946] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:27:36.873690+00:00, run_after=2022-10-22T17:27:36.873690+00:00
[2022-10-21 17:27:36,968] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.247 seconds
[2022-10-21 17:28:09,770] {processor.py:153} INFO - Started process (PID=79054) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:09,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:28:09,791] {logging_mixin.py:115} INFO - [2022-10-21 17:28:09,791] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:10,026] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:10,324] {logging_mixin.py:115} INFO - [2022-10-21 17:28:10,324] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:28:10,389] {logging_mixin.py:115} INFO - [2022-10-21 17:28:10,389] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:28:10.021331+00:00, run_after=2022-10-22T17:28:10.021331+00:00
[2022-10-21 17:28:10,430] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.675 seconds
[2022-10-21 17:28:12,299] {processor.py:153} INFO - Started process (PID=13438) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:12,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:28:12,303] {logging_mixin.py:115} INFO - [2022-10-21 17:28:12,303] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:12,520] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:12,559] {logging_mixin.py:115} INFO - [2022-10-21 17:28:12,559] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:28:12,613] {logging_mixin.py:115} INFO - [2022-10-21 17:28:12,613] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:28:12.487435+00:00, run_after=2022-10-22T17:28:12.487435+00:00
[2022-10-21 17:28:12,655] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.366 seconds
[2022-10-21 17:28:46,295] {processor.py:153} INFO - Started process (PID=13732) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:46,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:28:46,300] {logging_mixin.py:115} INFO - [2022-10-21 17:28:46,300] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:46,475] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:46,669] {logging_mixin.py:115} INFO - [2022-10-21 17:28:46,669] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:28:46,948] {processor.py:153} INFO - Started process (PID=79375) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:46,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:28:46,953] {logging_mixin.py:115} INFO - [2022-10-21 17:28:46,952] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:47,165] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:28:47,264] {logging_mixin.py:115} INFO - [2022-10-21 17:28:47,264] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:28:46.460764+00:00, run_after=2022-10-22T17:28:46.460764+00:00
[2022-10-21 17:28:47,309] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.023 seconds
[2022-10-21 17:28:47,495] {logging_mixin.py:115} INFO - [2022-10-21 17:28:47,494] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:28:47,552] {logging_mixin.py:115} INFO - [2022-10-21 17:28:47,552] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:28:47.156139+00:00, run_after=2022-10-22T17:28:47.156139+00:00
[2022-10-21 17:28:47,599] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.661 seconds
[2022-10-21 17:29:36,479] {processor.py:153} INFO - Started process (PID=14247) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:29:36,482] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:29:36,489] {logging_mixin.py:115} INFO - [2022-10-21 17:29:36,488] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:29:36,642] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:29:37,103] {logging_mixin.py:115} INFO - [2022-10-21 17:29:37,103] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:29:37,173] {logging_mixin.py:115} INFO - [2022-10-21 17:29:37,172] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:29:36.638360+00:00, run_after=2022-10-22T17:29:36.638360+00:00
[2022-10-21 17:29:37,215] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.744 seconds
[2022-10-21 17:29:58,427] {processor.py:153} INFO - Started process (PID=79661) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:29:58,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:29:58,433] {logging_mixin.py:115} INFO - [2022-10-21 17:29:58,432] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:29:58,648] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:29:58,700] {logging_mixin.py:115} INFO - [2022-10-21 17:29:58,700] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:29:58,763] {logging_mixin.py:115} INFO - [2022-10-21 17:29:58,763] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:29:58.641871+00:00, run_after=2022-10-22T17:29:58.641871+00:00
[2022-10-21 17:29:58,791] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.380 seconds
[2022-10-21 17:30:18,469] {processor.py:153} INFO - Started process (PID=14722) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:18,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:30:18,475] {logging_mixin.py:115} INFO - [2022-10-21 17:30:18,475] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:18,638] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:19,109] {logging_mixin.py:115} INFO - [2022-10-21 17:30:19,109] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:30:19,151] {logging_mixin.py:115} INFO - [2022-10-21 17:30:19,151] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:30:18.633747+00:00, run_after=2022-10-22T17:30:18.633747+00:00
[2022-10-21 17:30:19,187] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.729 seconds
[2022-10-21 17:30:35,714] {processor.py:153} INFO - Started process (PID=80074) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:35,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:30:35,722] {logging_mixin.py:115} INFO - [2022-10-21 17:30:35,721] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:35,906] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:35,948] {logging_mixin.py:115} INFO - [2022-10-21 17:30:35,948] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:30:35,999] {logging_mixin.py:115} INFO - [2022-10-21 17:30:35,999] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:30:35.900985+00:00, run_after=2022-10-22T17:30:35.900985+00:00
[2022-10-21 17:30:36,027] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.329 seconds
[2022-10-21 17:30:51,596] {processor.py:153} INFO - Started process (PID=15089) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:51,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:30:51,608] {logging_mixin.py:115} INFO - [2022-10-21 17:30:51,607] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:51,784] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:30:52,123] {logging_mixin.py:115} INFO - [2022-10-21 17:30:52,123] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:30:52,154] {logging_mixin.py:115} INFO - [2022-10-21 17:30:52,154] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:30:51.779707+00:00, run_after=2022-10-22T17:30:51.779707+00:00
[2022-10-21 17:30:52,192] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.603 seconds
[2022-10-21 17:31:17,618] {processor.py:153} INFO - Started process (PID=80401) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:31:17,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:31:17,630] {logging_mixin.py:115} INFO - [2022-10-21 17:31:17,630] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:31:18,318] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:31:18,395] {logging_mixin.py:115} INFO - [2022-10-21 17:31:18,395] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:31:18,546] {logging_mixin.py:115} INFO - [2022-10-21 17:31:18,546] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:31:18.285467+00:00, run_after=2022-10-22T17:31:18.285467+00:00
[2022-10-21 17:31:18,616] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.012 seconds
[2022-10-21 17:32:40,573] {processor.py:153} INFO - Started process (PID=80738) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:32:40,585] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:32:40,596] {logging_mixin.py:115} INFO - [2022-10-21 17:32:40,595] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:32:41,504] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:32:42,341] {logging_mixin.py:115} INFO - [2022-10-21 17:32:42,341] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:32:42,481] {logging_mixin.py:115} INFO - [2022-10-21 17:32:42,480] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:32:41.487486+00:00, run_after=2022-10-22T17:32:41.487486+00:00
[2022-10-21 17:32:42,573] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.037 seconds
[2022-10-21 17:55:26,749] {processor.py:153} INFO - Started process (PID=16427) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:55:26,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:55:26,763] {logging_mixin.py:115} INFO - [2022-10-21 17:55:26,762] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:55:27,287] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:55:27,551] {logging_mixin.py:115} INFO - [2022-10-21 17:55:27,551] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:55:27,622] {logging_mixin.py:115} INFO - [2022-10-21 17:55:27,622] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:55:27.244576+00:00, run_after=2022-10-22T17:55:27.244576+00:00
[2022-10-21 17:55:27,675] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.934 seconds
[2022-10-21 17:56:43,511] {processor.py:153} INFO - Started process (PID=16972) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:56:43,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:56:43,517] {logging_mixin.py:115} INFO - [2022-10-21 17:56:43,517] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:56:43,719] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:56:43,976] {logging_mixin.py:115} INFO - [2022-10-21 17:56:43,976] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:56:44,044] {logging_mixin.py:115} INFO - [2022-10-21 17:56:44,043] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:56:43.710973+00:00, run_after=2022-10-22T17:56:43.710973+00:00
[2022-10-21 17:56:44,097] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.597 seconds
[2022-10-21 17:58:14,248] {processor.py:153} INFO - Started process (PID=17315) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:58:14,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 17:58:14,263] {logging_mixin.py:115} INFO - [2022-10-21 17:58:14,262] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:58:15,182] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 17:58:17,011] {logging_mixin.py:115} INFO - [2022-10-21 17:58:17,010] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 17:58:17,280] {logging_mixin.py:115} INFO - [2022-10-21 17:58:17,280] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T17:58:15.164784+00:00, run_after=2022-10-22T17:58:15.164784+00:00
[2022-10-21 17:58:17,458] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 3.299 seconds
[2022-10-21 18:00:00,930] {processor.py:153} INFO - Started process (PID=81897) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:00,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:00:00,933] {logging_mixin.py:115} INFO - [2022-10-21 18:00:00,933] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:01,066] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:01,188] {logging_mixin.py:115} INFO - [2022-10-21 18:00:01,187] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:00:01,215] {logging_mixin.py:115} INFO - [2022-10-21 18:00:01,215] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:00:01.058884+00:00, run_after=2022-10-22T18:00:01.058884+00:00
[2022-10-21 18:00:01,237] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.318 seconds
[2022-10-21 18:00:07,372] {processor.py:153} INFO - Started process (PID=17809) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:07,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:00:07,378] {logging_mixin.py:115} INFO - [2022-10-21 18:00:07,378] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:07,815] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:07,876] {logging_mixin.py:115} INFO - [2022-10-21 18:00:07,876] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:00:07,937] {logging_mixin.py:115} INFO - [2022-10-21 18:00:07,936] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:00:07.812550+00:00, run_after=2022-10-22T18:00:07.812550+00:00
[2022-10-21 18:00:07,969] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.636 seconds
[2022-10-21 18:00:38,277] {processor.py:153} INFO - Started process (PID=82414) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:38,279] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:00:38,281] {logging_mixin.py:115} INFO - [2022-10-21 18:00:38,280] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:38,476] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:38,631] {logging_mixin.py:115} INFO - [2022-10-21 18:00:38,631] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:00:38,684] {logging_mixin.py:115} INFO - [2022-10-21 18:00:38,679] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:00:38.471127+00:00, run_after=2022-10-22T18:00:38.471127+00:00
[2022-10-21 18:00:38,727] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.467 seconds
[2022-10-21 18:00:43,231] {processor.py:153} INFO - Started process (PID=18298) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:43,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:00:43,243] {logging_mixin.py:115} INFO - [2022-10-21 18:00:43,242] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:43,746] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:00:43,822] {logging_mixin.py:115} INFO - [2022-10-21 18:00:43,821] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:00:43,911] {logging_mixin.py:115} INFO - [2022-10-21 18:00:43,911] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:00:43.743151+00:00, run_after=2022-10-22T18:00:43.743151+00:00
[2022-10-21 18:00:43,946] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.723 seconds
[2022-10-21 18:01:09,263] {processor.py:153} INFO - Started process (PID=82824) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:09,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:01:09,270] {logging_mixin.py:115} INFO - [2022-10-21 18:01:09,269] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:09,510] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:09,636] {logging_mixin.py:115} INFO - [2022-10-21 18:01:09,636] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:01:09,670] {logging_mixin.py:115} INFO - [2022-10-21 18:01:09,670] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:01:09.504316+00:00, run_after=2022-10-22T18:01:09.504316+00:00
[2022-10-21 18:01:09,693] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.444 seconds
[2022-10-21 18:01:22,068] {processor.py:153} INFO - Started process (PID=18816) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:22,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:01:22,078] {logging_mixin.py:115} INFO - [2022-10-21 18:01:22,077] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:22,542] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:22,585] {logging_mixin.py:115} INFO - [2022-10-21 18:01:22,585] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:01:22,642] {logging_mixin.py:115} INFO - [2022-10-21 18:01:22,642] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:01:22.539837+00:00, run_after=2022-10-22T18:01:22.539837+00:00
[2022-10-21 18:01:22,676] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.622 seconds
[2022-10-21 18:01:41,021] {processor.py:153} INFO - Started process (PID=83252) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:41,023] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:01:41,025] {logging_mixin.py:115} INFO - [2022-10-21 18:01:41,025] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:41,202] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:41,385] {logging_mixin.py:115} INFO - [2022-10-21 18:01:41,385] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:01:41,438] {logging_mixin.py:115} INFO - [2022-10-21 18:01:41,438] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:01:41.194094+00:00, run_after=2022-10-22T18:01:41.194094+00:00
[2022-10-21 18:01:41,490] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.475 seconds
[2022-10-21 18:01:53,415] {processor.py:153} INFO - Started process (PID=19243) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:53,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:01:53,418] {logging_mixin.py:115} INFO - [2022-10-21 18:01:53,418] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:53,549] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:01:53,577] {logging_mixin.py:115} INFO - [2022-10-21 18:01:53,577] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:01:53,944] {logging_mixin.py:115} INFO - [2022-10-21 18:01:53,943] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:01:53.543784+00:00, run_after=2022-10-22T18:01:53.543784+00:00
[2022-10-21 18:01:53,968] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.561 seconds
[2022-10-21 18:02:19,505] {processor.py:153} INFO - Started process (PID=83770) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:19,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:02:19,516] {logging_mixin.py:115} INFO - [2022-10-21 18:02:19,516] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:19,678] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:19,828] {logging_mixin.py:115} INFO - [2022-10-21 18:02:19,827] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:02:19,873] {logging_mixin.py:115} INFO - [2022-10-21 18:02:19,873] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:02:19.674342+00:00, run_after=2022-10-22T18:02:19.674342+00:00
[2022-10-21 18:02:19,893] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.395 seconds
[2022-10-21 18:02:30,987] {processor.py:153} INFO - Started process (PID=19756) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:30,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:02:30,992] {logging_mixin.py:115} INFO - [2022-10-21 18:02:30,992] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:31,127] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:31,173] {logging_mixin.py:115} INFO - [2022-10-21 18:02:31,173] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:02:31,490] {logging_mixin.py:115} INFO - [2022-10-21 18:02:31,490] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:02:31.122463+00:00, run_after=2022-10-22T18:02:31.122463+00:00
[2022-10-21 18:02:31,509] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.531 seconds
[2022-10-21 18:02:54,376] {processor.py:153} INFO - Started process (PID=84229) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:54,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:02:54,382] {logging_mixin.py:115} INFO - [2022-10-21 18:02:54,381] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:54,591] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:02:54,828] {logging_mixin.py:115} INFO - [2022-10-21 18:02:54,828] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:02:54,876] {logging_mixin.py:115} INFO - [2022-10-21 18:02:54,876] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:02:54.586107+00:00, run_after=2022-10-22T18:02:54.586107+00:00
[2022-10-21 18:02:54,915] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.545 seconds
[2022-10-21 18:03:08,121] {processor.py:153} INFO - Started process (PID=20265) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:08,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:03:08,125] {logging_mixin.py:115} INFO - [2022-10-21 18:03:08,125] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:08,589] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:08,627] {logging_mixin.py:115} INFO - [2022-10-21 18:03:08,627] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:03:08,662] {logging_mixin.py:115} INFO - [2022-10-21 18:03:08,662] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:03:08.585840+00:00, run_after=2022-10-22T18:03:08.585840+00:00
[2022-10-21 18:03:08,677] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.568 seconds
[2022-10-21 18:03:28,203] {processor.py:153} INFO - Started process (PID=84676) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:28,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:03:28,214] {logging_mixin.py:115} INFO - [2022-10-21 18:03:28,213] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:28,377] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:28,587] {logging_mixin.py:115} INFO - [2022-10-21 18:03:28,586] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:03:28,620] {logging_mixin.py:115} INFO - [2022-10-21 18:03:28,620] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:03:28.368457+00:00, run_after=2022-10-22T18:03:28.368457+00:00
[2022-10-21 18:03:28,653] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.456 seconds
[2022-10-21 18:03:46,191] {processor.py:153} INFO - Started process (PID=20775) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:46,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:03:46,199] {logging_mixin.py:115} INFO - [2022-10-21 18:03:46,198] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:46,671] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:03:46,696] {logging_mixin.py:115} INFO - [2022-10-21 18:03:46,695] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:03:46,752] {logging_mixin.py:115} INFO - [2022-10-21 18:03:46,752] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:03:46.667359+00:00, run_after=2022-10-22T18:03:46.667359+00:00
[2022-10-21 18:03:46,784] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.600 seconds
[2022-10-21 18:04:05,441] {processor.py:153} INFO - Started process (PID=85195) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:04:05,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:04:05,445] {logging_mixin.py:115} INFO - [2022-10-21 18:04:05,445] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:04:05,737] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:04:05,884] {logging_mixin.py:115} INFO - [2022-10-21 18:04:05,884] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:04:05,954] {logging_mixin.py:115} INFO - [2022-10-21 18:04:05,953] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:04:05.725006+00:00, run_after=2022-10-22T18:04:05.725006+00:00
[2022-10-21 18:04:06,001] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.567 seconds
[2022-10-21 18:04:24,336] {processor.py:153} INFO - Started process (PID=21290) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:04:24,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:04:24,352] {logging_mixin.py:115} INFO - [2022-10-21 18:04:24,352] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:04:24,974] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:04:24,993] {logging_mixin.py:115} INFO - [2022-10-21 18:04:24,993] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:04:25,022] {logging_mixin.py:115} INFO - [2022-10-21 18:04:25,022] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:04:24.971347+00:00, run_after=2022-10-22T18:04:24.971347+00:00
[2022-10-21 18:04:25,047] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.736 seconds
[2022-10-21 18:05:03,646] {processor.py:153} INFO - Started process (PID=85519) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:03,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:05:03,650] {logging_mixin.py:115} INFO - [2022-10-21 18:05:03,650] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:03,779] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:03,926] {logging_mixin.py:115} INFO - [2022-10-21 18:05:03,925] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:05:03,957] {logging_mixin.py:115} INFO - [2022-10-21 18:05:03,957] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:05:03.771982+00:00, run_after=2022-10-22T18:05:03.771982+00:00
[2022-10-21 18:05:03,986] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.352 seconds
[2022-10-21 18:05:14,597] {processor.py:153} INFO - Started process (PID=21537) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:14,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:05:14,601] {logging_mixin.py:115} INFO - [2022-10-21 18:05:14,600] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:14,777] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:14,810] {logging_mixin.py:115} INFO - [2022-10-21 18:05:14,810] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:05:14,867] {logging_mixin.py:115} INFO - [2022-10-21 18:05:14,867] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:05:14.772676+00:00, run_after=2022-10-22T18:05:14.772676+00:00
[2022-10-21 18:05:14,894] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.306 seconds
[2022-10-21 18:05:40,897] {processor.py:153} INFO - Started process (PID=86012) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:40,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:05:40,900] {logging_mixin.py:115} INFO - [2022-10-21 18:05:40,900] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:41,029] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:41,166] {logging_mixin.py:115} INFO - [2022-10-21 18:05:41,166] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:05:41,198] {logging_mixin.py:115} INFO - [2022-10-21 18:05:41,198] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:05:41.024990+00:00, run_after=2022-10-22T18:05:41.024990+00:00
[2022-10-21 18:05:41,216] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.326 seconds
[2022-10-21 18:05:48,046] {processor.py:153} INFO - Started process (PID=21980) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:48,049] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:05:48,052] {logging_mixin.py:115} INFO - [2022-10-21 18:05:48,052] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:48,237] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:05:48,265] {logging_mixin.py:115} INFO - [2022-10-21 18:05:48,265] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:05:48,334] {logging_mixin.py:115} INFO - [2022-10-21 18:05:48,333] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:05:48.232691+00:00, run_after=2022-10-22T18:05:48.232691+00:00
[2022-10-21 18:05:48,375] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.348 seconds
[2022-10-21 18:06:18,277] {processor.py:153} INFO - Started process (PID=86484) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:18,278] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:06:18,280] {logging_mixin.py:115} INFO - [2022-10-21 18:06:18,280] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:18,485] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:18,668] {logging_mixin.py:115} INFO - [2022-10-21 18:06:18,668] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:06:18,745] {logging_mixin.py:115} INFO - [2022-10-21 18:06:18,745] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:06:18.480979+00:00, run_after=2022-10-22T18:06:18.480979+00:00
[2022-10-21 18:06:18,797] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.527 seconds
[2022-10-21 18:06:20,366] {processor.py:153} INFO - Started process (PID=22413) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:20,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:06:20,370] {logging_mixin.py:115} INFO - [2022-10-21 18:06:20,370] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:20,552] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:20,587] {logging_mixin.py:115} INFO - [2022-10-21 18:06:20,587] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:06:20,651] {logging_mixin.py:115} INFO - [2022-10-21 18:06:20,649] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:06:20.546108+00:00, run_after=2022-10-22T18:06:20.546108+00:00
[2022-10-21 18:06:20,688] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.340 seconds
[2022-10-21 18:06:56,929] {processor.py:153} INFO - Started process (PID=86933) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:56,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:06:56,934] {logging_mixin.py:115} INFO - [2022-10-21 18:06:56,934] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:57,194] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:06:57,409] {logging_mixin.py:115} INFO - [2022-10-21 18:06:57,409] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:06:57,456] {logging_mixin.py:115} INFO - [2022-10-21 18:06:57,456] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:06:57.189848+00:00, run_after=2022-10-22T18:06:57.189848+00:00
[2022-10-21 18:06:57,484] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.580 seconds
[2022-10-21 18:07:01,789] {processor.py:153} INFO - Started process (PID=22929) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:01,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:07:01,796] {logging_mixin.py:115} INFO - [2022-10-21 18:07:01,796] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:02,037] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:02,067] {logging_mixin.py:115} INFO - [2022-10-21 18:07:02,067] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:07:02,102] {logging_mixin.py:115} INFO - [2022-10-21 18:07:02,102] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:07:02.032962+00:00, run_after=2022-10-22T18:07:02.032962+00:00
[2022-10-21 18:07:02,149] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.367 seconds
[2022-10-21 18:07:34,072] {processor.py:153} INFO - Started process (PID=23343) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:34,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:07:34,079] {logging_mixin.py:115} INFO - [2022-10-21 18:07:34,079] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:34,257] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:34,453] {logging_mixin.py:115} INFO - [2022-10-21 18:07:34,453] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:07:34,497] {logging_mixin.py:115} INFO - [2022-10-21 18:07:34,496] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:07:34.252285+00:00, run_after=2022-10-22T18:07:34.252285+00:00
[2022-10-21 18:07:34,523] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.468 seconds
[2022-10-21 18:07:35,188] {processor.py:153} INFO - Started process (PID=87408) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:35,190] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:07:35,192] {logging_mixin.py:115} INFO - [2022-10-21 18:07:35,192] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:35,348] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:07:35,394] {logging_mixin.py:115} INFO - [2022-10-21 18:07:35,394] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:07:35,473] {logging_mixin.py:115} INFO - [2022-10-21 18:07:35,473] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:07:35.344480+00:00, run_after=2022-10-22T18:07:35.344480+00:00
[2022-10-21 18:07:35,496] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.314 seconds
[2022-10-21 18:08:07,097] {processor.py:153} INFO - Started process (PID=87814) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:07,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:08:07,108] {logging_mixin.py:115} INFO - [2022-10-21 18:08:07,107] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:07,426] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:07,639] {logging_mixin.py:115} INFO - [2022-10-21 18:08:07,639] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:08:07,685] {logging_mixin.py:115} INFO - [2022-10-21 18:08:07,685] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:08:07.399976+00:00, run_after=2022-10-22T18:08:07.399976+00:00
[2022-10-21 18:08:07,709] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.646 seconds
[2022-10-21 18:08:09,796] {processor.py:153} INFO - Started process (PID=23815) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:09,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:08:09,803] {logging_mixin.py:115} INFO - [2022-10-21 18:08:09,803] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:10,070] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:10,114] {logging_mixin.py:115} INFO - [2022-10-21 18:08:10,114] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:08:10,166] {logging_mixin.py:115} INFO - [2022-10-21 18:08:10,166] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:08:10.065874+00:00, run_after=2022-10-22T18:08:10.065874+00:00
[2022-10-21 18:08:10,195] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.409 seconds
[2022-10-21 18:08:40,455] {processor.py:153} INFO - Started process (PID=88206) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:40,457] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:08:40,459] {logging_mixin.py:115} INFO - [2022-10-21 18:08:40,459] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:40,646] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:40,842] {logging_mixin.py:115} INFO - [2022-10-21 18:08:40,842] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:08:40,877] {logging_mixin.py:115} INFO - [2022-10-21 18:08:40,877] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:08:40.639551+00:00, run_after=2022-10-22T18:08:40.639551+00:00
[2022-10-21 18:08:40,908] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.462 seconds
[2022-10-21 18:08:48,991] {processor.py:153} INFO - Started process (PID=24304) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:48,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:08:48,997] {logging_mixin.py:115} INFO - [2022-10-21 18:08:48,996] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:49,191] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:08:49,256] {logging_mixin.py:115} INFO - [2022-10-21 18:08:49,255] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:08:49,306] {logging_mixin.py:115} INFO - [2022-10-21 18:08:49,306] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:08:49.165852+00:00, run_after=2022-10-22T18:08:49.165852+00:00
[2022-10-21 18:08:49,339] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.354 seconds
[2022-10-21 18:09:23,542] {processor.py:153} INFO - Started process (PID=88696) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:09:23,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:09:23,545] {logging_mixin.py:115} INFO - [2022-10-21 18:09:23,545] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:09:23,729] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:09:23,962] {logging_mixin.py:115} INFO - [2022-10-21 18:09:23,962] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:09:23,997] {logging_mixin.py:115} INFO - [2022-10-21 18:09:23,997] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:09:23.724116+00:00, run_after=2022-10-22T18:09:23.724116+00:00
[2022-10-21 18:09:24,028] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.501 seconds
[2022-10-21 18:09:24,108] {processor.py:153} INFO - Started process (PID=24730) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:09:24,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:09:24,113] {logging_mixin.py:115} INFO - [2022-10-21 18:09:24,113] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:09:24,254] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:09:24,282] {logging_mixin.py:115} INFO - [2022-10-21 18:09:24,282] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:09:24,325] {logging_mixin.py:115} INFO - [2022-10-21 18:09:24,325] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:09:24.247499+00:00, run_after=2022-10-22T18:09:24.247499+00:00
[2022-10-21 18:09:24,348] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.252 seconds
[2022-10-21 18:10:08,759] {processor.py:153} INFO - Started process (PID=24892) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:10:08,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:10:08,780] {logging_mixin.py:115} INFO - [2022-10-21 18:10:08,766] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:10:09,021] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:10:09,243] {logging_mixin.py:115} INFO - [2022-10-21 18:10:09,243] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:10:09,306] {logging_mixin.py:115} INFO - [2022-10-21 18:10:09,306] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:10:09.016890+00:00, run_after=2022-10-22T18:10:09.016890+00:00
[2022-10-21 18:10:09,339] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.604 seconds
[2022-10-21 18:10:11,161] {processor.py:153} INFO - Started process (PID=88889) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:10:11,163] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:10:11,167] {logging_mixin.py:115} INFO - [2022-10-21 18:10:11,166] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:10:11,323] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:10:11,367] {logging_mixin.py:115} INFO - [2022-10-21 18:10:11,367] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:10:11,420] {logging_mixin.py:115} INFO - [2022-10-21 18:10:11,420] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:10:11.317425+00:00, run_after=2022-10-22T18:10:11.317425+00:00
[2022-10-21 18:10:11,455] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.302 seconds
[2022-10-21 18:15:06,988] {processor.py:153} INFO - Started process (PID=89292) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:06,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:15:06,993] {logging_mixin.py:115} INFO - [2022-10-21 18:15:06,992] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:07,296] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:07,438] {logging_mixin.py:115} INFO - [2022-10-21 18:15:07,438] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:15:07,467] {logging_mixin.py:115} INFO - [2022-10-21 18:15:07,466] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:15:07.291983+00:00, run_after=2022-10-22T18:15:07.291983+00:00
[2022-10-21 18:15:07,493] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.514 seconds
[2022-10-21 18:15:17,521] {processor.py:153} INFO - Started process (PID=25434) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:17,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:15:17,531] {logging_mixin.py:115} INFO - [2022-10-21 18:15:17,531] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:17,719] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:17,743] {logging_mixin.py:115} INFO - [2022-10-21 18:15:17,742] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:15:17,786] {logging_mixin.py:115} INFO - [2022-10-21 18:15:17,786] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:15:17.714403+00:00, run_after=2022-10-22T18:15:17.714403+00:00
[2022-10-21 18:15:17,814] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.299 seconds
[2022-10-21 18:15:39,768] {processor.py:153} INFO - Started process (PID=89610) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:39,770] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:15:39,771] {logging_mixin.py:115} INFO - [2022-10-21 18:15:39,771] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:39,994] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:15:40,224] {logging_mixin.py:115} INFO - [2022-10-21 18:15:40,224] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:15:40,291] {logging_mixin.py:115} INFO - [2022-10-21 18:15:40,291] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:15:39.989507+00:00, run_after=2022-10-22T18:15:39.989507+00:00
[2022-10-21 18:15:40,319] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.569 seconds
[2022-10-21 18:20:34,106] {processor.py:153} INFO - Started process (PID=89840) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:20:34,107] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:20:34,093] {logging_mixin.py:115} INFO - [2022-10-21 18:20:34,092] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:20:34,240] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:20:34,403] {logging_mixin.py:115} INFO - [2022-10-21 18:20:34,403] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:20:34,436] {logging_mixin.py:115} INFO - [2022-10-21 18:20:34,436] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:20:34.236852+00:00, run_after=2022-10-22T18:20:34.236852+00:00
[2022-10-21 18:20:34,457] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.377 seconds
[2022-10-21 18:20:42,781] {processor.py:153} INFO - Started process (PID=25953) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:20:42,782] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:20:42,784] {logging_mixin.py:115} INFO - [2022-10-21 18:20:42,784] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:20:42,909] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:20:42,940] {logging_mixin.py:115} INFO - [2022-10-21 18:20:42,940] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:20:42,988] {logging_mixin.py:115} INFO - [2022-10-21 18:20:42,987] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:20:42.903489+00:00, run_after=2022-10-22T18:20:42.903489+00:00
[2022-10-21 18:20:43,001] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.228 seconds
[2022-10-21 18:28:54,336] {processor.py:153} INFO - Started process (PID=90342) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:28:54,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:28:54,343] {logging_mixin.py:115} INFO - [2022-10-21 18:28:54,343] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:28:54,519] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:28:54,706] {logging_mixin.py:115} INFO - [2022-10-21 18:28:54,706] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:28:54,748] {logging_mixin.py:115} INFO - [2022-10-21 18:28:54,748] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:28:54.515460+00:00, run_after=2022-10-22T18:28:54.515460+00:00
[2022-10-21 18:28:54,779] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.448 seconds
[2022-10-21 18:29:00,148] {processor.py:153} INFO - Started process (PID=26342) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:00,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:29:00,152] {logging_mixin.py:115} INFO - [2022-10-21 18:29:00,152] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:00,297] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:00,334] {logging_mixin.py:115} INFO - [2022-10-21 18:29:00,334] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:29:00,370] {logging_mixin.py:115} INFO - [2022-10-21 18:29:00,370] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:29:00.292797+00:00, run_after=2022-10-22T18:29:00.292797+00:00
[2022-10-21 18:29:00,393] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.250 seconds
[2022-10-21 18:29:27,471] {processor.py:153} INFO - Started process (PID=90842) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:27,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:29:27,476] {logging_mixin.py:115} INFO - [2022-10-21 18:29:27,476] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:27,646] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:27,778] {logging_mixin.py:115} INFO - [2022-10-21 18:29:27,778] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:29:27,810] {logging_mixin.py:115} INFO - [2022-10-21 18:29:27,810] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:29:27.635869+00:00, run_after=2022-10-22T18:29:27.635869+00:00
[2022-10-21 18:29:27,832] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.381 seconds
[2022-10-21 18:29:31,256] {processor.py:153} INFO - Started process (PID=26822) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:31,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 18:29:31,261] {logging_mixin.py:115} INFO - [2022-10-21 18:29:31,260] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:31,445] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 18:29:31,503] {logging_mixin.py:115} INFO - [2022-10-21 18:29:31,503] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 18:29:31,564] {logging_mixin.py:115} INFO - [2022-10-21 18:29:31,564] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T18:29:31.437159+00:00, run_after=2022-10-22T18:29:31.437159+00:00
[2022-10-21 18:29:31,599] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.350 seconds
[2022-10-21 19:05:59,044] {processor.py:153} INFO - Started process (PID=27067) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:05:59,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:05:59,048] {logging_mixin.py:115} INFO - [2022-10-21 19:05:59,048] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:05:59,189] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:05:59,316] {logging_mixin.py:115} INFO - [2022-10-21 19:05:59,316] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:05:59,341] {logging_mixin.py:115} INFO - [2022-10-21 19:05:59,341] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:05:59.182862+00:00, run_after=2022-10-22T19:05:59.182862+00:00
[2022-10-21 19:05:59,360] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.333 seconds
[2022-10-21 19:05:59,758] {processor.py:153} INFO - Started process (PID=91154) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:05:59,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:05:59,760] {logging_mixin.py:115} INFO - [2022-10-21 19:05:59,760] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:05:59,891] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:05:59,918] {logging_mixin.py:115} INFO - [2022-10-21 19:05:59,918] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:05:59,944] {logging_mixin.py:115} INFO - [2022-10-21 19:05:59,943] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:05:59.887381+00:00, run_after=2022-10-22T19:05:59.887381+00:00
[2022-10-21 19:05:59,960] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.206 seconds
[2022-10-21 19:06:32,843] {processor.py:153} INFO - Started process (PID=27585) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:06:32,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:06:32,847] {logging_mixin.py:115} INFO - [2022-10-21 19:06:32,847] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:06:32,944] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:06:33,057] {logging_mixin.py:115} INFO - [2022-10-21 19:06:33,057] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:06:33,088] {logging_mixin.py:115} INFO - [2022-10-21 19:06:33,088] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:06:32.940320+00:00, run_after=2022-10-22T19:06:32.940320+00:00
[2022-10-21 19:06:33,116] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.282 seconds
[2022-10-21 19:06:33,767] {processor.py:153} INFO - Started process (PID=91661) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:06:33,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:06:33,770] {logging_mixin.py:115} INFO - [2022-10-21 19:06:33,770] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:06:33,883] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:06:33,936] {logging_mixin.py:115} INFO - [2022-10-21 19:06:33,935] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:06:33,968] {logging_mixin.py:115} INFO - [2022-10-21 19:06:33,968] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:06:33.879109+00:00, run_after=2022-10-22T19:06:33.879109+00:00
[2022-10-21 19:06:33,995] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.235 seconds
[2022-10-21 19:07:03,762] {processor.py:153} INFO - Started process (PID=28089) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:07:03,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:07:03,768] {logging_mixin.py:115} INFO - [2022-10-21 19:07:03,768] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:07:03,917] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:07:04,012] {logging_mixin.py:115} INFO - [2022-10-21 19:07:04,011] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:07:04,042] {logging_mixin.py:115} INFO - [2022-10-21 19:07:04,042] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:07:03.914476+00:00, run_after=2022-10-22T19:07:03.914476+00:00
[2022-10-21 19:07:04,063] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.308 seconds
[2022-10-21 19:07:06,667] {processor.py:153} INFO - Started process (PID=92165) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:07:06,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:07:06,676] {logging_mixin.py:115} INFO - [2022-10-21 19:07:06,675] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:07:07,912] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:07:07,984] {logging_mixin.py:115} INFO - [2022-10-21 19:07:07,983] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:07:08,078] {logging_mixin.py:115} INFO - [2022-10-21 19:07:08,078] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:07:07.905309+00:00, run_after=2022-10-22T19:07:07.905309+00:00
[2022-10-21 19:07:08,094] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.441 seconds
[2022-10-21 19:11:56,147] {processor.py:153} INFO - Started process (PID=92206) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:11:56,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:11:56,150] {logging_mixin.py:115} INFO - [2022-10-21 19:11:56,150] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:11:56,238] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:11:56,351] {logging_mixin.py:115} INFO - [2022-10-21 19:11:56,351] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:11:56,380] {logging_mixin.py:115} INFO - [2022-10-21 19:11:56,380] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:11:56.230038+00:00, run_after=2022-10-22T19:11:56.230038+00:00
[2022-10-21 19:11:56,399] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.256 seconds
[2022-10-21 19:12:02,331] {processor.py:153} INFO - Started process (PID=28195) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:12:02,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:12:02,334] {logging_mixin.py:115} INFO - [2022-10-21 19:12:02,334] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:12:02,423] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:12:02,449] {logging_mixin.py:115} INFO - [2022-10-21 19:12:02,449] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:12:02,499] {logging_mixin.py:115} INFO - [2022-10-21 19:12:02,498] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:12:02.419249+00:00, run_after=2022-10-22T19:12:02.419249+00:00
[2022-10-21 19:12:02,529] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.204 seconds
[2022-10-21 19:30:04,914] {processor.py:153} INFO - Started process (PID=92735) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:04,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:30:04,917] {logging_mixin.py:115} INFO - [2022-10-21 19:30:04,917] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:05,011] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:05,158] {logging_mixin.py:115} INFO - [2022-10-21 19:30:05,158] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:30:05,197] {logging_mixin.py:115} INFO - [2022-10-21 19:30:05,197] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:30:05.007138+00:00, run_after=2022-10-22T19:30:05.007138+00:00
[2022-10-21 19:30:05,213] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.305 seconds
[2022-10-21 19:30:10,458] {processor.py:153} INFO - Started process (PID=28671) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:10,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:30:10,466] {logging_mixin.py:115} INFO - [2022-10-21 19:30:10,466] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:10,608] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:10,643] {logging_mixin.py:115} INFO - [2022-10-21 19:30:10,643] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:30:10,674] {logging_mixin.py:115} INFO - [2022-10-21 19:30:10,674] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:30:10.598760+00:00, run_after=2022-10-22T19:30:10.598760+00:00
[2022-10-21 19:30:10,689] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.236 seconds
[2022-10-21 19:30:35,719] {processor.py:153} INFO - Started process (PID=93242) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:35,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:30:35,723] {logging_mixin.py:115} INFO - [2022-10-21 19:30:35,723] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:35,832] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:35,923] {logging_mixin.py:115} INFO - [2022-10-21 19:30:35,923] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:30:35,946] {logging_mixin.py:115} INFO - [2022-10-21 19:30:35,946] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:30:35.828219+00:00, run_after=2022-10-22T19:30:35.828219+00:00
[2022-10-21 19:30:35,960] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.252 seconds
[2022-10-21 19:30:40,822] {processor.py:153} INFO - Started process (PID=29178) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:40,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:30:40,825] {logging_mixin.py:115} INFO - [2022-10-21 19:30:40,825] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:40,937] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:30:40,982] {logging_mixin.py:115} INFO - [2022-10-21 19:30:40,982] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:30:41,032] {logging_mixin.py:115} INFO - [2022-10-21 19:30:41,032] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:30:40.933037+00:00, run_after=2022-10-22T19:30:40.933037+00:00
[2022-10-21 19:30:41,060] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.245 seconds
[2022-10-21 19:31:06,715] {processor.py:153} INFO - Started process (PID=93704) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:06,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:31:06,718] {logging_mixin.py:115} INFO - [2022-10-21 19:31:06,718] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:06,895] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:07,079] {logging_mixin.py:115} INFO - [2022-10-21 19:31:07,078] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:31:07,117] {logging_mixin.py:115} INFO - [2022-10-21 19:31:07,116] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:31:06.884664+00:00, run_after=2022-10-22T19:31:06.884664+00:00
[2022-10-21 19:31:07,158] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.456 seconds
[2022-10-21 19:31:15,294] {processor.py:153} INFO - Started process (PID=29671) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:15,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:31:15,298] {logging_mixin.py:115} INFO - [2022-10-21 19:31:15,298] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:15,475] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:15,527] {logging_mixin.py:115} INFO - [2022-10-21 19:31:15,527] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:31:15,589] {logging_mixin.py:115} INFO - [2022-10-21 19:31:15,589] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:31:15.472315+00:00, run_after=2022-10-22T19:31:15.472315+00:00
[2022-10-21 19:31:15,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.365 seconds
[2022-10-21 19:31:40,243] {processor.py:153} INFO - Started process (PID=94186) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:40,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:31:40,246] {logging_mixin.py:115} INFO - [2022-10-21 19:31:40,246] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:40,384] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:40,608] {logging_mixin.py:115} INFO - [2022-10-21 19:31:40,608] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:31:40,662] {logging_mixin.py:115} INFO - [2022-10-21 19:31:40,662] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:31:40.377657+00:00, run_after=2022-10-22T19:31:40.377657+00:00
[2022-10-21 19:31:40,695] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.457 seconds
[2022-10-21 19:31:47,336] {processor.py:153} INFO - Started process (PID=30109) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:47,339] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:31:47,341] {logging_mixin.py:115} INFO - [2022-10-21 19:31:47,341] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:47,540] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:31:47,614] {logging_mixin.py:115} INFO - [2022-10-21 19:31:47,613] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:31:47,701] {logging_mixin.py:115} INFO - [2022-10-21 19:31:47,701] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:31:47.535500+00:00, run_after=2022-10-22T19:31:47.535500+00:00
[2022-10-21 19:31:47,746] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.429 seconds
[2022-10-21 19:32:17,179] {processor.py:153} INFO - Started process (PID=94575) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:17,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:32:17,189] {logging_mixin.py:115} INFO - [2022-10-21 19:32:17,188] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:17,412] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:17,578] {logging_mixin.py:115} INFO - [2022-10-21 19:32:17,578] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:32:17,627] {logging_mixin.py:115} INFO - [2022-10-21 19:32:17,626] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:32:17.407940+00:00, run_after=2022-10-22T19:32:17.407940+00:00
[2022-10-21 19:32:17,665] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.513 seconds
[2022-10-21 19:32:27,856] {processor.py:153} INFO - Started process (PID=30551) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:27,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:32:27,861] {logging_mixin.py:115} INFO - [2022-10-21 19:32:27,861] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:28,033] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:28,074] {logging_mixin.py:115} INFO - [2022-10-21 19:32:28,074] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:32:28,115] {logging_mixin.py:115} INFO - [2022-10-21 19:32:28,115] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:32:28.027061+00:00, run_after=2022-10-22T19:32:28.027061+00:00
[2022-10-21 19:32:28,145] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.308 seconds
[2022-10-21 19:32:57,551] {processor.py:153} INFO - Started process (PID=95060) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:57,552] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:32:57,555] {logging_mixin.py:115} INFO - [2022-10-21 19:32:57,555] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:57,697] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:32:57,845] {logging_mixin.py:115} INFO - [2022-10-21 19:32:57,845] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:32:57,901] {logging_mixin.py:115} INFO - [2022-10-21 19:32:57,901] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:32:57.692842+00:00, run_after=2022-10-22T19:32:57.692842+00:00
[2022-10-21 19:32:57,941] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.405 seconds
[2022-10-21 19:33:03,447] {processor.py:153} INFO - Started process (PID=31020) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:03,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:33:03,454] {logging_mixin.py:115} INFO - [2022-10-21 19:33:03,453] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:03,600] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:03,648] {logging_mixin.py:115} INFO - [2022-10-21 19:33:03,647] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:33:03,693] {logging_mixin.py:115} INFO - [2022-10-21 19:33:03,693] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:33:03.589413+00:00, run_after=2022-10-22T19:33:03.589413+00:00
[2022-10-21 19:33:03,722] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.285 seconds
[2022-10-21 19:33:30,721] {processor.py:153} INFO - Started process (PID=95505) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:30,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:33:30,728] {logging_mixin.py:115} INFO - [2022-10-21 19:33:30,727] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:30,864] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:31,031] {logging_mixin.py:115} INFO - [2022-10-21 19:33:31,031] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:33:31,087] {logging_mixin.py:115} INFO - [2022-10-21 19:33:31,087] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:33:30.859454+00:00, run_after=2022-10-22T19:33:30.859454+00:00
[2022-10-21 19:33:31,125] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.411 seconds
[2022-10-21 19:33:34,564] {processor.py:153} INFO - Started process (PID=31439) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:34,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:33:34,568] {logging_mixin.py:115} INFO - [2022-10-21 19:33:34,568] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:34,764] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:33:34,794] {logging_mixin.py:115} INFO - [2022-10-21 19:33:34,793] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:33:34,834] {logging_mixin.py:115} INFO - [2022-10-21 19:33:34,834] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:33:34.757669+00:00, run_after=2022-10-22T19:33:34.757669+00:00
[2022-10-21 19:33:34,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.307 seconds
[2022-10-21 19:34:11,144] {processor.py:153} INFO - Started process (PID=31803) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:34:11,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:34:11,150] {logging_mixin.py:115} INFO - [2022-10-21 19:34:11,149] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:34:11,306] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:34:11,460] {logging_mixin.py:115} INFO - [2022-10-21 19:34:11,460] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:34:11,498] {logging_mixin.py:115} INFO - [2022-10-21 19:34:11,498] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:34:11.301264+00:00, run_after=2022-10-22T19:34:11.301264+00:00
[2022-10-21 19:34:11,555] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.430 seconds
[2022-10-21 19:34:16,188] {processor.py:153} INFO - Started process (PID=95913) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:34:16,191] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:34:16,201] {logging_mixin.py:115} INFO - [2022-10-21 19:34:16,201] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:34:16,545] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:34:16,596] {logging_mixin.py:115} INFO - [2022-10-21 19:34:16,596] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:34:16,671] {logging_mixin.py:115} INFO - [2022-10-21 19:34:16,671] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:34:16.538723+00:00, run_after=2022-10-22T19:34:16.538723+00:00
[2022-10-21 19:34:16,704] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.533 seconds
[2022-10-21 19:37:35,187] {processor.py:153} INFO - Started process (PID=31994) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:37:35,194] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:37:35,197] {logging_mixin.py:115} INFO - [2022-10-21 19:37:35,197] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:37:35,636] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:37:35,778] {logging_mixin.py:115} INFO - [2022-10-21 19:37:35,778] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:37:35,812] {logging_mixin.py:115} INFO - [2022-10-21 19:37:35,811] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:37:35.599147+00:00, run_after=2022-10-22T19:37:35.599147+00:00
[2022-10-21 19:37:35,841] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.669 seconds
[2022-10-21 19:37:38,135] {processor.py:153} INFO - Started process (PID=96028) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:37:38,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:37:38,150] {logging_mixin.py:115} INFO - [2022-10-21 19:37:38,150] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:37:38,378] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:37:38,429] {logging_mixin.py:115} INFO - [2022-10-21 19:37:38,428] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:37:38,510] {logging_mixin.py:115} INFO - [2022-10-21 19:37:38,510] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:37:38.359903+00:00, run_after=2022-10-22T19:37:38.359903+00:00
[2022-10-21 19:37:38,540] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.428 seconds
[2022-10-21 19:38:42,140] {processor.py:153} INFO - Started process (PID=32530) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:38:42,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:38:42,194] {logging_mixin.py:115} INFO - [2022-10-21 19:38:42,194] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:38:42,826] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:38:43,160] {logging_mixin.py:115} INFO - [2022-10-21 19:38:43,159] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:38:44,024] {logging_mixin.py:115} INFO - [2022-10-21 19:38:44,023] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:38:42.809022+00:00, run_after=2022-10-22T19:38:42.809022+00:00
[2022-10-21 19:38:44,137] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.052 seconds
[2022-10-21 19:38:50,140] {processor.py:153} INFO - Started process (PID=96554) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:38:50,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:38:50,147] {logging_mixin.py:115} INFO - [2022-10-21 19:38:50,147] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:38:50,370] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:38:50,409] {logging_mixin.py:115} INFO - [2022-10-21 19:38:50,408] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:38:50,474] {logging_mixin.py:115} INFO - [2022-10-21 19:38:50,474] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:38:50.363807+00:00, run_after=2022-10-22T19:38:50.363807+00:00
[2022-10-21 19:38:50,523] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.390 seconds
[2022-10-21 19:39:25,126] {processor.py:153} INFO - Started process (PID=32835) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:39:25,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:39:25,132] {logging_mixin.py:115} INFO - [2022-10-21 19:39:25,132] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:39:25,480] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:39:25,990] {logging_mixin.py:115} INFO - [2022-10-21 19:39:25,990] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:39:26,150] {logging_mixin.py:115} INFO - [2022-10-21 19:39:26,149] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:39:25.456611+00:00, run_after=2022-10-22T19:39:25.456611+00:00
[2022-10-21 19:39:26,197] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.097 seconds
[2022-10-21 19:39:42,437] {processor.py:153} INFO - Started process (PID=96875) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:39:42,448] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:39:42,470] {logging_mixin.py:115} INFO - [2022-10-21 19:39:42,468] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:39:42,734] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:39:42,864] {logging_mixin.py:115} INFO - [2022-10-21 19:39:42,863] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:39:42,929] {logging_mixin.py:115} INFO - [2022-10-21 19:39:42,929] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:39:42.723322+00:00, run_after=2022-10-22T19:39:42.723322+00:00
[2022-10-21 19:39:42,982] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.559 seconds
[2022-10-21 19:40:06,540] {processor.py:153} INFO - Started process (PID=33151) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:40:06,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:40:06,549] {logging_mixin.py:115} INFO - [2022-10-21 19:40:06,549] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:40:06,963] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:40:07,380] {logging_mixin.py:115} INFO - [2022-10-21 19:40:07,368] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:40:07,481] {logging_mixin.py:115} INFO - [2022-10-21 19:40:07,480] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:40:06.949726+00:00, run_after=2022-10-22T19:40:06.949726+00:00
[2022-10-21 19:40:07,526] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.018 seconds
[2022-10-21 19:40:30,856] {processor.py:153} INFO - Started process (PID=97253) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:40:30,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:40:30,862] {logging_mixin.py:115} INFO - [2022-10-21 19:40:30,862] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:40:31,197] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:40:31,290] {logging_mixin.py:115} INFO - [2022-10-21 19:40:31,289] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 19:40:31,379] {logging_mixin.py:115} INFO - [2022-10-21 19:40:31,376] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T19:40:31.178599+00:00, run_after=2022-10-22T19:40:31.178599+00:00
[2022-10-21 19:40:31,437] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.593 seconds
[2022-10-21 19:40:40,665] {processor.py:153} INFO - Started process (PID=33415) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:40:40,669] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:40:40,673] {logging_mixin.py:115} INFO - [2022-10-21 19:40:40,672] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:41:09,021] {processor.py:153} INFO - Started process (PID=97525) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:41:09,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:41:09,042] {logging_mixin.py:115} INFO - [2022-10-21 19:41:09,041] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:41:09,583] {logging_mixin.py:115} INFO - [2022-10-21 19:41:09,581] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 12, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 19:41:09,587] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:41:09,666] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.653 seconds
[2022-10-21 19:41:10,269] {logging_mixin.py:115} INFO - [2022-10-21 19:41:10,266] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 12, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
AttributeError: 'SparkSession' object has no attribute 'config'
[2022-10-21 19:41:10,277] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:41:10,341] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 29.711 seconds
[2022-10-21 19:41:46,430] {processor.py:153} INFO - Started process (PID=97832) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:41:46,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:41:46,440] {logging_mixin.py:115} INFO - [2022-10-21 19:41:46,439] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:41:46,978] {logging_mixin.py:115} INFO - [2022-10-21 19:41:46,974] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:41:46,979] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:41:47,063] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.651 seconds
[2022-10-21 19:42:44,675] {processor.py:153} INFO - Started process (PID=34240) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:42:44,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:42:44,681] {logging_mixin.py:115} INFO - [2022-10-21 19:42:44,681] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:42:44,860] {logging_mixin.py:115} INFO - [2022-10-21 19:42:44,857] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:42:44,861] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:42:44,909] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.249 seconds
[2022-10-21 19:42:50,205] {processor.py:153} INFO - Started process (PID=98113) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:42:50,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:42:50,210] {logging_mixin.py:115} INFO - [2022-10-21 19:42:50,210] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:42:50,458] {logging_mixin.py:115} INFO - [2022-10-21 19:42:50,440] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:42:50,461] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:42:50,532] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.340 seconds
[2022-10-21 19:43:15,367] {processor.py:153} INFO - Started process (PID=34586) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:15,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:43:15,371] {logging_mixin.py:115} INFO - [2022-10-21 19:43:15,371] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:15,584] {logging_mixin.py:115} INFO - [2022-10-21 19:43:15,581] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:43:15,587] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:15,663] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.308 seconds
[2022-10-21 19:43:36,736] {processor.py:153} INFO - Started process (PID=98615) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:36,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:43:36,740] {logging_mixin.py:115} INFO - [2022-10-21 19:43:36,740] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:36,912] {logging_mixin.py:115} INFO - [2022-10-21 19:43:36,900] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:43:36,913] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:36,957] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.228 seconds
[2022-10-21 19:43:55,030] {processor.py:153} INFO - Started process (PID=35073) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:55,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:43:55,035] {logging_mixin.py:115} INFO - [2022-10-21 19:43:55,034] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:55,204] {logging_mixin.py:115} INFO - [2022-10-21 19:43:55,202] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:43:55,207] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:43:55,264] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.244 seconds
[2022-10-21 19:44:08,304] {processor.py:153} INFO - Started process (PID=98972) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:08,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:44:08,308] {logging_mixin.py:115} INFO - [2022-10-21 19:44:08,308] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:08,459] {logging_mixin.py:115} INFO - [2022-10-21 19:44:08,456] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:44:08,461] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:08,498] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.200 seconds
[2022-10-21 19:44:32,364] {processor.py:153} INFO - Started process (PID=35509) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:32,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:44:32,367] {logging_mixin.py:115} INFO - [2022-10-21 19:44:32,367] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:32,593] {logging_mixin.py:115} INFO - [2022-10-21 19:44:32,590] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:44:32,596] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:32,665] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.311 seconds
[2022-10-21 19:44:38,994] {processor.py:153} INFO - Started process (PID=99299) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:38,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:44:39,001] {logging_mixin.py:115} INFO - [2022-10-21 19:44:39,001] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:39,200] {logging_mixin.py:115} INFO - [2022-10-21 19:44:39,194] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:44:39,204] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:44:39,350] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.378 seconds
[2022-10-21 19:45:12,449] {processor.py:153} INFO - Started process (PID=99671) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:12,452] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:45:12,459] {logging_mixin.py:115} INFO - [2022-10-21 19:45:12,459] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:12,765] {logging_mixin.py:115} INFO - [2022-10-21 19:45:12,762] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:45:12,766] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:12,844] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.408 seconds
[2022-10-21 19:45:12,995] {processor.py:153} INFO - Started process (PID=36002) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:12,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:45:12,999] {logging_mixin.py:115} INFO - [2022-10-21 19:45:12,999] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:13,216] {logging_mixin.py:115} INFO - [2022-10-21 19:45:13,211] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:45:13,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:13,268] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.288 seconds
[2022-10-21 19:45:43,572] {processor.py:153} INFO - Started process (PID=324) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:43,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:45:43,577] {logging_mixin.py:115} INFO - [2022-10-21 19:45:43,577] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:43,825] {logging_mixin.py:115} INFO - [2022-10-21 19:45:43,821] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:45:43,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:43,891] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.335 seconds
[2022-10-21 19:45:50,483] {processor.py:153} INFO - Started process (PID=36446) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:50,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:45:50,492] {logging_mixin.py:115} INFO - [2022-10-21 19:45:50,492] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:50,632] {logging_mixin.py:115} INFO - [2022-10-21 19:45:50,630] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:45:50,634] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:45:50,689] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.224 seconds
[2022-10-21 19:46:26,495] {processor.py:153} INFO - Started process (PID=36881) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:46:26,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:46:26,503] {logging_mixin.py:115} INFO - [2022-10-21 19:46:26,503] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:46:26,792] {logging_mixin.py:115} INFO - [2022-10-21 19:46:26,787] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:46:26,794] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:46:26,875] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.394 seconds
[2022-10-21 19:46:30,062] {processor.py:153} INFO - Started process (PID=840) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:46:30,070] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:46:30,087] {logging_mixin.py:115} INFO - [2022-10-21 19:46:30,086] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:46:30,305] {logging_mixin.py:115} INFO - [2022-10-21 19:46:30,301] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:46:30,306] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:46:30,378] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.328 seconds
[2022-10-21 19:47:28,197] {processor.py:153} INFO - Started process (PID=37249) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:47:28,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:47:28,202] {logging_mixin.py:115} INFO - [2022-10-21 19:47:28,202] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:47:28,343] {logging_mixin.py:115} INFO - [2022-10-21 19:47:28,340] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:47:28,345] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:47:28,405] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.218 seconds
[2022-10-21 19:47:34,145] {processor.py:153} INFO - Started process (PID=1227) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:47:34,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:47:34,149] {logging_mixin.py:115} INFO - [2022-10-21 19:47:34,149] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:47:34,391] {logging_mixin.py:115} INFO - [2022-10-21 19:47:34,381] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:47:34,396] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:47:34,471] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.335 seconds
[2022-10-21 19:48:09,207] {processor.py:153} INFO - Started process (PID=37702) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:09,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:48:09,211] {logging_mixin.py:115} INFO - [2022-10-21 19:48:09,211] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:09,403] {logging_mixin.py:115} INFO - [2022-10-21 19:48:09,400] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:48:09,404] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:09,472] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.273 seconds
[2022-10-21 19:48:12,349] {processor.py:153} INFO - Started process (PID=1634) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:12,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:48:12,354] {logging_mixin.py:115} INFO - [2022-10-21 19:48:12,354] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:12,577] {logging_mixin.py:115} INFO - [2022-10-21 19:48:12,573] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:48:12,579] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:12,644] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.304 seconds
[2022-10-21 19:48:52,503] {processor.py:153} INFO - Started process (PID=38214) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:52,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:48:52,517] {logging_mixin.py:115} INFO - [2022-10-21 19:48:52,517] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:52,826] {logging_mixin.py:115} INFO - [2022-10-21 19:48:52,817] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:48:52,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:52,877] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.390 seconds
[2022-10-21 19:48:56,409] {processor.py:153} INFO - Started process (PID=2150) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:56,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:48:56,422] {logging_mixin.py:115} INFO - [2022-10-21 19:48:56,421] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:56,675] {logging_mixin.py:115} INFO - [2022-10-21 19:48:56,672] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:48:56,677] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:48:56,745] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.354 seconds
[2022-10-21 19:49:32,613] {processor.py:153} INFO - Started process (PID=38689) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:49:32,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:49:32,619] {logging_mixin.py:115} INFO - [2022-10-21 19:49:32,619] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:49:32,838] {logging_mixin.py:115} INFO - [2022-10-21 19:49:32,834] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:49:32,839] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:49:32,908] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.305 seconds
[2022-10-21 19:49:39,421] {processor.py:153} INFO - Started process (PID=2648) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:49:39,424] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:49:39,433] {logging_mixin.py:115} INFO - [2022-10-21 19:49:39,433] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:49:39,778] {logging_mixin.py:115} INFO - [2022-10-21 19:49:39,772] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:49:39,779] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:49:39,849] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.446 seconds
[2022-10-21 19:50:11,144] {processor.py:153} INFO - Started process (PID=2986) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:11,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:50:11,155] {logging_mixin.py:115} INFO - [2022-10-21 19:50:11,155] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:11,430] {logging_mixin.py:115} INFO - [2022-10-21 19:50:11,426] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:50:11,432] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:11,503] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.372 seconds
[2022-10-21 19:50:14,566] {processor.py:153} INFO - Started process (PID=39173) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:14,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:50:14,570] {logging_mixin.py:115} INFO - [2022-10-21 19:50:14,570] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:14,827] {logging_mixin.py:115} INFO - [2022-10-21 19:50:14,820] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:50:14,829] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:14,897] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.348 seconds
[2022-10-21 19:50:45,134] {processor.py:153} INFO - Started process (PID=3351) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:45,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:50:45,141] {logging_mixin.py:115} INFO - [2022-10-21 19:50:45,140] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:45,419] {logging_mixin.py:115} INFO - [2022-10-21 19:50:45,416] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:50:45,421] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:45,488] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.365 seconds
[2022-10-21 19:50:45,745] {processor.py:153} INFO - Started process (PID=39507) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:45,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:50:45,751] {logging_mixin.py:115} INFO - [2022-10-21 19:50:45,750] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:46,012] {logging_mixin.py:115} INFO - [2022-10-21 19:50:46,009] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:50:46,014] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:50:46,073] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.340 seconds
[2022-10-21 19:51:17,189] {processor.py:153} INFO - Started process (PID=39870) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:17,191] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:51:17,194] {logging_mixin.py:115} INFO - [2022-10-21 19:51:17,193] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:17,439] {logging_mixin.py:115} INFO - [2022-10-21 19:51:17,436] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:51:17,444] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:17,563] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.381 seconds
[2022-10-21 19:51:20,625] {processor.py:153} INFO - Started process (PID=3735) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:20,630] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:51:20,632] {logging_mixin.py:115} INFO - [2022-10-21 19:51:20,632] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:20,883] {logging_mixin.py:115} INFO - [2022-10-21 19:51:20,879] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:51:20,884] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:20,925] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.314 seconds
[2022-10-21 19:51:53,796] {processor.py:153} INFO - Started process (PID=4093) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:53,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:51:53,803] {logging_mixin.py:115} INFO - [2022-10-21 19:51:53,803] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:54,234] {logging_mixin.py:115} INFO - [2022-10-21 19:51:54,227] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:51:54,237] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:51:54,303] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.515 seconds
[2022-10-21 19:52:38,652] {processor.py:153} INFO - Started process (PID=40399) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:52:38,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:52:38,661] {logging_mixin.py:115} INFO - [2022-10-21 19:52:38,661] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:52:38,891] {logging_mixin.py:115} INFO - [2022-10-21 19:52:38,871] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:52:38,896] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:52:38,946] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.304 seconds
[2022-10-21 19:52:50,296] {processor.py:153} INFO - Started process (PID=4312) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:52:50,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:52:50,304] {logging_mixin.py:115} INFO - [2022-10-21 19:52:50,303] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:52:50,527] {logging_mixin.py:115} INFO - [2022-10-21 19:52:50,521] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:52:50,530] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:52:50,603] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.325 seconds
[2022-10-21 19:53:16,301] {processor.py:153} INFO - Started process (PID=40815) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:53:16,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:53:16,307] {logging_mixin.py:115} INFO - [2022-10-21 19:53:16,306] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:53:16,771] {logging_mixin.py:115} INFO - [2022-10-21 19:53:16,768] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:53:16,772] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:53:16,849] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.559 seconds
[2022-10-21 19:53:34,682] {processor.py:153} INFO - Started process (PID=4818) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:53:34,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:53:34,693] {logging_mixin.py:115} INFO - [2022-10-21 19:53:34,693] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:53:35,054] {logging_mixin.py:115} INFO - [2022-10-21 19:53:35,051] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:53:35,056] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:53:35,134] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.463 seconds
[2022-10-21 19:54:02,319] {processor.py:153} INFO - Started process (PID=41323) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:54:02,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:54:02,324] {logging_mixin.py:115} INFO - [2022-10-21 19:54:02,324] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:54:02,684] {logging_mixin.py:115} INFO - [2022-10-21 19:54:02,682] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:54:02,685] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:54:02,713] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.400 seconds
[2022-10-21 19:54:06,044] {processor.py:153} INFO - Started process (PID=5151) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:54:06,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 19:54:06,090] {logging_mixin.py:115} INFO - [2022-10-21 19:54:06,078] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:54:06,768] {logging_mixin.py:115} INFO - [2022-10-21 19:54:06,765] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 19:54:06,770] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 19:54:06,859] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.932 seconds
[2022-10-21 20:03:03,503] {processor.py:153} INFO - Started process (PID=41522) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:03,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:03:03,507] {logging_mixin.py:115} INFO - [2022-10-21 20:03:03,507] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:03,676] {logging_mixin.py:115} INFO - [2022-10-21 20:03:03,673] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:03:03,679] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:03,724] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.226 seconds
[2022-10-21 20:03:04,757] {processor.py:153} INFO - Started process (PID=5363) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:04,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:03:04,761] {logging_mixin.py:115} INFO - [2022-10-21 20:03:04,761] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:04,888] {logging_mixin.py:115} INFO - [2022-10-21 20:03:04,886] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:03:04,890] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:04,922] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.176 seconds
[2022-10-21 20:03:37,042] {processor.py:153} INFO - Started process (PID=42001) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:37,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:03:37,046] {logging_mixin.py:115} INFO - [2022-10-21 20:03:37,045] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:37,215] {logging_mixin.py:115} INFO - [2022-10-21 20:03:37,211] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:03:37,225] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:37,274] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.241 seconds
[2022-10-21 20:03:37,713] {processor.py:153} INFO - Started process (PID=5798) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:37,715] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:03:37,717] {logging_mixin.py:115} INFO - [2022-10-21 20:03:37,717] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:37,892] {logging_mixin.py:115} INFO - [2022-10-21 20:03:37,887] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:03:37,896] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:03:37,952] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.248 seconds
[2022-10-21 20:04:09,151] {processor.py:153} INFO - Started process (PID=42429) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:09,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:04:09,177] {logging_mixin.py:115} INFO - [2022-10-21 20:04:09,177] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:10,227] {logging_mixin.py:115} INFO - [2022-10-21 20:04:09,346] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:04:10,230] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:10,310] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.169 seconds
[2022-10-21 20:04:16,605] {processor.py:153} INFO - Started process (PID=6272) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:16,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:04:16,616] {logging_mixin.py:115} INFO - [2022-10-21 20:04:16,616] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:16,879] {logging_mixin.py:115} INFO - [2022-10-21 20:04:16,875] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:04:16,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:16,929] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.330 seconds
[2022-10-21 20:04:46,085] {processor.py:153} INFO - Started process (PID=42885) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:46,087] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:04:46,092] {logging_mixin.py:115} INFO - [2022-10-21 20:04:46,092] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:46,497] {logging_mixin.py:115} INFO - [2022-10-21 20:04:46,493] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:04:46,504] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:46,602] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.547 seconds
[2022-10-21 20:04:54,353] {processor.py:153} INFO - Started process (PID=6700) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:54,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:04:54,375] {logging_mixin.py:115} INFO - [2022-10-21 20:04:54,375] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:54,559] {logging_mixin.py:115} INFO - [2022-10-21 20:04:54,556] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:04:54,560] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:04:54,642] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.305 seconds
[2022-10-21 20:05:20,127] {processor.py:153} INFO - Started process (PID=43219) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:05:20,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:05:20,134] {logging_mixin.py:115} INFO - [2022-10-21 20:05:20,134] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:05:20,405] {logging_mixin.py:115} INFO - [2022-10-21 20:05:20,402] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:05:20,408] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:05:20,468] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.357 seconds
[2022-10-21 20:05:41,153] {processor.py:153} INFO - Started process (PID=7122) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:05:41,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:05:41,179] {logging_mixin.py:115} INFO - [2022-10-21 20:05:41,179] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:05:41,543] {logging_mixin.py:115} INFO - [2022-10-21 20:05:41,529] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:05:41,550] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:05:41,610] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.472 seconds
[2022-10-21 20:06:22,721] {processor.py:153} INFO - Started process (PID=7365) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:06:22,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:06:22,735] {logging_mixin.py:115} INFO - [2022-10-21 20:06:22,735] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:06:23,180] {logging_mixin.py:115} INFO - [2022-10-21 20:06:23,174] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 24, in <module>
    python_callable=pyspark.start_spark_session
AttributeError: module 'pyspark_scripts' has no attribute 'start_spark_session'
[2022-10-21 20:06:23,186] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:06:23,324] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.630 seconds
[2022-10-21 20:06:36,471] {processor.py:153} INFO - Started process (PID=43740) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:06:36,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:06:36,483] {logging_mixin.py:115} INFO - [2022-10-21 20:06:36,482] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:07:06,776] {logging_mixin.py:115} INFO - [2022-10-21 20:07:06,776] {timeout.py:67} ERROR - Process timed out, PID: 43740
[2022-10-21 20:07:06,789] {logging_mixin.py:115} INFO - [2022-10-21 20:07:06,785] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 43740
[2022-10-21 20:07:06,798] {logging_mixin.py:115} INFO - [2022-10-21 20:07:06,797] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:07:06,843] {logging_mixin.py:115} INFO - [2022-10-21 20:07:06,810] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 43740

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:07:06,871] {logging_mixin.py:115} INFO - [2022-10-21 20:07:06,871] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:07:06,874] {logging_mixin.py:115} INFO - [2022-10-21 20:07:06,873] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 272, in getOrCreate
    session = SparkSession(sc, options=self._options)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 307, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc(), options)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession
[2022-10-21 20:07:06,887] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:07:07,381] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.656 seconds
[2022-10-21 20:07:16,253] {processor.py:153} INFO - Started process (PID=7702) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:07:16,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:07:16,260] {logging_mixin.py:115} INFO - [2022-10-21 20:07:16,259] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:07:16,630] {logging_mixin.py:115} INFO - [2022-10-21 20:07:16,629] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:07:16,642] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:07:16,704] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.471 seconds
[2022-10-21 20:08:33,140] {processor.py:153} INFO - Started process (PID=44400) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:08:33,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:08:33,150] {logging_mixin.py:115} INFO - [2022-10-21 20:08:33,150] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:08:39,003] {processor.py:153} INFO - Started process (PID=8037) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:08:39,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:08:39,010] {logging_mixin.py:115} INFO - [2022-10-21 20:08:39,010] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:08:39,384] {logging_mixin.py:115} INFO - [2022-10-21 20:08:39,381] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:08:39,386] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:08:39,457] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.468 seconds
[2022-10-21 20:08:59,563] {logging_mixin.py:115} INFO - [2022-10-21 20:08:59,557] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
AttributeError: 'SparkSession' object has no attribute 'config'
[2022-10-21 20:08:59,573] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:08:59,711] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 26.619 seconds
[2022-10-21 20:09:16,687] {processor.py:153} INFO - Started process (PID=8316) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:09:16,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:09:16,696] {logging_mixin.py:115} INFO - [2022-10-21 20:09:16,696] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:09:16,729] {logging_mixin.py:115} INFO - [2022-10-21 20:09:16,724] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 26
    def load_and_normalize_json_data(json_path: str) -> None:
                                                            ^
IndentationError: unexpected unindent
[2022-10-21 20:09:16,731] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:09:16,844] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.180 seconds
[2022-10-21 20:09:40,074] {processor.py:153} INFO - Started process (PID=44942) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:09:40,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:09:40,085] {logging_mixin.py:115} INFO - [2022-10-21 20:09:40,084] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:09:40,143] {logging_mixin.py:115} INFO - [2022-10-21 20:09:40,137] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 26
    def load_and_normalize_json_data(json_path: str) -> None:
                                                            ^
IndentationError: unexpected unindent
[2022-10-21 20:09:40,146] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:09:40,277] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.248 seconds
[2022-10-21 20:10:12,288] {processor.py:153} INFO - Started process (PID=8622) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:10:12,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:10:12,302] {logging_mixin.py:115} INFO - [2022-10-21 20:10:12,301] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:10:12,351] {logging_mixin.py:115} INFO - [2022-10-21 20:10:12,339] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 26
    def load_and_normalize_json_data(json_path: str) -> None:
                                                            ^
IndentationError: unexpected unindent
[2022-10-21 20:10:12,363] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:10:12,490] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.223 seconds
[2022-10-21 20:10:31,019] {processor.py:153} INFO - Started process (PID=45254) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:10:31,026] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:10:31,030] {logging_mixin.py:115} INFO - [2022-10-21 20:10:31,030] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:10:31,071] {logging_mixin.py:115} INFO - [2022-10-21 20:10:31,065] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 26
    def load_and_normalize_json_data(json_path: str) -> None:
                                                            ^
IndentationError: unexpected unindent
[2022-10-21 20:10:31,073] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:10:31,145] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.149 seconds
[2022-10-21 20:11:07,728] {processor.py:153} INFO - Started process (PID=9004) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:11:07,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:11:07,736] {logging_mixin.py:115} INFO - [2022-10-21 20:11:07,736] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:11:08,308] {logging_mixin.py:115} INFO - [2022-10-21 20:11:08,306] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:11:08,314] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:11:08,500] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.823 seconds
[2022-10-21 20:11:21,680] {processor.py:153} INFO - Started process (PID=45579) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:11:21,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:11:21,690] {logging_mixin.py:115} INFO - [2022-10-21 20:11:21,689] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:11:51,682] {logging_mixin.py:115} INFO - [2022-10-21 20:11:51,681] {timeout.py:67} ERROR - Process timed out, PID: 45579
[2022-10-21 20:11:51,701] {logging_mixin.py:115} INFO - [2022-10-21 20:11:51,683] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 45579
[2022-10-21 20:11:51,704] {logging_mixin.py:115} INFO - [2022-10-21 20:11:51,704] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:11:51,709] {logging_mixin.py:115} INFO - [2022-10-21 20:11:51,707] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 45579

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:11:51,712] {logging_mixin.py:115} INFO - [2022-10-21 20:11:51,712] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:11:51,728] {logging_mixin.py:115} INFO - [2022-10-21 20:11:51,714] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:11:51,739] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:11:52,264] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.641 seconds
[2022-10-21 20:12:12,340] {processor.py:153} INFO - Started process (PID=9345) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:12:12,346] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:12:12,350] {logging_mixin.py:115} INFO - [2022-10-21 20:12:12,349] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:12:13,276] {logging_mixin.py:115} INFO - [2022-10-21 20:12:13,273] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:12:13,295] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:12:13,461] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.155 seconds
[2022-10-21 20:14:48,386] {processor.py:153} INFO - Started process (PID=46013) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:14:48,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:14:48,397] {logging_mixin.py:115} INFO - [2022-10-21 20:14:48,397] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:14:49,784] {processor.py:153} INFO - Started process (PID=9464) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:14:49,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:14:49,806] {logging_mixin.py:115} INFO - [2022-10-21 20:14:49,803] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:14:50,382] {logging_mixin.py:115} INFO - [2022-10-21 20:14:50,380] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:14:50,389] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:14:50,465] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.710 seconds
[2022-10-21 20:15:14,996] {logging_mixin.py:115} INFO - [2022-10-21 20:15:14,994] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
AttributeError: 'SparkSession' object has no attribute 'config'
[2022-10-21 20:15:15,001] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:15:15,138] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 26.791 seconds
[2022-10-21 20:16:12,832] {processor.py:153} INFO - Started process (PID=10011) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:16:12,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:16:12,846] {logging_mixin.py:115} INFO - [2022-10-21 20:16:12,845] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:16:13,491] {logging_mixin.py:115} INFO - [2022-10-21 20:16:13,480] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:16:13,504] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:16:13,661] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.853 seconds
[2022-10-21 20:16:34,937] {processor.py:153} INFO - Started process (PID=46828) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:16:34,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:16:34,946] {logging_mixin.py:115} INFO - [2022-10-21 20:16:34,946] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:17:04,549] {processor.py:153} INFO - Started process (PID=10344) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:17:04,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:17:04,564] {logging_mixin.py:115} INFO - [2022-10-21 20:17:04,563] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:17:04,943] {logging_mixin.py:115} INFO - [2022-10-21 20:17:04,942] {timeout.py:67} ERROR - Process timed out, PID: 46828
[2022-10-21 20:17:04,954] {logging_mixin.py:115} INFO - [2022-10-21 20:17:04,952] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 46828
[2022-10-21 20:17:04,961] {logging_mixin.py:115} INFO - [2022-10-21 20:17:04,960] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:17:04,970] {logging_mixin.py:115} INFO - [2022-10-21 20:17:04,963] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 46828

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:17:04,974] {logging_mixin.py:115} INFO - [2022-10-21 20:17:04,974] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:17:04,988] {logging_mixin.py:115} INFO - [2022-10-21 20:17:04,976] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:17:04,996] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:17:05,247] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.341 seconds
[2022-10-21 20:17:05,251] {logging_mixin.py:115} INFO - [2022-10-21 20:17:05,247] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.getOrCreate().config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:17:05,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:17:05,428] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.894 seconds
[2022-10-21 20:18:01,837] {processor.py:153} INFO - Started process (PID=47385) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:18:01,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:18:01,845] {logging_mixin.py:115} INFO - [2022-10-21 20:18:01,844] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:18:05,631] {processor.py:153} INFO - Started process (PID=10683) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:18:05,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:18:05,647] {logging_mixin.py:115} INFO - [2022-10-21 20:18:05,647] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:18:06,078] {logging_mixin.py:115} INFO - [2022-10-21 20:18:06,071] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:18:06,081] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:18:06,153] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.553 seconds
[2022-10-21 20:18:31,856] {logging_mixin.py:115} INFO - [2022-10-21 20:18:31,840] {timeout.py:67} ERROR - Process timed out, PID: 47385
[2022-10-21 20:18:31,953] {logging_mixin.py:115} INFO - [2022-10-21 20:18:31,886] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 47385
[2022-10-21 20:18:31,965] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:18:32,493] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.713 seconds
[2022-10-21 20:20:16,063] {processor.py:153} INFO - Started process (PID=11087) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:20:16,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:20:16,070] {logging_mixin.py:115} INFO - [2022-10-21 20:20:16,069] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:20:16,451] {logging_mixin.py:115} INFO - [2022-10-21 20:20:16,449] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21 20:20:16,454] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:20:16,523] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.471 seconds
[2022-10-21 20:29:26,229] {processor.py:153} INFO - Started process (PID=48884) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:29:26,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:29:26,240] {logging_mixin.py:115} INFO - [2022-10-21 20:29:26,240] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:29:56,247] {logging_mixin.py:115} INFO - [2022-10-21 20:29:56,242] {timeout.py:67} ERROR - Process timed out, PID: 48884
[2022-10-21 20:29:56,279] {logging_mixin.py:115} INFO - [2022-10-21 20:29:56,259] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 48884
[2022-10-21 20:29:56,286] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:29:57,991] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.802 seconds
[2022-10-21 20:32:09,247] {processor.py:153} INFO - Started process (PID=49747) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:32:09,255] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:32:09,259] {logging_mixin.py:115} INFO - [2022-10-21 20:32:09,259] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:32:39,262] {logging_mixin.py:115} INFO - [2022-10-21 20:32:39,262] {timeout.py:67} ERROR - Process timed out, PID: 49747
[2022-10-21 20:32:39,280] {logging_mixin.py:115} INFO - [2022-10-21 20:32:39,278] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 49747
[2022-10-21 20:32:39,285] {logging_mixin.py:115} INFO - [2022-10-21 20:32:39,284] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:32:39,309] {logging_mixin.py:115} INFO - [2022-10-21 20:32:39,289] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 49747

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:32:39,312] {logging_mixin.py:115} INFO - [2022-10-21 20:32:39,311] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:32:39,320] {logging_mixin.py:115} INFO - [2022-10-21 20:32:39,315] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:32:39,335] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:32:39,502] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.292 seconds
[2022-10-21 20:35:22,960] {processor.py:153} INFO - Started process (PID=50464) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:35:22,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:35:22,970] {logging_mixin.py:115} INFO - [2022-10-21 20:35:22,970] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:35:37,000] {processor.py:153} INFO - Started process (PID=15038) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:35:37,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:35:37,011] {logging_mixin.py:115} INFO - [2022-10-21 20:35:37,011] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:35:47,592] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:35:47,697] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:35:48,127] {logging_mixin.py:115} INFO - [2022-10-21 20:35:48,127] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:35:48,250] {logging_mixin.py:115} INFO - [2022-10-21 20:35:48,249] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:35:47.655025+00:00, run_after=2022-10-22T20:35:47.655025+00:00
[2022-10-21 20:35:48,359] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 25.450 seconds
[2022-10-21 20:36:07,005] {logging_mixin.py:115} INFO - [2022-10-21 20:36:07,000] {timeout.py:67} ERROR - Process timed out, PID: 15038
[2022-10-21 20:36:07,015] {logging_mixin.py:115} INFO - [2022-10-21 20:36:07,008] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 15038
[2022-10-21 20:36:07,022] {logging_mixin.py:115} INFO - [2022-10-21 20:36:07,021] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:36:07,075] {logging_mixin.py:115} INFO - [2022-10-21 20:36:07,026] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 15038

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:36:07,086] {logging_mixin.py:115} INFO - [2022-10-21 20:36:07,080] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:36:07,110] {logging_mixin.py:115} INFO - [2022-10-21 20:36:07,094] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:36:07,137] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:36:07,465] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.500 seconds
[2022-10-21 20:36:55,078] {processor.py:153} INFO - Started process (PID=51292) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:36:55,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:36:55,092] {logging_mixin.py:115} INFO - [2022-10-21 20:36:55,092] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:37:21,758] {processor.py:153} INFO - Started process (PID=15781) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:37:21,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:37:21,782] {logging_mixin.py:115} INFO - [2022-10-21 20:37:21,782] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:37:25,083] {logging_mixin.py:115} INFO - [2022-10-21 20:37:25,083] {timeout.py:67} ERROR - Process timed out, PID: 51292
[2022-10-21 20:37:25,100] {logging_mixin.py:115} INFO - [2022-10-21 20:37:25,091] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 51292
[2022-10-21 20:37:25,108] {logging_mixin.py:115} INFO - [2022-10-21 20:37:25,107] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:37:25,123] {logging_mixin.py:115} INFO - [2022-10-21 20:37:25,115] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 51292

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:37:25,139] {logging_mixin.py:115} INFO - [2022-10-21 20:37:25,133] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:37:25,158] {logging_mixin.py:115} INFO - [2022-10-21 20:37:25,144] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:37:25,168] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:37:25,411] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.365 seconds
[2022-10-21 20:37:51,772] {logging_mixin.py:115} INFO - [2022-10-21 20:37:51,772] {timeout.py:67} ERROR - Process timed out, PID: 15781
[2022-10-21 20:37:51,787] {logging_mixin.py:115} INFO - [2022-10-21 20:37:51,775] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 15781
[2022-10-21 20:37:51,794] {logging_mixin.py:115} INFO - [2022-10-21 20:37:51,793] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:37:51,807] {logging_mixin.py:115} INFO - [2022-10-21 20:37:51,797] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 15781

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:37:51,811] {logging_mixin.py:115} INFO - [2022-10-21 20:37:51,811] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:37:51,818] {logging_mixin.py:115} INFO - [2022-10-21 20:37:51,816] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:37:51,822] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:37:52,341] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.626 seconds
[2022-10-21 20:38:05,120] {processor.py:153} INFO - Started process (PID=51773) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:38:05,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:38:05,129] {logging_mixin.py:115} INFO - [2022-10-21 20:38:05,128] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:38:35,121] {logging_mixin.py:115} INFO - [2022-10-21 20:38:35,121] {timeout.py:67} ERROR - Process timed out, PID: 51773
[2022-10-21 20:38:35,125] {logging_mixin.py:115} INFO - [2022-10-21 20:38:35,123] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 51773
[2022-10-21 20:38:35,127] {logging_mixin.py:115} INFO - [2022-10-21 20:38:35,127] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:38:35,130] {logging_mixin.py:115} INFO - [2022-10-21 20:38:35,129] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 51773

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:38:35,138] {logging_mixin.py:115} INFO - [2022-10-21 20:38:35,138] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:38:35,141] {logging_mixin.py:115} INFO - [2022-10-21 20:38:35,140] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:38:35,143] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:38:35,348] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.263 seconds
[2022-10-21 20:38:40,464] {processor.py:153} INFO - Started process (PID=16249) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:38:40,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:38:40,479] {logging_mixin.py:115} INFO - [2022-10-21 20:38:40,479] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:39:10,468] {logging_mixin.py:115} INFO - [2022-10-21 20:39:10,468] {timeout.py:67} ERROR - Process timed out, PID: 16249
[2022-10-21 20:39:10,473] {logging_mixin.py:115} INFO - [2022-10-21 20:39:10,470] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 16249
[2022-10-21 20:39:10,479] {logging_mixin.py:115} INFO - [2022-10-21 20:39:10,479] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:39:10,487] {logging_mixin.py:115} INFO - [2022-10-21 20:39:10,482] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 16249

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:39:10,489] {logging_mixin.py:115} INFO - [2022-10-21 20:39:10,489] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:39:10,506] {logging_mixin.py:115} INFO - [2022-10-21 20:39:10,492] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:39:10,516] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:39:10,788] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.371 seconds
[2022-10-21 20:39:17,997] {processor.py:153} INFO - Started process (PID=52301) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:39:18,003] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:39:18,012] {logging_mixin.py:115} INFO - [2022-10-21 20:39:18,012] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:39:48,012] {logging_mixin.py:115} INFO - [2022-10-21 20:39:48,012] {timeout.py:67} ERROR - Process timed out, PID: 52301
[2022-10-21 20:39:48,017] {logging_mixin.py:115} INFO - [2022-10-21 20:39:48,015] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 52301
[2022-10-21 20:39:48,019] {logging_mixin.py:115} INFO - [2022-10-21 20:39:48,019] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:39:48,022] {logging_mixin.py:115} INFO - [2022-10-21 20:39:48,020] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 52301

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:39:48,024] {logging_mixin.py:115} INFO - [2022-10-21 20:39:48,024] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:39:48,030] {logging_mixin.py:115} INFO - [2022-10-21 20:39:48,028] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:39:48,032] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:39:48,128] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.216 seconds
[2022-10-21 20:47:34,984] {processor.py:153} INFO - Started process (PID=16931) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:47:34,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:47:34,992] {logging_mixin.py:115} INFO - [2022-10-21 20:47:34,992] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:47:42,958] {processor.py:153} INFO - Started process (PID=53100) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:47:42,961] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:47:42,964] {logging_mixin.py:115} INFO - [2022-10-21 20:47:42,964] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:47:52,468] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:47:52,505] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:47:53,219] {logging_mixin.py:115} INFO - [2022-10-21 20:47:53,219] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:47:53,423] {logging_mixin.py:115} INFO - [2022-10-21 20:47:53,423] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:47:52.493502+00:00, run_after=2022-10-22T20:47:52.493502+00:00
[2022-10-21 20:47:53,510] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 18.561 seconds
[2022-10-21 20:48:07,095] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:48:07,153] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:48:07,217] {logging_mixin.py:115} INFO - [2022-10-21 20:48:07,217] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:48:07,318] {logging_mixin.py:115} INFO - [2022-10-21 20:48:07,317] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:48:07.143281+00:00, run_after=2022-10-22T20:48:07.143281+00:00
[2022-10-21 20:48:07,370] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 24.441 seconds
[2022-10-21 20:48:49,895] {processor.py:153} INFO - Started process (PID=17717) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:48:49,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:48:49,901] {logging_mixin.py:115} INFO - [2022-10-21 20:48:49,900] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:48:59,022] {processor.py:153} INFO - Started process (PID=53914) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:48:59,025] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:48:59,029] {logging_mixin.py:115} INFO - [2022-10-21 20:48:59,029] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:49:10,780] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:49:10,863] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:49:11,380] {logging_mixin.py:115} INFO - [2022-10-21 20:49:11,380] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:49:11,542] {logging_mixin.py:115} INFO - [2022-10-21 20:49:11,542] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:49:10.855418+00:00, run_after=2022-10-22T20:49:10.855418+00:00
[2022-10-21 20:49:11,839] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 21.959 seconds
[2022-10-21 20:49:22,432] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:49:22,499] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:49:22,532] {logging_mixin.py:115} INFO - [2022-10-21 20:49:22,532] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:49:22,584] {logging_mixin.py:115} INFO - [2022-10-21 20:49:22,584] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:49:22.491581+00:00, run_after=2022-10-22T20:49:22.491581+00:00
[2022-10-21 20:49:22,610] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 23.633 seconds
[2022-10-21 20:50:08,289] {processor.py:153} INFO - Started process (PID=18504) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:50:08,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:50:08,297] {logging_mixin.py:115} INFO - [2022-10-21 20:50:08,297] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:50:13,042] {processor.py:153} INFO - Started process (PID=54680) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:50:13,045] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:50:13,047] {logging_mixin.py:115} INFO - [2022-10-21 20:50:13,047] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:50:33,779] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:50:33,884] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:50:34,246] {logging_mixin.py:115} INFO - [2022-10-21 20:50:34,245] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:50:34,315] {logging_mixin.py:115} INFO - [2022-10-21 20:50:34,314] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:50:33.866756+00:00, run_after=2022-10-22T20:50:33.866756+00:00
[2022-10-21 20:50:34,387] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 26.140 seconds
[2022-10-21 20:50:40,092] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:50:40,115] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:50:40,174] {logging_mixin.py:115} INFO - [2022-10-21 20:50:40,173] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:50:40,224] {logging_mixin.py:115} INFO - [2022-10-21 20:50:40,223] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:50:40.108010+00:00, run_after=2022-10-22T20:50:40.108010+00:00
[2022-10-21 20:50:40,263] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 27.253 seconds
[2022-10-21 20:51:32,623] {processor.py:153} INFO - Started process (PID=19294) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:51:32,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:51:32,633] {logging_mixin.py:115} INFO - [2022-10-21 20:51:32,632] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:51:34,655] {processor.py:153} INFO - Started process (PID=55506) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:51:34,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:51:34,664] {logging_mixin.py:115} INFO - [2022-10-21 20:51:34,664] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:52:00,564] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:52:00,708] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:52:01,710] {logging_mixin.py:115} INFO - [2022-10-21 20:52:01,709] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:52:01,773] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:52:01,841] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:52:01,883] {logging_mixin.py:115} INFO - [2022-10-21 20:52:01,882] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:52:00.686362+00:00, run_after=2022-10-22T20:52:00.686362+00:00
[2022-10-21 20:52:02,004] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 29.430 seconds
[2022-10-21 20:52:02,245] {logging_mixin.py:115} INFO - [2022-10-21 20:52:02,244] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:52:02,554] {logging_mixin.py:115} INFO - [2022-10-21 20:52:02,554] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:52:01.815831+00:00, run_after=2022-10-22T20:52:01.815831+00:00
[2022-10-21 20:52:02,684] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 28.069 seconds
[2022-10-21 20:53:06,303] {processor.py:153} INFO - Started process (PID=55996) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:53:06,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:53:06,319] {logging_mixin.py:115} INFO - [2022-10-21 20:53:06,318] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:53:08,405] {processor.py:153} INFO - Started process (PID=19818) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:53:08,416] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:53:08,419] {logging_mixin.py:115} INFO - [2022-10-21 20:53:08,419] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:53:28,687] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:53:28,810] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:53:30,939] {logging_mixin.py:115} INFO - [2022-10-21 20:53:30,939] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:53:31,257] {logging_mixin.py:115} INFO - [2022-10-21 20:53:31,257] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:53:28.798811+00:00, run_after=2022-10-22T20:53:28.798811+00:00
[2022-10-21 20:53:31,332] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 25.066 seconds
[2022-10-21 20:53:36,044] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:53:36,135] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:53:36,339] {logging_mixin.py:115} INFO - [2022-10-21 20:53:36,338] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:53:36,444] {logging_mixin.py:115} INFO - [2022-10-21 20:53:36,443] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:53:36.126455+00:00, run_after=2022-10-22T20:53:36.126455+00:00
[2022-10-21 20:53:36,499] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 28.125 seconds
[2022-10-21 20:54:07,728] {processor.py:153} INFO - Started process (PID=56603) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:54:07,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:54:07,734] {logging_mixin.py:115} INFO - [2022-10-21 20:54:07,734] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:54:07,999] {processor.py:153} INFO - Started process (PID=20384) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:54:08,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:54:08,003] {logging_mixin.py:115} INFO - [2022-10-21 20:54:08,003] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:54:29,110] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:54:29,182] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:54:30,425] {logging_mixin.py:115} INFO - [2022-10-21 20:54:30,425] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:54:30,490] {logging_mixin.py:115} INFO - [2022-10-21 20:54:30,490] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:54:29.156556+00:00, run_after=2022-10-22T20:54:29.156556+00:00
[2022-10-21 20:54:30,568] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 22.875 seconds
[2022-10-21 20:54:31,133] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:54:31,195] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:54:31,328] {logging_mixin.py:115} INFO - [2022-10-21 20:54:31,327] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:54:31,614] {logging_mixin.py:115} INFO - [2022-10-21 20:54:31,614] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:54:31.182062+00:00, run_after=2022-10-22T20:54:31.182062+00:00
[2022-10-21 20:54:31,753] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 23.796 seconds
[2022-10-21 20:55:49,880] {processor.py:153} INFO - Started process (PID=57421) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:55:49,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:55:49,892] {logging_mixin.py:115} INFO - [2022-10-21 20:55:49,892] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:55:49,930] {processor.py:153} INFO - Started process (PID=21182) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:55:49,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:55:49,938] {logging_mixin.py:115} INFO - [2022-10-21 20:55:49,938] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:56:19,886] {logging_mixin.py:115} INFO - [2022-10-21 20:56:19,885] {timeout.py:67} ERROR - Process timed out, PID: 57421
[2022-10-21 20:56:19,911] {logging_mixin.py:115} INFO - [2022-10-21 20:56:19,907] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 57421
[2022-10-21 20:56:19,917] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:56:19,937] {logging_mixin.py:115} INFO - [2022-10-21 20:56:19,934] {timeout.py:67} ERROR - Process timed out, PID: 21182
[2022-10-21 20:56:19,962] {logging_mixin.py:115} INFO - [2022-10-21 20:56:19,943] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 21182
[2022-10-21 20:56:19,977] {logging_mixin.py:115} INFO - [2022-10-21 20:56:19,969] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:56:19,981] {logging_mixin.py:115} INFO - [2022-10-21 20:56:19,979] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 21182

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:56:19,990] {logging_mixin.py:115} INFO - [2022-10-21 20:56:19,990] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:56:19,994] {logging_mixin.py:115} INFO - [2022-10-21 20:56:19,992] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:56:20,004] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:56:20,231] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.338 seconds
[2022-10-21 20:56:20,382] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.554 seconds
[2022-10-21 20:58:22,124] {processor.py:153} INFO - Started process (PID=58290) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:58:22,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:58:22,129] {logging_mixin.py:115} INFO - [2022-10-21 20:58:22,128] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:58:30,598] {processor.py:153} INFO - Started process (PID=21568) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:58:30,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:58:30,606] {logging_mixin.py:115} INFO - [2022-10-21 20:58:30,605] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:58:52,136] {logging_mixin.py:115} INFO - [2022-10-21 20:58:52,127] {timeout.py:67} ERROR - Process timed out, PID: 58290
[2022-10-21 20:58:52,154] {logging_mixin.py:115} INFO - [2022-10-21 20:58:52,146] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 58290
[2022-10-21 20:58:52,160] {logging_mixin.py:115} INFO - [2022-10-21 20:58:52,160] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:58:52,164] {logging_mixin.py:115} INFO - [2022-10-21 20:58:52,162] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 58290

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:58:52,193] {logging_mixin.py:115} INFO - [2022-10-21 20:58:52,192] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:58:52,214] {logging_mixin.py:115} INFO - [2022-10-21 20:58:52,212] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:58:52,219] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:58:52,570] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.496 seconds
[2022-10-21 20:59:00,622] {logging_mixin.py:115} INFO - [2022-10-21 20:59:00,613] {timeout.py:67} ERROR - Process timed out, PID: 21568
[2022-10-21 20:59:00,653] {logging_mixin.py:115} INFO - [2022-10-21 20:59:00,638] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 21568
[2022-10-21 20:59:00,663] {logging_mixin.py:115} INFO - [2022-10-21 20:59:00,663] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:59:00,679] {logging_mixin.py:115} INFO - [2022-10-21 20:59:00,677] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 21568

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 20:59:00,692] {logging_mixin.py:115} INFO - [2022-10-21 20:59:00,692] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 20:59:00,723] {logging_mixin.py:115} INFO - [2022-10-21 20:59:00,710] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21 20:59:00,726] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:59:00,929] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.381 seconds
[2022-10-21 20:59:28,009] {processor.py:153} INFO - Started process (PID=58777) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:59:28,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 20:59:28,021] {logging_mixin.py:115} INFO - [2022-10-21 20:59:28,020] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:59:53,616] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 20:59:53,728] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 20:59:54,302] {logging_mixin.py:115} INFO - [2022-10-21 20:59:54,302] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 20:59:54,396] {logging_mixin.py:115} INFO - [2022-10-21 20:59:54,395] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T20:59:53.707032+00:00, run_after=2022-10-22T20:59:53.707032+00:00
[2022-10-21 20:59:54,490] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 26.537 seconds
[2022-10-21 21:00:06,130] {processor.py:153} INFO - Started process (PID=22261) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:00:06,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 21:00:06,134] {logging_mixin.py:115} INFO - [2022-10-21 21:00:06,134] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:00:29,035] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 21:00:29,138] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:00:29,735] {logging_mixin.py:115} INFO - [2022-10-21 21:00:29,735] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 21:00:29,817] {logging_mixin.py:115} INFO - [2022-10-21 21:00:29,817] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T21:00:29.110705+00:00, run_after=2022-10-22T21:00:29.110705+00:00
[2022-10-21 21:00:29,925] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 23.825 seconds
[2022-10-21 21:01:04,102] {processor.py:153} INFO - Started process (PID=59695) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:01:04,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 21:01:04,108] {logging_mixin.py:115} INFO - [2022-10-21 21:01:04,108] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:01:04,844] {processor.py:153} INFO - Started process (PID=22796) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:01:04,846] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 21:01:04,851] {logging_mixin.py:115} INFO - [2022-10-21 21:01:04,851] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:01:28,287] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21 21:01:28,354] {processor.py:651} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:01:28,611] {logging_mixin.py:115} INFO - [2022-10-21 21:01:28,611] {dag.py:2420} INFO - Sync 1 DAGs
[2022-10-21 21:01:28,667] {logging_mixin.py:115} INFO - [2022-10-21 21:01:28,666] {dag.py:2972} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T21:01:28.346185+00:00, run_after=2022-10-22T21:01:28.346185+00:00
[2022-10-21 21:01:28,721] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 24.673 seconds
[2022-10-21 21:01:34,839] {logging_mixin.py:115} INFO - [2022-10-21 21:01:34,839] {timeout.py:67} ERROR - Process timed out, PID: 22796
[2022-10-21 21:01:34,856] {logging_mixin.py:115} INFO - [2022-10-21 21:01:34,843] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 22796
[2022-10-21 21:01:34,866] {logging_mixin.py:115} INFO - [2022-10-21 21:01:34,865] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 21:01:34,877] {logging_mixin.py:115} INFO - [2022-10-21 21:01:34,872] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 22796

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21 21:01:34,879] {logging_mixin.py:115} INFO - [2022-10-21 21:01:34,879] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21 21:01:34,884] {logging_mixin.py:115} INFO - [2022-10-21 21:01:34,881] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 272, in getOrCreate
    session = SparkSession(sc, options=self._options)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 307, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc(), options)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession
[2022-10-21 21:01:34,896] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:01:35,085] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.284 seconds
[2022-10-21 21:02:00,922] {processor.py:153} INFO - Started process (PID=60174) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:02:00,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 21:02:00,930] {logging_mixin.py:115} INFO - [2022-10-21 21:02:00,929] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:02:18,466] {processor.py:153} INFO - Started process (PID=23351) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:02:18,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21 21:02:18,483] {logging_mixin.py:115} INFO - [2022-10-21 21:02:18,482] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:02:31,189] {logging_mixin.py:115} INFO - [2022-10-21 21:02:31,095] {timeout.py:67} ERROR - Process timed out, PID: 60174
[2022-10-21 21:02:31,465] {logging_mixin.py:115} INFO - [2022-10-21 21:02:31,225] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.3/best-practices.html#reducing-dag-complexity, PID: 60174
[2022-10-21 21:02:31,493] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21 21:02:32,495] {processor.py:161} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.645 seconds
[2022-10-21T21:28:32.423+0000] {processor.py:156} INFO - Started process (PID=257) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:28:32.425+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:28:32.427+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:28:32.426+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:28:32.669+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:28:32.667+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:28:32.671+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:28:32.709+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.291 seconds
[2022-10-21T21:29:03.745+0000] {processor.py:156} INFO - Started process (PID=787) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:29:03.747+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:29:03.751+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:29:03.750+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:29:04.010+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:29:04.009+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:29:04.013+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:29:04.054+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.316 seconds
[2022-10-21T21:29:35.171+0000] {processor.py:156} INFO - Started process (PID=1302) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:29:35.175+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:29:35.178+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:29:35.178+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:29:35.482+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:29:35.480+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:29:35.486+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:29:35.533+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.378 seconds
[2022-10-21T21:30:06.103+0000] {processor.py:156} INFO - Started process (PID=1814) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:30:06.107+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:30:06.109+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:30:06.109+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:30:06.373+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:30:06.368+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:30:06.376+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:30:06.421+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.329 seconds
[2022-10-21T21:30:37.462+0000] {processor.py:156} INFO - Started process (PID=2310) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:30:37.464+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:30:37.466+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:30:37.466+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:30:37.728+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:30:37.726+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:30:37.730+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:30:37.779+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.325 seconds
[2022-10-21T21:31:08.677+0000] {processor.py:156} INFO - Started process (PID=2799) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:31:08.681+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:31:08.683+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:31:08.683+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:31:08.944+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:31:08.942+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:31:08.948+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:31:09.002+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.332 seconds
[2022-10-21T21:31:39.750+0000] {processor.py:156} INFO - Started process (PID=3248) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:31:39.754+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:31:39.756+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:31:39.756+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:31:40.057+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:31:40.054+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:31:40.061+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:31:40.132+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.392 seconds
[2022-10-21T21:32:18.841+0000] {processor.py:156} INFO - Started process (PID=3755) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:32:18.846+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:32:18.850+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:32:18.849+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:32:19.134+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:32:19.132+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:32:19.138+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:32:19.192+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.359 seconds
[2022-10-21T21:33:46.713+0000] {processor.py:156} INFO - Started process (PID=4180) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:33:46.716+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:33:46.718+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:33:46.718+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:33:47.013+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:33:47.010+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:33:47.016+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:33:47.060+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.357 seconds
[2022-10-21T21:34:32.256+0000] {processor.py:156} INFO - Started process (PID=5254) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:34:32.259+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:34:32.262+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:34:32.262+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:34:32.615+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:34:32.613+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:34:32.619+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:34:32.682+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.434 seconds
[2022-10-21T21:35:27.554+0000] {processor.py:156} INFO - Started process (PID=6155) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:35:27.561+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:35:27.572+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:35:27.571+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:35:28.114+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:35:28.112+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:35:28.118+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:35:28.257+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.717 seconds
[2022-10-21T21:36:02.955+0000] {processor.py:156} INFO - Started process (PID=7098) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:36:02.963+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:36:02.970+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:36:02.969+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:36:03.369+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:36:03.367+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:36:03.372+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:36:03.438+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.512 seconds
[2022-10-21T21:36:42.370+0000] {processor.py:156} INFO - Started process (PID=9098) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:36:42.374+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:36:42.378+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:36:42.377+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:36:56.107+0000] {logging_mixin.py:117} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21T21:36:56.188+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:36:56.501+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:36:56.500+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T21:36:56.632+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:36:56.631+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T21:36:56.150359+00:00, run_after=2022-10-22T21:36:56.150359+00:00
[2022-10-21T21:36:56.717+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 14.356 seconds
[2022-10-21T21:37:30.783+0000] {processor.py:156} INFO - Started process (PID=9801) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:37:30.791+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:37:30.798+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:37:30.796+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:37:43.889+0000] {logging_mixin.py:117} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21T21:37:43.941+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:37:44.196+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:37:44.196+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T21:37:44.293+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:37:44.292+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T21:37:43.910250+00:00, run_after=2022-10-22T21:37:43.910250+00:00
[2022-10-21T21:37:44.382+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 13.610 seconds
[2022-10-21T21:38:57.446+0000] {processor.py:156} INFO - Started process (PID=10482) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:38:57.450+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:38:57.454+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:38:57.453+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:39:27.447+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:39:27.445+0000] {timeout.py:68} ERROR - Process timed out, PID: 10482
[2022-10-21T21:39:27.460+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:39:27.449+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 10482
[2022-10-21T21:39:27.465+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:39:27.465+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21T21:39:27.492+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:39:27.470+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 10482

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21T21:39:27.511+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:39:27.498+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21T21:39:27.541+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:39:27.513+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21T21:39:27.708+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:39:28.010+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.595 seconds
[2022-10-21T21:40:34.263+0000] {processor.py:156} INFO - Started process (PID=11050) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:40:34.272+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:40:34.286+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:40:34.282+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:41:04.280+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:41:04.274+0000] {timeout.py:68} ERROR - Process timed out, PID: 11050
[2022-10-21T21:41:04.314+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:41:04.290+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 11050
[2022-10-21T21:41:04.320+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:41:04.318+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21T21:41:04.329+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:41:04.326+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 11050

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21T21:41:04.332+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:41:04.332+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21T21:41:04.337+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:41:04.335+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21T21:41:04.344+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:41:04.563+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.383 seconds
[2022-10-21T21:42:23.564+0000] {processor.py:156} INFO - Started process (PID=11579) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:42:23.570+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:42:23.575+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:42:23.575+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:42:53.577+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:42:53.574+0000] {timeout.py:68} ERROR - Process timed out, PID: 11579
[2022-10-21T21:42:53.624+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:42:53.589+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 11579
[2022-10-21T21:42:53.647+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:42:53.645+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21T21:42:53.670+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:42:53.651+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 11579

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21T21:42:53.702+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:42:53.699+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21T21:42:53.724+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:42:53.712+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21T21:42:53.744+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:42:54.626+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 31.115 seconds
[2022-10-21T21:54:41.646+0000] {processor.py:156} INFO - Started process (PID=2013) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:54:41.661+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:54:41.670+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:54:41.670+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:54:42.242+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:54:42.239+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:54:42.245+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:54:42.303+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.672 seconds
[2022-10-21T21:54:59.408+0000] {processor.py:156} INFO - Started process (PID=12199) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:54:59.411+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:54:59.414+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:54:59.413+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:55:24.003+0000] {logging_mixin.py:117} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-10-21T21:55:24.106+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:55:24.789+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:55:24.788+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T21:55:24.935+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:55:24.934+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T21:55:24.065828+00:00, run_after=2022-10-22T21:55:24.065828+00:00
[2022-10-21T21:55:25.121+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 25.745 seconds
[2022-10-21T21:55:42.075+0000] {processor.py:156} INFO - Started process (PID=2566) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:55:42.081+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:55:42.090+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:55:42.088+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:55:42.554+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:55:42.550+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:55:42.558+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:55:42.610+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.543 seconds
[2022-10-21T21:56:14.189+0000] {processor.py:156} INFO - Started process (PID=2852) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:56:14.201+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:56:14.210+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:56:14.210+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:56:14.856+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:56:14.852+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:56:14.860+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:56:14.936+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.782 seconds
[2022-10-21T21:56:35.735+0000] {processor.py:156} INFO - Started process (PID=12979) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:56:35.748+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:56:35.761+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:56:35.757+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:57:03.661+0000] {processor.py:156} INFO - Started process (PID=3128) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:57:03.670+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:57:03.674+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:57:03.673+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:57:04.065+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:57:04.063+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:57:04.067+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:57:04.143+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.497 seconds
[2022-10-21T21:57:05.761+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:57:05.760+0000] {timeout.py:68} ERROR - Process timed out, PID: 12979
[2022-10-21T21:57:05.781+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:57:05.770+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 12979
[2022-10-21T21:57:05.785+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:57:06.136+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.494 seconds
[2022-10-21T21:58:05.111+0000] {processor.py:156} INFO - Started process (PID=4092) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:58:05.114+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:58:05.117+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:05.117+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:58:05.731+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:05.728+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-21T21:58:05.735+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:58:05.830+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.728 seconds
[2022-10-21T21:58:07.189+0000] {processor.py:156} INFO - Started process (PID=13438) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:58:07.192+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T21:58:07.202+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:07.200+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:58:37.195+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:37.194+0000] {timeout.py:68} ERROR - Process timed out, PID: 13438
[2022-10-21T21:58:37.204+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:37.201+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 13438
[2022-10-21T21:58:37.209+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:37.209+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21T21:58:37.249+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:37.214+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pyspark_jobs.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 13438

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-21T21:58:37.257+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:37.256+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-21T21:58:37.266+0000] {logging_mixin.py:117} INFO - [2022-10-21T21:58:37.260+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/pyspark_jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pyspark_jobs.py", line 10, in <module>
    import pyspark_scripts as pyspark
  File "/opt/airflow/dags/pyspark_scripts.py", line 13, in <module>
    spark = SparkSession.builder.config('spark.jars', '/opt/airflow/dags/postgresql-42.5.0.jar').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-21T21:58:37.271+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T21:58:37.737+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 30.582 seconds
[2022-10-21T23:23:51.294+0000] {processor.py:156} INFO - Started process (PID=256) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:23:51.296+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:23:51.298+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:23:51.298+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:23:51.470+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:23:51.604+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:23:51.604+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:23:51.646+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:23:51.646+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:23:51.432124+00:00, run_after=2022-10-22T23:23:51.432124+00:00
[2022-10-21T23:23:51.688+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.399 seconds
[2022-10-21T23:24:32.423+0000] {processor.py:156} INFO - Started process (PID=770) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:24:32.427+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:24:32.430+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:24:32.429+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:24:32.591+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:24:32.822+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:24:32.822+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:24:32.887+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:24:32.886+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:24:32.572697+00:00, run_after=2022-10-22T23:24:32.572697+00:00
[2022-10-21T23:24:32.937+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.520 seconds
[2022-10-21T23:25:07.620+0000] {processor.py:156} INFO - Started process (PID=1127) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:25:07.626+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:25:07.630+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:25:07.629+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:25:08.188+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:25:09.161+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:25:09.155+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:25:09.387+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:25:09.385+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:25:08.129019+00:00, run_after=2022-10-22T23:25:08.129019+00:00
[2022-10-21T23:25:09.486+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.893 seconds
[2022-10-21T23:25:44.387+0000] {processor.py:156} INFO - Started process (PID=1335) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:25:44.391+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:25:44.395+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:25:44.394+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:25:44.787+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:25:45.132+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:25:45.130+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:25:45.283+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:25:45.282+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:25:44.748762+00:00, run_after=2022-10-22T23:25:44.748762+00:00
[2022-10-21T23:25:45.399+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.027 seconds
[2022-10-21T23:26:27.954+0000] {processor.py:156} INFO - Started process (PID=1668) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:26:27.964+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:26:27.969+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:26:27.969+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:26:28.248+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:26:28.423+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:26:28.422+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:26:28.488+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:26:28.488+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:26:28.203027+00:00, run_after=2022-10-22T23:26:28.203027+00:00
[2022-10-21T23:26:28.532+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.601 seconds
[2022-10-21T23:27:25.623+0000] {processor.py:156} INFO - Started process (PID=2193) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:27:25.628+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:27:25.630+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:27:25.630+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:27:25.802+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:27:25.970+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:27:25.969+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:27:26.046+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:27:26.046+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:27:25.783252+00:00, run_after=2022-10-22T23:27:25.783252+00:00
[2022-10-21T23:27:26.437+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.823 seconds
[2022-10-21T23:28:02.918+0000] {processor.py:156} INFO - Started process (PID=2447) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:28:02.925+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:28:02.933+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:28:02.931+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:28:03.105+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:28:03.296+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:28:03.295+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:28:03.340+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:28:03.340+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:28:03.085189+00:00, run_after=2022-10-22T23:28:03.085189+00:00
[2022-10-21T23:28:03.391+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.499 seconds
[2022-10-21T23:29:07.118+0000] {processor.py:156} INFO - Started process (PID=3730) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:07.127+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:29:07.129+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:07.129+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:07.372+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:07.552+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:07.551+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:29:07.986+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:07.986+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:29:07.364913+00:00, run_after=2022-10-22T23:29:07.364913+00:00
[2022-10-21T23:29:08.048+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.935 seconds
[2022-10-21T23:29:17.251+0000] {processor.py:156} INFO - Started process (PID=2783) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:17.253+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:29:17.256+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:17.255+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:17.437+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:17.463+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:17.462+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:29:17.525+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:17.525+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:29:17.410488+00:00, run_after=2022-10-22T23:29:17.410488+00:00
[2022-10-21T23:29:17.574+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.332 seconds
[2022-10-21T23:29:55.279+0000] {processor.py:156} INFO - Started process (PID=3167) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:55.282+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:29:55.284+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:55.284+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:55.582+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:55.815+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:55.815+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:29:55.873+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:55.872+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:29:55.535817+00:00, run_after=2022-10-22T23:29:55.535817+00:00
[2022-10-21T23:29:55.920+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.657 seconds
[2022-10-21T23:29:57.956+0000] {processor.py:156} INFO - Started process (PID=4252) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:57.962+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:29:57.966+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:57.966+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:58.291+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:29:58.342+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:58.342+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:29:58.471+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:29:58.470+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:29:58.286175+00:00, run_after=2022-10-22T23:29:58.286175+00:00
[2022-10-21T23:29:58.553+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.614 seconds
[2022-10-21T23:30:34.855+0000] {processor.py:156} INFO - Started process (PID=3581) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:30:34.858+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:30:34.861+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:30:34.861+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:30:35.188+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:30:35.686+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:30:35.685+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:30:35.838+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:30:35.831+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:30:35.127715+00:00, run_after=2022-10-22T23:30:35.127715+00:00
[2022-10-21T23:30:35.971+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.136 seconds
[2022-10-21T23:30:38.121+0000] {processor.py:156} INFO - Started process (PID=4671) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:30:38.123+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:30:38.125+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:30:38.125+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:30:38.266+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:30:38.327+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:30:38.326+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:30:38.422+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:30:38.420+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:30:38.258815+00:00, run_after=2022-10-22T23:30:38.258815+00:00
[2022-10-21T23:30:38.489+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.376 seconds
[2022-10-21T23:31:12.448+0000] {processor.py:156} INFO - Started process (PID=3975) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:12.451+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:31:12.456+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:12.455+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:12.724+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:12.901+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:12.901+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:31:12.971+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:12.971+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:31:12.685475+00:00, run_after=2022-10-22T23:31:12.685475+00:00
[2022-10-21T23:31:13.039+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.606 seconds
[2022-10-21T23:31:13.781+0000] {processor.py:156} INFO - Started process (PID=5048) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:13.784+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:31:13.787+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:13.787+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:14.047+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:14.100+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:14.100+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:31:14.206+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:14.206+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:31:14.041747+00:00, run_after=2022-10-22T23:31:14.041747+00:00
[2022-10-21T23:31:14.264+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.505 seconds
[2022-10-21T23:31:50.035+0000] {processor.py:156} INFO - Started process (PID=5440) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:50.038+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:31:50.040+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:50.039+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:50.207+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:50.658+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:50.657+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:31:50.715+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:50.715+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:31:50.202346+00:00, run_after=2022-10-22T23:31:50.202346+00:00
[2022-10-21T23:31:50.762+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.736 seconds
[2022-10-21T23:31:51.526+0000] {processor.py:156} INFO - Started process (PID=4379) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:51.530+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:31:51.534+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:51.533+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:51.781+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:31:51.826+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:51.826+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:31:51.990+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:31:51.983+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:31:51.731904+00:00, run_after=2022-10-22T23:31:51.731904+00:00
[2022-10-21T23:31:52.089+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.577 seconds
[2022-10-21T23:32:25.993+0000] {processor.py:156} INFO - Started process (PID=5815) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:32:26.008+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:32:26.012+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:32:26.011+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:32:26.249+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:32:27.126+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:32:27.125+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:32:27.187+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:32:27.187+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:32:26.242500+00:00, run_after=2022-10-22T23:32:26.242500+00:00
[2022-10-21T23:32:27.229+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.275 seconds
[2022-10-21T23:32:30.113+0000] {processor.py:156} INFO - Started process (PID=4778) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:32:30.116+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:32:30.119+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:32:30.119+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:32:30.328+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:32:30.379+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:32:30.378+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:32:30.472+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:32:30.472+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:32:30.309049+00:00, run_after=2022-10-22T23:32:30.309049+00:00
[2022-10-21T23:32:30.576+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.471 seconds
[2022-10-21T23:33:06.464+0000] {processor.py:156} INFO - Started process (PID=6226) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:33:06.470+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:33:06.473+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:33:06.473+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:33:06.663+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:33:07.411+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:33:07.411+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:33:07.466+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:33:07.466+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:33:06.644977+00:00, run_after=2022-10-22T23:33:06.644977+00:00
[2022-10-21T23:33:07.523+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.066 seconds
[2022-10-21T23:33:12.530+0000] {processor.py:156} INFO - Started process (PID=5197) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:33:12.542+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:33:12.546+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:33:12.546+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:33:12.780+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:33:12.818+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:33:12.818+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:33:12.880+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:33:12.880+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:33:12.739442+00:00, run_after=2022-10-22T23:33:12.739442+00:00
[2022-10-21T23:33:12.928+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.421 seconds
[2022-10-21T23:34:07.332+0000] {processor.py:156} INFO - Started process (PID=6456) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:07.334+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:34:07.338+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:07.337+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:07.516+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:07.774+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:07.774+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:34:07.880+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:07.879+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:34:07.504327+00:00, run_after=2022-10-22T23:34:07.504327+00:00
[2022-10-21T23:34:07.943+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.620 seconds
[2022-10-21T23:34:13.938+0000] {processor.py:156} INFO - Started process (PID=5431) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:13.941+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:34:13.944+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:13.943+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:14.119+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:14.159+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:14.159+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:34:14.219+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:14.218+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:34:14.100160+00:00, run_after=2022-10-22T23:34:14.100160+00:00
[2022-10-21T23:34:14.323+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.392 seconds
[2022-10-21T23:34:51.418+0000] {processor.py:156} INFO - Started process (PID=5799) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:51.423+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:34:51.428+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:51.428+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:51.683+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:51.900+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:51.899+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:34:51.991+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:51.988+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:34:51.665427+00:00, run_after=2022-10-22T23:34:51.665427+00:00
[2022-10-21T23:34:52.085+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.683 seconds
[2022-10-21T23:34:54.795+0000] {processor.py:156} INFO - Started process (PID=6944) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:54.799+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:34:54.801+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:54.800+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:54.997+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:34:55.056+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:55.055+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:34:55.139+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:34:55.138+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:34:54.986446+00:00, run_after=2022-10-22T23:34:54.986446+00:00
[2022-10-21T23:34:55.186+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.403 seconds
[2022-10-21T23:35:32.757+0000] {processor.py:156} INFO - Started process (PID=6221) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:35:32.761+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:35:32.765+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:35:32.765+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:35:32.812+0000] {processor.py:156} INFO - Started process (PID=7350) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:35:32.816+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:35:32.818+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:35:32.818+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:35:32.971+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:35:33.082+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:35:33.155+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:35:33.154+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:35:33.215+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:35:33.215+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:35:32.965746+00:00, run_after=2022-10-22T23:35:32.965746+00:00
[2022-10-21T23:35:33.247+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:35:33.246+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:35:33.272+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.472 seconds
[2022-10-21T23:35:33.336+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:35:33.335+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:35:33.054104+00:00, run_after=2022-10-22T23:35:33.054104+00:00
[2022-10-21T23:35:33.375+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.627 seconds
[2022-10-21T23:36:11.048+0000] {processor.py:156} INFO - Started process (PID=7746) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:11.052+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:36:11.056+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:11.055+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:11.351+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:11.699+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:11.699+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:36:11.792+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:11.791+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:36:11.341090+00:00, run_after=2022-10-22T23:36:11.341090+00:00
[2022-10-21T23:36:11.842+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.810 seconds
[2022-10-21T23:36:13.419+0000] {processor.py:156} INFO - Started process (PID=6634) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:13.424+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:36:13.427+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:13.427+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:13.723+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:13.764+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:13.764+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:36:13.892+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:13.891+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:36:13.699288+00:00, run_after=2022-10-22T23:36:13.699288+00:00
[2022-10-21T23:36:13.945+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.541 seconds
[2022-10-21T23:36:53.285+0000] {processor.py:156} INFO - Started process (PID=8152) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:53.293+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:36:53.298+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:53.296+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:53.573+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:53.946+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:53.946+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:36:54.058+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:54.058+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:36:53.561054+00:00, run_after=2022-10-22T23:36:53.561054+00:00
[2022-10-21T23:36:54.143+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.876 seconds
[2022-10-21T23:36:58.805+0000] {processor.py:156} INFO - Started process (PID=7066) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:58.808+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:36:58.811+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:58.810+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:59.208+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:36:59.290+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:59.290+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:36:59.401+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:36:59.401+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:36:59.152242+00:00, run_after=2022-10-22T23:36:59.152242+00:00
[2022-10-21T23:36:59.505+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.710 seconds
[2022-10-21T23:37:38.999+0000] {processor.py:156} INFO - Started process (PID=8625) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:37:39.005+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:37:39.012+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:37:39.010+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:37:39.227+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:37:39.454+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:37:39.453+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:37:39.569+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:37:39.569+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:37:39.221816+00:00, run_after=2022-10-22T23:37:39.221816+00:00
[2022-10-21T23:37:39.636+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.651 seconds
[2022-10-21T23:37:47.075+0000] {processor.py:156} INFO - Started process (PID=7540) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:37:47.078+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:37:47.081+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:37:47.080+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:37:47.250+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:37:47.294+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:37:47.294+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:37:47.362+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:37:47.361+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:37:47.224731+00:00, run_after=2022-10-22T23:37:47.224731+00:00
[2022-10-21T23:37:47.406+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.339 seconds
[2022-10-21T23:38:14.372+0000] {processor.py:156} INFO - Started process (PID=9018) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:38:14.374+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:38:14.376+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:38:14.376+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:38:14.517+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:38:14.677+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:38:14.677+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:38:14.733+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:38:14.733+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:38:14.512534+00:00, run_after=2022-10-22T23:38:14.512534+00:00
[2022-10-21T23:38:14.802+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.436 seconds
[2022-10-21T23:38:57.234+0000] {processor.py:156} INFO - Started process (PID=7953) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:38:57.237+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:38:57.240+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:38:57.239+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:38:57.697+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:38:57.817+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:38:57.816+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:38:57.866+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:38:57.865+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:38:57.416342+00:00, run_after=2022-10-22T23:38:57.416342+00:00
[2022-10-21T23:38:57.902+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.681 seconds
[2022-10-21T23:39:04.004+0000] {processor.py:156} INFO - Started process (PID=9202) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:04.007+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:39:04.010+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:04.010+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:04.221+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:04.272+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:04.271+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:39:04.340+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:04.340+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:39:04.216507+00:00, run_after=2022-10-22T23:39:04.216507+00:00
[2022-10-21T23:39:04.407+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.412 seconds
[2022-10-21T23:39:41.865+0000] {processor.py:156} INFO - Started process (PID=8452) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:41.868+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:39:41.871+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:41.871+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:42.354+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:42.528+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:42.528+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:39:42.578+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:42.577+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:39:42.339585+00:00, run_after=2022-10-22T23:39:42.339585+00:00
[2022-10-21T23:39:42.620+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.765 seconds
[2022-10-21T23:39:47.025+0000] {processor.py:156} INFO - Started process (PID=9685) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:47.028+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:39:47.030+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:47.030+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:47.179+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:39:47.253+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:47.252+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:39:47.354+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:39:47.354+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:39:47.170397+00:00, run_after=2022-10-22T23:39:47.170397+00:00
[2022-10-21T23:39:47.411+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.392 seconds
[2022-10-21T23:40:25.688+0000] {processor.py:156} INFO - Started process (PID=8974) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:40:25.694+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:40:25.697+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:40:25.697+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:40:26.162+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:40:26.345+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:40:26.344+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:40:26.434+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:40:26.431+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:40:26.139460+00:00, run_after=2022-10-22T23:40:26.139460+00:00
[2022-10-21T23:40:26.511+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.842 seconds
[2022-10-21T23:40:30.254+0000] {processor.py:156} INFO - Started process (PID=10208) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:40:30.258+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:40:30.260+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:40:30.259+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:40:30.432+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:40:30.475+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:40:30.475+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:40:30.564+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:40:30.564+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:40:30.425633+00:00, run_after=2022-10-22T23:40:30.425633+00:00
[2022-10-21T23:40:30.606+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.361 seconds
[2022-10-21T23:41:06.082+0000] {processor.py:156} INFO - Started process (PID=9443) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:06.086+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:41:06.088+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:06.088+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:06.603+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:06.779+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:06.778+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:41:06.830+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:06.829+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:41:06.573876+00:00, run_after=2022-10-22T23:41:06.573876+00:00
[2022-10-21T23:41:06.906+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.831 seconds
[2022-10-21T23:41:08.556+0000] {processor.py:156} INFO - Started process (PID=10653) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:08.563+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:41:08.566+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:08.566+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:08.819+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:08.848+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:08.848+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:41:08.935+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:08.933+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:41:08.813295+00:00, run_after=2022-10-22T23:41:08.813295+00:00
[2022-10-21T23:41:08.978+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.429 seconds
[2022-10-21T23:41:53.103+0000] {processor.py:156} INFO - Started process (PID=9961) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:53.113+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:41:53.115+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:53.114+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:53.139+0000] {processor.py:156} INFO - Started process (PID=11167) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:53.143+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:41:53.145+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:53.145+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:53.328+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:53.641+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:53.641+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:41:53.673+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:41:53.755+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:53.755+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:41:53.321458+00:00, run_after=2022-10-22T23:41:53.321458+00:00
[2022-10-21T23:41:53.855+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:53.855+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:41:53.869+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.739 seconds
[2022-10-21T23:41:53.934+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:41:53.934+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:41:53.656747+00:00, run_after=2022-10-22T23:41:53.656747+00:00
[2022-10-21T23:41:53.971+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.876 seconds
[2022-10-21T23:42:26.009+0000] {processor.py:156} INFO - Started process (PID=10338) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:42:26.016+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:42:26.019+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:42:26.019+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:42:26.500+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:42:26.691+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:42:26.690+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:42:26.755+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:42:26.754+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:42:26.483535+00:00, run_after=2022-10-22T23:42:26.483535+00:00
[2022-10-21T23:42:26.814+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.817 seconds
[2022-10-21T23:42:33.997+0000] {processor.py:156} INFO - Started process (PID=11662) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:42:33.999+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:42:34.003+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:42:34.002+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:42:34.168+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:42:34.201+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:42:34.201+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:42:34.260+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:42:34.260+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:42:34.161020+00:00, run_after=2022-10-22T23:42:34.161020+00:00
[2022-10-21T23:42:34.298+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.312 seconds
[2022-10-21T23:43:08.568+0000] {processor.py:156} INFO - Started process (PID=10831) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:43:08.571+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:43:08.574+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:43:08.573+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:43:09.115+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:43:09.324+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:43:09.324+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:43:09.373+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:43:09.372+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:43:09.095943+00:00, run_after=2022-10-22T23:43:09.095943+00:00
[2022-10-21T23:43:09.446+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.886 seconds
[2022-10-21T23:43:12.205+0000] {processor.py:156} INFO - Started process (PID=12124) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:43:12.209+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:43:12.212+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:43:12.212+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:43:12.433+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:43:12.482+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:43:12.482+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:43:12.546+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:43:12.545+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:43:12.427457+00:00, run_after=2022-10-22T23:43:12.427457+00:00
[2022-10-21T23:43:12.607+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.407 seconds
[2022-10-21T23:48:14.944+0000] {processor.py:156} INFO - Started process (PID=11093) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:48:14.949+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:48:14.951+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:48:14.951+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:48:15.171+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:48:15.351+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:48:15.350+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:48:15.399+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:48:15.399+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:48:15.157659+00:00, run_after=2022-10-22T23:48:15.157659+00:00
[2022-10-21T23:48:15.473+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.543 seconds
[2022-10-21T23:48:30.465+0000] {processor.py:156} INFO - Started process (PID=12950) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:48:30.469+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:48:30.476+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:48:30.476+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:48:31.025+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:48:31.048+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:48:31.048+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:48:31.102+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:48:31.101+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:48:31.014900+00:00, run_after=2022-10-22T23:48:31.014900+00:00
[2022-10-21T23:48:31.183+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.726 seconds
[2022-10-21T23:49:02.569+0000] {processor.py:156} INFO - Started process (PID=11618) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:02.571+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:49:02.577+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:02.576+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:02.757+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:02.926+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:02.925+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:49:02.979+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:02.979+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:49:02.751647+00:00, run_after=2022-10-22T23:49:02.751647+00:00
[2022-10-21T23:49:03.027+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.465 seconds
[2022-10-21T23:49:18.543+0000] {processor.py:156} INFO - Started process (PID=13474) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:18.547+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:49:18.552+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:18.552+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:19.351+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:19.378+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:19.378+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:49:19.440+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:19.440+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:49:19.347488+00:00, run_after=2022-10-22T23:49:19.347488+00:00
[2022-10-21T23:49:19.521+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.986 seconds
[2022-10-21T23:49:41.123+0000] {processor.py:156} INFO - Started process (PID=12028) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:41.133+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:49:41.136+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:41.136+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:41.366+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:41.581+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:41.580+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:49:41.676+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:41.675+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:49:41.361438+00:00, run_after=2022-10-22T23:49:41.361438+00:00
[2022-10-21T23:49:41.751+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.635 seconds
[2022-10-21T23:49:51.894+0000] {processor.py:156} INFO - Started process (PID=13830) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:51.896+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:49:51.898+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:51.898+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:52.283+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:49:52.314+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:52.313+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:49:52.371+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:49:52.371+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:49:52.280248+00:00, run_after=2022-10-22T23:49:52.280248+00:00
[2022-10-21T23:49:52.423+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.535 seconds
[2022-10-21T23:50:19.050+0000] {processor.py:156} INFO - Started process (PID=12418) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:19.053+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:50:19.056+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:19.055+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:19.244+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:19.392+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:19.391+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:50:19.478+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:19.477+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:50:19.231673+00:00, run_after=2022-10-22T23:50:19.231673+00:00
[2022-10-21T23:50:19.522+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.480 seconds
[2022-10-21T23:50:23.569+0000] {processor.py:156} INFO - Started process (PID=14175) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:23.572+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:50:23.576+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:23.575+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:24.050+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:24.069+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:24.069+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:50:24.136+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:24.135+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:50:24.046414+00:00, run_after=2022-10-22T23:50:24.046414+00:00
[2022-10-21T23:50:24.189+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.633 seconds
[2022-10-21T23:50:55.832+0000] {processor.py:156} INFO - Started process (PID=14527) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:55.846+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:50:55.853+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:55.852+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:56.130+0000] {processor.py:156} INFO - Started process (PID=12816) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:56.134+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:50:56.137+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:56.136+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:56.325+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:56.370+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:50:56.519+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:56.519+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:50:56.541+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:56.540+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:50:56.594+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:56.594+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:50:56.311428+00:00, run_after=2022-10-22T23:50:56.311428+00:00
[2022-10-21T23:50:56.670+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:50:56.669+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:50:56.361528+00:00, run_after=2022-10-22T23:50:56.361528+00:00
[2022-10-21T23:50:56.695+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.590 seconds
[2022-10-21T23:50:56.712+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.890 seconds
[2022-10-21T23:51:32.232+0000] {processor.py:156} INFO - Started process (PID=13196) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:51:32.236+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:51:32.239+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:51:32.239+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:51:32.472+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:51:32.653+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:51:32.653+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:51:32.709+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:51:32.709+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:51:32.467363+00:00, run_after=2022-10-22T23:51:32.467363+00:00
[2022-10-21T23:51:32.760+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.546 seconds
[2022-10-21T23:51:35.074+0000] {processor.py:156} INFO - Started process (PID=14907) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:51:35.076+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:51:35.078+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:51:35.078+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:51:35.234+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:51:35.280+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:51:35.279+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:51:35.388+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:51:35.387+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:51:35.225697+00:00, run_after=2022-10-22T23:51:35.225697+00:00
[2022-10-21T23:51:35.456+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.391 seconds
[2022-10-21T23:52:09.156+0000] {processor.py:156} INFO - Started process (PID=13586) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:52:09.160+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:52:09.164+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:52:09.163+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:52:09.445+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:52:09.732+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:52:09.731+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:52:09.792+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:52:09.792+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:52:09.440192+00:00, run_after=2022-10-22T23:52:09.440192+00:00
[2022-10-21T23:52:09.850+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.701 seconds
[2022-10-21T23:52:16.423+0000] {processor.py:156} INFO - Started process (PID=15357) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:52:16.426+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:52:16.435+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:52:16.434+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:52:16.655+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:52:16.700+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:52:16.700+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:52:16.772+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:52:16.772+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:52:16.648901+00:00, run_after=2022-10-22T23:52:16.648901+00:00
[2022-10-21T23:52:16.839+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.426 seconds
[2022-10-21T23:53:26.830+0000] {processor.py:156} INFO - Started process (PID=14010) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:53:26.833+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:53:26.835+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:53:26.835+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:53:26.977+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:53:27.177+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:53:27.176+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:53:27.232+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:53:27.231+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:53:26.966475+00:00, run_after=2022-10-22T23:53:26.966475+00:00
[2022-10-21T23:53:27.273+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.452 seconds
[2022-10-21T23:53:31.420+0000] {processor.py:156} INFO - Started process (PID=15776) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:53:31.424+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:53:31.430+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:53:31.429+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:53:31.785+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:53:31.828+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:53:31.828+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:53:31.932+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:53:31.932+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:53:31.772123+00:00, run_after=2022-10-22T23:53:31.772123+00:00
[2022-10-21T23:53:31.994+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.600 seconds
[2022-10-21T23:54:06.263+0000] {processor.py:156} INFO - Started process (PID=14406) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:54:06.266+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:54:06.270+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:54:06.270+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:54:06.447+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:54:06.666+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:54:06.666+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:54:06.720+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:54:06.719+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:54:06.441594+00:00, run_after=2022-10-22T23:54:06.441594+00:00
[2022-10-21T23:54:06.798+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.545 seconds
[2022-10-21T23:54:16.647+0000] {processor.py:156} INFO - Started process (PID=16279) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:54:16.651+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:54:16.656+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:54:16.654+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:54:16.828+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:54:16.854+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:54:16.854+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:54:16.976+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:54:16.976+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:54:16.822164+00:00, run_after=2022-10-22T23:54:16.822164+00:00
[2022-10-21T23:54:17.033+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.395 seconds
[2022-10-21T23:55:03.081+0000] {processor.py:156} INFO - Started process (PID=14846) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:03.086+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:55:03.090+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:03.090+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:03.301+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:03.787+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:03.786+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:55:03.977+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:03.976+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:55:03.292911+00:00, run_after=2022-10-22T23:55:03.292911+00:00
[2022-10-21T23:55:04.125+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.064 seconds
[2022-10-21T23:55:39.827+0000] {processor.py:156} INFO - Started process (PID=16925) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:39.840+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:55:39.846+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:39.845+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:40.391+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:41.795+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:41.795+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:55:42.191+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:42.191+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:55:40.370231+00:00, run_after=2022-10-22T23:55:40.370231+00:00
[2022-10-21T23:55:42.532+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 2.765 seconds
[2022-10-21T23:55:56.064+0000] {processor.py:156} INFO - Started process (PID=15173) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:56.070+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:55:56.077+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:56.076+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:56.405+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:55:56.478+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:56.477+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:55:56.584+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:55:56.584+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:55:56.390726+00:00, run_after=2022-10-22T23:55:56.390726+00:00
[2022-10-21T23:55:56.633+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.577 seconds
[2022-10-21T23:56:42.405+0000] {processor.py:156} INFO - Started process (PID=15506) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:56:42.412+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:56:42.414+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:56:42.414+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:56:42.878+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:56:43.168+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:56:43.167+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:56:43.261+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:56:43.261+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:56:42.863762+00:00, run_after=2022-10-22T23:56:42.863762+00:00
[2022-10-21T23:56:43.413+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 1.019 seconds
[2022-10-21T23:56:49.657+0000] {processor.py:156} INFO - Started process (PID=17493) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:56:49.661+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:56:49.664+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:56:49.664+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:56:50.122+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:56:50.188+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:56:50.187+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:56:50.384+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:56:50.384+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:56:50.109151+00:00, run_after=2022-10-22T23:56:50.109151+00:00
[2022-10-21T23:56:50.478+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.828 seconds
[2022-10-21T23:57:18.845+0000] {processor.py:156} INFO - Started process (PID=15790) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:57:18.848+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:57:18.851+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:57:18.850+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:57:19.021+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:57:19.225+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:57:19.224+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:57:19.285+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:57:19.284+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:57:19.014716+00:00, run_after=2022-10-22T23:57:19.014716+00:00
[2022-10-21T23:57:19.327+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.491 seconds
[2022-10-21T23:57:34.090+0000] {processor.py:156} INFO - Started process (PID=17976) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:57:34.093+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:57:34.095+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:57:34.095+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:57:34.279+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:57:34.324+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:57:34.324+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:57:34.388+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:57:34.388+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:57:34.273194+00:00, run_after=2022-10-22T23:57:34.273194+00:00
[2022-10-21T23:57:34.432+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.351 seconds
[2022-10-21T23:58:27.684+0000] {processor.py:156} INFO - Started process (PID=16072) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:58:27.699+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:58:27.702+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:58:27.702+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:58:27.877+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:58:28.053+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:58:28.053+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:58:28.108+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:58:28.108+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:58:27.871789+00:00, run_after=2022-10-22T23:58:27.871789+00:00
[2022-10-21T23:58:28.160+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.484 seconds
[2022-10-21T23:58:39.556+0000] {processor.py:156} INFO - Started process (PID=18238) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:58:39.561+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:58:39.563+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:58:39.563+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:58:39.776+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:58:39.840+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:58:39.840+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:58:39.955+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:58:39.954+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:58:39.766667+00:00, run_after=2022-10-22T23:58:39.766667+00:00
[2022-10-21T23:58:40.036+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.489 seconds
[2022-10-21T23:59:30.628+0000] {processor.py:156} INFO - Started process (PID=16524) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:59:30.634+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:59:30.636+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:59:30.636+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:59:30.880+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:59:31.193+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:59:31.193+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:59:31.292+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:59:31.292+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:59:30.866441+00:00, run_after=2022-10-22T23:59:30.866441+00:00
[2022-10-21T23:59:31.368+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.757 seconds
[2022-10-21T23:59:50.649+0000] {processor.py:156} INFO - Started process (PID=18801) to work on /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:59:50.661+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/pyspark_jobs.py for tasks to queue
[2022-10-21T23:59:50.668+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:59:50.668+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:59:51.008+0000] {processor.py:768} INFO - DAG(s) dict_keys(['pyspark_jobs']) retrieved from /opt/airflow/dags/pyspark_jobs.py
[2022-10-21T23:59:51.105+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:59:51.105+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-10-21T23:59:51.210+0000] {logging_mixin.py:117} INFO - [2022-10-21T23:59:51.210+0000] {dag.py:3328} INFO - Setting next_dagrun for pyspark_jobs to 2022-10-21T23:59:50.998551+00:00, run_after=2022-10-22T23:59:50.998551+00:00
[2022-10-21T23:59:51.300+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/pyspark_jobs.py took 0.660 seconds
