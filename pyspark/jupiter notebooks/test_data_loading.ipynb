{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import functions as sqlf \n",
    "#col, lit, udf,sum,avg,max,min,mean,count, udf \n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/30 22:05:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Stage - Ingest').getOrCreate()\n",
    "conf = SparkConf().setAppName('Stage - Ingest')\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import pendulum\n",
    "from datetime import datetime\n",
    "\n",
    "def get_jsonl_folders(path: str) -> list:\n",
    "    \"\"\"\n",
    "    Function that searchs for sub-directories inside a directory \n",
    "    then returns a list of all the directories names.\n",
    "    \"\"\"\n",
    "    subdirectories = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "    subdirectories = [x.split('/')[7] for x in subdirectories]\n",
    "    return [datetime.strptime(directory, '%Y-%m-%d').date() for directory in subdirectories]\n",
    "    \n",
    "\n",
    "def get_latest_folder(folders: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns the latest date from the list.\n",
    "    \"\"\"\n",
    "    return str(max(folders))\n",
    "\n",
    "\n",
    "def loadJsonData(json_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains jsonlines files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_jsonl_folders(json_path))\n",
    "    if os.path.exists(os.path.dirname(os.path.join(json_path, latest))):\n",
    "        df = spark.read.json(os.path.join(json_path, latest))\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to jsonl files doesn\\'t exist')\n",
    "\n",
    "\n",
    "def loadParquetData(parquet_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains parquet files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_jsonl_folders(parquet_path))\n",
    "    if os.path.exists(os.path.dirname(parquet_path)):\n",
    "        df = spark.read.option('recursiveFileLookup', 'true').option('header', 'true').parquet(parquet_path)\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to parquet file deosn\\'t exist')\n",
    "\n",
    "\n",
    "def loadCSVData(csv_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains csv files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_jsonl_folders(csv_path))\n",
    "    if os.path.exists(os.path.dirname(csv_path)):\n",
    "        df = spark.read.option('recursiveFileLookup', 'true').option('header', 'true').csv(csv_path)\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to csv file doesn\\'t exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+---+-------------------+----+\n",
      "| amount|customer_first_name|customer_last_name| id|                 ts|type|\n",
      "+-------+-------------------+------------------+---+-------------------+----+\n",
      "|$293.92|             Isabel|               Kim| 10|2022-09-29T16:15:36|   0|\n",
      "+-------+-------------------+------------------+---+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingesting jsonlines data\n",
    "df = loadJsonData(json_path='/Users/gonzo/Desktop/capstone_project/data_storage/json_storage/')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+----------+-------------------+--------+\n",
      "| Id|First_name|Last_name|    Amount|          timestamp|Store_id|\n",
      "+---+----------+---------+----------+-------------------+--------+\n",
      "|408|     Julia|   Garcia|     $5.78|2022-09-29T05:10:10|      14|\n",
      "| 45|   Jeffrey|    Wells| $5,706.18|2022-09-28T01:16:37|      15|\n",
      "|788|   Richard|   Larsen|    $19.08|2022-09-28T12:26:47|      14|\n",
      "|719|    Daniel|   Taylor|   $762.91|2022-09-29T10:51:51|       9|\n",
      "|249|     James|    Smith|$26,894.90|2022-09-28T00:14:01|       5|\n",
      "|466|   Deborah|     Wade|    $79.90|2022-09-28T21:14:59|       4|\n",
      "|793|   William|    Smith|$27,596.28|2022-09-28T11:45:09|       7|\n",
      "| 29|   Richard|     Ford|$48,422.07|2022-09-30T18:54:09|       7|\n",
      "|824|     Tonya|   Farmer|     $0.60|2022-09-30T16:20:15|       5|\n",
      "|151|   Michael|   Obrien|    $56.83|2022-09-27T23:12:57|       7|\n",
      "|729| Elizabeth|    Scott|    $97.40|2022-09-29T13:30:30|      10|\n",
      "|650|     Jason|     Ward|     $3.36|2022-09-28T02:55:47|      17|\n",
      "|253|   Raymond|   Peters| $8,940.49|2022-09-28T00:17:37|       6|\n",
      "|247|    Joshua|   Butler|    $97.75|2022-09-28T14:40:41|       2|\n",
      "|278|    Carrie|     Ross| $9,395.55|2022-09-29T20:52:36|      19|\n",
      "| 88|    Jordan|    Jones|$73,829.56|2022-09-30T08:56:52|      19|\n",
      "|417|      Drew|   Garcia| $4,910.47|2022-09-28T03:45:14|       4|\n",
      "| 41|       Amy|     Ross| $7,843.86|2022-09-30T17:20:49|      19|\n",
      "|843|   Anthony|     Berg|$73,915.56|2022-09-27T23:55:11|       9|\n",
      "|856|      Mrs.|   Travis| $9,052.71|2022-09-30T07:54:13|       4|\n",
      "+---+----------+---------+----------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Ingesting parquet data\n",
    "df2 = loadParquetData(parquet_path='/Users/gonzo/Desktop/capstone_project/data_storage/parquet_storage/')\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+-------------------+\n",
      "| id|first_name|last_name|phone_number|            address|\n",
      "+---+----------+---------+------------+-------------------+\n",
      "|101|   Matthew|    Brown|  5269187503|       East Russell|\n",
      "|102|   Anthony|    Patel|  0565170581|    New Angelaville|\n",
      "|103|    Hannah|Fernandez|  6556807051|         Port James|\n",
      "|104| Alejandra|    Flynn|  9902275041|         Moraleston|\n",
      "|105|      Sean|   Lester|  8516957937|     North Courtney|\n",
      "|106|   Maxwell|    Lewis|  7881815482|         West Kelly|\n",
      "|107|   Kaitlin|   Warren|  6668531685|      North Kaitlyn|\n",
      "|108|    Leslie| Ferguson|  9427440597|     Frederickmouth|\n",
      "|109|  Samantha|     Mann|  8748732685|        Matthewside|\n",
      "|110|    Joseph|   Morgan|  7850146994|           Adamside|\n",
      "|111|     Scott| Trujillo|  2281479263|   West Samuelmouth|\n",
      "|112|     James|  Simpson|  5820604215|          Brownstad|\n",
      "|113|  Michelle|   Rogers|  2928540921|    Port Josephbury|\n",
      "|114|   William|   Meyers|  1688619356|         Obrienstad|\n",
      "|115|     Keith|    Woods|  7651596202|        Pittmanfurt|\n",
      "|116|  Courtney|Schneider|  5662984031|         Port Dylan|\n",
      "|117|   Jessica|   Garcia|  7025726504|      East Dalestad|\n",
      "|118|     James|   Torres|  4718654883|South Benjaminville|\n",
      "|119| Christine|   Holmes|  0547980444|        North David|\n",
      "|120|    Nathan|    Brown|  7018443628|          West Troy|\n",
      "+---+----------+---------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingesting RDBMS (PostgreSQL) data\n",
    "df3 = loadCSVData(csv_path='/Users/gonzo/Desktop/capstone_project/data_storage/csv_storage')\n",
    "df3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('CapstoneENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "874b0dd84e8b98467c3d8042fd47d9e77e6c7558a12d29c4392edcac270f293e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
