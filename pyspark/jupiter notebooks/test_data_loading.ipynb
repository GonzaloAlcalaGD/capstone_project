{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import functions as sqlf \n",
    "#col, lit, udf,sum,avg,max,min,mean,count, udf \n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/30 22:05:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Stage - Ingest').getOrCreate()\n",
    "conf = SparkConf().setAppName('Stage - Ingest')\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import pendulum\n",
    "from datetime import datetime\n",
    "\n",
    "def get_subdirectories(path: str) -> list:\n",
    "    \"\"\"\n",
    "    Function that searchs for sub-directories inside a directory \n",
    "    then returns a list of all the directories names.\n",
    "    \"\"\"\n",
    "    if path.split('/')[7] in ['customer', 'transaction']:\n",
    "        subdirectories = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "        subdirectories = [x.split('/')[8] for x in subdirectories]\n",
    "        csv_directories = [directory.split('_')[1] for directory in subdirectories]\n",
    "        return csv_directories\n",
    "    else:\n",
    "        subdirectories = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "        subdirectories = [x.split('/')[7] for x in subdirectories]\n",
    "        return [datetime.strptime(directory, '%Y-%m-%d').date() for directory in subdirectories] \n",
    "        \n",
    "\n",
    "def get_latest_folder(folders: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns the latest date from the list.\n",
    "    \"\"\"\n",
    "    return str(max(folders))\n",
    "\n",
    "\n",
    "def loadJsonData(json_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains jsonlines files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_subdirectories(json_path))\n",
    "    if os.path.exists(os.path.dirname(os.path.join(json_path, latest))):\n",
    "        df = spark.read.json(os.path.join(json_path, latest))\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to jsonl files doesn\\'t exist')\n",
    "\n",
    "\n",
    "def loadParquetData(parquet_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains parquet files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_subdirectories(parquet_path))\n",
    "    if os.path.exists(os.path.dirname(parquet_path)):\n",
    "        df = spark.read.option('recursiveFileLookup', 'true').option('header', 'true').parquet(parquet_path)\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to parquet file deosn\\'t exist')\n",
    "\n",
    "\n",
    "def loadCSVData(csv_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains csv files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_subdirectories(csv_path))\n",
    "    if os.path.exists(os.path.dirname(csv_path)):\n",
    "        df = spark.read.option('recursiveFileLookup', 'true').option('header', 'true').csv(csv_path)\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to csv file doesn\\'t exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+------------------+----------+----+\n",
      "| id|                 ts|customer_first_name|customer_last_name|    amount|type|\n",
      "+---+-------------------+-------------------+------------------+----------+----+\n",
      "|237|2022-09-30T21:58:34|             Thomas|            Booker|    $12.67|   1|\n",
      "|501|2022-09-30T20:29:21|              Karen|            Vaughn|     $2.85|   0|\n",
      "|886|2022-10-02T06:15:44|             Donald|             Mason|     $0.76|   0|\n",
      "|215|2022-10-01T18:21:19|            Jessica|           Hammond|$99,832.19|   0|\n",
      "|715|2022-09-30T13:42:05|              Brent|           Walters|$84,840.26|   0|\n",
      "|149|2022-10-01T08:08:07|            Stephen|           Daniels|   $895.46|   1|\n",
      "|411|2022-10-02T00:40:34|               Jeff|            Murphy|    $66.89|   1|\n",
      "|618|2022-10-01T18:39:25|              Wyatt|            Glover|$61,080.48|   1|\n",
      "|401|2022-10-01T03:00:26|            Anthony|            Murray|$77,473.81|   0|\n",
      "|692|2022-10-01T01:24:53|              David|            Ramsey| $7,889.06|   1|\n",
      "|133|2022-10-03T06:11:36|               John|          Gonzalez|   $104.70|   1|\n",
      "|424|2022-10-03T05:49:44|            Whitney|        Richardson|$74,559.47|   1|\n",
      "|394|2022-10-03T03:15:37|           Theodore|            Nguyen|     $7.14|   0|\n",
      "|600|2022-10-01T00:22:49|            Matthew|            Garcia|   $511.17|   1|\n",
      "|349|2022-10-01T08:31:51|             Leslie|           Sanchez|    $78.75|   1|\n",
      "|637|2022-10-02T23:45:57|              Keith|            Thomas|    $73.01|   1|\n",
      "|770|2022-10-02T08:48:26|           Samantha|            Robles|     $7.31|   0|\n",
      "|  9|2022-10-01T08:10:29|          Stephanie|              Vega|   $561.87|   1|\n",
      "|550|2022-10-01T05:12:14|              Tyler|           Walters|    $59.97|   1|\n",
      "| 93|2022-10-02T04:28:58|               Beth|              Leon|$64,421.67|   1|\n",
      "+---+-------------------+-------------------+------------------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingesting jsonlines data\n",
    "df = loadJsonData(json_path='/Users/gonzo/Desktop/capstone_project/data_storage/json_storage/')\n",
    "df = df.select('id', 'ts', 'customer_first_name', 'customer_last_name', 'amount', 'type')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+----------+-------------------+--------+\n",
      "| Id|First_name|Last_name|    Amount|          timestamp|Store_id|\n",
      "+---+----------+---------+----------+-------------------+--------+\n",
      "| 82|     Larry|Fernandez|    $42.60|2022-10-01T12:51:42|       3|\n",
      "|817|     Tonya|   Krause|$47,909.91|2022-09-30T18:31:50|      20|\n",
      "|507|  Danielle|   Garcia|$45,244.89|2022-09-30T08:39:06|       7|\n",
      "|620|     Kevin|    Ortiz| $3,677.43|2022-09-29T15:52:24|      17|\n",
      "|818|     Chloe|    Brown|    $51.67|2022-09-29T19:58:04|       8|\n",
      "|849|      Cory|    Price|   $595.48|2022-09-29T16:26:44|      11|\n",
      "|369|     David|    Green|   $454.53|2022-09-29T21:35:23|      10|\n",
      "|764|    Shelby|  Miranda|   $527.20|2022-09-29T14:27:13|       5|\n",
      "|431|      Tina|   Chavez|$58,514.39|2022-09-30T18:19:56|      14|\n",
      "|155|   Natalie|Zimmerman|$91,667.09|2022-10-01T08:03:20|       3|\n",
      "|656|   Kristen| Mcdonald|    $90.58|2022-09-30T03:48:51|       2|\n",
      "|590|   Michael| Hamilton|   $834.01|2022-10-01T07:57:12|       7|\n",
      "|691|    Sylvia| Williams| $7,768.72|2022-10-01T14:19:13|      18|\n",
      "|553|    Donald|  Stanley|    $53.78|2022-09-30T00:47:51|       8|\n",
      "|585|    Joseph| Williams|    $52.94|2022-09-30T21:09:58|      18|\n",
      "|545|      Juan| Thompson| $6,279.82|2022-10-01T18:51:52|       9|\n",
      "|648|    Daniel| Williams|    $73.62|2022-09-30T18:47:19|       1|\n",
      "|812|   Cynthia|     Hunt| $7,010.35|2022-09-30T00:14:57|      20|\n",
      "|300|   Michael|   Butler|     $2.17|2022-09-29T13:55:57|       4|\n",
      "|870|   Jessica|    Jones|    $20.06|2022-09-29T20:19:24|       5|\n",
      "+---+----------+---------+----------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingesting parquet data\n",
    "df2 = loadParquetData(parquet_path='/Users/gonzo/Desktop/capstone_project/data_storage/parquet_storage/')\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---------+------------+-----------------+\n",
      "| id| first_name|last_name|phone_number|          address|\n",
      "+---+-----------+---------+------------+-----------------+\n",
      "| 21|     Alicia|   Glover|  6521283839|         Allenton|\n",
      "|239|   Jennifer|  Herrera|  1300415237|         Allenton|\n",
      "|781|      Jared|    Dixon|  2104822627|New Marthaborough|\n",
      "|886|     Donald|   Wagner|  1620409568|    Port Loriview|\n",
      "| 20|       Ruth|    Fritz|  5322972176|    Michelleburgh|\n",
      "|220|    Gregory|    Hanna|  6268379314|      Melissafurt|\n",
      "|291|     Yvonne|    Miles|  1944254819|     Brownchester|\n",
      "|113|    Vincent|    Green|  1241766638|         Clayview|\n",
      "|319|    Valerie|   Harper|  1601056191|      Veronicaton|\n",
      "|651|    Jeffrey|Hernandez|  5212825535|      Melissafurt|\n",
      "|890|      Jason|  Bentley|  5644645140|         Allenton|\n",
      "|372|      Kevin|    Parks|  0137713202|       Grahamstad|\n",
      "|202|Christopher|  Acevedo|  0821339386|New Marthaborough|\n",
      "|810|      Jason|     Pena|  6767859520|Port Benjaminfurt|\n",
      "|867|       Ryan|     Soto|  2815526823|      Lake Karina|\n",
      "| 17|       Ryan|    Jones|  9649801022|        Hicksview|\n",
      "|456|      Kevin| Reynolds|  4590093339|      Veronicaton|\n",
      "|862|   Michelle|   Bailey|  9029223493|New Marthaborough|\n",
      "|383|Christopher| Ferguson|  7517371841|     Brownchester|\n",
      "|716|     Jeanne|    Smith|  3556842726|        Erikville|\n",
      "+---+-----------+---------+------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingesting RDBMS (PostgreSQL) data\n",
    "df3 = loadCSVData(csv_path='/Users/gonzo/Desktop/capstone_project/data_storage/pgdata/customer/')\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-------------------+----------+\n",
      "| id|customer_id|     transaction_ts|    amount|\n",
      "+---+-----------+-------------------+----------+\n",
      "|329|        834|2022-10-03 07:04:41| $7,946.15|\n",
      "|593|        511|2022-09-30 15:52:16|     $0.14|\n",
      "|399|        106|2022-10-02 16:50:15|     $8.80|\n",
      "|496|         15|2022-10-02 11:56:02|    $94.76|\n",
      "| 17|        865|2022-10-03 06:36:50|   $834.31|\n",
      "|677|        791|2022-10-01 21:54:38| $5,885.03|\n",
      "|127|         53|2022-10-01 05:31:38| $9,117.86|\n",
      "|629|        441|2022-10-02 17:50:04|   $379.96|\n",
      "|142|        386|2022-10-03 04:25:02|     $3.95|\n",
      "|752|        530|2022-10-02 21:02:32|$86,170.73|\n",
      "|117|        123|2022-09-30 16:09:27|    $67.56|\n",
      "|188|        134|2022-10-03 06:58:07|$33,515.66|\n",
      "| 32|        779|2022-10-03 11:51:13|   $657.09|\n",
      "|574|        326|2022-10-03 06:52:25|   $870.84|\n",
      "|122|        313|2022-10-01 12:51:34|    $12.51|\n",
      "|858|        597|2022-10-01 15:30:48|   $214.21|\n",
      "|512|        401|2022-10-02 12:01:20|   $404.07|\n",
      "|732|         70|2022-09-30 13:27:02|$50,338.54|\n",
      "|  6|        240|2022-10-01 16:00:21|    $26.04|\n",
      "|729|        610|2022-10-03 07:15:45|     $7.68|\n",
      "+---+-----------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingesting RDBMS (PostgreSQL) data\n",
    "df4 = loadCSVData(csv_path='/Users/gonzo/Desktop/capstone_project/data_storage/pgdata/transaction/')\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "unified_model = spark.createDataFrame([],\n",
    "                StructType(\n",
    "                    [\n",
    "                     StructField('type', IntegerType(), True),\n",
    "                     StructField('id', IntegerType(), True),\n",
    "                     StructField('store_id', IntegerType(), True),\n",
    "                     StructField('customer_id', IntegerType(), True),\n",
    "                     StructField('customer_firts_name', StringType(), True),\n",
    "                     StructField('customer_last_name', StringType(), True),\n",
    "                     StructField('phone_number', IntegerType(), True),\n",
    "                     StructField('address', StringType(), True),\n",
    "                     StructField('amount', FloatType(), True),\n",
    "                     StructField('timestamp', StringType(), True)\n",
    "                    ]\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------+-----------+-------------------+------------------+------------+-------+------+---------+\n",
      "|type| id|store_id|customer_id|customer_firts_name|customer_last_name|phone_number|address|amount|timestamp|\n",
      "+----+---+--------+-----------+-------------------+------------------+------------+-------+------+---------+\n",
      "+----+---+--------+-----------+-------------------+------------------+------------+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unified_model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('CapstoneENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "874b0dd84e8b98467c3d8042fd47d9e77e6c7558a12d29c4392edcac270f293e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
