{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import functions as sqlf \n",
    "#col, lit, udf,sum,avg,max,min,mean,count, udf \n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/30 22:05:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Stage - Ingest').getOrCreate()\n",
    "conf = SparkConf().setAppName('Stage - Ingest')\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import pendulum\n",
    "from datetime import datetime\n",
    "\n",
    "def get_subdirectories(path: str) -> list:\n",
    "    \"\"\"\n",
    "    Function that searchs for sub-directories inside a directory \n",
    "    then returns a list of all the directories names.\n",
    "    \"\"\"\n",
    "    if path.split('/')[7] in ['customer', 'transaction']:\n",
    "        subdirectories = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "        subdirectories = [x.split('/')[8] for x in subdirectories]\n",
    "        csv_directories = [directory.split('_')[1] for directory in subdirectories]\n",
    "        return csv_directories\n",
    "    else:\n",
    "        subdirectories = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "        subdirectories = [x.split('/')[7] for x in subdirectories]\n",
    "        return [datetime.strptime(directory, '%Y-%m-%d').date() for directory in subdirectories] \n",
    "\n",
    "\n",
    "\n",
    "def get_latest_folder(folders: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns the latest date from the list.\n",
    "    \"\"\"\n",
    "    return str(max(folders))\n",
    "\n",
    "\n",
    "def loadJsonData(json_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains jsonlines files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_subdirectories(json_path))\n",
    "    if os.path.exists(os.path.dirname(os.path.join(json_path, latest))):\n",
    "        df = spark.read.json(os.path.join(json_path, latest))\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to jsonl files doesn\\'t exist')\n",
    "\n",
    "\n",
    "def loadParquetData(parquet_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains parquet files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_subdirectories(parquet_path))\n",
    "    if os.path.exists(os.path.dirname(parquet_path)):\n",
    "        df = spark.read.option('recursiveFileLookup', 'true').option('header', 'true').parquet(parquet_path)\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to parquet file deosn\\'t exist')\n",
    "\n",
    "\n",
    "def customer_loadCSVData(csv_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function that returns a dataframe from a valid directory that contains csv files.\n",
    "    \"\"\"\n",
    "    latest = get_latest_folder(get_subdirectories(csv_path))\n",
    "    if os.path.exists(os.path.dirname(csv_path)):\n",
    "        df = spark.read.option('recursiveFileLookup', 'true').option('header', 'true').csv(csv_path)\n",
    "        return df\n",
    "    else:\n",
    "        return logging.critical('Path to csv file doesn\\'t exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+---+-------------------+----+\n",
      "| amount|customer_first_name|customer_last_name| id|                 ts|type|\n",
      "+-------+-------------------+------------------+---+-------------------+----+\n",
      "|$293.92|             Isabel|               Kim| 10|2022-09-29T16:15:36|   0|\n",
      "+-------+-------------------+------------------+---+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingesting jsonlines data\n",
    "df = loadJsonData(json_path='/Users/gonzo/Desktop/capstone_project/data_storage/json_storage/')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+----------+-------------------+--------+\n",
      "| Id|First_name|Last_name|    Amount|          timestamp|Store_id|\n",
      "+---+----------+---------+----------+-------------------+--------+\n",
      "|408|     Julia|   Garcia|     $5.78|2022-09-29T05:10:10|      14|\n",
      "| 45|   Jeffrey|    Wells| $5,706.18|2022-09-28T01:16:37|      15|\n",
      "|788|   Richard|   Larsen|    $19.08|2022-09-28T12:26:47|      14|\n",
      "|719|    Daniel|   Taylor|   $762.91|2022-09-29T10:51:51|       9|\n",
      "|249|     James|    Smith|$26,894.90|2022-09-28T00:14:01|       5|\n",
      "|466|   Deborah|     Wade|    $79.90|2022-09-28T21:14:59|       4|\n",
      "|793|   William|    Smith|$27,596.28|2022-09-28T11:45:09|       7|\n",
      "| 29|   Richard|     Ford|$48,422.07|2022-09-30T18:54:09|       7|\n",
      "|824|     Tonya|   Farmer|     $0.60|2022-09-30T16:20:15|       5|\n",
      "|151|   Michael|   Obrien|    $56.83|2022-09-27T23:12:57|       7|\n",
      "|729| Elizabeth|    Scott|    $97.40|2022-09-29T13:30:30|      10|\n",
      "|650|     Jason|     Ward|     $3.36|2022-09-28T02:55:47|      17|\n",
      "|253|   Raymond|   Peters| $8,940.49|2022-09-28T00:17:37|       6|\n",
      "|247|    Joshua|   Butler|    $97.75|2022-09-28T14:40:41|       2|\n",
      "|278|    Carrie|     Ross| $9,395.55|2022-09-29T20:52:36|      19|\n",
      "| 88|    Jordan|    Jones|$73,829.56|2022-09-30T08:56:52|      19|\n",
      "|417|      Drew|   Garcia| $4,910.47|2022-09-28T03:45:14|       4|\n",
      "| 41|       Amy|     Ross| $7,843.86|2022-09-30T17:20:49|      19|\n",
      "|843|   Anthony|     Berg|$73,915.56|2022-09-27T23:55:11|       9|\n",
      "|856|      Mrs.|   Travis| $9,052.71|2022-09-30T07:54:13|       4|\n",
      "+---+----------+---------+----------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Ingesting parquet data\n",
    "df2 = loadParquetData(parquet_path='/Users/gonzo/Desktop/capstone_project/data_storage/parquet_storage/')\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04\n",
      "+---+-----------+---------+------------+-----------------+\n",
      "| id| first_name|last_name|phone_number|          address|\n",
      "+---+-----------+---------+------------+-----------------+\n",
      "| 21|     Alicia|   Glover|  6521283839|         Allenton|\n",
      "|239|   Jennifer|  Herrera|  1300415237|         Allenton|\n",
      "|781|      Jared|    Dixon|  2104822627|New Marthaborough|\n",
      "|886|     Donald|   Wagner|  1620409568|    Port Loriview|\n",
      "| 20|       Ruth|    Fritz|  5322972176|    Michelleburgh|\n",
      "|220|    Gregory|    Hanna|  6268379314|      Melissafurt|\n",
      "|291|     Yvonne|    Miles|  1944254819|     Brownchester|\n",
      "|113|    Vincent|    Green|  1241766638|         Clayview|\n",
      "|319|    Valerie|   Harper|  1601056191|      Veronicaton|\n",
      "|651|    Jeffrey|Hernandez|  5212825535|      Melissafurt|\n",
      "|890|      Jason|  Bentley|  5644645140|         Allenton|\n",
      "|372|      Kevin|    Parks|  0137713202|       Grahamstad|\n",
      "|202|Christopher|  Acevedo|  0821339386|New Marthaborough|\n",
      "|810|      Jason|     Pena|  6767859520|Port Benjaminfurt|\n",
      "|867|       Ryan|     Soto|  2815526823|      Lake Karina|\n",
      "| 17|       Ryan|    Jones|  9649801022|        Hicksview|\n",
      "|456|      Kevin| Reynolds|  4590093339|      Veronicaton|\n",
      "|862|   Michelle|   Bailey|  9029223493|New Marthaborough|\n",
      "|383|Christopher| Ferguson|  7517371841|     Brownchester|\n",
      "|716|     Jeanne|    Smith|  3556842726|        Erikville|\n",
      "+---+-----------+---------+------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingesting RDBMS (PostgreSQL) data\n",
    "df3 = customer_loadCSVData(csv_path='/Users/gonzo/Desktop/capstone_project/data_storage/pgdata/customer/')\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('CapstoneENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "874b0dd84e8b98467c3d8042fd47d9e77e6c7558a12d29c4392edcac270f293e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
